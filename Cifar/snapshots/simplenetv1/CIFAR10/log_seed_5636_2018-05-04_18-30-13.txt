save path : ./snapshots/simplenet
{'arch': 'simplenet', 'batch_size': 100, 'data_path': './data/cifar.python', 'dataset': 'cifar10', 'decay': 0.002, 'epochs': 540, 'evaluate': False, 'gammas': [0.1, 0.1, 0.1, 0.1, 0.1], 'learning_rate': 0.1, 'manualSeed': 5636, 'momentum': 0.9, 'ngpu': 1, 'print_freq': 200, 'resume': '', 'save_path': './snapshots/simplenet', 'schedule': [100, 190, 306, 390, 440, 540], 'start_epoch': 0, 'use_cuda': True, 'workers': 2}
Random Seed: 5636
python version : 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)  [GCC 7.2.0]
torch  version : 0.3.1
cudnn  version : 7005
=> creating model 'simplenet'
=> network :
 simplenet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (5): ReLU(inplace)
    (6): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (8): ReLU(inplace)
    (9): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (13): Dropout2d(p=0.1)
    (14): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (16): ReLU(inplace)
    (17): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (19): ReLU(inplace)
    (20): Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (22): ReLU(inplace)
    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (24): Dropout2d(p=0.1)
    (25): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (26): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (27): ReLU(inplace)
    (28): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (29): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (30): ReLU(inplace)
    (31): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (32): Dropout2d(p=0.1)
    (33): Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.05, affine=True)
    (35): ReLU(inplace)
    (36): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (37): Dropout2d(p=0.1)
    (38): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1))
    (39): BatchNorm2d(2048, eps=1e-05, momentum=0.05, affine=True)
    (40): ReLU(inplace)
    (41): Conv2d(2048, 256, kernel_size=[1, 1], stride=(1, 1))
    (42): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (43): ReLU(inplace)
    (44): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (45): Dropout2d(p=0.1)
    (46): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (47): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (48): ReLU(inplace)
  )
  (classifier): Linear(in_features=256, out_features=10, bias=True)
)
=> Seed '5636'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> optimizer '{'optimizer': {'state': {}, 'param_groups': [{'lr': 0.1, 'rho': 0.9, 'eps': 0.001, 'weight_decay': 0.001, 'params': [140224309146472, 140224309146632, 140224160068536, 140224160068616, 140224160068696, 140224160068776, 140224160068856, 140224160068936, 140224160069016, 140224160069096, 140224160069176, 140224160069256, 140224160069336, 140224160069416, 140224160069496, 140224160069576, 140224160069736, 140224160069816, 140224160069896, 140224160069976, 140224160070056, 140224160070136, 140224160070216, 140224160070296, 140224160070376, 140224160070456, 140224160070536, 140224160070696, 140224160070856, 140224160070936, 140224160071016, 140224160071096, 140224160071176, 140224160071256, 140224160071336, 140224160071416, 140224160071576, 140224261453368, 140224261453448, 140224261453528, 140224261453688, 140224261453768, 140224261453848, 140224261453928, 140224261454008, 140224261454088, 140224261454168, 140224261454248, 140224261454408, 140224261454488, 140224261454568, 140224261454648, 140224261454888, 140224261454968]}]}}'
=> did not use any checkpoint for simplenet model

==>>[2018-05-04 14:00:19] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.100000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 5.641 (5.641)   Data 0.093 (0.093)   Loss 2.3258 (2.3258)   Prec@1 5.000 (5.000)   Prec@5 48.000 (48.000)   [2018-05-04 14:00:24]
  Epoch: [000][200/500]   Time 0.055 (0.082)   Data 0.000 (0.001)   Loss 1.4820 (1.7454)   Prec@1 48.000 (34.662)   Prec@5 93.000 (86.139)   [2018-05-04 14:00:35]
  Epoch: [000][400/500]   Time 0.057 (0.069)   Data 0.000 (0.000)   Loss 1.4134 (1.5802)   Prec@1 42.000 (41.481)   Prec@5 97.000 (89.426)   [2018-05-04 14:00:46]
  **Train** Prec@1 44.156 Prec@5 90.418 Error@1 55.844
  **Test** Prec@1 58.680 Prec@5 96.010 Error@1 41.320

==>>[2018-05-04 14:00:54] [Epoch=001/540] [Need: 05:13:28] [learning_rate=0.100000] [Best : Accuracy=58.68, Error=41.32]
  Epoch: [001][000/500]   Time 0.068 (0.068)   Data 0.043 (0.043)   Loss 1.2501 (1.2501)   Prec@1 55.000 (55.000)   Prec@5 97.000 (97.000)   [2018-05-04 14:00:54]
  Epoch: [001][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 1.0708 (1.1241)   Prec@1 59.000 (59.602)   Prec@5 97.000 (95.682)   [2018-05-04 14:01:05]
  Epoch: [001][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8357 (1.0614)   Prec@1 72.000 (62.117)   Prec@5 99.000 (96.192)   [2018-05-04 14:01:16]
  **Train** Prec@1 63.046 Prec@5 96.344 Error@1 36.954
  **Test** Prec@1 62.220 Prec@5 95.880 Error@1 37.780

==>>[2018-05-04 14:01:24] [Epoch=002/540] [Need: 04:52:46] [learning_rate=0.100000] [Best : Accuracy=62.22, Error=37.78]
  Epoch: [002][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 1.0481 (1.0481)   Prec@1 66.000 (66.000)   Prec@5 97.000 (97.000)   [2018-05-04 14:01:25]
  Epoch: [002][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.8344 (0.8925)   Prec@1 73.000 (68.682)   Prec@5 98.000 (97.333)   [2018-05-04 14:01:36]
  Epoch: [002][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.8379 (0.8530)   Prec@1 70.000 (70.090)   Prec@5 98.000 (97.594)   [2018-05-04 14:01:47]
  **Train** Prec@1 70.502 Prec@5 97.648 Error@1 29.498
  **Test** Prec@1 69.040 Prec@5 97.400 Error@1 30.960

==>>[2018-05-04 14:01:55] [Epoch=003/540] [Need: 04:46:29] [learning_rate=0.100000] [Best : Accuracy=69.04, Error=30.96]
  Epoch: [003][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.6981 (0.6981)   Prec@1 72.000 (72.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:01:55]
  Epoch: [003][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.7556 (0.7525)   Prec@1 73.000 (74.204)   Prec@5 98.000 (98.124)   [2018-05-04 14:02:06]
  Epoch: [003][400/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.6666 (0.7390)   Prec@1 77.000 (74.616)   Prec@5 99.000 (98.257)   [2018-05-04 14:02:18]
  **Train** Prec@1 74.988 Prec@5 98.266 Error@1 25.012
  **Test** Prec@1 74.610 Prec@5 98.150 Error@1 25.390

==>>[2018-05-04 14:02:26] [Epoch=004/540] [Need: 04:43:19] [learning_rate=0.100000] [Best : Accuracy=74.61, Error=25.39]
  Epoch: [004][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.8794 (0.8794)   Prec@1 69.000 (69.000)   Prec@5 97.000 (97.000)   [2018-05-04 14:02:26]
  Epoch: [004][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.6406 (0.6654)   Prec@1 78.000 (76.995)   Prec@5 98.000 (98.537)   [2018-05-04 14:02:37]
  Epoch: [004][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.5568 (0.6568)   Prec@1 82.000 (77.521)   Prec@5 99.000 (98.479)   [2018-05-04 14:02:49]
  **Train** Prec@1 77.676 Prec@5 98.542 Error@1 22.324
  **Test** Prec@1 79.260 Prec@5 98.440 Error@1 20.740

==>>[2018-05-04 14:02:57] [Epoch=005/540] [Need: 04:41:12] [learning_rate=0.100000] [Best : Accuracy=79.26, Error=20.74]
  Epoch: [005][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.5104 (0.5104)   Prec@1 84.000 (84.000)   Prec@5 98.000 (98.000)   [2018-05-04 14:02:57]
  Epoch: [005][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.6787 (0.5901)   Prec@1 76.000 (79.851)   Prec@5 98.000 (98.975)   [2018-05-04 14:03:08]
  Epoch: [005][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.5086 (0.5936)   Prec@1 83.000 (79.703)   Prec@5 100.000 (98.870)   [2018-05-04 14:03:19]
  **Train** Prec@1 79.880 Prec@5 98.864 Error@1 20.120
  **Test** Prec@1 78.500 Prec@5 98.860 Error@1 21.500

==>>[2018-05-04 14:03:28] [Epoch=006/540] [Need: 04:39:56] [learning_rate=0.100000] [Best : Accuracy=79.26, Error=20.74]
  Epoch: [006][000/500]   Time 0.077 (0.077)   Data 0.048 (0.048)   Loss 0.5324 (0.5324)   Prec@1 83.000 (83.000)   Prec@5 98.000 (98.000)   [2018-05-04 14:03:28]
  Epoch: [006][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.6976 (0.5422)   Prec@1 71.000 (81.542)   Prec@5 98.000 (98.985)   [2018-05-04 14:03:39]
  Epoch: [006][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.4223 (0.5495)   Prec@1 89.000 (81.272)   Prec@5 99.000 (98.960)   [2018-05-04 14:03:51]
  **Train** Prec@1 81.260 Prec@5 98.980 Error@1 18.740
  **Test** Prec@1 81.860 Prec@5 98.800 Error@1 18.140

==>>[2018-05-04 14:03:59] [Epoch=007/540] [Need: 04:38:48] [learning_rate=0.100000] [Best : Accuracy=81.86, Error=18.14]
  Epoch: [007][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.5084 (0.5084)   Prec@1 84.000 (84.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:03:59]
  Epoch: [007][200/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.4623 (0.5145)   Prec@1 88.000 (82.572)   Prec@5 99.000 (98.935)   [2018-05-04 14:04:10]
  Epoch: [007][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.4870 (0.5155)   Prec@1 83.000 (82.566)   Prec@5 100.000 (98.993)   [2018-05-04 14:04:22]
  **Train** Prec@1 82.652 Prec@5 99.026 Error@1 17.348
  **Test** Prec@1 83.870 Prec@5 99.150 Error@1 16.130

==>>[2018-05-04 14:04:30] [Epoch=008/540] [Need: 04:38:14] [learning_rate=0.100000] [Best : Accuracy=83.87, Error=16.13]
  Epoch: [008][000/500]   Time 0.075 (0.075)   Data 0.047 (0.047)   Loss 0.4717 (0.4717)   Prec@1 84.000 (84.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:04:30]
  Epoch: [008][200/500]   Time 0.063 (0.058)   Data 0.000 (0.000)   Loss 0.3651 (0.4806)   Prec@1 88.000 (83.761)   Prec@5 99.000 (99.154)   [2018-05-04 14:04:42]
  Epoch: [008][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.5947 (0.4829)   Prec@1 75.000 (83.566)   Prec@5 98.000 (99.182)   [2018-05-04 14:04:53]
  **Train** Prec@1 83.572 Prec@5 99.204 Error@1 16.428
  **Test** Prec@1 85.350 Prec@5 99.330 Error@1 14.650

==>>[2018-05-04 14:05:02] [Epoch=009/540] [Need: 04:37:53] [learning_rate=0.100000] [Best : Accuracy=85.35, Error=14.65]
  Epoch: [009][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.3819 (0.3819)   Prec@1 89.000 (89.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:05:02]
  Epoch: [009][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.4272 (0.4555)   Prec@1 84.000 (84.512)   Prec@5 100.000 (99.323)   [2018-05-04 14:05:13]
  Epoch: [009][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.5036 (0.4552)   Prec@1 84.000 (84.596)   Prec@5 100.000 (99.274)   [2018-05-04 14:05:25]
  **Train** Prec@1 84.674 Prec@5 99.286 Error@1 15.326
  **Test** Prec@1 82.100 Prec@5 99.120 Error@1 17.900

==>>[2018-05-04 14:05:33] [Epoch=010/540] [Need: 04:37:01] [learning_rate=0.100000] [Best : Accuracy=85.35, Error=14.65]
  Epoch: [010][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.3819 (0.3819)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:05:33]
  Epoch: [010][200/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.3900 (0.4336)   Prec@1 88.000 (85.517)   Prec@5 100.000 (99.318)   [2018-05-04 14:05:44]
  Epoch: [010][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.4707 (0.4344)   Prec@1 89.000 (85.506)   Prec@5 98.000 (99.322)   [2018-05-04 14:05:55]
  **Train** Prec@1 85.430 Prec@5 99.306 Error@1 14.570
  **Test** Prec@1 81.820 Prec@5 98.700 Error@1 18.180

==>>[2018-05-04 14:06:04] [Epoch=011/540] [Need: 04:36:06] [learning_rate=0.100000] [Best : Accuracy=85.35, Error=14.65]
  Epoch: [011][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.4390 (0.4390)   Prec@1 86.000 (86.000)   Prec@5 97.000 (97.000)   [2018-05-04 14:06:04]
  Epoch: [011][200/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.4532 (0.4155)   Prec@1 81.000 (85.990)   Prec@5 100.000 (99.438)   [2018-05-04 14:06:15]
  Epoch: [011][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3703 (0.4110)   Prec@1 90.000 (86.297)   Prec@5 100.000 (99.384)   [2018-05-04 14:06:26]
  **Train** Prec@1 86.174 Prec@5 99.366 Error@1 13.826
  **Test** Prec@1 84.140 Prec@5 99.240 Error@1 15.860

==>>[2018-05-04 14:06:34] [Epoch=012/540] [Need: 04:34:54] [learning_rate=0.100000] [Best : Accuracy=85.35, Error=14.65]
  Epoch: [012][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.4402 (0.4402)   Prec@1 80.000 (80.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:06:34]
  Epoch: [012][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.4668 (0.3874)   Prec@1 84.000 (86.766)   Prec@5 98.000 (99.428)   [2018-05-04 14:06:46]
  Epoch: [012][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.4051 (0.3929)   Prec@1 84.000 (86.771)   Prec@5 99.000 (99.419)   [2018-05-04 14:06:57]
  **Train** Prec@1 86.752 Prec@5 99.420 Error@1 13.248
  **Test** Prec@1 86.410 Prec@5 99.450 Error@1 13.590

==>>[2018-05-04 14:07:05] [Epoch=013/540] [Need: 04:34:17] [learning_rate=0.100000] [Best : Accuracy=86.41, Error=13.59]
  Epoch: [013][000/500]   Time 0.074 (0.074)   Data 0.045 (0.045)   Loss 0.3436 (0.3436)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:07:05]
  Epoch: [013][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.5557 (0.3739)   Prec@1 79.000 (87.453)   Prec@5 99.000 (99.468)   [2018-05-04 14:07:17]
  Epoch: [013][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.4160 (0.3734)   Prec@1 86.000 (87.349)   Prec@5 98.000 (99.491)   [2018-05-04 14:07:28]
  **Train** Prec@1 87.144 Prec@5 99.490 Error@1 12.856
  **Test** Prec@1 85.030 Prec@5 98.950 Error@1 14.970

==>>[2018-05-04 14:07:36] [Epoch=014/540] [Need: 04:33:31] [learning_rate=0.100000] [Best : Accuracy=86.41, Error=13.59]
  Epoch: [014][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.3022 (0.3022)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:07:36]
  Epoch: [014][200/500]   Time 0.067 (0.057)   Data 0.000 (0.000)   Loss 0.3426 (0.3563)   Prec@1 91.000 (88.129)   Prec@5 98.000 (99.617)   [2018-05-04 14:07:47]
  Epoch: [014][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.3367 (0.3595)   Prec@1 91.000 (88.035)   Prec@5 100.000 (99.579)   [2018-05-04 14:07:59]
  **Train** Prec@1 87.880 Prec@5 99.556 Error@1 12.120
  **Test** Prec@1 84.660 Prec@5 99.180 Error@1 15.340

==>>[2018-05-04 14:08:08] [Epoch=015/540] [Need: 04:33:30] [learning_rate=0.100000] [Best : Accuracy=86.41, Error=13.59]
  Epoch: [015][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.3610 (0.3610)   Prec@1 84.000 (84.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:08:08]
  Epoch: [015][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.4399 (0.3477)   Prec@1 84.000 (88.517)   Prec@5 100.000 (99.537)   [2018-05-04 14:08:19]
  Epoch: [015][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.3210 (0.3507)   Prec@1 88.000 (88.302)   Prec@5 100.000 (99.534)   [2018-05-04 14:08:30]
  **Train** Prec@1 88.218 Prec@5 99.540 Error@1 11.782
  **Test** Prec@1 86.780 Prec@5 99.440 Error@1 13.220

==>>[2018-05-04 14:08:39] [Epoch=016/540] [Need: 04:32:34] [learning_rate=0.100000] [Best : Accuracy=86.78, Error=13.22]
  Epoch: [016][000/500]   Time 0.074 (0.074)   Data 0.046 (0.046)   Loss 0.2585 (0.2585)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:08:39]
  Epoch: [016][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.5382 (0.3309)   Prec@1 84.000 (88.841)   Prec@5 98.000 (99.537)   [2018-05-04 14:08:50]
  Epoch: [016][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3030 (0.3395)   Prec@1 91.000 (88.596)   Prec@5 100.000 (99.526)   [2018-05-04 14:09:01]
  **Train** Prec@1 88.546 Prec@5 99.520 Error@1 11.454
  **Test** Prec@1 87.200 Prec@5 99.440 Error@1 12.800

==>>[2018-05-04 14:09:09] [Epoch=017/540] [Need: 04:31:50] [learning_rate=0.100000] [Best : Accuracy=87.20, Error=12.80]
  Epoch: [017][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.2893 (0.2893)   Prec@1 89.000 (89.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:09:09]
  Epoch: [017][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.4657 (0.3182)   Prec@1 82.000 (89.234)   Prec@5 100.000 (99.592)   [2018-05-04 14:09:21]
  Epoch: [017][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.4695 (0.3284)   Prec@1 87.000 (88.943)   Prec@5 99.000 (99.581)   [2018-05-04 14:09:33]
  **Train** Prec@1 88.928 Prec@5 99.590 Error@1 11.072
  **Test** Prec@1 85.630 Prec@5 99.370 Error@1 14.370

==>>[2018-05-04 14:09:42] [Epoch=018/540] [Need: 04:31:58] [learning_rate=0.100000] [Best : Accuracy=87.20, Error=12.80]
  Epoch: [018][000/500]   Time 0.072 (0.072)   Data 0.047 (0.047)   Loss 0.2661 (0.2661)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:09:42]
  Epoch: [018][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3036 (0.3068)   Prec@1 91.000 (89.706)   Prec@5 100.000 (99.587)   [2018-05-04 14:09:53]
  Epoch: [018][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2596 (0.3159)   Prec@1 90.000 (89.312)   Prec@5 100.000 (99.579)   [2018-05-04 14:10:04]
  **Train** Prec@1 89.374 Prec@5 99.602 Error@1 10.626
  **Test** Prec@1 87.770 Prec@5 99.560 Error@1 12.230

==>>[2018-05-04 14:10:12] [Epoch=019/540] [Need: 04:30:55] [learning_rate=0.100000] [Best : Accuracy=87.77, Error=12.23]
  Epoch: [019][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.3421 (0.3421)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:10:12]
  Epoch: [019][200/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.4853 (0.3033)   Prec@1 82.000 (89.637)   Prec@5 98.000 (99.672)   [2018-05-04 14:10:23]
  Epoch: [019][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.2936 (0.3086)   Prec@1 93.000 (89.531)   Prec@5 100.000 (99.653)   [2018-05-04 14:10:35]
  **Train** Prec@1 89.528 Prec@5 99.650 Error@1 10.472
  **Test** Prec@1 84.320 Prec@5 99.280 Error@1 15.680

==>>[2018-05-04 14:10:43] [Epoch=020/540] [Need: 04:30:18] [learning_rate=0.100000] [Best : Accuracy=87.77, Error=12.23]
  Epoch: [020][000/500]   Time 0.075 (0.075)   Data 0.047 (0.047)   Loss 0.2977 (0.2977)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:10:43]
  Epoch: [020][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3096 (0.3001)   Prec@1 91.000 (90.030)   Prec@5 100.000 (99.662)   [2018-05-04 14:10:54]
  Epoch: [020][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1852 (0.3016)   Prec@1 92.000 (90.025)   Prec@5 100.000 (99.631)   [2018-05-04 14:11:05]
  **Train** Prec@1 89.948 Prec@5 99.628 Error@1 10.052
  **Test** Prec@1 86.090 Prec@5 99.630 Error@1 13.910

==>>[2018-05-04 14:11:13] [Epoch=021/540] [Need: 04:29:28] [learning_rate=0.100000] [Best : Accuracy=87.77, Error=12.23]
  Epoch: [021][000/500]   Time 0.071 (0.071)   Data 0.046 (0.046)   Loss 0.3150 (0.3150)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:11:14]
  Epoch: [021][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2203 (0.2912)   Prec@1 94.000 (90.254)   Prec@5 99.000 (99.697)   [2018-05-04 14:11:24]
  Epoch: [021][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3677 (0.2944)   Prec@1 89.000 (90.122)   Prec@5 100.000 (99.693)   [2018-05-04 14:11:35]
  **Train** Prec@1 90.080 Prec@5 99.688 Error@1 9.920
  **Test** Prec@1 88.580 Prec@5 99.640 Error@1 11.420

==>>[2018-05-04 14:11:44] [Epoch=022/540] [Need: 04:28:33] [learning_rate=0.100000] [Best : Accuracy=88.58, Error=11.42]
  Epoch: [022][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.2605 (0.2605)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:11:44]
  Epoch: [022][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2953 (0.2821)   Prec@1 90.000 (90.517)   Prec@5 100.000 (99.701)   [2018-05-04 14:11:55]
  Epoch: [022][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1425 (0.2893)   Prec@1 96.000 (90.382)   Prec@5 100.000 (99.683)   [2018-05-04 14:12:06]
  **Train** Prec@1 90.330 Prec@5 99.674 Error@1 9.670
  **Test** Prec@1 87.800 Prec@5 99.470 Error@1 12.200

==>>[2018-05-04 14:12:14] [Epoch=023/540] [Need: 04:27:50] [learning_rate=0.100000] [Best : Accuracy=88.58, Error=11.42]
  Epoch: [023][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.3389 (0.3389)   Prec@1 88.000 (88.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:12:14]
  Epoch: [023][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.2328 (0.2755)   Prec@1 96.000 (90.677)   Prec@5 99.000 (99.746)   [2018-05-04 14:12:25]
  Epoch: [023][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.3155 (0.2828)   Prec@1 87.000 (90.424)   Prec@5 100.000 (99.721)   [2018-05-04 14:12:36]
  **Train** Prec@1 90.396 Prec@5 99.716 Error@1 9.604
  **Test** Prec@1 89.290 Prec@5 99.610 Error@1 10.710

==>>[2018-05-04 14:12:45] [Epoch=024/540] [Need: 04:27:09] [learning_rate=0.100000] [Best : Accuracy=89.29, Error=10.71]
  Epoch: [024][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.3245 (0.3245)   Prec@1 90.000 (90.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:12:45]
  Epoch: [024][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2783 (0.2647)   Prec@1 91.000 (91.139)   Prec@5 100.000 (99.721)   [2018-05-04 14:12:56]
  Epoch: [024][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.3401 (0.2770)   Prec@1 86.000 (90.746)   Prec@5 100.000 (99.706)   [2018-05-04 14:13:07]
  **Train** Prec@1 90.696 Prec@5 99.682 Error@1 9.304
  **Test** Prec@1 88.750 Prec@5 99.590 Error@1 11.250

==>>[2018-05-04 14:13:15] [Epoch=025/540] [Need: 04:26:23] [learning_rate=0.100000] [Best : Accuracy=89.29, Error=10.71]
  Epoch: [025][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.3177 (0.3177)   Prec@1 89.000 (89.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:13:15]
  Epoch: [025][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2101 (0.2719)   Prec@1 91.000 (90.940)   Prec@5 100.000 (99.701)   [2018-05-04 14:13:26]
  Epoch: [025][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.2268 (0.2713)   Prec@1 93.000 (90.940)   Prec@5 100.000 (99.703)   [2018-05-04 14:13:38]
  **Train** Prec@1 90.838 Prec@5 99.674 Error@1 9.162
  **Test** Prec@1 88.740 Prec@5 99.680 Error@1 11.260

==>>[2018-05-04 14:13:46] [Epoch=026/540] [Need: 04:25:46] [learning_rate=0.100000] [Best : Accuracy=89.29, Error=10.71]
  Epoch: [026][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.2959 (0.2959)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:13:46]
  Epoch: [026][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3322 (0.2582)   Prec@1 89.000 (91.408)   Prec@5 99.000 (99.731)   [2018-05-04 14:13:57]
  Epoch: [026][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2151 (0.2643)   Prec@1 94.000 (91.117)   Prec@5 100.000 (99.748)   [2018-05-04 14:14:08]
  **Train** Prec@1 91.050 Prec@5 99.746 Error@1 8.950
  **Test** Prec@1 83.490 Prec@5 99.500 Error@1 16.510

==>>[2018-05-04 14:14:16] [Epoch=027/540] [Need: 04:25:01] [learning_rate=0.100000] [Best : Accuracy=89.29, Error=10.71]
  Epoch: [027][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.2947 (0.2947)   Prec@1 93.000 (93.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:14:16]
  Epoch: [027][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.2906 (0.2586)   Prec@1 90.000 (91.154)   Prec@5 100.000 (99.766)   [2018-05-04 14:14:28]
  Epoch: [027][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3824 (0.2577)   Prec@1 86.000 (91.232)   Prec@5 99.000 (99.766)   [2018-05-04 14:14:39]
  **Train** Prec@1 91.140 Prec@5 99.764 Error@1 8.860
  **Test** Prec@1 87.120 Prec@5 99.460 Error@1 12.880

==>>[2018-05-04 14:14:47] [Epoch=028/540] [Need: 04:24:35] [learning_rate=0.100000] [Best : Accuracy=89.29, Error=10.71]
  Epoch: [028][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.1953 (0.1953)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:14:47]
  Epoch: [028][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.3311 (0.2521)   Prec@1 90.000 (91.677)   Prec@5 100.000 (99.756)   [2018-05-04 14:14:59]
  Epoch: [028][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2380 (0.2639)   Prec@1 93.000 (91.264)   Prec@5 100.000 (99.761)   [2018-05-04 14:15:10]
  **Train** Prec@1 91.174 Prec@5 99.752 Error@1 8.826
  **Test** Prec@1 89.440 Prec@5 99.700 Error@1 10.560

==>>[2018-05-04 14:15:18] [Epoch=029/540] [Need: 04:24:00] [learning_rate=0.100000] [Best : Accuracy=89.44, Error=10.56]
  Epoch: [029][000/500]   Time 0.079 (0.079)   Data 0.047 (0.047)   Loss 0.2204 (0.2204)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:15:18]
  Epoch: [029][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.3398 (0.2484)   Prec@1 88.000 (91.721)   Prec@5 100.000 (99.766)   [2018-05-04 14:15:30]
  Epoch: [029][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.3602 (0.2579)   Prec@1 90.000 (91.384)   Prec@5 98.000 (99.758)   [2018-05-04 14:15:41]
  **Train** Prec@1 91.374 Prec@5 99.776 Error@1 8.626
  **Test** Prec@1 87.330 Prec@5 99.570 Error@1 12.670

==>>[2018-05-04 14:15:49] [Epoch=030/540] [Need: 04:23:32] [learning_rate=0.100000] [Best : Accuracy=89.44, Error=10.56]
  Epoch: [030][000/500]   Time 0.074 (0.074)   Data 0.046 (0.046)   Loss 0.1751 (0.1751)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:15:49]
  Epoch: [030][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.2336 (0.2419)   Prec@1 91.000 (91.891)   Prec@5 100.000 (99.756)   [2018-05-04 14:16:01]
  Epoch: [030][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.3175 (0.2481)   Prec@1 88.000 (91.693)   Prec@5 100.000 (99.741)   [2018-05-04 14:16:12]
  **Train** Prec@1 91.692 Prec@5 99.750 Error@1 8.308
  **Test** Prec@1 88.070 Prec@5 99.420 Error@1 11.930

==>>[2018-05-04 14:16:21] [Epoch=031/540] [Need: 04:23:09] [learning_rate=0.100000] [Best : Accuracy=89.44, Error=10.56]
  Epoch: [031][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.1500 (0.1500)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:16:21]
  Epoch: [031][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.3456 (0.2438)   Prec@1 90.000 (91.721)   Prec@5 100.000 (99.801)   [2018-05-04 14:16:32]
  Epoch: [031][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.3739 (0.2430)   Prec@1 89.000 (91.823)   Prec@5 100.000 (99.773)   [2018-05-04 14:16:44]
  **Train** Prec@1 91.640 Prec@5 99.766 Error@1 8.360
  **Test** Prec@1 87.910 Prec@5 99.520 Error@1 12.090

==>>[2018-05-04 14:16:53] [Epoch=032/540] [Need: 04:22:49] [learning_rate=0.100000] [Best : Accuracy=89.44, Error=10.56]
  Epoch: [032][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.2679 (0.2679)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:16:53]
  Epoch: [032][200/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.3203 (0.2330)   Prec@1 90.000 (92.244)   Prec@5 98.000 (99.771)   [2018-05-04 14:17:04]
  Epoch: [032][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3609 (0.2419)   Prec@1 89.000 (91.970)   Prec@5 100.000 (99.736)   [2018-05-04 14:17:15]
  **Train** Prec@1 91.976 Prec@5 99.740 Error@1 8.024
  **Test** Prec@1 89.240 Prec@5 99.530 Error@1 10.760

==>>[2018-05-04 14:17:23] [Epoch=033/540] [Need: 04:22:10] [learning_rate=0.100000] [Best : Accuracy=89.44, Error=10.56]
  Epoch: [033][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.1615 (0.1615)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:17:23]
  Epoch: [033][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2674 (0.2292)   Prec@1 92.000 (92.318)   Prec@5 99.000 (99.776)   [2018-05-04 14:17:34]
  Epoch: [033][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1549 (0.2363)   Prec@1 95.000 (92.035)   Prec@5 100.000 (99.798)   [2018-05-04 14:17:45]
  **Train** Prec@1 91.938 Prec@5 99.796 Error@1 8.062
  **Test** Prec@1 87.730 Prec@5 99.620 Error@1 12.270

==>>[2018-05-04 14:17:54] [Epoch=034/540] [Need: 04:21:35] [learning_rate=0.100000] [Best : Accuracy=89.44, Error=10.56]
  Epoch: [034][000/500]   Time 0.073 (0.073)   Data 0.048 (0.048)   Loss 0.2484 (0.2484)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:17:54]
  Epoch: [034][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1273 (0.2289)   Prec@1 97.000 (92.229)   Prec@5 100.000 (99.781)   [2018-05-04 14:18:05]
  Epoch: [034][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2774 (0.2423)   Prec@1 92.000 (91.888)   Prec@5 99.000 (99.771)   [2018-05-04 14:18:16]
  **Train** Prec@1 91.872 Prec@5 99.762 Error@1 8.128
  **Test** Prec@1 89.660 Prec@5 99.630 Error@1 10.340

==>>[2018-05-04 14:18:24] [Epoch=035/540] [Need: 04:20:53] [learning_rate=0.100000] [Best : Accuracy=89.66, Error=10.34]
  Epoch: [035][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.1962 (0.1962)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:18:24]
  Epoch: [035][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2839 (0.2322)   Prec@1 90.000 (92.418)   Prec@5 100.000 (99.781)   [2018-05-04 14:18:35]
  Epoch: [035][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2196 (0.2340)   Prec@1 92.000 (92.175)   Prec@5 100.000 (99.771)   [2018-05-04 14:18:46]
  **Train** Prec@1 92.068 Prec@5 99.760 Error@1 7.932
  **Test** Prec@1 88.400 Prec@5 99.430 Error@1 11.600

==>>[2018-05-04 14:18:54] [Epoch=036/540] [Need: 04:20:07] [learning_rate=0.100000] [Best : Accuracy=89.66, Error=10.34]
  Epoch: [036][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.1790 (0.1790)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:18:54]
  Epoch: [036][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2453 (0.2259)   Prec@1 88.000 (92.284)   Prec@5 100.000 (99.796)   [2018-05-04 14:19:05]
  Epoch: [036][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2148 (0.2289)   Prec@1 92.000 (92.304)   Prec@5 100.000 (99.788)   [2018-05-04 14:19:16]
  **Train** Prec@1 92.264 Prec@5 99.794 Error@1 7.736
  **Test** Prec@1 89.020 Prec@5 99.630 Error@1 10.980

==>>[2018-05-04 14:19:24] [Epoch=037/540] [Need: 04:19:26] [learning_rate=0.100000] [Best : Accuracy=89.66, Error=10.34]
  Epoch: [037][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.2839 (0.2839)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:19:24]
  Epoch: [037][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2176 (0.2249)   Prec@1 91.000 (92.373)   Prec@5 100.000 (99.806)   [2018-05-04 14:19:36]
  Epoch: [037][400/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.2181 (0.2335)   Prec@1 93.000 (92.055)   Prec@5 100.000 (99.800)   [2018-05-04 14:19:47]
  **Train** Prec@1 91.940 Prec@5 99.782 Error@1 8.060
  **Test** Prec@1 87.860 Prec@5 99.610 Error@1 12.140

==>>[2018-05-04 14:19:55] [Epoch=038/540] [Need: 04:18:55] [learning_rate=0.100000] [Best : Accuracy=89.66, Error=10.34]
  Epoch: [038][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.2144 (0.2144)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:19:55]
  Epoch: [038][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1800 (0.2218)   Prec@1 95.000 (92.547)   Prec@5 99.000 (99.841)   [2018-05-04 14:20:06]
  Epoch: [038][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2100 (0.2282)   Prec@1 93.000 (92.254)   Prec@5 100.000 (99.825)   [2018-05-04 14:20:17]
  **Train** Prec@1 92.246 Prec@5 99.836 Error@1 7.754
  **Test** Prec@1 88.480 Prec@5 99.570 Error@1 11.520

==>>[2018-05-04 14:20:26] [Epoch=039/540] [Need: 04:18:17] [learning_rate=0.100000] [Best : Accuracy=89.66, Error=10.34]
  Epoch: [039][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.2493 (0.2493)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:20:26]
  Epoch: [039][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2851 (0.2247)   Prec@1 90.000 (92.483)   Prec@5 100.000 (99.801)   [2018-05-04 14:20:37]
  Epoch: [039][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.2662 (0.2258)   Prec@1 93.000 (92.337)   Prec@5 99.000 (99.828)   [2018-05-04 14:20:48]
  **Train** Prec@1 92.284 Prec@5 99.820 Error@1 7.716
  **Test** Prec@1 87.850 Prec@5 99.490 Error@1 12.150

==>>[2018-05-04 14:20:56] [Epoch=040/540] [Need: 04:17:37] [learning_rate=0.100000] [Best : Accuracy=89.66, Error=10.34]
  Epoch: [040][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.2083 (0.2083)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:20:56]
  Epoch: [040][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2528 (0.2033)   Prec@1 92.000 (93.313)   Prec@5 100.000 (99.826)   [2018-05-04 14:21:07]
  Epoch: [040][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2565 (0.2191)   Prec@1 89.000 (92.778)   Prec@5 100.000 (99.825)   [2018-05-04 14:21:18]
  **Train** Prec@1 92.636 Prec@5 99.812 Error@1 7.364
  **Test** Prec@1 90.720 Prec@5 99.650 Error@1 9.280

==>>[2018-05-04 14:21:27] [Epoch=041/540] [Need: 04:17:03] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [041][000/500]   Time 0.075 (0.075)   Data 0.047 (0.047)   Loss 0.3477 (0.3477)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:21:27]
  Epoch: [041][200/500]   Time 0.056 (0.066)   Data 0.000 (0.000)   Loss 0.2903 (0.2188)   Prec@1 90.000 (92.781)   Prec@5 100.000 (99.821)   [2018-05-04 14:21:40]
  Epoch: [041][400/500]   Time 0.057 (0.065)   Data 0.000 (0.000)   Loss 0.2509 (0.2220)   Prec@1 94.000 (92.761)   Prec@5 100.000 (99.798)   [2018-05-04 14:21:53]
  **Train** Prec@1 92.686 Prec@5 99.796 Error@1 7.314
  **Test** Prec@1 84.400 Prec@5 99.000 Error@1 15.600

==>>[2018-05-04 14:22:01] [Epoch=042/540] [Need: 04:17:14] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [042][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.2912 (0.2912)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:22:01]
  Epoch: [042][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.3552 (0.2162)   Prec@1 88.000 (92.791)   Prec@5 100.000 (99.821)   [2018-05-04 14:22:12]
  Epoch: [042][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.3671 (0.2215)   Prec@1 86.000 (92.616)   Prec@5 100.000 (99.825)   [2018-05-04 14:22:24]
  **Train** Prec@1 92.558 Prec@5 99.824 Error@1 7.442
  **Test** Prec@1 88.360 Prec@5 99.630 Error@1 11.640

==>>[2018-05-04 14:22:33] [Epoch=043/540] [Need: 04:16:50] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [043][000/500]   Time 0.081 (0.081)   Data 0.050 (0.050)   Loss 0.1617 (0.1617)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:22:33]
  Epoch: [043][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2330 (0.2168)   Prec@1 94.000 (92.701)   Prec@5 100.000 (99.856)   [2018-05-04 14:22:44]
  Epoch: [043][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.3161 (0.2247)   Prec@1 93.000 (92.456)   Prec@5 99.000 (99.825)   [2018-05-04 14:22:55]
  **Train** Prec@1 92.470 Prec@5 99.832 Error@1 7.530
  **Test** Prec@1 89.610 Prec@5 99.640 Error@1 10.390

==>>[2018-05-04 14:23:04] [Epoch=044/540] [Need: 04:16:23] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [044][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.1271 (0.1271)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:23:04]
  Epoch: [044][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1695 (0.2106)   Prec@1 96.000 (92.920)   Prec@5 100.000 (99.846)   [2018-05-04 14:23:15]
  Epoch: [044][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2033 (0.2127)   Prec@1 93.000 (92.830)   Prec@5 100.000 (99.845)   [2018-05-04 14:23:27]
  **Train** Prec@1 92.742 Prec@5 99.848 Error@1 7.258
  **Test** Prec@1 86.470 Prec@5 99.410 Error@1 13.530

==>>[2018-05-04 14:23:35] [Epoch=045/540] [Need: 04:15:57] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [045][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.2852 (0.2852)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:23:35]
  Epoch: [045][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1853 (0.1964)   Prec@1 94.000 (93.697)   Prec@5 100.000 (99.861)   [2018-05-04 14:23:47]
  Epoch: [045][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.1781 (0.2091)   Prec@1 96.000 (93.077)   Prec@5 100.000 (99.835)   [2018-05-04 14:23:58]
  **Train** Prec@1 92.894 Prec@5 99.822 Error@1 7.106
  **Test** Prec@1 87.700 Prec@5 99.650 Error@1 12.300

==>>[2018-05-04 14:24:07] [Epoch=046/540] [Need: 04:15:31] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [046][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.1467 (0.1467)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:24:07]
  Epoch: [046][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2054 (0.2046)   Prec@1 94.000 (93.229)   Prec@5 100.000 (99.846)   [2018-05-04 14:24:18]
  Epoch: [046][400/500]   Time 0.063 (0.057)   Data 0.000 (0.000)   Loss 0.2141 (0.2092)   Prec@1 95.000 (93.162)   Prec@5 99.000 (99.820)   [2018-05-04 14:24:30]
  **Train** Prec@1 92.988 Prec@5 99.814 Error@1 7.012
  **Test** Prec@1 88.450 Prec@5 99.510 Error@1 11.550

==>>[2018-05-04 14:24:38] [Epoch=047/540] [Need: 04:15:04] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [047][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.1836 (0.1836)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:24:38]
  Epoch: [047][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1658 (0.2003)   Prec@1 93.000 (93.438)   Prec@5 100.000 (99.846)   [2018-05-04 14:24:50]
  Epoch: [047][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2734 (0.2069)   Prec@1 89.000 (93.214)   Prec@5 100.000 (99.850)   [2018-05-04 14:25:01]
  **Train** Prec@1 93.148 Prec@5 99.850 Error@1 6.852
  **Test** Prec@1 88.980 Prec@5 99.640 Error@1 11.020

==>>[2018-05-04 14:25:09] [Epoch=048/540] [Need: 04:14:34] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [048][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.1281 (0.1281)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:25:10]
  Epoch: [048][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2388 (0.1871)   Prec@1 90.000 (93.687)   Prec@5 100.000 (99.856)   [2018-05-04 14:25:21]
  Epoch: [048][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.3654 (0.2064)   Prec@1 86.000 (93.209)   Prec@5 100.000 (99.848)   [2018-05-04 14:25:32]
  **Train** Prec@1 93.028 Prec@5 99.848 Error@1 6.972
  **Test** Prec@1 88.140 Prec@5 99.580 Error@1 11.860

==>>[2018-05-04 14:25:41] [Epoch=049/540] [Need: 04:14:06] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [049][000/500]   Time 0.081 (0.081)   Data 0.052 (0.052)   Loss 0.1530 (0.1530)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:25:41]
  Epoch: [049][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.2336 (0.2005)   Prec@1 92.000 (93.453)   Prec@5 100.000 (99.886)   [2018-05-04 14:25:52]
  Epoch: [049][400/500]   Time 0.054 (0.058)   Data 0.000 (0.000)   Loss 0.3123 (0.2030)   Prec@1 87.000 (93.314)   Prec@5 100.000 (99.873)   [2018-05-04 14:26:04]
  **Train** Prec@1 93.216 Prec@5 99.876 Error@1 6.784
  **Test** Prec@1 87.420 Prec@5 99.610 Error@1 12.580

==>>[2018-05-04 14:26:13] [Epoch=050/540] [Need: 04:13:41] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [050][000/500]   Time 0.079 (0.079)   Data 0.049 (0.049)   Loss 0.1520 (0.1520)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:26:13]
  Epoch: [050][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2453 (0.1872)   Prec@1 92.000 (93.711)   Prec@5 100.000 (99.910)   [2018-05-04 14:26:24]
  Epoch: [050][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2461 (0.2028)   Prec@1 92.000 (93.242)   Prec@5 99.000 (99.870)   [2018-05-04 14:26:35]
  **Train** Prec@1 93.024 Prec@5 99.862 Error@1 6.976
  **Test** Prec@1 88.170 Prec@5 99.690 Error@1 11.830

==>>[2018-05-04 14:26:44] [Epoch=051/540] [Need: 04:13:14] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [051][000/500]   Time 0.079 (0.079)   Data 0.051 (0.051)   Loss 0.3146 (0.3146)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:26:44]
  Epoch: [051][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.1146 (0.2005)   Prec@1 97.000 (93.214)   Prec@5 100.000 (99.866)   [2018-05-04 14:26:55]
  Epoch: [051][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1804 (0.2059)   Prec@1 96.000 (93.000)   Prec@5 100.000 (99.848)   [2018-05-04 14:27:07]
  **Train** Prec@1 92.926 Prec@5 99.834 Error@1 7.074
  **Test** Prec@1 87.990 Prec@5 99.600 Error@1 12.010

==>>[2018-05-04 14:27:15] [Epoch=052/540] [Need: 04:12:43] [learning_rate=0.100000] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [052][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.2302 (0.2302)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:27:15]
  Epoch: [052][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2752 (0.1928)   Prec@1 91.000 (93.488)   Prec@5 100.000 (99.866)   [2018-05-04 14:27:26]
  Epoch: [052][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.2249 (0.2036)   Prec@1 93.000 (93.160)   Prec@5 100.000 (99.830)   [2018-05-04 14:27:38]
  **Train** Prec@1 93.124 Prec@5 99.836 Error@1 6.876
  **Test** Prec@1 90.850 Prec@5 99.700 Error@1 9.150

==>>[2018-05-04 14:27:46] [Epoch=053/540] [Need: 04:12:14] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [053][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.1701 (0.1701)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:27:46]
  Epoch: [053][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1447 (0.1959)   Prec@1 95.000 (93.542)   Prec@5 100.000 (99.861)   [2018-05-04 14:27:58]
  Epoch: [053][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.3073 (0.2020)   Prec@1 89.000 (93.307)   Prec@5 99.000 (99.850)   [2018-05-04 14:28:09]
  **Train** Prec@1 93.326 Prec@5 99.836 Error@1 6.674
  **Test** Prec@1 90.100 Prec@5 99.720 Error@1 9.900

==>>[2018-05-04 14:28:17] [Epoch=054/540] [Need: 04:11:44] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [054][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.2066 (0.2066)   Prec@1 93.000 (93.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:28:18]
  Epoch: [054][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.2568 (0.1858)   Prec@1 93.000 (93.652)   Prec@5 100.000 (99.871)   [2018-05-04 14:28:29]
  Epoch: [054][400/500]   Time 0.063 (0.057)   Data 0.000 (0.000)   Loss 0.3467 (0.1999)   Prec@1 88.000 (93.244)   Prec@5 99.000 (99.868)   [2018-05-04 14:28:40]
  **Train** Prec@1 93.170 Prec@5 99.860 Error@1 6.830
  **Test** Prec@1 89.090 Prec@5 99.630 Error@1 10.910

==>>[2018-05-04 14:28:49] [Epoch=055/540] [Need: 04:11:14] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [055][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0950 (0.0950)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:28:49]
  Epoch: [055][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.1741 (0.1935)   Prec@1 91.000 (93.502)   Prec@5 100.000 (99.881)   [2018-05-04 14:29:00]
  Epoch: [055][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0695 (0.1972)   Prec@1 100.000 (93.466)   Prec@5 100.000 (99.853)   [2018-05-04 14:29:12]
  **Train** Prec@1 93.438 Prec@5 99.846 Error@1 6.562
  **Test** Prec@1 88.890 Prec@5 99.550 Error@1 11.110

==>>[2018-05-04 14:29:20] [Epoch=056/540] [Need: 04:10:44] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [056][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.1933 (0.1933)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:29:20]
  Epoch: [056][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1614 (0.1953)   Prec@1 96.000 (93.731)   Prec@5 100.000 (99.831)   [2018-05-04 14:29:31]
  Epoch: [056][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.2051 (0.2024)   Prec@1 92.000 (93.364)   Prec@5 100.000 (99.805)   [2018-05-04 14:29:43]
  **Train** Prec@1 93.206 Prec@5 99.804 Error@1 6.794
  **Test** Prec@1 88.740 Prec@5 99.430 Error@1 11.260

==>>[2018-05-04 14:29:51] [Epoch=057/540] [Need: 04:10:15] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [057][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.2362 (0.2362)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:29:51]
  Epoch: [057][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.3511 (0.1946)   Prec@1 91.000 (93.532)   Prec@5 98.000 (99.851)   [2018-05-04 14:30:03]
  Epoch: [057][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2370 (0.1971)   Prec@1 92.000 (93.389)   Prec@5 100.000 (99.843)   [2018-05-04 14:30:14]
  **Train** Prec@1 93.324 Prec@5 99.840 Error@1 6.676
  **Test** Prec@1 88.740 Prec@5 99.500 Error@1 11.260

==>>[2018-05-04 14:30:23] [Epoch=058/540] [Need: 04:09:47] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [058][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.1804 (0.1804)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:30:23]
  Epoch: [058][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.1445 (0.1958)   Prec@1 94.000 (93.582)   Prec@5 100.000 (99.826)   [2018-05-04 14:30:34]
  Epoch: [058][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.3262 (0.2010)   Prec@1 90.000 (93.379)   Prec@5 99.000 (99.840)   [2018-05-04 14:30:46]
  **Train** Prec@1 93.424 Prec@5 99.834 Error@1 6.576
  **Test** Prec@1 89.610 Prec@5 99.580 Error@1 10.390

==>>[2018-05-04 14:30:54] [Epoch=059/540] [Need: 04:09:17] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [059][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.2116 (0.2116)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:30:54]
  Epoch: [059][200/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.2574 (0.1961)   Prec@1 92.000 (93.527)   Prec@5 100.000 (99.876)   [2018-05-04 14:31:05]
  Epoch: [059][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.2035 (0.1967)   Prec@1 93.000 (93.534)   Prec@5 100.000 (99.883)   [2018-05-04 14:31:17]
  **Train** Prec@1 93.310 Prec@5 99.870 Error@1 6.690
  **Test** Prec@1 87.450 Prec@5 99.510 Error@1 12.550

==>>[2018-05-04 14:31:25] [Epoch=060/540] [Need: 04:08:46] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [060][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.1666 (0.1666)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:31:25]
  Epoch: [060][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.1680 (0.1971)   Prec@1 92.000 (93.512)   Prec@5 100.000 (99.831)   [2018-05-04 14:31:36]
  Epoch: [060][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1666 (0.2003)   Prec@1 93.000 (93.359)   Prec@5 100.000 (99.830)   [2018-05-04 14:31:47]
  **Train** Prec@1 93.338 Prec@5 99.840 Error@1 6.662
  **Test** Prec@1 89.830 Prec@5 99.700 Error@1 10.170

==>>[2018-05-04 14:31:56] [Epoch=061/540] [Need: 04:08:11] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [061][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.1497 (0.1497)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:31:56]
  Epoch: [061][200/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.1737 (0.1934)   Prec@1 93.000 (93.632)   Prec@5 100.000 (99.861)   [2018-05-04 14:32:07]
  Epoch: [061][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.1374 (0.2001)   Prec@1 94.000 (93.399)   Prec@5 100.000 (99.855)   [2018-05-04 14:32:19]
  **Train** Prec@1 93.512 Prec@5 99.868 Error@1 6.488
  **Test** Prec@1 89.950 Prec@5 99.670 Error@1 10.050

==>>[2018-05-04 14:32:27] [Epoch=062/540] [Need: 04:07:42] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [062][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.1118 (0.1118)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:32:27]
  Epoch: [062][200/500]   Time 0.062 (0.057)   Data 0.000 (0.000)   Loss 0.1509 (0.1832)   Prec@1 97.000 (93.791)   Prec@5 100.000 (99.871)   [2018-05-04 14:32:38]
  Epoch: [062][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2949 (0.1938)   Prec@1 91.000 (93.469)   Prec@5 100.000 (99.848)   [2018-05-04 14:32:50]
  **Train** Prec@1 93.440 Prec@5 99.846 Error@1 6.560
  **Test** Prec@1 87.660 Prec@5 99.370 Error@1 12.340

==>>[2018-05-04 14:32:58] [Epoch=063/540] [Need: 04:07:12] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [063][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.2393 (0.2393)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:32:58]
  Epoch: [063][200/500]   Time 0.063 (0.056)   Data 0.000 (0.000)   Loss 0.2181 (0.1817)   Prec@1 93.000 (93.925)   Prec@5 100.000 (99.871)   [2018-05-04 14:33:09]
  Epoch: [063][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.2522 (0.1889)   Prec@1 93.000 (93.758)   Prec@5 100.000 (99.858)   [2018-05-04 14:33:21]
  **Train** Prec@1 93.586 Prec@5 99.850 Error@1 6.414
  **Test** Prec@1 88.820 Prec@5 99.590 Error@1 11.180

==>>[2018-05-04 14:33:29] [Epoch=064/540] [Need: 04:06:38] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [064][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.1522 (0.1522)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:33:29]
  Epoch: [064][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.2295 (0.1860)   Prec@1 91.000 (93.841)   Prec@5 100.000 (99.900)   [2018-05-04 14:33:40]
  Epoch: [064][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.1447 (0.1890)   Prec@1 95.000 (93.738)   Prec@5 100.000 (99.873)   [2018-05-04 14:33:52]
  **Train** Prec@1 93.556 Prec@5 99.870 Error@1 6.444
  **Test** Prec@1 88.330 Prec@5 99.600 Error@1 11.670

==>>[2018-05-04 14:34:00] [Epoch=065/540] [Need: 04:06:06] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [065][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.1570 (0.1570)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:34:00]
  Epoch: [065][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.2734 (0.1812)   Prec@1 89.000 (93.801)   Prec@5 99.000 (99.886)   [2018-05-04 14:34:11]
  Epoch: [065][400/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.1985 (0.1853)   Prec@1 94.000 (93.681)   Prec@5 99.000 (99.870)   [2018-05-04 14:34:23]
  **Train** Prec@1 93.582 Prec@5 99.872 Error@1 6.418
  **Test** Prec@1 89.950 Prec@5 99.650 Error@1 10.050

==>>[2018-05-04 14:34:31] [Epoch=066/540] [Need: 04:05:38] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [066][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.1130 (0.1130)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:34:31]
  Epoch: [066][200/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.1599 (0.1887)   Prec@1 93.000 (93.677)   Prec@5 100.000 (99.891)   [2018-05-04 14:34:43]
  Epoch: [066][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.2199 (0.1910)   Prec@1 96.000 (93.589)   Prec@5 100.000 (99.875)   [2018-05-04 14:34:54]
  **Train** Prec@1 93.506 Prec@5 99.874 Error@1 6.494
  **Test** Prec@1 89.040 Prec@5 99.370 Error@1 10.960

==>>[2018-05-04 14:35:03] [Epoch=067/540] [Need: 04:05:10] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [067][000/500]   Time 0.078 (0.078)   Data 0.050 (0.050)   Loss 0.2636 (0.2636)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:35:03]
  Epoch: [067][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.1838 (0.1824)   Prec@1 94.000 (93.821)   Prec@5 100.000 (99.856)   [2018-05-04 14:35:14]
  Epoch: [067][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1137 (0.1914)   Prec@1 98.000 (93.559)   Prec@5 100.000 (99.848)   [2018-05-04 14:35:26]
  **Train** Prec@1 93.504 Prec@5 99.840 Error@1 6.496
  **Test** Prec@1 87.270 Prec@5 99.350 Error@1 12.730

==>>[2018-05-04 14:35:34] [Epoch=068/540] [Need: 04:04:42] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [068][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.1614 (0.1614)   Prec@1 95.000 (95.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:35:35]
  Epoch: [068][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.3251 (0.1857)   Prec@1 88.000 (93.955)   Prec@5 100.000 (99.871)   [2018-05-04 14:35:46]
  Epoch: [068][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.1568 (0.1893)   Prec@1 95.000 (93.768)   Prec@5 100.000 (99.873)   [2018-05-04 14:35:58]
  **Train** Prec@1 93.724 Prec@5 99.870 Error@1 6.276
  **Test** Prec@1 88.890 Prec@5 99.680 Error@1 11.110

==>>[2018-05-04 14:36:06] [Epoch=069/540] [Need: 04:04:16] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [069][000/500]   Time 0.075 (0.075)   Data 0.050 (0.050)   Loss 0.1963 (0.1963)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:36:06]
  Epoch: [069][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1028 (0.1775)   Prec@1 96.000 (94.050)   Prec@5 100.000 (99.900)   [2018-05-04 14:36:17]
  Epoch: [069][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1676 (0.1859)   Prec@1 92.000 (93.860)   Prec@5 100.000 (99.885)   [2018-05-04 14:36:28]
  **Train** Prec@1 93.722 Prec@5 99.882 Error@1 6.278
  **Test** Prec@1 88.880 Prec@5 99.530 Error@1 11.120

==>>[2018-05-04 14:36:37] [Epoch=070/540] [Need: 04:03:39] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [070][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.2343 (0.2343)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:36:37]
  Epoch: [070][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.2712 (0.1884)   Prec@1 92.000 (93.816)   Prec@5 100.000 (99.900)   [2018-05-04 14:36:48]
  Epoch: [070][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.2487 (0.1916)   Prec@1 94.000 (93.698)   Prec@5 100.000 (99.895)   [2018-05-04 14:36:59]
  **Train** Prec@1 93.664 Prec@5 99.882 Error@1 6.336
  **Test** Prec@1 89.360 Prec@5 99.450 Error@1 10.640

==>>[2018-05-04 14:37:07] [Epoch=071/540] [Need: 04:03:07] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [071][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.1426 (0.1426)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:37:08]
  Epoch: [071][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2080 (0.1778)   Prec@1 93.000 (94.095)   Prec@5 99.000 (99.896)   [2018-05-04 14:37:19]
  Epoch: [071][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2909 (0.1818)   Prec@1 90.000 (93.925)   Prec@5 99.000 (99.873)   [2018-05-04 14:37:30]
  **Train** Prec@1 93.900 Prec@5 99.868 Error@1 6.100
  **Test** Prec@1 87.630 Prec@5 99.510 Error@1 12.370

==>>[2018-05-04 14:37:38] [Epoch=072/540] [Need: 04:02:32] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [072][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.1666 (0.1666)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:37:38]
  Epoch: [072][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.1535 (0.1784)   Prec@1 95.000 (94.109)   Prec@5 100.000 (99.881)   [2018-05-04 14:37:49]
  Epoch: [072][400/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.1654 (0.1846)   Prec@1 95.000 (93.868)   Prec@5 100.000 (99.873)   [2018-05-04 14:38:00]
  **Train** Prec@1 93.736 Prec@5 99.880 Error@1 6.264
  **Test** Prec@1 89.300 Prec@5 99.730 Error@1 10.700

==>>[2018-05-04 14:38:09] [Epoch=073/540] [Need: 04:01:58] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [073][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.1188 (0.1188)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:38:09]
  Epoch: [073][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3187 (0.1737)   Prec@1 91.000 (94.194)   Prec@5 100.000 (99.856)   [2018-05-04 14:38:20]
  Epoch: [073][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2070 (0.1834)   Prec@1 92.000 (93.860)   Prec@5 99.000 (99.863)   [2018-05-04 14:38:31]
  **Train** Prec@1 93.720 Prec@5 99.874 Error@1 6.280
  **Test** Prec@1 86.430 Prec@5 99.470 Error@1 13.570

==>>[2018-05-04 14:38:39] [Epoch=074/540] [Need: 04:01:21] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [074][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.1341 (0.1341)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:38:39]
  Epoch: [074][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1748 (0.1755)   Prec@1 95.000 (94.274)   Prec@5 100.000 (99.891)   [2018-05-04 14:38:50]
  Epoch: [074][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1850 (0.1804)   Prec@1 97.000 (93.995)   Prec@5 100.000 (99.855)   [2018-05-04 14:39:01]
  **Train** Prec@1 93.978 Prec@5 99.858 Error@1 6.022
  **Test** Prec@1 90.210 Prec@5 99.650 Error@1 9.790

==>>[2018-05-04 14:39:09] [Epoch=075/540] [Need: 04:00:46] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [075][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.2068 (0.2068)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:39:09]
  Epoch: [075][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1102 (0.1745)   Prec@1 97.000 (94.224)   Prec@5 100.000 (99.851)   [2018-05-04 14:39:20]
  Epoch: [075][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1372 (0.1855)   Prec@1 95.000 (93.890)   Prec@5 100.000 (99.853)   [2018-05-04 14:39:32]
  **Train** Prec@1 93.910 Prec@5 99.856 Error@1 6.090
  **Test** Prec@1 89.450 Prec@5 99.600 Error@1 10.550

==>>[2018-05-04 14:39:40] [Epoch=076/540] [Need: 04:00:12] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [076][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.2660 (0.2660)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:39:40]
  Epoch: [076][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1263 (0.1761)   Prec@1 97.000 (94.045)   Prec@5 100.000 (99.876)   [2018-05-04 14:39:51]
  Epoch: [076][400/500]   Time 0.059 (0.055)   Data 0.000 (0.000)   Loss 0.2498 (0.1873)   Prec@1 91.000 (93.731)   Prec@5 100.000 (99.865)   [2018-05-04 14:40:02]
  **Train** Prec@1 93.726 Prec@5 99.858 Error@1 6.274
  **Test** Prec@1 89.310 Prec@5 99.630 Error@1 10.690

==>>[2018-05-04 14:40:10] [Epoch=077/540] [Need: 03:59:37] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [077][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.2071 (0.2071)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:40:10]
  Epoch: [077][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1422 (0.1784)   Prec@1 95.000 (94.020)   Prec@5 100.000 (99.886)   [2018-05-04 14:40:21]
  Epoch: [077][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.2769 (0.1819)   Prec@1 93.000 (93.933)   Prec@5 99.000 (99.875)   [2018-05-04 14:40:33]
  **Train** Prec@1 93.792 Prec@5 99.876 Error@1 6.208
  **Test** Prec@1 88.620 Prec@5 99.390 Error@1 11.380

==>>[2018-05-04 14:40:41] [Epoch=078/540] [Need: 03:59:03] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [078][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.1385 (0.1385)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:40:41]
  Epoch: [078][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1621 (0.1755)   Prec@1 95.000 (94.189)   Prec@5 100.000 (99.930)   [2018-05-04 14:40:52]
  Epoch: [078][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1386 (0.1837)   Prec@1 95.000 (93.888)   Prec@5 100.000 (99.925)   [2018-05-04 14:41:03]
  **Train** Prec@1 93.778 Prec@5 99.898 Error@1 6.222
  **Test** Prec@1 89.300 Prec@5 99.580 Error@1 10.700

==>>[2018-05-04 14:41:11] [Epoch=079/540] [Need: 03:58:29] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [079][000/500]   Time 0.080 (0.080)   Data 0.051 (0.051)   Loss 0.1786 (0.1786)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:41:11]
  Epoch: [079][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1240 (0.1781)   Prec@1 98.000 (94.179)   Prec@5 100.000 (99.861)   [2018-05-04 14:41:23]
  Epoch: [079][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1344 (0.1792)   Prec@1 96.000 (94.117)   Prec@5 100.000 (99.898)   [2018-05-04 14:41:34]
  **Train** Prec@1 94.066 Prec@5 99.880 Error@1 5.934
  **Test** Prec@1 89.410 Prec@5 99.690 Error@1 10.590

==>>[2018-05-04 14:41:42] [Epoch=080/540] [Need: 03:57:55] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [080][000/500]   Time 0.078 (0.078)   Data 0.050 (0.050)   Loss 0.2407 (0.2407)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:41:42]
  Epoch: [080][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1615 (0.1753)   Prec@1 91.000 (94.189)   Prec@5 100.000 (99.871)   [2018-05-04 14:41:53]
  Epoch: [080][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1970 (0.1810)   Prec@1 93.000 (94.020)   Prec@5 100.000 (99.863)   [2018-05-04 14:42:04]
  **Train** Prec@1 93.990 Prec@5 99.856 Error@1 6.010
  **Test** Prec@1 89.490 Prec@5 99.670 Error@1 10.510

==>>[2018-05-04 14:42:12] [Epoch=081/540] [Need: 03:57:20] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [081][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.1639 (0.1639)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:42:12]
  Epoch: [081][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1212 (0.1803)   Prec@1 96.000 (94.055)   Prec@5 100.000 (99.876)   [2018-05-04 14:42:23]
  Epoch: [081][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1983 (0.1805)   Prec@1 94.000 (94.007)   Prec@5 100.000 (99.868)   [2018-05-04 14:42:34]
  **Train** Prec@1 93.846 Prec@5 99.866 Error@1 6.154
  **Test** Prec@1 90.460 Prec@5 99.520 Error@1 9.540

==>>[2018-05-04 14:42:43] [Epoch=082/540] [Need: 03:56:46] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [082][000/500]   Time 0.071 (0.071)   Data 0.046 (0.046)   Loss 0.1570 (0.1570)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:42:43]
  Epoch: [082][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1812 (0.1717)   Prec@1 91.000 (94.279)   Prec@5 100.000 (99.920)   [2018-05-04 14:42:54]
  Epoch: [082][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1573 (0.1788)   Prec@1 95.000 (93.980)   Prec@5 100.000 (99.883)   [2018-05-04 14:43:05]
  **Train** Prec@1 93.994 Prec@5 99.884 Error@1 6.006
  **Test** Prec@1 89.570 Prec@5 99.540 Error@1 10.430

==>>[2018-05-04 14:43:13] [Epoch=083/540] [Need: 03:56:11] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [083][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.1859 (0.1859)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:43:13]
  Epoch: [083][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2193 (0.1664)   Prec@1 91.000 (94.627)   Prec@5 100.000 (99.896)   [2018-05-04 14:43:24]
  Epoch: [083][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.3656 (0.1739)   Prec@1 89.000 (94.312)   Prec@5 100.000 (99.878)   [2018-05-04 14:43:35]
  **Train** Prec@1 94.086 Prec@5 99.856 Error@1 5.914
  **Test** Prec@1 89.710 Prec@5 99.590 Error@1 10.290

==>>[2018-05-04 14:43:44] [Epoch=084/540] [Need: 03:55:38] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [084][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.1220 (0.1220)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:43:44]
  Epoch: [084][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0910 (0.1727)   Prec@1 98.000 (94.224)   Prec@5 100.000 (99.871)   [2018-05-04 14:43:55]
  Epoch: [084][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.1115 (0.1770)   Prec@1 97.000 (94.170)   Prec@5 100.000 (99.880)   [2018-05-04 14:44:06]
  **Train** Prec@1 94.174 Prec@5 99.886 Error@1 5.826
  **Test** Prec@1 89.460 Prec@5 99.630 Error@1 10.540

==>>[2018-05-04 14:44:15] [Epoch=085/540] [Need: 03:55:08] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [085][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.2045 (0.2045)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:44:15]
  Epoch: [085][200/500]   Time 0.055 (0.059)   Data 0.000 (0.000)   Loss 0.1710 (0.1705)   Prec@1 94.000 (94.363)   Prec@5 100.000 (99.831)   [2018-05-04 14:44:27]
  Epoch: [085][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.3163 (0.1784)   Prec@1 89.000 (94.010)   Prec@5 100.000 (99.853)   [2018-05-04 14:44:38]
  **Train** Prec@1 93.884 Prec@5 99.856 Error@1 6.116
  **Test** Prec@1 90.690 Prec@5 99.680 Error@1 9.310

==>>[2018-05-04 14:44:46] [Epoch=086/540] [Need: 03:54:38] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [086][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.2600 (0.2600)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:44:46]
  Epoch: [086][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.2520 (0.1743)   Prec@1 91.000 (94.269)   Prec@5 100.000 (99.920)   [2018-05-04 14:44:57]
  Epoch: [086][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2207 (0.1818)   Prec@1 93.000 (93.998)   Prec@5 99.000 (99.888)   [2018-05-04 14:45:08]
  **Train** Prec@1 93.942 Prec@5 99.882 Error@1 6.058
  **Test** Prec@1 87.100 Prec@5 99.100 Error@1 12.900

==>>[2018-05-04 14:45:16] [Epoch=087/540] [Need: 03:54:04] [learning_rate=0.100000] [Best : Accuracy=90.85, Error=9.15]
  Epoch: [087][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0986 (0.0986)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:45:17]
  Epoch: [087][200/500]   Time 0.063 (0.056)   Data 0.000 (0.000)   Loss 0.1069 (0.1657)   Prec@1 96.000 (94.488)   Prec@5 100.000 (99.886)   [2018-05-04 14:45:28]
  Epoch: [087][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.2511 (0.1758)   Prec@1 90.000 (94.117)   Prec@5 100.000 (99.903)   [2018-05-04 14:45:39]
  **Train** Prec@1 94.086 Prec@5 99.910 Error@1 5.914
  **Test** Prec@1 90.930 Prec@5 99.630 Error@1 9.070

==>>[2018-05-04 14:45:48] [Epoch=088/540] [Need: 03:53:34] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [088][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.1349 (0.1349)   Prec@1 96.000 (96.000)   Prec@5 99.000 (99.000)   [2018-05-04 14:45:48]
  Epoch: [088][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.2802 (0.1708)   Prec@1 90.000 (94.393)   Prec@5 100.000 (99.930)   [2018-05-04 14:45:59]
  Epoch: [088][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.2415 (0.1737)   Prec@1 94.000 (94.257)   Prec@5 100.000 (99.920)   [2018-05-04 14:46:11]
  **Train** Prec@1 94.118 Prec@5 99.902 Error@1 5.882
  **Test** Prec@1 87.230 Prec@5 99.540 Error@1 12.770

==>>[2018-05-04 14:46:20] [Epoch=089/540] [Need: 03:53:08] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [089][000/500]   Time 0.075 (0.075)   Data 0.047 (0.047)   Loss 0.4013 (0.4013)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:46:20]
  Epoch: [089][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.1880 (0.1664)   Prec@1 93.000 (94.522)   Prec@5 100.000 (99.900)   [2018-05-04 14:46:31]
  Epoch: [089][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.3007 (0.1756)   Prec@1 90.000 (94.170)   Prec@5 100.000 (99.895)   [2018-05-04 14:46:43]
  **Train** Prec@1 94.050 Prec@5 99.892 Error@1 5.950
  **Test** Prec@1 89.710 Prec@5 99.740 Error@1 10.290

==>>[2018-05-04 14:46:51] [Epoch=090/540] [Need: 03:52:39] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [090][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.1489 (0.1489)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:46:51]
  Epoch: [090][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.1410 (0.1628)   Prec@1 96.000 (94.652)   Prec@5 100.000 (99.935)   [2018-05-04 14:47:03]
  Epoch: [090][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1957 (0.1733)   Prec@1 94.000 (94.185)   Prec@5 100.000 (99.918)   [2018-05-04 14:47:14]
  **Train** Prec@1 94.202 Prec@5 99.908 Error@1 5.798
  **Test** Prec@1 90.800 Prec@5 99.750 Error@1 9.200

==>>[2018-05-04 14:47:22] [Epoch=091/540] [Need: 03:52:06] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [091][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.2094 (0.2094)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:47:22]
  Epoch: [091][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1619 (0.1622)   Prec@1 95.000 (94.701)   Prec@5 100.000 (99.900)   [2018-05-04 14:47:33]
  Epoch: [091][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1844 (0.1730)   Prec@1 94.000 (94.254)   Prec@5 100.000 (99.880)   [2018-05-04 14:47:44]
  **Train** Prec@1 94.146 Prec@5 99.876 Error@1 5.854
  **Test** Prec@1 89.930 Prec@5 99.670 Error@1 10.070

==>>[2018-05-04 14:47:52] [Epoch=092/540] [Need: 03:51:32] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [092][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.1660 (0.1660)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:47:52]
  Epoch: [092][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.2180 (0.1766)   Prec@1 94.000 (94.129)   Prec@5 100.000 (99.836)   [2018-05-04 14:48:03]
  Epoch: [092][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.1396 (0.1777)   Prec@1 95.000 (94.062)   Prec@5 100.000 (99.863)   [2018-05-04 14:48:14]
  **Train** Prec@1 94.078 Prec@5 99.864 Error@1 5.922
  **Test** Prec@1 89.780 Prec@5 99.620 Error@1 10.220

==>>[2018-05-04 14:48:23] [Epoch=093/540] [Need: 03:50:59] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [093][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.1771 (0.1771)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:48:23]
  Epoch: [093][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1911 (0.1736)   Prec@1 92.000 (94.303)   Prec@5 100.000 (99.910)   [2018-05-04 14:48:34]
  Epoch: [093][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1768 (0.1777)   Prec@1 93.000 (94.077)   Prec@5 100.000 (99.888)   [2018-05-04 14:48:45]
  **Train** Prec@1 94.094 Prec@5 99.898 Error@1 5.906
  **Test** Prec@1 88.140 Prec@5 99.420 Error@1 11.860

==>>[2018-05-04 14:48:53] [Epoch=094/540] [Need: 03:50:25] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [094][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.2246 (0.2246)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:48:53]
  Epoch: [094][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2117 (0.1593)   Prec@1 93.000 (94.761)   Prec@5 100.000 (99.935)   [2018-05-04 14:49:04]
  Epoch: [094][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.1159 (0.1716)   Prec@1 96.000 (94.374)   Prec@5 100.000 (99.890)   [2018-05-04 14:49:15]
  **Train** Prec@1 94.182 Prec@5 99.892 Error@1 5.818
  **Test** Prec@1 90.080 Prec@5 99.560 Error@1 9.920

==>>[2018-05-04 14:49:24] [Epoch=095/540] [Need: 03:49:53] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [095][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.2092 (0.2092)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:49:24]
  Epoch: [095][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.2477 (0.1664)   Prec@1 94.000 (94.418)   Prec@5 100.000 (99.905)   [2018-05-04 14:49:36]
  Epoch: [095][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.1346 (0.1685)   Prec@1 97.000 (94.406)   Prec@5 99.000 (99.913)   [2018-05-04 14:49:47]
  **Train** Prec@1 94.120 Prec@5 99.908 Error@1 5.880
  **Test** Prec@1 89.690 Prec@5 99.630 Error@1 10.310

==>>[2018-05-04 14:49:56] [Epoch=096/540] [Need: 03:49:27] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [096][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.1955 (0.1955)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:49:56]
  Epoch: [096][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.2436 (0.1644)   Prec@1 94.000 (94.622)   Prec@5 99.000 (99.915)   [2018-05-04 14:50:07]
  Epoch: [096][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.2771 (0.1709)   Prec@1 93.000 (94.397)   Prec@5 100.000 (99.898)   [2018-05-04 14:50:19]
  **Train** Prec@1 94.272 Prec@5 99.900 Error@1 5.728
  **Test** Prec@1 90.120 Prec@5 99.560 Error@1 9.880

==>>[2018-05-04 14:50:28] [Epoch=097/540] [Need: 03:49:00] [learning_rate=0.100000] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [097][000/500]   Time 0.079 (0.079)   Data 0.051 (0.051)   Loss 0.1893 (0.1893)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:50:28]
  Epoch: [097][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.2114 (0.1634)   Prec@1 93.000 (94.537)   Prec@5 100.000 (99.886)   [2018-05-04 14:50:40]
  Epoch: [097][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2298 (0.1749)   Prec@1 92.000 (94.152)   Prec@5 100.000 (99.885)   [2018-05-04 14:50:52]
  **Train** Prec@1 94.064 Prec@5 99.878 Error@1 5.936
  **Test** Prec@1 92.140 Prec@5 99.740 Error@1 7.860

==>>[2018-05-04 14:51:00] [Epoch=098/540] [Need: 03:48:36] [learning_rate=0.100000] [Best : Accuracy=92.14, Error=7.86]
  Epoch: [098][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.2501 (0.2501)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:51:01]
  Epoch: [098][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.1659 (0.1729)   Prec@1 92.000 (94.184)   Prec@5 100.000 (99.900)   [2018-05-04 14:51:12]
  Epoch: [098][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1797 (0.1744)   Prec@1 93.000 (94.075)   Prec@5 100.000 (99.890)   [2018-05-04 14:51:23]
  **Train** Prec@1 94.134 Prec@5 99.884 Error@1 5.866
  **Test** Prec@1 90.330 Prec@5 99.600 Error@1 9.670

==>>[2018-05-04 14:51:31] [Epoch=099/540] [Need: 03:48:03] [learning_rate=0.100000] [Best : Accuracy=92.14, Error=7.86]
  Epoch: [099][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0805 (0.0805)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:51:31]
  Epoch: [099][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.2099 (0.1612)   Prec@1 91.000 (94.746)   Prec@5 100.000 (99.896)   [2018-05-04 14:51:42]
  Epoch: [099][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1931 (0.1766)   Prec@1 92.000 (94.082)   Prec@5 100.000 (99.865)   [2018-05-04 14:51:53]
  **Train** Prec@1 94.176 Prec@5 99.874 Error@1 5.824
  **Test** Prec@1 90.280 Prec@5 99.650 Error@1 9.720

==>>[2018-05-04 14:52:02] [Epoch=100/540] [Need: 03:47:30] [learning_rate=0.100000] [Best : Accuracy=92.14, Error=7.86]
  Epoch: [100][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.2288 (0.2288)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:52:02]
  Epoch: [100][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.1167 (0.1163)   Prec@1 97.000 (96.070)   Prec@5 100.000 (99.940)   [2018-05-04 14:52:13]
  Epoch: [100][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0416 (0.1026)   Prec@1 99.000 (96.636)   Prec@5 100.000 (99.963)   [2018-05-04 14:52:24]
  **Train** Prec@1 96.804 Prec@5 99.964 Error@1 3.196
  **Test** Prec@1 93.890 Prec@5 99.850 Error@1 6.110

==>>[2018-05-04 14:52:32] [Epoch=101/540] [Need: 03:46:57] [learning_rate=0.010000] [Best : Accuracy=93.89, Error=6.11]
  Epoch: [101][000/500]   Time 0.072 (0.072)   Data 0.045 (0.045)   Loss 0.0592 (0.0592)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:52:32]
  Epoch: [101][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0537 (0.0743)   Prec@1 99.000 (97.746)   Prec@5 100.000 (99.975)   [2018-05-04 14:52:43]
  Epoch: [101][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0707 (0.0734)   Prec@1 98.000 (97.808)   Prec@5 100.000 (99.983)   [2018-05-04 14:52:54]
  **Train** Prec@1 97.844 Prec@5 99.982 Error@1 2.156
  **Test** Prec@1 94.000 Prec@5 99.860 Error@1 6.000

==>>[2018-05-04 14:53:03] [Epoch=102/540] [Need: 03:46:23] [learning_rate=0.010000] [Best : Accuracy=94.00, Error=6.00]
  Epoch: [102][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0929 (0.0929)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:53:03]
  Epoch: [102][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0479 (0.0672)   Prec@1 99.000 (97.935)   Prec@5 100.000 (99.975)   [2018-05-04 14:53:14]
  Epoch: [102][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0699 (0.0639)   Prec@1 98.000 (98.060)   Prec@5 100.000 (99.973)   [2018-05-04 14:53:24]
  **Train** Prec@1 98.108 Prec@5 99.974 Error@1 1.892
  **Test** Prec@1 94.290 Prec@5 99.870 Error@1 5.710

==>>[2018-05-04 14:53:33] [Epoch=103/540] [Need: 03:45:48] [learning_rate=0.010000] [Best : Accuracy=94.29, Error=5.71]
  Epoch: [103][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0261 (0.0261)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:53:33]
  Epoch: [103][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0960 (0.0573)   Prec@1 97.000 (98.348)   Prec@5 100.000 (99.990)   [2018-05-04 14:53:44]
  Epoch: [103][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0457 (0.0551)   Prec@1 98.000 (98.369)   Prec@5 100.000 (99.985)   [2018-05-04 14:53:55]
  **Train** Prec@1 98.310 Prec@5 99.988 Error@1 1.690
  **Test** Prec@1 94.370 Prec@5 99.870 Error@1 5.630

==>>[2018-05-04 14:54:03] [Epoch=104/540] [Need: 03:45:13] [learning_rate=0.010000] [Best : Accuracy=94.37, Error=5.63]
  Epoch: [104][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0478 (0.0478)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:54:03]
  Epoch: [104][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0247 (0.0510)   Prec@1 99.000 (98.498)   Prec@5 100.000 (99.990)   [2018-05-04 14:54:14]
  Epoch: [104][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0391 (0.0509)   Prec@1 99.000 (98.489)   Prec@5 100.000 (99.993)   [2018-05-04 14:54:25]
  **Train** Prec@1 98.424 Prec@5 99.992 Error@1 1.576
  **Test** Prec@1 94.350 Prec@5 99.850 Error@1 5.650

==>>[2018-05-04 14:54:33] [Epoch=105/540] [Need: 03:44:38] [learning_rate=0.010000] [Best : Accuracy=94.37, Error=5.63]
  Epoch: [105][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0524 (0.0524)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:54:33]
  Epoch: [105][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0197 (0.0462)   Prec@1 100.000 (98.677)   Prec@5 100.000 (99.995)   [2018-05-04 14:54:44]
  Epoch: [105][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0722 (0.0470)   Prec@1 97.000 (98.589)   Prec@5 100.000 (99.990)   [2018-05-04 14:54:55]
  **Train** Prec@1 98.602 Prec@5 99.982 Error@1 1.398
  **Test** Prec@1 94.390 Prec@5 99.840 Error@1 5.610

==>>[2018-05-04 14:55:03] [Epoch=106/540] [Need: 03:44:04] [learning_rate=0.010000] [Best : Accuracy=94.39, Error=5.61]
  Epoch: [106][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0545 (0.0545)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:55:03]
  Epoch: [106][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0745 (0.0437)   Prec@1 97.000 (98.687)   Prec@5 100.000 (100.000)   [2018-05-04 14:55:14]
  Epoch: [106][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0240 (0.0444)   Prec@1 99.000 (98.686)   Prec@5 100.000 (99.993)   [2018-05-04 14:55:25]
  **Train** Prec@1 98.736 Prec@5 99.992 Error@1 1.264
  **Test** Prec@1 94.430 Prec@5 99.870 Error@1 5.570

==>>[2018-05-04 14:55:33] [Epoch=107/540] [Need: 03:43:30] [learning_rate=0.010000] [Best : Accuracy=94.43, Error=5.57]
  Epoch: [107][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0280 (0.0280)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:55:33]
  Epoch: [107][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0152 (0.0413)   Prec@1 100.000 (98.766)   Prec@5 100.000 (99.995)   [2018-05-04 14:55:44]
  Epoch: [107][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0436 (0.0421)   Prec@1 98.000 (98.753)   Prec@5 100.000 (99.993)   [2018-05-04 14:55:55]
  **Train** Prec@1 98.802 Prec@5 99.994 Error@1 1.198
  **Test** Prec@1 94.210 Prec@5 99.810 Error@1 5.790

==>>[2018-05-04 14:56:03] [Epoch=108/540] [Need: 03:42:56] [learning_rate=0.010000] [Best : Accuracy=94.43, Error=5.57]
  Epoch: [108][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0414 (0.0414)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:56:03]
  Epoch: [108][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0664 (0.0372)   Prec@1 98.000 (98.965)   Prec@5 100.000 (99.995)   [2018-05-04 14:56:14]
  Epoch: [108][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0124 (0.0376)   Prec@1 100.000 (98.910)   Prec@5 100.000 (99.990)   [2018-05-04 14:56:25]
  **Train** Prec@1 98.872 Prec@5 99.990 Error@1 1.128
  **Test** Prec@1 94.510 Prec@5 99.790 Error@1 5.490

==>>[2018-05-04 14:56:33] [Epoch=109/540] [Need: 03:42:21] [learning_rate=0.010000] [Best : Accuracy=94.51, Error=5.49]
  Epoch: [109][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0698 (0.0698)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:56:33]
  Epoch: [109][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0223 (0.0360)   Prec@1 99.000 (98.925)   Prec@5 100.000 (100.000)   [2018-05-04 14:56:44]
  Epoch: [109][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0190 (0.0364)   Prec@1 99.000 (98.898)   Prec@5 100.000 (99.998)   [2018-05-04 14:56:55]
  **Train** Prec@1 98.926 Prec@5 99.990 Error@1 1.074
  **Test** Prec@1 94.460 Prec@5 99.830 Error@1 5.540

==>>[2018-05-04 14:57:04] [Epoch=110/540] [Need: 03:41:47] [learning_rate=0.010000] [Best : Accuracy=94.51, Error=5.49]
  Epoch: [110][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:57:04]
  Epoch: [110][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0191 (0.0343)   Prec@1 100.000 (99.080)   Prec@5 100.000 (99.995)   [2018-05-04 14:57:15]
  Epoch: [110][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0465 (0.0348)   Prec@1 98.000 (99.022)   Prec@5 100.000 (99.995)   [2018-05-04 14:57:25]
  **Train** Prec@1 98.994 Prec@5 99.994 Error@1 1.006
  **Test** Prec@1 94.410 Prec@5 99.850 Error@1 5.590

==>>[2018-05-04 14:57:34] [Epoch=111/540] [Need: 03:41:13] [learning_rate=0.010000] [Best : Accuracy=94.51, Error=5.49]
  Epoch: [111][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0251 (0.0251)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:57:34]
  Epoch: [111][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0670 (0.0317)   Prec@1 98.000 (99.015)   Prec@5 100.000 (100.000)   [2018-05-04 14:57:45]
  Epoch: [111][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0066 (0.0334)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.993)   [2018-05-04 14:57:55]
  **Train** Prec@1 99.010 Prec@5 99.994 Error@1 0.990
  **Test** Prec@1 94.300 Prec@5 99.860 Error@1 5.700

==>>[2018-05-04 14:58:04] [Epoch=112/540] [Need: 03:40:39] [learning_rate=0.010000] [Best : Accuracy=94.51, Error=5.49]
  Epoch: [112][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0304 (0.0304)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:58:04]
  Epoch: [112][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0323 (0.0296)   Prec@1 99.000 (99.299)   Prec@5 100.000 (99.995)   [2018-05-04 14:58:15]
  Epoch: [112][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0125 (0.0321)   Prec@1 100.000 (99.147)   Prec@5 100.000 (99.998)   [2018-05-04 14:58:26]
  **Train** Prec@1 99.150 Prec@5 99.998 Error@1 0.850
  **Test** Prec@1 94.500 Prec@5 99.820 Error@1 5.500

==>>[2018-05-04 14:58:34] [Epoch=113/540] [Need: 03:40:06] [learning_rate=0.010000] [Best : Accuracy=94.51, Error=5.49]
  Epoch: [113][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0679 (0.0679)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:58:34]
  Epoch: [113][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0198 (0.0316)   Prec@1 100.000 (99.154)   Prec@5 100.000 (100.000)   [2018-05-04 14:58:46]
  Epoch: [113][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0100 (0.0298)   Prec@1 100.000 (99.195)   Prec@5 100.000 (100.000)   [2018-05-04 14:58:58]
  **Train** Prec@1 99.154 Prec@5 99.998 Error@1 0.846
  **Test** Prec@1 94.450 Prec@5 99.870 Error@1 5.550

==>>[2018-05-04 14:59:06] [Epoch=114/540] [Need: 03:39:40] [learning_rate=0.010000] [Best : Accuracy=94.51, Error=5.49]
  Epoch: [114][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0133 (0.0133)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:59:07]
  Epoch: [114][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0136 (0.0265)   Prec@1 100.000 (99.308)   Prec@5 100.000 (99.995)   [2018-05-04 14:59:18]
  Epoch: [114][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0135 (0.0275)   Prec@1 100.000 (99.252)   Prec@5 100.000 (99.998)   [2018-05-04 14:59:29]
  **Train** Prec@1 99.272 Prec@5 99.998 Error@1 0.728
  **Test** Prec@1 94.610 Prec@5 99.850 Error@1 5.390

==>>[2018-05-04 14:59:37] [Epoch=115/540] [Need: 03:39:08] [learning_rate=0.010000] [Best : Accuracy=94.61, Error=5.39]
  Epoch: [115][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 14:59:37]
  Epoch: [115][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0146 (0.0272)   Prec@1 100.000 (99.209)   Prec@5 100.000 (99.995)   [2018-05-04 14:59:48]
  Epoch: [115][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0085 (0.0273)   Prec@1 100.000 (99.197)   Prec@5 100.000 (99.995)   [2018-05-04 14:59:59]
  **Train** Prec@1 99.226 Prec@5 99.994 Error@1 0.774
  **Test** Prec@1 94.540 Prec@5 99.850 Error@1 5.460

==>>[2018-05-04 15:00:07] [Epoch=116/540] [Need: 03:38:35] [learning_rate=0.010000] [Best : Accuracy=94.61, Error=5.39]
  Epoch: [116][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:00:07]
  Epoch: [116][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0508 (0.0243)   Prec@1 98.000 (99.368)   Prec@5 100.000 (100.000)   [2018-05-04 15:00:18]
  Epoch: [116][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0251 (0.0254)   Prec@1 100.000 (99.319)   Prec@5 100.000 (100.000)   [2018-05-04 15:00:29]
  **Train** Prec@1 99.298 Prec@5 100.000 Error@1 0.702
  **Test** Prec@1 94.680 Prec@5 99.860 Error@1 5.320

==>>[2018-05-04 15:00:38] [Epoch=117/540] [Need: 03:38:02] [learning_rate=0.010000] [Best : Accuracy=94.68, Error=5.32]
  Epoch: [117][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0120 (0.0120)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:00:38]
  Epoch: [117][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0380 (0.0240)   Prec@1 98.000 (99.408)   Prec@5 100.000 (100.000)   [2018-05-04 15:00:49]
  Epoch: [117][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0098 (0.0238)   Prec@1 100.000 (99.416)   Prec@5 100.000 (100.000)   [2018-05-04 15:01:00]
  **Train** Prec@1 99.408 Prec@5 99.998 Error@1 0.592
  **Test** Prec@1 94.440 Prec@5 99.860 Error@1 5.560

==>>[2018-05-04 15:01:08] [Epoch=118/540] [Need: 03:37:29] [learning_rate=0.010000] [Best : Accuracy=94.68, Error=5.32]
  Epoch: [118][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0205 (0.0205)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:01:08]
  Epoch: [118][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0275 (0.0234)   Prec@1 99.000 (99.403)   Prec@5 100.000 (99.995)   [2018-05-04 15:01:19]
  Epoch: [118][400/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.0295 (0.0255)   Prec@1 99.000 (99.324)   Prec@5 100.000 (99.998)   [2018-05-04 15:01:31]
  **Train** Prec@1 99.346 Prec@5 99.998 Error@1 0.654
  **Test** Prec@1 94.690 Prec@5 99.840 Error@1 5.310

==>>[2018-05-04 15:01:40] [Epoch=119/540] [Need: 03:37:00] [learning_rate=0.010000] [Best : Accuracy=94.69, Error=5.31]
  Epoch: [119][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0265 (0.0265)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:01:40]
  Epoch: [119][200/500]   Time 0.054 (0.060)   Data 0.000 (0.000)   Loss 0.0050 (0.0243)   Prec@1 100.000 (99.348)   Prec@5 100.000 (99.995)   [2018-05-04 15:01:52]
  Epoch: [119][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0179 (0.0242)   Prec@1 99.000 (99.342)   Prec@5 100.000 (99.998)   [2018-05-04 15:02:03]
  **Train** Prec@1 99.352 Prec@5 99.998 Error@1 0.648
  **Test** Prec@1 94.560 Prec@5 99.880 Error@1 5.440

==>>[2018-05-04 15:02:12] [Epoch=120/540] [Need: 03:36:33] [learning_rate=0.010000] [Best : Accuracy=94.69, Error=5.31]
  Epoch: [120][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0243 (0.0243)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:02:12]
  Epoch: [120][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0500 (0.0226)   Prec@1 99.000 (99.363)   Prec@5 100.000 (99.990)   [2018-05-04 15:02:23]
  Epoch: [120][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0341 (0.0236)   Prec@1 99.000 (99.344)   Prec@5 100.000 (99.995)   [2018-05-04 15:02:34]
  **Train** Prec@1 99.322 Prec@5 99.996 Error@1 0.678
  **Test** Prec@1 94.510 Prec@5 99.860 Error@1 5.490

==>>[2018-05-04 15:02:43] [Epoch=121/540] [Need: 03:36:03] [learning_rate=0.010000] [Best : Accuracy=94.69, Error=5.31]
  Epoch: [121][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0245 (0.0245)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:02:43]
  Epoch: [121][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0288 (0.0232)   Prec@1 99.000 (99.403)   Prec@5 100.000 (100.000)   [2018-05-04 15:02:54]
  Epoch: [121][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0142 (0.0225)   Prec@1 100.000 (99.409)   Prec@5 100.000 (100.000)   [2018-05-04 15:03:06]
  **Train** Prec@1 99.414 Prec@5 99.998 Error@1 0.586
  **Test** Prec@1 94.660 Prec@5 99.870 Error@1 5.340

==>>[2018-05-04 15:03:15] [Epoch=122/540] [Need: 03:35:35] [learning_rate=0.010000] [Best : Accuracy=94.69, Error=5.31]
  Epoch: [122][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:03:15]
  Epoch: [122][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0063 (0.0226)   Prec@1 100.000 (99.428)   Prec@5 100.000 (100.000)   [2018-05-04 15:03:26]
  Epoch: [122][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0105 (0.0218)   Prec@1 100.000 (99.466)   Prec@5 100.000 (100.000)   [2018-05-04 15:03:37]
  **Train** Prec@1 99.454 Prec@5 99.998 Error@1 0.546
  **Test** Prec@1 94.600 Prec@5 99.840 Error@1 5.400

==>>[2018-05-04 15:03:45] [Epoch=123/540] [Need: 03:35:02] [learning_rate=0.010000] [Best : Accuracy=94.69, Error=5.31]
  Epoch: [123][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0291 (0.0291)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:03:45]
  Epoch: [123][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0180 (0.0220)   Prec@1 99.000 (99.428)   Prec@5 100.000 (100.000)   [2018-05-04 15:03:56]
  Epoch: [123][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0177 (0.0214)   Prec@1 99.000 (99.474)   Prec@5 100.000 (99.998)   [2018-05-04 15:04:07]
  **Train** Prec@1 99.456 Prec@5 99.998 Error@1 0.544
  **Test** Prec@1 94.520 Prec@5 99.850 Error@1 5.480

==>>[2018-05-04 15:04:15] [Epoch=124/540] [Need: 03:34:28] [learning_rate=0.010000] [Best : Accuracy=94.69, Error=5.31]
  Epoch: [124][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:04:15]
  Epoch: [124][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0220 (0.0208)   Prec@1 99.000 (99.438)   Prec@5 100.000 (100.000)   [2018-05-04 15:04:26]
  Epoch: [124][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0057 (0.0205)   Prec@1 100.000 (99.434)   Prec@5 100.000 (100.000)   [2018-05-04 15:04:37]
  **Train** Prec@1 99.410 Prec@5 100.000 Error@1 0.590
  **Test** Prec@1 94.420 Prec@5 99.850 Error@1 5.580

==>>[2018-05-04 15:04:45] [Epoch=125/540] [Need: 03:33:54] [learning_rate=0.010000] [Best : Accuracy=94.69, Error=5.31]
  Epoch: [125][000/500]   Time 0.072 (0.072)   Data 0.045 (0.045)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:04:45]
  Epoch: [125][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0067 (0.0199)   Prec@1 100.000 (99.483)   Prec@5 100.000 (99.995)   [2018-05-04 15:04:56]
  Epoch: [125][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0670 (0.0214)   Prec@1 97.000 (99.424)   Prec@5 100.000 (99.998)   [2018-05-04 15:05:07]
  **Train** Prec@1 99.412 Prec@5 99.998 Error@1 0.588
  **Test** Prec@1 94.760 Prec@5 99.850 Error@1 5.240

==>>[2018-05-04 15:05:15] [Epoch=126/540] [Need: 03:33:21] [learning_rate=0.010000] [Best : Accuracy=94.76, Error=5.24]
  Epoch: [126][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:05:15]
  Epoch: [126][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0187)   Prec@1 100.000 (99.557)   Prec@5 100.000 (100.000)   [2018-05-04 15:05:26]
  Epoch: [126][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0115 (0.0197)   Prec@1 100.000 (99.511)   Prec@5 100.000 (99.998)   [2018-05-04 15:05:37]
  **Train** Prec@1 99.510 Prec@5 99.996 Error@1 0.490
  **Test** Prec@1 94.800 Prec@5 99.890 Error@1 5.200

==>>[2018-05-04 15:05:45] [Epoch=127/540] [Need: 03:32:47] [learning_rate=0.010000] [Best : Accuracy=94.80, Error=5.20]
  Epoch: [127][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0445 (0.0445)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:05:45]
  Epoch: [127][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0166 (0.0184)   Prec@1 99.000 (99.542)   Prec@5 100.000 (99.995)   [2018-05-04 15:05:56]
  Epoch: [127][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0122 (0.0192)   Prec@1 100.000 (99.509)   Prec@5 100.000 (99.998)   [2018-05-04 15:06:07]
  **Train** Prec@1 99.496 Prec@5 99.998 Error@1 0.504
  **Test** Prec@1 94.700 Prec@5 99.840 Error@1 5.300

==>>[2018-05-04 15:06:16] [Epoch=128/540] [Need: 03:32:14] [learning_rate=0.010000] [Best : Accuracy=94.80, Error=5.20]
  Epoch: [128][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0114 (0.0114)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:06:16]
  Epoch: [128][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0177 (0.0181)   Prec@1 100.000 (99.512)   Prec@5 100.000 (100.000)   [2018-05-04 15:06:27]
  Epoch: [128][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0199 (0.0185)   Prec@1 99.000 (99.514)   Prec@5 100.000 (100.000)   [2018-05-04 15:06:38]
  **Train** Prec@1 99.500 Prec@5 99.998 Error@1 0.500
  **Test** Prec@1 94.810 Prec@5 99.810 Error@1 5.190

==>>[2018-05-04 15:06:46] [Epoch=129/540] [Need: 03:31:42] [learning_rate=0.010000] [Best : Accuracy=94.81, Error=5.19]
  Epoch: [129][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:06:46]
  Epoch: [129][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0537 (0.0173)   Prec@1 98.000 (99.552)   Prec@5 100.000 (100.000)   [2018-05-04 15:06:58]
  Epoch: [129][400/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.0071 (0.0181)   Prec@1 100.000 (99.556)   Prec@5 100.000 (99.998)   [2018-05-04 15:07:09]
  **Train** Prec@1 99.524 Prec@5 99.998 Error@1 0.476
  **Test** Prec@1 94.720 Prec@5 99.860 Error@1 5.280

==>>[2018-05-04 15:07:17] [Epoch=130/540] [Need: 03:31:11] [learning_rate=0.010000] [Best : Accuracy=94.81, Error=5.19]
  Epoch: [130][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0121 (0.0121)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:07:17]
  Epoch: [130][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0307 (0.0163)   Prec@1 99.000 (99.637)   Prec@5 100.000 (100.000)   [2018-05-04 15:07:28]
  Epoch: [130][400/500]   Time 0.062 (0.057)   Data 0.000 (0.000)   Loss 0.0465 (0.0165)   Prec@1 99.000 (99.599)   Prec@5 100.000 (100.000)   [2018-05-04 15:07:40]
  **Train** Prec@1 99.602 Prec@5 100.000 Error@1 0.398
  **Test** Prec@1 94.830 Prec@5 99.840 Error@1 5.170

==>>[2018-05-04 15:07:48] [Epoch=131/540] [Need: 03:30:41] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [131][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:07:48]
  Epoch: [131][200/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0084 (0.0161)   Prec@1 100.000 (99.612)   Prec@5 100.000 (100.000)   [2018-05-04 15:07:59]
  Epoch: [131][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0459 (0.0170)   Prec@1 98.000 (99.564)   Prec@5 100.000 (99.998)   [2018-05-04 15:08:11]
  **Train** Prec@1 99.556 Prec@5 99.998 Error@1 0.444
  **Test** Prec@1 94.580 Prec@5 99.830 Error@1 5.420

==>>[2018-05-04 15:08:19] [Epoch=132/540] [Need: 03:30:10] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [132][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0210 (0.0210)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:08:19]
  Epoch: [132][200/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.0273 (0.0172)   Prec@1 99.000 (99.547)   Prec@5 100.000 (100.000)   [2018-05-04 15:08:30]
  Epoch: [132][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0194 (0.0190)   Prec@1 100.000 (99.501)   Prec@5 100.000 (99.998)   [2018-05-04 15:08:41]
  **Train** Prec@1 99.496 Prec@5 99.998 Error@1 0.504
  **Test** Prec@1 94.730 Prec@5 99.850 Error@1 5.270

==>>[2018-05-04 15:08:50] [Epoch=133/540] [Need: 03:29:38] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [133][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:08:50]
  Epoch: [133][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0105 (0.0155)   Prec@1 100.000 (99.637)   Prec@5 100.000 (100.000)   [2018-05-04 15:09:01]
  Epoch: [133][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0423 (0.0163)   Prec@1 99.000 (99.608)   Prec@5 100.000 (99.998)   [2018-05-04 15:09:12]
  **Train** Prec@1 99.586 Prec@5 99.998 Error@1 0.414
  **Test** Prec@1 94.590 Prec@5 99.830 Error@1 5.410

==>>[2018-05-04 15:09:21] [Epoch=134/540] [Need: 03:29:08] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [134][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0356 (0.0356)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:09:21]
  Epoch: [134][200/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0061 (0.0172)   Prec@1 100.000 (99.602)   Prec@5 100.000 (100.000)   [2018-05-04 15:09:32]
  Epoch: [134][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0066 (0.0182)   Prec@1 100.000 (99.531)   Prec@5 100.000 (100.000)   [2018-05-04 15:09:44]
  **Train** Prec@1 99.540 Prec@5 100.000 Error@1 0.460
  **Test** Prec@1 94.670 Prec@5 99.850 Error@1 5.330

==>>[2018-05-04 15:09:52] [Epoch=135/540] [Need: 03:28:38] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [135][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0212 (0.0212)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:09:52]
  Epoch: [135][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0487 (0.0168)   Prec@1 98.000 (99.512)   Prec@5 100.000 (100.000)   [2018-05-04 15:10:03]
  Epoch: [135][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0044 (0.0166)   Prec@1 100.000 (99.554)   Prec@5 100.000 (100.000)   [2018-05-04 15:10:14]
  **Train** Prec@1 99.546 Prec@5 100.000 Error@1 0.454
  **Test** Prec@1 94.600 Prec@5 99.860 Error@1 5.400

==>>[2018-05-04 15:10:23] [Epoch=136/540] [Need: 03:28:06] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [136][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:10:23]
  Epoch: [136][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0082 (0.0182)   Prec@1 100.000 (99.532)   Prec@5 100.000 (99.995)   [2018-05-04 15:10:34]
  Epoch: [136][400/500]   Time 0.059 (0.055)   Data 0.000 (0.000)   Loss 0.0090 (0.0170)   Prec@1 100.000 (99.579)   Prec@5 100.000 (99.995)   [2018-05-04 15:10:45]
  **Train** Prec@1 99.598 Prec@5 99.996 Error@1 0.402
  **Test** Prec@1 94.810 Prec@5 99.810 Error@1 5.190

==>>[2018-05-04 15:10:53] [Epoch=137/540] [Need: 03:27:34] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [137][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:10:53]
  Epoch: [137][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0160 (0.0172)   Prec@1 100.000 (99.562)   Prec@5 100.000 (100.000)   [2018-05-04 15:11:05]
  Epoch: [137][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0045 (0.0166)   Prec@1 100.000 (99.586)   Prec@5 100.000 (99.998)   [2018-05-04 15:11:16]
  **Train** Prec@1 99.560 Prec@5 99.998 Error@1 0.440
  **Test** Prec@1 94.710 Prec@5 99.850 Error@1 5.290

==>>[2018-05-04 15:11:25] [Epoch=138/540] [Need: 03:27:05] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [138][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0096 (0.0096)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:11:25]
  Epoch: [138][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0123 (0.0132)   Prec@1 100.000 (99.736)   Prec@5 100.000 (100.000)   [2018-05-04 15:11:36]
  Epoch: [138][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0178 (0.0135)   Prec@1 100.000 (99.733)   Prec@5 100.000 (100.000)   [2018-05-04 15:11:48]
  **Train** Prec@1 99.708 Prec@5 100.000 Error@1 0.292
  **Test** Prec@1 94.600 Prec@5 99.860 Error@1 5.400

==>>[2018-05-04 15:11:56] [Epoch=139/540] [Need: 03:26:35] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [139][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:11:56]
  Epoch: [139][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0052 (0.0145)   Prec@1 100.000 (99.597)   Prec@5 100.000 (100.000)   [2018-05-04 15:12:07]
  Epoch: [139][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0144 (0.0155)   Prec@1 100.000 (99.574)   Prec@5 100.000 (100.000)   [2018-05-04 15:12:19]
  **Train** Prec@1 99.568 Prec@5 100.000 Error@1 0.432
  **Test** Prec@1 94.860 Prec@5 99.850 Error@1 5.140

==>>[2018-05-04 15:12:27] [Epoch=140/540] [Need: 03:26:06] [learning_rate=0.010000] [Best : Accuracy=94.86, Error=5.14]
  Epoch: [140][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0119 (0.0119)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:12:27]
  Epoch: [140][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0097 (0.0152)   Prec@1 100.000 (99.667)   Prec@5 100.000 (100.000)   [2018-05-04 15:12:38]
  Epoch: [140][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0482 (0.0156)   Prec@1 99.000 (99.621)   Prec@5 100.000 (100.000)   [2018-05-04 15:12:49]
  **Train** Prec@1 99.614 Prec@5 100.000 Error@1 0.386
  **Test** Prec@1 94.810 Prec@5 99.820 Error@1 5.190

==>>[2018-05-04 15:12:58] [Epoch=141/540] [Need: 03:25:33] [learning_rate=0.010000] [Best : Accuracy=94.86, Error=5.14]
  Epoch: [141][000/500]   Time 0.073 (0.073)   Data 0.048 (0.048)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:12:58]
  Epoch: [141][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0146)   Prec@1 100.000 (99.677)   Prec@5 100.000 (100.000)   [2018-05-04 15:13:09]
  Epoch: [141][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0104 (0.0158)   Prec@1 100.000 (99.623)   Prec@5 100.000 (100.000)   [2018-05-04 15:13:19]
  **Train** Prec@1 99.612 Prec@5 100.000 Error@1 0.388
  **Test** Prec@1 94.670 Prec@5 99.810 Error@1 5.330

==>>[2018-05-04 15:13:28] [Epoch=142/540] [Need: 03:25:00] [learning_rate=0.010000] [Best : Accuracy=94.86, Error=5.14]
  Epoch: [142][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0114 (0.0114)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:13:28]
  Epoch: [142][200/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.0422 (0.0138)   Prec@1 99.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-04 15:13:39]
  Epoch: [142][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0336 (0.0149)   Prec@1 98.000 (99.628)   Prec@5 100.000 (100.000)   [2018-05-04 15:13:51]
  **Train** Prec@1 99.638 Prec@5 100.000 Error@1 0.362
  **Test** Prec@1 94.750 Prec@5 99.850 Error@1 5.250

==>>[2018-05-04 15:13:59] [Epoch=143/540] [Need: 03:24:31] [learning_rate=0.010000] [Best : Accuracy=94.86, Error=5.14]
  Epoch: [143][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0241 (0.0241)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:13:59]
  Epoch: [143][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0149 (0.0150)   Prec@1 99.000 (99.637)   Prec@5 100.000 (99.995)   [2018-05-04 15:14:11]
  Epoch: [143][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0082 (0.0149)   Prec@1 100.000 (99.648)   Prec@5 100.000 (99.998)   [2018-05-04 15:14:22]
  **Train** Prec@1 99.638 Prec@5 99.998 Error@1 0.362
  **Test** Prec@1 94.930 Prec@5 99.830 Error@1 5.070

==>>[2018-05-04 15:14:30] [Epoch=144/540] [Need: 03:23:59] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [144][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0143 (0.0143)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:14:30]
  Epoch: [144][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0130 (0.0144)   Prec@1 99.000 (99.652)   Prec@5 100.000 (100.000)   [2018-05-04 15:14:41]
  Epoch: [144][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0126 (0.0142)   Prec@1 100.000 (99.666)   Prec@5 100.000 (100.000)   [2018-05-04 15:14:52]
  **Train** Prec@1 99.650 Prec@5 100.000 Error@1 0.350
  **Test** Prec@1 94.570 Prec@5 99.810 Error@1 5.430

==>>[2018-05-04 15:15:01] [Epoch=145/540] [Need: 03:23:28] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [145][000/500]   Time 0.078 (0.078)   Data 0.050 (0.050)   Loss 0.0596 (0.0596)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:15:01]
  Epoch: [145][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0143)   Prec@1 100.000 (99.662)   Prec@5 100.000 (100.000)   [2018-05-04 15:15:12]
  Epoch: [145][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0138)   Prec@1 100.000 (99.681)   Prec@5 100.000 (100.000)   [2018-05-04 15:15:23]
  **Train** Prec@1 99.678 Prec@5 100.000 Error@1 0.322
  **Test** Prec@1 94.890 Prec@5 99.810 Error@1 5.110

==>>[2018-05-04 15:15:32] [Epoch=146/540] [Need: 03:22:57] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [146][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:15:32]
  Epoch: [146][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0155 (0.0135)   Prec@1 100.000 (99.701)   Prec@5 100.000 (99.995)   [2018-05-04 15:15:43]
  Epoch: [146][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0096 (0.0142)   Prec@1 100.000 (99.668)   Prec@5 100.000 (99.998)   [2018-05-04 15:15:54]
  **Train** Prec@1 99.672 Prec@5 99.998 Error@1 0.328
  **Test** Prec@1 94.750 Prec@5 99.850 Error@1 5.250

==>>[2018-05-04 15:16:02] [Epoch=147/540] [Need: 03:22:24] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [147][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:16:02]
  Epoch: [147][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0136)   Prec@1 100.000 (99.657)   Prec@5 100.000 (100.000)   [2018-05-04 15:16:13]
  Epoch: [147][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0162 (0.0137)   Prec@1 100.000 (99.663)   Prec@5 100.000 (100.000)   [2018-05-04 15:16:24]
  **Train** Prec@1 99.666 Prec@5 100.000 Error@1 0.334
  **Test** Prec@1 94.830 Prec@5 99.870 Error@1 5.170

==>>[2018-05-04 15:16:32] [Epoch=148/540] [Need: 03:21:51] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [148][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:16:32]
  Epoch: [148][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0107 (0.0122)   Prec@1 100.000 (99.706)   Prec@5 100.000 (100.000)   [2018-05-04 15:16:43]
  Epoch: [148][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0101 (0.0129)   Prec@1 100.000 (99.688)   Prec@5 100.000 (100.000)   [2018-05-04 15:16:54]
  **Train** Prec@1 99.692 Prec@5 100.000 Error@1 0.308
  **Test** Prec@1 94.800 Prec@5 99.780 Error@1 5.200

==>>[2018-05-04 15:17:02] [Epoch=149/540] [Need: 03:21:18] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [149][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0223 (0.0223)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:17:02]
  Epoch: [149][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0132 (0.0126)   Prec@1 100.000 (99.701)   Prec@5 100.000 (100.000)   [2018-05-04 15:17:13]
  Epoch: [149][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0136)   Prec@1 100.000 (99.686)   Prec@5 100.000 (100.000)   [2018-05-04 15:17:24]
  **Train** Prec@1 99.658 Prec@5 100.000 Error@1 0.342
  **Test** Prec@1 94.790 Prec@5 99.820 Error@1 5.210

==>>[2018-05-04 15:17:32] [Epoch=150/540] [Need: 03:20:45] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [150][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:17:32]
  Epoch: [150][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0096 (0.0125)   Prec@1 100.000 (99.731)   Prec@5 100.000 (100.000)   [2018-05-04 15:17:43]
  Epoch: [150][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0294 (0.0129)   Prec@1 99.000 (99.731)   Prec@5 100.000 (100.000)   [2018-05-04 15:17:54]
  **Train** Prec@1 99.728 Prec@5 100.000 Error@1 0.272
  **Test** Prec@1 94.600 Prec@5 99.830 Error@1 5.400

==>>[2018-05-04 15:18:02] [Epoch=151/540] [Need: 03:20:12] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [151][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0109 (0.0109)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:18:02]
  Epoch: [151][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0077 (0.0119)   Prec@1 100.000 (99.771)   Prec@5 100.000 (100.000)   [2018-05-04 15:18:13]
  Epoch: [151][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0275 (0.0124)   Prec@1 99.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:18:24]
  **Train** Prec@1 99.724 Prec@5 100.000 Error@1 0.276
  **Test** Prec@1 94.730 Prec@5 99.830 Error@1 5.270

==>>[2018-05-04 15:18:32] [Epoch=152/540] [Need: 03:19:39] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [152][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0157 (0.0157)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:18:32]
  Epoch: [152][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0141)   Prec@1 100.000 (99.726)   Prec@5 100.000 (100.000)   [2018-05-04 15:18:43]
  Epoch: [152][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0072 (0.0144)   Prec@1 100.000 (99.666)   Prec@5 100.000 (100.000)   [2018-05-04 15:18:54]
  **Train** Prec@1 99.672 Prec@5 100.000 Error@1 0.328
  **Test** Prec@1 94.820 Prec@5 99.840 Error@1 5.180

==>>[2018-05-04 15:19:02] [Epoch=153/540] [Need: 03:19:06] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [153][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:19:03]
  Epoch: [153][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0075 (0.0137)   Prec@1 100.000 (99.682)   Prec@5 100.000 (99.995)   [2018-05-04 15:19:13]
  Epoch: [153][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0133)   Prec@1 100.000 (99.708)   Prec@5 100.000 (99.995)   [2018-05-04 15:19:24]
  **Train** Prec@1 99.692 Prec@5 99.996 Error@1 0.308
  **Test** Prec@1 94.820 Prec@5 99.840 Error@1 5.180

==>>[2018-05-04 15:19:33] [Epoch=154/540] [Need: 03:18:34] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [154][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:19:33]
  Epoch: [154][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0255 (0.0131)   Prec@1 99.000 (99.731)   Prec@5 100.000 (100.000)   [2018-05-04 15:19:44]
  Epoch: [154][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0055 (0.0135)   Prec@1 100.000 (99.703)   Prec@5 100.000 (100.000)   [2018-05-04 15:19:55]
  **Train** Prec@1 99.706 Prec@5 100.000 Error@1 0.294
  **Test** Prec@1 94.860 Prec@5 99.860 Error@1 5.140

==>>[2018-05-04 15:20:03] [Epoch=155/540] [Need: 03:18:01] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [155][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:20:03]
  Epoch: [155][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0196 (0.0121)   Prec@1 99.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-04 15:20:14]
  Epoch: [155][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0091 (0.0130)   Prec@1 100.000 (99.696)   Prec@5 100.000 (100.000)   [2018-05-04 15:20:24]
  **Train** Prec@1 99.702 Prec@5 100.000 Error@1 0.298
  **Test** Prec@1 94.570 Prec@5 99.820 Error@1 5.430

==>>[2018-05-04 15:20:33] [Epoch=156/540] [Need: 03:17:28] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [156][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0175 (0.0175)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:20:33]
  Epoch: [156][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0055 (0.0135)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-04 15:20:44]
  Epoch: [156][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0059 (0.0132)   Prec@1 100.000 (99.701)   Prec@5 100.000 (100.000)   [2018-05-04 15:20:55]
  **Train** Prec@1 99.692 Prec@5 100.000 Error@1 0.308
  **Test** Prec@1 94.900 Prec@5 99.820 Error@1 5.100

==>>[2018-05-04 15:21:03] [Epoch=157/540] [Need: 03:16:57] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [157][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0345 (0.0345)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:21:03]
  Epoch: [157][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0162 (0.0129)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-04 15:21:14]
  Epoch: [157][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0240 (0.0130)   Prec@1 99.000 (99.696)   Prec@5 100.000 (100.000)   [2018-05-04 15:21:25]
  **Train** Prec@1 99.672 Prec@5 100.000 Error@1 0.328
  **Test** Prec@1 94.730 Prec@5 99.840 Error@1 5.270

==>>[2018-05-04 15:21:33] [Epoch=158/540] [Need: 03:16:24] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [158][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0185 (0.0185)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:21:34]
  Epoch: [158][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0279 (0.0125)   Prec@1 99.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-04 15:21:44]
  Epoch: [158][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0219 (0.0127)   Prec@1 99.000 (99.701)   Prec@5 100.000 (100.000)   [2018-05-04 15:21:55]
  **Train** Prec@1 99.706 Prec@5 100.000 Error@1 0.294
  **Test** Prec@1 94.870 Prec@5 99.830 Error@1 5.130

==>>[2018-05-04 15:22:04] [Epoch=159/540] [Need: 03:15:51] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [159][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:22:04]
  Epoch: [159][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0075 (0.0110)   Prec@1 100.000 (99.806)   Prec@5 100.000 (100.000)   [2018-05-04 15:22:15]
  Epoch: [159][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0119)   Prec@1 100.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:22:25]
  **Train** Prec@1 99.740 Prec@5 100.000 Error@1 0.260
  **Test** Prec@1 94.870 Prec@5 99.820 Error@1 5.130

==>>[2018-05-04 15:22:34] [Epoch=160/540] [Need: 03:15:19] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [160][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:22:34]
  Epoch: [160][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0106 (0.0102)   Prec@1 100.000 (99.806)   Prec@5 100.000 (100.000)   [2018-05-04 15:22:45]
  Epoch: [160][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0116)   Prec@1 100.000 (99.753)   Prec@5 100.000 (100.000)   [2018-05-04 15:22:56]
  **Train** Prec@1 99.744 Prec@5 100.000 Error@1 0.256
  **Test** Prec@1 94.850 Prec@5 99.830 Error@1 5.150

==>>[2018-05-04 15:23:04] [Epoch=161/540] [Need: 03:14:46] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [161][000/500]   Time 0.072 (0.072)   Data 0.045 (0.045)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:23:04]
  Epoch: [161][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0156 (0.0119)   Prec@1 99.000 (99.716)   Prec@5 100.000 (100.000)   [2018-05-04 15:23:15]
  Epoch: [161][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0141 (0.0127)   Prec@1 100.000 (99.706)   Prec@5 100.000 (100.000)   [2018-05-04 15:23:26]
  **Train** Prec@1 99.702 Prec@5 100.000 Error@1 0.298
  **Test** Prec@1 94.880 Prec@5 99.830 Error@1 5.120

==>>[2018-05-04 15:23:34] [Epoch=162/540] [Need: 03:14:14] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [162][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0117 (0.0117)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:23:34]
  Epoch: [162][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0245 (0.0118)   Prec@1 99.000 (99.766)   Prec@5 100.000 (100.000)   [2018-05-04 15:23:45]
  Epoch: [162][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0462 (0.0128)   Prec@1 99.000 (99.746)   Prec@5 100.000 (100.000)   [2018-05-04 15:23:56]
  **Train** Prec@1 99.742 Prec@5 100.000 Error@1 0.258
  **Test** Prec@1 94.770 Prec@5 99.830 Error@1 5.230

==>>[2018-05-04 15:24:04] [Epoch=163/540] [Need: 03:13:41] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [163][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:24:04]
  Epoch: [163][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0093 (0.0105)   Prec@1 100.000 (99.801)   Prec@5 100.000 (100.000)   [2018-05-04 15:24:15]
  Epoch: [163][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0264 (0.0110)   Prec@1 99.000 (99.783)   Prec@5 100.000 (100.000)   [2018-05-04 15:24:26]
  **Train** Prec@1 99.780 Prec@5 100.000 Error@1 0.220
  **Test** Prec@1 94.780 Prec@5 99.890 Error@1 5.220

==>>[2018-05-04 15:24:34] [Epoch=164/540] [Need: 03:13:09] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [164][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:24:34]
  Epoch: [164][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0126)   Prec@1 100.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:24:45]
  Epoch: [164][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0057 (0.0114)   Prec@1 100.000 (99.783)   Prec@5 100.000 (100.000)   [2018-05-04 15:24:56]
  **Train** Prec@1 99.766 Prec@5 100.000 Error@1 0.234
  **Test** Prec@1 94.820 Prec@5 99.830 Error@1 5.180

==>>[2018-05-04 15:25:04] [Epoch=165/540] [Need: 03:12:36] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [165][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:25:04]
  Epoch: [165][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0124)   Prec@1 100.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-04 15:25:15]
  Epoch: [165][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0125)   Prec@1 100.000 (99.721)   Prec@5 100.000 (100.000)   [2018-05-04 15:25:26]
  **Train** Prec@1 99.716 Prec@5 100.000 Error@1 0.284
  **Test** Prec@1 94.750 Prec@5 99.840 Error@1 5.250

==>>[2018-05-04 15:25:34] [Epoch=166/540] [Need: 03:12:04] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [166][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0103 (0.0103)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:25:34]
  Epoch: [166][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0121 (0.0128)   Prec@1 100.000 (99.731)   Prec@5 100.000 (100.000)   [2018-05-04 15:25:45]
  Epoch: [166][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0178 (0.0135)   Prec@1 99.000 (99.696)   Prec@5 100.000 (100.000)   [2018-05-04 15:25:56]
  **Train** Prec@1 99.696 Prec@5 100.000 Error@1 0.304
  **Test** Prec@1 94.690 Prec@5 99.860 Error@1 5.310

==>>[2018-05-04 15:26:04] [Epoch=167/540] [Need: 03:11:31] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [167][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:26:04]
  Epoch: [167][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0129)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-04 15:26:15]
  Epoch: [167][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0131)   Prec@1 100.000 (99.706)   Prec@5 100.000 (100.000)   [2018-05-04 15:26:26]
  **Train** Prec@1 99.706 Prec@5 100.000 Error@1 0.294
  **Test** Prec@1 94.750 Prec@5 99.790 Error@1 5.250

==>>[2018-05-04 15:26:34] [Epoch=168/540] [Need: 03:10:59] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [168][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:26:34]
  Epoch: [168][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0094 (0.0129)   Prec@1 100.000 (99.662)   Prec@5 100.000 (100.000)   [2018-05-04 15:26:45]
  Epoch: [168][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0127)   Prec@1 100.000 (99.698)   Prec@5 100.000 (100.000)   [2018-05-04 15:26:56]
  **Train** Prec@1 99.686 Prec@5 99.998 Error@1 0.314
  **Test** Prec@1 94.840 Prec@5 99.840 Error@1 5.160

==>>[2018-05-04 15:27:05] [Epoch=169/540] [Need: 03:10:26] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [169][000/500]   Time 0.072 (0.072)   Data 0.045 (0.045)   Loss 0.0102 (0.0102)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:27:05]
  Epoch: [169][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0051 (0.0121)   Prec@1 100.000 (99.751)   Prec@5 100.000 (100.000)   [2018-05-04 15:27:16]
  Epoch: [169][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0139 (0.0128)   Prec@1 100.000 (99.708)   Prec@5 100.000 (99.998)   [2018-05-04 15:27:26]
  **Train** Prec@1 99.730 Prec@5 99.996 Error@1 0.270
  **Test** Prec@1 94.890 Prec@5 99.850 Error@1 5.110

==>>[2018-05-04 15:27:35] [Epoch=170/540] [Need: 03:09:54] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [170][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0434 (0.0434)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:27:35]
  Epoch: [170][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0118 (0.0128)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-04 15:27:46]
  Epoch: [170][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0066 (0.0119)   Prec@1 100.000 (99.733)   Prec@5 100.000 (100.000)   [2018-05-04 15:27:57]
  **Train** Prec@1 99.730 Prec@5 99.998 Error@1 0.270
  **Test** Prec@1 94.590 Prec@5 99.840 Error@1 5.410

==>>[2018-05-04 15:28:05] [Epoch=171/540] [Need: 03:09:22] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [171][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0663 (0.0663)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:28:05]
  Epoch: [171][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0072 (0.0109)   Prec@1 100.000 (99.781)   Prec@5 100.000 (100.000)   [2018-05-04 15:28:16]
  Epoch: [171][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0258 (0.0121)   Prec@1 99.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:28:27]
  **Train** Prec@1 99.754 Prec@5 100.000 Error@1 0.246
  **Test** Prec@1 94.590 Prec@5 99.810 Error@1 5.410

==>>[2018-05-04 15:28:35] [Epoch=172/540] [Need: 03:08:50] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [172][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0574 (0.0574)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:28:35]
  Epoch: [172][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0062 (0.0133)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-04 15:28:46]
  Epoch: [172][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0059 (0.0131)   Prec@1 100.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-04 15:28:57]
  **Train** Prec@1 99.712 Prec@5 100.000 Error@1 0.288
  **Test** Prec@1 94.680 Prec@5 99.870 Error@1 5.320

==>>[2018-05-04 15:29:05] [Epoch=173/540] [Need: 03:08:18] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [173][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:29:05]
  Epoch: [173][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0123)   Prec@1 100.000 (99.687)   Prec@5 100.000 (100.000)   [2018-05-04 15:29:16]
  Epoch: [173][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0343 (0.0127)   Prec@1 99.000 (99.688)   Prec@5 100.000 (100.000)   [2018-05-04 15:29:27]
  **Train** Prec@1 99.692 Prec@5 100.000 Error@1 0.308
  **Test** Prec@1 94.460 Prec@5 99.820 Error@1 5.540

==>>[2018-05-04 15:29:35] [Epoch=174/540] [Need: 03:07:45] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [174][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:29:35]
  Epoch: [174][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0133)   Prec@1 100.000 (99.751)   Prec@5 100.000 (100.000)   [2018-05-04 15:29:46]
  Epoch: [174][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0267 (0.0129)   Prec@1 99.000 (99.728)   Prec@5 100.000 (100.000)   [2018-05-04 15:29:57]
  **Train** Prec@1 99.734 Prec@5 100.000 Error@1 0.266
  **Test** Prec@1 94.740 Prec@5 99.840 Error@1 5.260

==>>[2018-05-04 15:30:05] [Epoch=175/540] [Need: 03:07:13] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [175][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:30:05]
  Epoch: [175][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0108)   Prec@1 100.000 (99.796)   Prec@5 100.000 (100.000)   [2018-05-04 15:30:16]
  Epoch: [175][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0255 (0.0115)   Prec@1 99.000 (99.763)   Prec@5 100.000 (100.000)   [2018-05-04 15:30:27]
  **Train** Prec@1 99.754 Prec@5 100.000 Error@1 0.246
  **Test** Prec@1 94.540 Prec@5 99.840 Error@1 5.460

==>>[2018-05-04 15:30:35] [Epoch=176/540] [Need: 03:06:41] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [176][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0110 (0.0110)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:30:35]
  Epoch: [176][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0113)   Prec@1 100.000 (99.786)   Prec@5 100.000 (100.000)   [2018-05-04 15:30:46]
  Epoch: [176][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0066 (0.0120)   Prec@1 100.000 (99.748)   Prec@5 100.000 (100.000)   [2018-05-04 15:30:57]
  **Train** Prec@1 99.736 Prec@5 100.000 Error@1 0.264
  **Test** Prec@1 94.860 Prec@5 99.840 Error@1 5.140

==>>[2018-05-04 15:31:05] [Epoch=177/540] [Need: 03:06:08] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [177][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0171 (0.0171)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:31:05]
  Epoch: [177][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0479 (0.0131)   Prec@1 99.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-04 15:31:16]
  Epoch: [177][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0335 (0.0127)   Prec@1 99.000 (99.703)   Prec@5 100.000 (100.000)   [2018-05-04 15:31:27]
  **Train** Prec@1 99.712 Prec@5 100.000 Error@1 0.288
  **Test** Prec@1 94.590 Prec@5 99.810 Error@1 5.410

==>>[2018-05-04 15:31:35] [Epoch=178/540] [Need: 03:05:36] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [178][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:31:35]
  Epoch: [178][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0126)   Prec@1 100.000 (99.706)   Prec@5 100.000 (99.995)   [2018-05-04 15:31:46]
  Epoch: [178][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0199 (0.0132)   Prec@1 99.000 (99.686)   Prec@5 100.000 (99.998)   [2018-05-04 15:31:57]
  **Train** Prec@1 99.672 Prec@5 99.998 Error@1 0.328
  **Test** Prec@1 94.750 Prec@5 99.860 Error@1 5.250

==>>[2018-05-04 15:32:05] [Epoch=179/540] [Need: 03:05:04] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [179][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:32:05]
  Epoch: [179][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0131)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-04 15:32:16]
  Epoch: [179][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0606 (0.0126)   Prec@1 98.000 (99.701)   Prec@5 100.000 (99.998)   [2018-05-04 15:32:27]
  **Train** Prec@1 99.710 Prec@5 99.998 Error@1 0.290
  **Test** Prec@1 94.660 Prec@5 99.880 Error@1 5.340

==>>[2018-05-04 15:32:35] [Epoch=180/540] [Need: 03:04:31] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [180][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0750 (0.0750)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:32:35]
  Epoch: [180][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0108)   Prec@1 100.000 (99.781)   Prec@5 100.000 (100.000)   [2018-05-04 15:32:46]
  Epoch: [180][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0115)   Prec@1 100.000 (99.748)   Prec@5 100.000 (100.000)   [2018-05-04 15:32:57]
  **Train** Prec@1 99.720 Prec@5 100.000 Error@1 0.280
  **Test** Prec@1 94.670 Prec@5 99.880 Error@1 5.330

==>>[2018-05-04 15:33:05] [Epoch=181/540] [Need: 03:03:59] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [181][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:33:05]
  Epoch: [181][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0167 (0.0138)   Prec@1 99.000 (99.692)   Prec@5 100.000 (100.000)   [2018-05-04 15:33:16]
  Epoch: [181][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0132)   Prec@1 100.000 (99.713)   Prec@5 100.000 (100.000)   [2018-05-04 15:33:27]
  **Train** Prec@1 99.708 Prec@5 99.998 Error@1 0.292
  **Test** Prec@1 94.720 Prec@5 99.770 Error@1 5.280

==>>[2018-05-04 15:33:36] [Epoch=182/540] [Need: 03:03:28] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [182][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:33:36]
  Epoch: [182][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0078 (0.0120)   Prec@1 100.000 (99.756)   Prec@5 100.000 (100.000)   [2018-05-04 15:33:47]
  Epoch: [182][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0096 (0.0123)   Prec@1 100.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:33:57]
  **Train** Prec@1 99.740 Prec@5 100.000 Error@1 0.260
  **Test** Prec@1 94.660 Prec@5 99.790 Error@1 5.340

==>>[2018-05-04 15:34:06] [Epoch=183/540] [Need: 03:02:55] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [183][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0101 (0.0101)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:34:06]
  Epoch: [183][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0123)   Prec@1 100.000 (99.736)   Prec@5 100.000 (100.000)   [2018-05-04 15:34:17]
  Epoch: [183][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0271 (0.0123)   Prec@1 99.000 (99.723)   Prec@5 100.000 (100.000)   [2018-05-04 15:34:27]
  **Train** Prec@1 99.692 Prec@5 100.000 Error@1 0.308
  **Test** Prec@1 94.630 Prec@5 99.760 Error@1 5.370

==>>[2018-05-04 15:34:35] [Epoch=184/540] [Need: 03:02:23] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [184][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0140 (0.0140)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:34:36]
  Epoch: [184][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0126)   Prec@1 100.000 (99.721)   Prec@5 100.000 (100.000)   [2018-05-04 15:34:47]
  Epoch: [184][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0173 (0.0124)   Prec@1 99.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:34:57]
  **Train** Prec@1 99.722 Prec@5 100.000 Error@1 0.278
  **Test** Prec@1 94.560 Prec@5 99.810 Error@1 5.440

==>>[2018-05-04 15:35:06] [Epoch=185/540] [Need: 03:01:51] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [185][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:35:06]
  Epoch: [185][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0150 (0.0120)   Prec@1 99.000 (99.751)   Prec@5 100.000 (100.000)   [2018-05-04 15:35:17]
  Epoch: [185][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0117 (0.0124)   Prec@1 100.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:35:28]
  **Train** Prec@1 99.728 Prec@5 99.998 Error@1 0.272
  **Test** Prec@1 94.800 Prec@5 99.820 Error@1 5.200

==>>[2018-05-04 15:35:36] [Epoch=186/540] [Need: 03:01:19] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [186][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0101 (0.0101)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:35:36]
  Epoch: [186][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0098)   Prec@1 100.000 (99.791)   Prec@5 100.000 (100.000)   [2018-05-04 15:35:47]
  Epoch: [186][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0091 (0.0114)   Prec@1 100.000 (99.773)   Prec@5 100.000 (100.000)   [2018-05-04 15:35:58]
  **Train** Prec@1 99.750 Prec@5 100.000 Error@1 0.250
  **Test** Prec@1 94.650 Prec@5 99.810 Error@1 5.350

==>>[2018-05-04 15:36:06] [Epoch=187/540] [Need: 03:00:47] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [187][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:36:06]
  Epoch: [187][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0216 (0.0122)   Prec@1 99.000 (99.701)   Prec@5 100.000 (100.000)   [2018-05-04 15:36:17]
  Epoch: [187][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0117)   Prec@1 100.000 (99.738)   Prec@5 100.000 (100.000)   [2018-05-04 15:36:28]
  **Train** Prec@1 99.748 Prec@5 100.000 Error@1 0.252
  **Test** Prec@1 94.640 Prec@5 99.800 Error@1 5.360

==>>[2018-05-04 15:36:36] [Epoch=188/540] [Need: 03:00:15] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [188][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:36:36]
  Epoch: [188][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0073 (0.0124)   Prec@1 100.000 (99.746)   Prec@5 100.000 (100.000)   [2018-05-04 15:36:47]
  Epoch: [188][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0169 (0.0134)   Prec@1 99.000 (99.698)   Prec@5 100.000 (100.000)   [2018-05-04 15:36:58]
  **Train** Prec@1 99.690 Prec@5 100.000 Error@1 0.310
  **Test** Prec@1 94.540 Prec@5 99.780 Error@1 5.460

==>>[2018-05-04 15:37:06] [Epoch=189/540] [Need: 02:59:43] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [189][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:37:06]
  Epoch: [189][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0055 (0.0131)   Prec@1 100.000 (99.716)   Prec@5 100.000 (100.000)   [2018-05-04 15:37:17]
  Epoch: [189][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0130 (0.0138)   Prec@1 100.000 (99.688)   Prec@5 100.000 (100.000)   [2018-05-04 15:37:28]
  **Train** Prec@1 99.670 Prec@5 100.000 Error@1 0.330
  **Test** Prec@1 94.430 Prec@5 99.780 Error@1 5.570

==>>[2018-05-04 15:37:36] [Epoch=190/540] [Need: 02:59:11] [learning_rate=0.010000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [190][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:37:36]
  Epoch: [190][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0124)   Prec@1 100.000 (99.706)   Prec@5 100.000 (100.000)   [2018-05-04 15:37:47]
  Epoch: [190][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0071 (0.0124)   Prec@1 100.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-04 15:37:58]
  **Train** Prec@1 99.726 Prec@5 100.000 Error@1 0.274
  **Test** Prec@1 94.740 Prec@5 99.780 Error@1 5.260

==>>[2018-05-04 15:38:06] [Epoch=191/540] [Need: 02:58:39] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [191][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:38:06]
  Epoch: [191][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0207 (0.0119)   Prec@1 98.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-04 15:38:17]
  Epoch: [191][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0331 (0.0116)   Prec@1 99.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-04 15:38:28]
  **Train** Prec@1 99.744 Prec@5 100.000 Error@1 0.256
  **Test** Prec@1 94.730 Prec@5 99.820 Error@1 5.270

==>>[2018-05-04 15:38:36] [Epoch=192/540] [Need: 02:58:07] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [192][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0219 (0.0219)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:38:36]
  Epoch: [192][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0097)   Prec@1 100.000 (99.811)   Prec@5 100.000 (100.000)   [2018-05-04 15:38:47]
  Epoch: [192][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0096 (0.0100)   Prec@1 100.000 (99.818)   Prec@5 100.000 (100.000)   [2018-05-04 15:38:58]
  **Train** Prec@1 99.812 Prec@5 100.000 Error@1 0.188
  **Test** Prec@1 94.850 Prec@5 99.830 Error@1 5.150

==>>[2018-05-04 15:39:06] [Epoch=193/540] [Need: 02:57:35] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [193][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0313 (0.0313)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:39:06]
  Epoch: [193][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0087)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-05-04 15:39:17]
  Epoch: [193][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0131 (0.0088)   Prec@1 100.000 (99.853)   Prec@5 100.000 (100.000)   [2018-05-04 15:39:28]
  **Train** Prec@1 99.848 Prec@5 100.000 Error@1 0.152
  **Test** Prec@1 94.800 Prec@5 99.800 Error@1 5.200

==>>[2018-05-04 15:39:36] [Epoch=194/540] [Need: 02:57:03] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [194][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:39:36]
  Epoch: [194][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0132 (0.0083)   Prec@1 100.000 (99.851)   Prec@5 100.000 (100.000)   [2018-05-04 15:39:47]
  Epoch: [194][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0088)   Prec@1 100.000 (99.843)   Prec@5 100.000 (100.000)   [2018-05-04 15:39:58]
  **Train** Prec@1 99.842 Prec@5 100.000 Error@1 0.158
  **Test** Prec@1 94.830 Prec@5 99.790 Error@1 5.170

==>>[2018-05-04 15:40:06] [Epoch=195/540] [Need: 02:56:31] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [195][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:40:06]
  Epoch: [195][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0051 (0.0093)   Prec@1 100.000 (99.836)   Prec@5 100.000 (100.000)   [2018-05-04 15:40:17]
  Epoch: [195][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0093)   Prec@1 100.000 (99.810)   Prec@5 100.000 (100.000)   [2018-05-04 15:40:28]
  **Train** Prec@1 99.820 Prec@5 100.000 Error@1 0.180
  **Test** Prec@1 94.760 Prec@5 99.840 Error@1 5.240

==>>[2018-05-04 15:40:36] [Epoch=196/540] [Need: 02:55:59] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [196][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0106 (0.0106)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:40:36]
  Epoch: [196][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0206 (0.0083)   Prec@1 99.000 (99.871)   Prec@5 100.000 (100.000)   [2018-05-04 15:40:47]
  Epoch: [196][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0069 (0.0084)   Prec@1 100.000 (99.868)   Prec@5 100.000 (99.998)   [2018-05-04 15:40:58]
  **Train** Prec@1 99.860 Prec@5 99.998 Error@1 0.140
  **Test** Prec@1 94.790 Prec@5 99.840 Error@1 5.210

==>>[2018-05-04 15:41:06] [Epoch=197/540] [Need: 02:55:27] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [197][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:41:06]
  Epoch: [197][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0081)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-05-04 15:41:17]
  Epoch: [197][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0083)   Prec@1 100.000 (99.855)   Prec@5 100.000 (100.000)   [2018-05-04 15:41:28]
  **Train** Prec@1 99.854 Prec@5 100.000 Error@1 0.146
  **Test** Prec@1 94.890 Prec@5 99.810 Error@1 5.110

==>>[2018-05-04 15:41:36] [Epoch=198/540] [Need: 02:54:55] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [198][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:41:36]
  Epoch: [198][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0076)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-05-04 15:41:47]
  Epoch: [198][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0057 (0.0080)   Prec@1 100.000 (99.870)   Prec@5 100.000 (100.000)   [2018-05-04 15:41:58]
  **Train** Prec@1 99.872 Prec@5 100.000 Error@1 0.128
  **Test** Prec@1 94.870 Prec@5 99.840 Error@1 5.130

==>>[2018-05-04 15:42:06] [Epoch=199/540] [Need: 02:54:24] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [199][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:42:06]
  Epoch: [199][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0079)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 15:42:17]
  Epoch: [199][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0055 (0.0077)   Prec@1 100.000 (99.905)   Prec@5 100.000 (99.998)   [2018-05-04 15:42:28]
  **Train** Prec@1 99.898 Prec@5 99.998 Error@1 0.102
  **Test** Prec@1 94.890 Prec@5 99.840 Error@1 5.110

==>>[2018-05-04 15:42:36] [Epoch=200/540] [Need: 02:53:52] [learning_rate=0.001000] [Best : Accuracy=94.93, Error=5.07]
  Epoch: [200][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:42:36]
  Epoch: [200][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0085)   Prec@1 100.000 (99.836)   Prec@5 100.000 (100.000)   [2018-05-04 15:42:47]
  Epoch: [200][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0026 (0.0087)   Prec@1 100.000 (99.845)   Prec@5 100.000 (100.000)   [2018-05-04 15:42:58]
  **Train** Prec@1 99.842 Prec@5 100.000 Error@1 0.158
  **Test** Prec@1 95.000 Prec@5 99.830 Error@1 5.000

==>>[2018-05-04 15:43:06] [Epoch=201/540] [Need: 02:53:21] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [201][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:43:06]
  Epoch: [201][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0060 (0.0079)   Prec@1 100.000 (99.866)   Prec@5 100.000 (100.000)   [2018-05-04 15:43:17]
  Epoch: [201][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0078)   Prec@1 100.000 (99.863)   Prec@5 100.000 (100.000)   [2018-05-04 15:43:28]
  **Train** Prec@1 99.860 Prec@5 100.000 Error@1 0.140
  **Test** Prec@1 94.880 Prec@5 99.810 Error@1 5.120

==>>[2018-05-04 15:43:36] [Epoch=202/540] [Need: 02:52:49] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [202][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:43:36]
  Epoch: [202][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0065 (0.0076)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 15:43:47]
  Epoch: [202][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0081)   Prec@1 100.000 (99.863)   Prec@5 100.000 (100.000)   [2018-05-04 15:43:58]
  **Train** Prec@1 99.870 Prec@5 100.000 Error@1 0.130
  **Test** Prec@1 94.860 Prec@5 99.840 Error@1 5.140

==>>[2018-05-04 15:44:06] [Epoch=203/540] [Need: 02:52:17] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [203][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:44:06]
  Epoch: [203][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0095 (0.0069)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 15:44:17]
  Epoch: [203][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0066 (0.0071)   Prec@1 100.000 (99.888)   Prec@5 100.000 (100.000)   [2018-05-04 15:44:28]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 94.930 Prec@5 99.820 Error@1 5.070

==>>[2018-05-04 15:44:36] [Epoch=204/540] [Need: 02:51:45] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [204][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:44:36]
  Epoch: [204][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0078)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-04 15:44:47]
  Epoch: [204][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0078)   Prec@1 100.000 (99.880)   Prec@5 100.000 (100.000)   [2018-05-04 15:44:58]
  **Train** Prec@1 99.874 Prec@5 100.000 Error@1 0.126
  **Test** Prec@1 94.910 Prec@5 99.800 Error@1 5.090

==>>[2018-05-04 15:45:06] [Epoch=205/540] [Need: 02:51:14] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [205][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0144 (0.0144)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:45:06]
  Epoch: [205][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0112 (0.0080)   Prec@1 100.000 (99.846)   Prec@5 100.000 (100.000)   [2018-05-04 15:45:17]
  Epoch: [205][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0104 (0.0076)   Prec@1 100.000 (99.878)   Prec@5 100.000 (100.000)   [2018-05-04 15:45:28]
  **Train** Prec@1 99.874 Prec@5 100.000 Error@1 0.126
  **Test** Prec@1 94.950 Prec@5 99.830 Error@1 5.050

==>>[2018-05-04 15:45:36] [Epoch=206/540] [Need: 02:50:42] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [206][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:45:36]
  Epoch: [206][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0074)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 15:45:47]
  Epoch: [206][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0073)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 15:45:58]
  **Train** Prec@1 99.890 Prec@5 100.000 Error@1 0.110
  **Test** Prec@1 94.940 Prec@5 99.830 Error@1 5.060

==>>[2018-05-04 15:46:06] [Epoch=207/540] [Need: 02:50:10] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [207][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:46:06]
  Epoch: [207][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0074)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 15:46:17]
  Epoch: [207][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0089 (0.0074)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-04 15:46:28]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 95.010 Prec@5 99.840 Error@1 4.990

==>>[2018-05-04 15:46:36] [Epoch=208/540] [Need: 02:49:38] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [208][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:46:36]
  Epoch: [208][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0068 (0.0082)   Prec@1 100.000 (99.856)   Prec@5 100.000 (100.000)   [2018-05-04 15:46:47]
  Epoch: [208][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0233 (0.0078)   Prec@1 99.000 (99.863)   Prec@5 100.000 (100.000)   [2018-05-04 15:46:58]
  **Train** Prec@1 99.868 Prec@5 100.000 Error@1 0.132
  **Test** Prec@1 94.870 Prec@5 99.860 Error@1 5.130

==>>[2018-05-04 15:47:06] [Epoch=209/540] [Need: 02:49:07] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [209][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0158 (0.0158)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:47:06]
  Epoch: [209][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0072)   Prec@1 100.000 (99.876)   Prec@5 100.000 (100.000)   [2018-05-04 15:47:17]
  Epoch: [209][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0140 (0.0074)   Prec@1 99.000 (99.885)   Prec@5 100.000 (100.000)   [2018-05-04 15:47:28]
  **Train** Prec@1 99.890 Prec@5 100.000 Error@1 0.110
  **Test** Prec@1 94.900 Prec@5 99.840 Error@1 5.100

==>>[2018-05-04 15:47:36] [Epoch=210/540] [Need: 02:48:35] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [210][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:47:36]
  Epoch: [210][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0105 (0.0075)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-05-04 15:47:47]
  Epoch: [210][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0074)   Prec@1 100.000 (99.888)   Prec@5 100.000 (100.000)   [2018-05-04 15:47:58]
  **Train** Prec@1 99.888 Prec@5 100.000 Error@1 0.112
  **Test** Prec@1 94.900 Prec@5 99.850 Error@1 5.100

==>>[2018-05-04 15:48:06] [Epoch=211/540] [Need: 02:48:03] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [211][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:48:06]
  Epoch: [211][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0072)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 15:48:17]
  Epoch: [211][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0068)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-05-04 15:48:28]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 94.930 Prec@5 99.820 Error@1 5.070

==>>[2018-05-04 15:48:36] [Epoch=212/540] [Need: 02:47:32] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [212][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:48:36]
  Epoch: [212][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0077)   Prec@1 100.000 (99.876)   Prec@5 100.000 (100.000)   [2018-05-04 15:48:47]
  Epoch: [212][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0078 (0.0076)   Prec@1 100.000 (99.873)   Prec@5 100.000 (100.000)   [2018-05-04 15:48:58]
  **Train** Prec@1 99.874 Prec@5 100.000 Error@1 0.126
  **Test** Prec@1 95.020 Prec@5 99.830 Error@1 4.980

==>>[2018-05-04 15:49:06] [Epoch=213/540] [Need: 02:47:00] [learning_rate=0.001000] [Best : Accuracy=95.02, Error=4.98]
  Epoch: [213][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:49:07]
  Epoch: [213][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0066 (0.0073)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-04 15:49:17]
  Epoch: [213][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0072)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-05-04 15:49:28]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 94.920 Prec@5 99.840 Error@1 5.080

==>>[2018-05-04 15:49:36] [Epoch=214/540] [Need: 02:46:29] [learning_rate=0.001000] [Best : Accuracy=95.02, Error=4.98]
  Epoch: [214][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0126 (0.0126)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:49:37]
  Epoch: [214][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0066)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 15:49:47]
  Epoch: [214][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0068)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-04 15:49:58]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 95.020 Prec@5 99.830 Error@1 4.980

==>>[2018-05-04 15:50:06] [Epoch=215/540] [Need: 02:45:57] [learning_rate=0.001000] [Best : Accuracy=95.02, Error=4.98]
  Epoch: [215][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:50:07]
  Epoch: [215][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0074)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-05-04 15:50:17]
  Epoch: [215][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0176 (0.0069)   Prec@1 100.000 (99.878)   Prec@5 100.000 (100.000)   [2018-05-04 15:50:28]
  **Train** Prec@1 99.872 Prec@5 100.000 Error@1 0.128
  **Test** Prec@1 95.030 Prec@5 99.840 Error@1 4.970

==>>[2018-05-04 15:50:36] [Epoch=216/540] [Need: 02:45:25] [learning_rate=0.001000] [Best : Accuracy=95.03, Error=4.97]
  Epoch: [216][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0103 (0.0103)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:50:37]
  Epoch: [216][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0092 (0.0069)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-04 15:50:47]
  Epoch: [216][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0075 (0.0069)   Prec@1 100.000 (99.893)   Prec@5 100.000 (100.000)   [2018-05-04 15:50:58]
  **Train** Prec@1 99.900 Prec@5 100.000 Error@1 0.100
  **Test** Prec@1 94.990 Prec@5 99.810 Error@1 5.010

==>>[2018-05-04 15:51:07] [Epoch=217/540] [Need: 02:44:54] [learning_rate=0.001000] [Best : Accuracy=95.03, Error=4.97]
  Epoch: [217][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:51:07]
  Epoch: [217][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0067)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 15:51:18]
  Epoch: [217][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0115 (0.0067)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-04 15:51:29]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 94.960 Prec@5 99.800 Error@1 5.040

==>>[2018-05-04 15:51:37] [Epoch=218/540] [Need: 02:44:22] [learning_rate=0.001000] [Best : Accuracy=95.03, Error=4.97]
  Epoch: [218][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:51:37]
  Epoch: [218][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0067)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 15:51:48]
  Epoch: [218][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0069)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-04 15:51:59]
  **Train** Prec@1 99.896 Prec@5 100.000 Error@1 0.104
  **Test** Prec@1 94.970 Prec@5 99.810 Error@1 5.030

==>>[2018-05-04 15:52:07] [Epoch=219/540] [Need: 02:43:51] [learning_rate=0.001000] [Best : Accuracy=95.03, Error=4.97]
  Epoch: [219][000/500]   Time 0.072 (0.072)   Data 0.047 (0.047)   Loss 0.0051 (0.0051)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:52:07]
  Epoch: [219][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0121 (0.0068)   Prec@1 99.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 15:52:18]
  Epoch: [219][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0050 (0.0067)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-05-04 15:52:29]
  **Train** Prec@1 99.904 Prec@5 100.000 Error@1 0.096
  **Test** Prec@1 95.060 Prec@5 99.840 Error@1 4.940

==>>[2018-05-04 15:52:37] [Epoch=220/540] [Need: 02:43:19] [learning_rate=0.001000] [Best : Accuracy=95.06, Error=4.94]
  Epoch: [220][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:52:37]
  Epoch: [220][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0065)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 15:52:48]
  Epoch: [220][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0094 (0.0070)   Prec@1 100.000 (99.893)   Prec@5 100.000 (100.000)   [2018-05-04 15:52:59]
  **Train** Prec@1 99.900 Prec@5 100.000 Error@1 0.100
  **Test** Prec@1 95.080 Prec@5 99.790 Error@1 4.920

==>>[2018-05-04 15:53:07] [Epoch=221/540] [Need: 02:42:48] [learning_rate=0.001000] [Best : Accuracy=95.08, Error=4.92]
  Epoch: [221][000/500]   Time 0.074 (0.074)   Data 0.046 (0.046)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:53:07]
  Epoch: [221][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0066)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 15:53:18]
  Epoch: [221][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0068)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-04 15:53:29]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 95.130 Prec@5 99.850 Error@1 4.870

==>>[2018-05-04 15:53:37] [Epoch=222/540] [Need: 02:42:16] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [222][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:53:37]
  Epoch: [222][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0104 (0.0062)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 15:53:48]
  Epoch: [222][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0056 (0.0058)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 15:53:59]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.060 Prec@5 99.810 Error@1 4.940

==>>[2018-05-04 15:54:07] [Epoch=223/540] [Need: 02:41:45] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [223][000/500]   Time 0.075 (0.075)   Data 0.050 (0.050)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:54:07]
  Epoch: [223][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0065)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 15:54:18]
  Epoch: [223][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0067)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 15:54:29]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 95.100 Prec@5 99.820 Error@1 4.900

==>>[2018-05-04 15:54:37] [Epoch=224/540] [Need: 02:41:13] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [224][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:54:37]
  Epoch: [224][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0067 (0.0065)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 15:54:48]
  Epoch: [224][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0113 (0.0069)   Prec@1 99.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 15:54:59]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 95.010 Prec@5 99.820 Error@1 4.990

==>>[2018-05-04 15:55:07] [Epoch=225/540] [Need: 02:40:42] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [225][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:55:07]
  Epoch: [225][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0070)   Prec@1 100.000 (99.876)   Prec@5 100.000 (99.995)   [2018-05-04 15:55:18]
  Epoch: [225][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0169 (0.0071)   Prec@1 99.000 (99.878)   Prec@5 100.000 (99.998)   [2018-05-04 15:55:29]
  **Train** Prec@1 99.886 Prec@5 99.998 Error@1 0.114
  **Test** Prec@1 95.010 Prec@5 99.830 Error@1 4.990

==>>[2018-05-04 15:55:37] [Epoch=226/540] [Need: 02:40:11] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [226][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:55:37]
  Epoch: [226][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0065)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 15:55:48]
  Epoch: [226][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0077 (0.0064)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 15:55:59]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.090 Prec@5 99.820 Error@1 4.910

==>>[2018-05-04 15:56:07] [Epoch=227/540] [Need: 02:39:39] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [227][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:56:07]
  Epoch: [227][200/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0064)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 15:56:18]
  Epoch: [227][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0062)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 15:56:29]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.100 Prec@5 99.840 Error@1 4.900

==>>[2018-05-04 15:56:37] [Epoch=228/540] [Need: 02:39:08] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [228][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:56:37]
  Epoch: [228][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0064)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 15:56:48]
  Epoch: [228][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0321 (0.0066)   Prec@1 99.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-04 15:56:59]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 94.970 Prec@5 99.840 Error@1 5.030

==>>[2018-05-04 15:57:07] [Epoch=229/540] [Need: 02:38:36] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [229][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:57:07]
  Epoch: [229][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0075 (0.0066)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 15:57:18]
  Epoch: [229][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0064)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-04 15:57:29]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 95.040 Prec@5 99.840 Error@1 4.960

==>>[2018-05-04 15:57:37] [Epoch=230/540] [Need: 02:38:05] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [230][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:57:37]
  Epoch: [230][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0056)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 15:57:48]
  Epoch: [230][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0065 (0.0056)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 15:57:59]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.070 Prec@5 99.830 Error@1 4.930

==>>[2018-05-04 15:58:07] [Epoch=231/540] [Need: 02:37:34] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [231][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0114 (0.0114)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:58:07]
  Epoch: [231][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0068)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 15:58:18]
  Epoch: [231][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0066)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-05-04 15:58:29]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 95.010 Prec@5 99.810 Error@1 4.990

==>>[2018-05-04 15:58:37] [Epoch=232/540] [Need: 02:37:02] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [232][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:58:37]
  Epoch: [232][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0061)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 15:58:48]
  Epoch: [232][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0069)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-05-04 15:58:59]
  **Train** Prec@1 99.894 Prec@5 100.000 Error@1 0.106
  **Test** Prec@1 94.960 Prec@5 99.850 Error@1 5.040

==>>[2018-05-04 15:59:07] [Epoch=233/540] [Need: 02:36:31] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [233][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:59:07]
  Epoch: [233][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 15:59:18]
  Epoch: [233][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0062)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 15:59:29]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.020 Prec@5 99.820 Error@1 4.980

==>>[2018-05-04 15:59:37] [Epoch=234/540] [Need: 02:36:00] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [234][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 15:59:37]
  Epoch: [234][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0186 (0.0070)   Prec@1 99.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 15:59:48]
  Epoch: [234][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0094 (0.0070)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-04 15:59:59]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 95.070 Prec@5 99.810 Error@1 4.930

==>>[2018-05-04 16:00:07] [Epoch=235/540] [Need: 02:35:28] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [235][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:00:07]
  Epoch: [235][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0064)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 16:00:18]
  Epoch: [235][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0063 (0.0066)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 16:00:29]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 94.920 Prec@5 99.820 Error@1 5.080

==>>[2018-05-04 16:00:37] [Epoch=236/540] [Need: 02:34:57] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [236][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0123 (0.0123)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:00:37]
  Epoch: [236][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0063 (0.0063)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:00:48]
  Epoch: [236][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0061)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-04 16:00:59]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 95.070 Prec@5 99.810 Error@1 4.930

==>>[2018-05-04 16:01:07] [Epoch=237/540] [Need: 02:34:26] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [237][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:01:07]
  Epoch: [237][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0139 (0.0064)   Prec@1 99.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:01:18]
  Epoch: [237][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0102 (0.0067)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-04 16:01:29]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 95.120 Prec@5 99.830 Error@1 4.880

==>>[2018-05-04 16:01:37] [Epoch=238/540] [Need: 02:33:54] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [238][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:01:37]
  Epoch: [238][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0064)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:01:48]
  Epoch: [238][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0065)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-04 16:01:59]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 94.950 Prec@5 99.790 Error@1 5.050

==>>[2018-05-04 16:02:08] [Epoch=239/540] [Need: 02:33:24] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [239][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:02:08]
  Epoch: [239][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0071)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-05-04 16:02:19]
  Epoch: [239][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0066)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 16:02:29]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 95.090 Prec@5 99.840 Error@1 4.910

==>>[2018-05-04 16:02:38] [Epoch=240/540] [Need: 02:32:52] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [240][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:02:38]
  Epoch: [240][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0065)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:02:49]
  Epoch: [240][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0068)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-04 16:02:59]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 95.110 Prec@5 99.830 Error@1 4.890

==>>[2018-05-04 16:03:08] [Epoch=241/540] [Need: 02:32:21] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [241][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:03:08]
  Epoch: [241][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0124 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:03:19]
  Epoch: [241][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0078 (0.0060)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:03:30]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.050 Prec@5 99.800 Error@1 4.950

==>>[2018-05-04 16:03:38] [Epoch=242/540] [Need: 02:31:50] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [242][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:03:38]
  Epoch: [242][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0096 (0.0064)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:03:49]
  Epoch: [242][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0059 (0.0064)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 16:04:00]
  **Train** Prec@1 99.916 Prec@5 99.998 Error@1 0.084
  **Test** Prec@1 95.010 Prec@5 99.840 Error@1 4.990

==>>[2018-05-04 16:04:08] [Epoch=243/540] [Need: 02:31:19] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [243][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:04:08]
  Epoch: [243][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:04:19]
  Epoch: [243][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0083 (0.0067)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 16:04:30]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 95.120 Prec@5 99.790 Error@1 4.880

==>>[2018-05-04 16:04:38] [Epoch=244/540] [Need: 02:30:47] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [244][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:04:38]
  Epoch: [244][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0069)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 16:04:49]
  Epoch: [244][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0066)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 16:05:00]
  **Train** Prec@1 99.896 Prec@5 100.000 Error@1 0.104
  **Test** Prec@1 95.090 Prec@5 99.790 Error@1 4.910

==>>[2018-05-04 16:05:08] [Epoch=245/540] [Need: 02:30:16] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [245][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:05:08]
  Epoch: [245][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0064)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:05:19]
  Epoch: [245][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0068 (0.0061)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 16:05:30]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.130 Prec@5 99.860 Error@1 4.870

==>>[2018-05-04 16:05:38] [Epoch=246/540] [Need: 02:29:45] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [246][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:05:38]
  Epoch: [246][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0586 (0.0076)   Prec@1 99.000 (99.866)   Prec@5 100.000 (100.000)   [2018-05-04 16:05:49]
  Epoch: [246][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0069)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-05-04 16:06:00]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 95.110 Prec@5 99.820 Error@1 4.890

==>>[2018-05-04 16:06:08] [Epoch=247/540] [Need: 02:29:14] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [247][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:06:08]
  Epoch: [247][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0050 (0.0068)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-05-04 16:06:19]
  Epoch: [247][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0065)   Prec@1 100.000 (99.898)   Prec@5 100.000 (100.000)   [2018-05-04 16:06:30]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-05-04 16:06:38] [Epoch=248/540] [Need: 02:28:43] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [248][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:06:38]
  Epoch: [248][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0061)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:06:49]
  Epoch: [248][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0062)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 16:07:00]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 95.090 Prec@5 99.820 Error@1 4.910

==>>[2018-05-04 16:07:08] [Epoch=249/540] [Need: 02:28:11] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [249][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:07:08]
  Epoch: [249][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0067 (0.0060)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:07:19]
  Epoch: [249][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:07:30]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 95.060 Prec@5 99.810 Error@1 4.940

==>>[2018-05-04 16:07:38] [Epoch=250/540] [Need: 02:27:40] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [250][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:07:38]
  Epoch: [250][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0061)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:07:49]
  Epoch: [250][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0061)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 16:08:00]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.120 Prec@5 99.790 Error@1 4.880

==>>[2018-05-04 16:08:08] [Epoch=251/540] [Need: 02:27:09] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [251][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0187 (0.0187)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:08:08]
  Epoch: [251][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0093 (0.0061)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:08:19]
  Epoch: [251][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0064)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 16:08:30]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.100 Prec@5 99.830 Error@1 4.900

==>>[2018-05-04 16:08:38] [Epoch=252/540] [Need: 02:26:38] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [252][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:08:38]
  Epoch: [252][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0061)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:08:49]
  Epoch: [252][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0100 (0.0060)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:09:00]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.160 Prec@5 99.840 Error@1 4.840

==>>[2018-05-04 16:09:08] [Epoch=253/540] [Need: 02:26:07] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [253][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:09:08]
  Epoch: [253][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0069)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 16:09:19]
  Epoch: [253][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0066)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-04 16:09:30]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 95.090 Prec@5 99.840 Error@1 4.910

==>>[2018-05-04 16:09:38] [Epoch=254/540] [Need: 02:25:36] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [254][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:09:38]
  Epoch: [254][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0215 (0.0064)   Prec@1 99.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 16:09:49]
  Epoch: [254][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0061)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 16:10:00]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.020 Prec@5 99.800 Error@1 4.980

==>>[2018-05-04 16:10:08] [Epoch=255/540] [Need: 02:25:04] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [255][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:10:08]
  Epoch: [255][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:10:19]
  Epoch: [255][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0059)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 16:10:30]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.130 Prec@5 99.780 Error@1 4.870

==>>[2018-05-04 16:10:38] [Epoch=256/540] [Need: 02:24:33] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [256][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:10:38]
  Epoch: [256][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0063)   Prec@1 100.000 (99.925)   Prec@5 100.000 (99.995)   [2018-05-04 16:10:49]
  Epoch: [256][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0062)   Prec@1 100.000 (99.940)   Prec@5 100.000 (99.998)   [2018-05-04 16:11:00]
  **Train** Prec@1 99.938 Prec@5 99.998 Error@1 0.062
  **Test** Prec@1 95.070 Prec@5 99.860 Error@1 4.930

==>>[2018-05-04 16:11:08] [Epoch=257/540] [Need: 02:24:02] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [257][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:11:08]
  Epoch: [257][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0068)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 16:11:19]
  Epoch: [257][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0067)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 16:11:30]
  **Train** Prec@1 99.896 Prec@5 100.000 Error@1 0.104
  **Test** Prec@1 95.080 Prec@5 99.820 Error@1 4.920

==>>[2018-05-04 16:11:38] [Epoch=258/540] [Need: 02:23:31] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [258][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0051 (0.0051)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:11:38]
  Epoch: [258][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0062)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:11:49]
  Epoch: [258][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0061)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 16:12:00]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 95.080 Prec@5 99.820 Error@1 4.920

==>>[2018-05-04 16:12:08] [Epoch=259/540] [Need: 02:23:00] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [259][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:12:08]
  Epoch: [259][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:12:19]
  Epoch: [259][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:12:30]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.080 Prec@5 99.850 Error@1 4.920

==>>[2018-05-04 16:12:38] [Epoch=260/540] [Need: 02:22:29] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [260][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0141 (0.0141)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:12:38]
  Epoch: [260][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0057)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 16:12:49]
  Epoch: [260][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0059)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:13:00]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 95.040 Prec@5 99.810 Error@1 4.960

==>>[2018-05-04 16:13:08] [Epoch=261/540] [Need: 02:21:58] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [261][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:13:08]
  Epoch: [261][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0061)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:13:19]
  Epoch: [261][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0063)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-04 16:13:30]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.010 Prec@5 99.830 Error@1 4.990

==>>[2018-05-04 16:13:38] [Epoch=262/540] [Need: 02:21:27] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [262][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:13:38]
  Epoch: [262][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0057)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 16:13:49]
  Epoch: [262][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:14:00]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.050 Prec@5 99.830 Error@1 4.950

==>>[2018-05-04 16:14:08] [Epoch=263/540] [Need: 02:20:56] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [263][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:14:08]
  Epoch: [263][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0066)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:14:19]
  Epoch: [263][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0066)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-05-04 16:14:30]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 95.110 Prec@5 99.780 Error@1 4.890

==>>[2018-05-04 16:14:38] [Epoch=264/540] [Need: 02:20:25] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [264][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:14:39]
  Epoch: [264][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0065 (0.0062)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:14:50]
  Epoch: [264][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0062)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:15:01]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.010 Prec@5 99.840 Error@1 4.990

==>>[2018-05-04 16:15:10] [Epoch=265/540] [Need: 02:19:55] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [265][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:15:10]
  Epoch: [265][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0038 (0.0065)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:15:21]
  Epoch: [265][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0028 (0.0061)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 16:15:32]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.140 Prec@5 99.830 Error@1 4.860

==>>[2018-05-04 16:15:41] [Epoch=266/540] [Need: 02:19:25] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [266][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:15:41]
  Epoch: [266][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0060)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:15:52]
  Epoch: [266][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0062)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-04 16:16:04]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.090 Prec@5 99.830 Error@1 4.910

==>>[2018-05-04 16:16:12] [Epoch=267/540] [Need: 02:18:56] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [267][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:16:12]
  Epoch: [267][200/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.0028 (0.0061)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:16:24]
  Epoch: [267][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0059)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:16:35]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.160 Prec@5 99.850 Error@1 4.840

==>>[2018-05-04 16:16:43] [Epoch=268/540] [Need: 02:18:26] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [268][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:16:43]
  Epoch: [268][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0036 (0.0064)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 16:16:55]
  Epoch: [268][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0127 (0.0067)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 16:17:06]
  **Train** Prec@1 99.900 Prec@5 100.000 Error@1 0.100
  **Test** Prec@1 95.070 Prec@5 99.840 Error@1 4.930

==>>[2018-05-04 16:17:14] [Epoch=269/540] [Need: 02:17:55] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [269][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:17:14]
  Epoch: [269][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 16:17:25]
  Epoch: [269][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0075 (0.0058)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 16:17:37]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.030 Prec@5 99.820 Error@1 4.970

==>>[2018-05-04 16:17:45] [Epoch=270/540] [Need: 02:17:25] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [270][000/500]   Time 0.075 (0.075)   Data 0.047 (0.047)   Loss 0.0189 (0.0189)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:17:45]
  Epoch: [270][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0058)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:17:57]
  Epoch: [270][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0106 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:18:08]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.110 Prec@5 99.820 Error@1 4.890

==>>[2018-05-04 16:18:16] [Epoch=271/540] [Need: 02:16:55] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [271][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:18:16]
  Epoch: [271][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0072)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 16:18:27]
  Epoch: [271][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0068)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:18:39]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 95.040 Prec@5 99.810 Error@1 4.960

==>>[2018-05-04 16:18:48] [Epoch=272/540] [Need: 02:16:26] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [272][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0026 (0.0026)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:18:48]
  Epoch: [272][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0061)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 16:18:59]
  Epoch: [272][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:19:11]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.150 Prec@5 99.810 Error@1 4.850

==>>[2018-05-04 16:19:20] [Epoch=273/540] [Need: 02:15:57] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [273][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:19:20]
  Epoch: [273][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0060)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:19:32]
  Epoch: [273][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0034 (0.0058)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:19:44]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.060 Prec@5 99.810 Error@1 4.940

==>>[2018-05-04 16:19:52] [Epoch=274/540] [Need: 02:15:28] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [274][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:19:52]
  Epoch: [274][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0031 (0.0061)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 16:20:04]
  Epoch: [274][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0055 (0.0061)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-04 16:20:16]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 95.090 Prec@5 99.790 Error@1 4.910

==>>[2018-05-04 16:20:25] [Epoch=275/540] [Need: 02:14:59] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [275][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:20:25]
  Epoch: [275][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0431 (0.0058)   Prec@1 99.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:20:37]
  Epoch: [275][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0099 (0.0059)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:20:48]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.110 Prec@5 99.810 Error@1 4.890

==>>[2018-05-04 16:20:57] [Epoch=276/540] [Need: 02:14:31] [learning_rate=0.001000] [Best : Accuracy=95.16, Error=4.84]
  Epoch: [276][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0137 (0.0137)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:20:57]
  Epoch: [276][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0064)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:21:09]
  Epoch: [276][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0062)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 16:21:20]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.190 Prec@5 99.810 Error@1 4.810

==>>[2018-05-04 16:21:29] [Epoch=277/540] [Need: 02:14:01] [learning_rate=0.001000] [Best : Accuracy=95.19, Error=4.81]
  Epoch: [277][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:21:29]
  Epoch: [277][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:21:40]
  Epoch: [277][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0037 (0.0062)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 16:21:51]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.130 Prec@5 99.840 Error@1 4.870

==>>[2018-05-04 16:22:00] [Epoch=278/540] [Need: 02:13:31] [learning_rate=0.001000] [Best : Accuracy=95.19, Error=4.81]
  Epoch: [278][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:22:00]
  Epoch: [278][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0049 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:22:11]
  Epoch: [278][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:22:22]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-05-04 16:22:31] [Epoch=279/540] [Need: 02:13:01] [learning_rate=0.001000] [Best : Accuracy=95.19, Error=4.81]
  Epoch: [279][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:22:31]
  Epoch: [279][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0026 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:22:43]
  Epoch: [279][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0048 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 16:22:54]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.150 Prec@5 99.800 Error@1 4.850

==>>[2018-05-04 16:23:03] [Epoch=280/540] [Need: 02:12:31] [learning_rate=0.001000] [Best : Accuracy=95.19, Error=4.81]
  Epoch: [280][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:23:03]
  Epoch: [280][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0074 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:23:14]
  Epoch: [280][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:23:25]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.200 Prec@5 99.810 Error@1 4.800

==>>[2018-05-04 16:23:34] [Epoch=281/540] [Need: 02:12:01] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [281][000/500]   Time 0.075 (0.075)   Data 0.047 (0.047)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:23:34]
  Epoch: [281][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0064 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 16:23:45]
  Epoch: [281][400/500]   Time 0.068 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0053)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 16:23:57]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.190 Prec@5 99.810 Error@1 4.810

==>>[2018-05-04 16:24:05] [Epoch=282/540] [Need: 02:11:32] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [282][000/500]   Time 0.078 (0.078)   Data 0.050 (0.050)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:24:05]
  Epoch: [282][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0049 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:24:17]
  Epoch: [282][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0026 (0.0062)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 16:24:28]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.080 Prec@5 99.820 Error@1 4.920

==>>[2018-05-04 16:24:36] [Epoch=283/540] [Need: 02:11:01] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [283][000/500]   Time 0.074 (0.074)   Data 0.049 (0.049)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:24:36]
  Epoch: [283][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0063)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 16:24:47]
  Epoch: [283][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0059)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 16:24:58]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.130 Prec@5 99.800 Error@1 4.870

==>>[2018-05-04 16:25:06] [Epoch=284/540] [Need: 02:10:29] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [284][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:25:06]
  Epoch: [284][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0374 (0.0066)   Prec@1 99.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 16:25:17]
  Epoch: [284][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0064)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:25:27]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.130 Prec@5 99.820 Error@1 4.870

==>>[2018-05-04 16:25:36] [Epoch=285/540] [Need: 02:09:58] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [285][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:25:36]
  Epoch: [285][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:25:47]
  Epoch: [285][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0058)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 16:25:58]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.030 Prec@5 99.800 Error@1 4.970

==>>[2018-05-04 16:26:06] [Epoch=286/540] [Need: 02:09:27] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [286][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:26:06]
  Epoch: [286][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:26:17]
  Epoch: [286][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0216 (0.0059)   Prec@1 99.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 16:26:28]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.090 Prec@5 99.820 Error@1 4.910

==>>[2018-05-04 16:26:36] [Epoch=287/540] [Need: 02:08:56] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [287][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:26:36]
  Epoch: [287][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:26:47]
  Epoch: [287][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:26:57]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.060 Prec@5 99.790 Error@1 4.940

==>>[2018-05-04 16:27:06] [Epoch=288/540] [Need: 02:08:25] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [288][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:27:06]
  Epoch: [288][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:27:17]
  Epoch: [288][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:27:27]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.190 Prec@5 99.840 Error@1 4.810

==>>[2018-05-04 16:27:36] [Epoch=289/540] [Need: 02:07:54] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [289][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:27:36]
  Epoch: [289][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:27:47]
  Epoch: [289][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0056)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 16:27:58]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.080 Prec@5 99.790 Error@1 4.920

==>>[2018-05-04 16:28:06] [Epoch=290/540] [Need: 02:07:23] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [290][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:28:06]
  Epoch: [290][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0067)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 16:28:17]
  Epoch: [290][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0062)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 16:28:27]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.010 Prec@5 99.820 Error@1 4.990

==>>[2018-05-04 16:28:35] [Epoch=291/540] [Need: 02:06:52] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [291][000/500]   Time 0.078 (0.078)   Data 0.050 (0.050)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:28:36]
  Epoch: [291][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0341 (0.0057)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:28:46]
  Epoch: [291][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0403 (0.0058)   Prec@1 99.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 16:28:57]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.060 Prec@5 99.830 Error@1 4.940

==>>[2018-05-04 16:29:05] [Epoch=292/540] [Need: 02:06:21] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [292][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:29:05]
  Epoch: [292][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0043 (0.0057)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:29:17]
  Epoch: [292][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0043 (0.0058)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 16:29:28]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.140 Prec@5 99.780 Error@1 4.860

==>>[2018-05-04 16:29:36] [Epoch=293/540] [Need: 02:05:50] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [293][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:29:36]
  Epoch: [293][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0052)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 16:29:47]
  Epoch: [293][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:29:58]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.150 Prec@5 99.830 Error@1 4.850

==>>[2018-05-04 16:30:06] [Epoch=294/540] [Need: 02:05:19] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [294][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:30:06]
  Epoch: [294][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:30:17]
  Epoch: [294][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:30:28]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.050 Prec@5 99.820 Error@1 4.950

==>>[2018-05-04 16:30:36] [Epoch=295/540] [Need: 02:04:48] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [295][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:30:36]
  Epoch: [295][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0095 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:30:47]
  Epoch: [295][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0060 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:30:58]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.120 Prec@5 99.820 Error@1 4.880

==>>[2018-05-04 16:31:06] [Epoch=296/540] [Need: 02:04:17] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [296][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0467 (0.0467)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:31:06]
  Epoch: [296][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0087 (0.0067)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:31:17]
  Epoch: [296][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0061)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 16:31:28]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.200 Prec@5 99.810 Error@1 4.800

==>>[2018-05-04 16:31:36] [Epoch=297/540] [Need: 02:03:46] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [297][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:31:36]
  Epoch: [297][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0240 (0.0060)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:31:47]
  Epoch: [297][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0059)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 16:31:58]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.090 Prec@5 99.810 Error@1 4.910

==>>[2018-05-04 16:32:06] [Epoch=298/540] [Need: 02:03:15] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [298][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:32:06]
  Epoch: [298][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:32:17]
  Epoch: [298][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0061)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 16:32:28]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.100 Prec@5 99.780 Error@1 4.900

==>>[2018-05-04 16:32:36] [Epoch=299/540] [Need: 02:02:44] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [299][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0051 (0.0051)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:32:36]
  Epoch: [299][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:32:47]
  Epoch: [299][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 16:32:58]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.190 Prec@5 99.810 Error@1 4.810

==>>[2018-05-04 16:33:06] [Epoch=300/540] [Need: 02:02:13] [learning_rate=0.001000] [Best : Accuracy=95.20, Error=4.80]
  Epoch: [300][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:33:06]
  Epoch: [300][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:33:17]
  Epoch: [300][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:33:28]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.320 Prec@5 99.860 Error@1 4.680

==>>[2018-05-04 16:33:36] [Epoch=301/540] [Need: 02:01:42] [learning_rate=0.001000] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [301][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:33:36]
  Epoch: [301][200/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0051 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:33:47]
  Epoch: [301][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:33:58]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.080 Prec@5 99.820 Error@1 4.920

==>>[2018-05-04 16:34:06] [Epoch=302/540] [Need: 02:01:11] [learning_rate=0.001000] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [302][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:34:06]
  Epoch: [302][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:34:17]
  Epoch: [302][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:34:28]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.190 Prec@5 99.800 Error@1 4.810

==>>[2018-05-04 16:34:36] [Epoch=303/540] [Need: 02:00:40] [learning_rate=0.001000] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [303][000/500]   Time 0.075 (0.075)   Data 0.047 (0.047)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:34:36]
  Epoch: [303][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:34:47]
  Epoch: [303][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:34:58]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-05-04 16:35:06] [Epoch=304/540] [Need: 02:00:09] [learning_rate=0.001000] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [304][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:35:06]
  Epoch: [304][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:35:17]
  Epoch: [304][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:35:28]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.210 Prec@5 99.800 Error@1 4.790

==>>[2018-05-04 16:35:36] [Epoch=305/540] [Need: 01:59:38] [learning_rate=0.001000] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [305][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:35:36]
  Epoch: [305][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0057)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:35:47]
  Epoch: [305][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0056)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 16:35:58]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.200 Prec@5 99.800 Error@1 4.800

==>>[2018-05-04 16:36:06] [Epoch=306/540] [Need: 01:59:07] [learning_rate=0.001000] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [306][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:36:06]
  Epoch: [306][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0059)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 16:36:17]
  Epoch: [306][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0059)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-04 16:36:28]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.160 Prec@5 99.830 Error@1 4.840

==>>[2018-05-04 16:36:36] [Epoch=307/540] [Need: 01:58:36] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [307][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:36:36]
  Epoch: [307][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0056)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:36:47]
  Epoch: [307][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:36:58]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.090 Prec@5 99.830 Error@1 4.910

==>>[2018-05-04 16:37:06] [Epoch=308/540] [Need: 01:58:05] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [308][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0142 (0.0142)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:37:06]
  Epoch: [308][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:37:17]
  Epoch: [308][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:37:28]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.110 Prec@5 99.800 Error@1 4.890

==>>[2018-05-04 16:37:36] [Epoch=309/540] [Need: 01:57:34] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [309][000/500]   Time 0.071 (0.071)   Data 0.046 (0.046)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:37:36]
  Epoch: [309][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:37:47]
  Epoch: [309][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0098 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:37:58]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.180 Prec@5 99.820 Error@1 4.820

==>>[2018-05-04 16:38:06] [Epoch=310/540] [Need: 01:57:03] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [310][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:38:06]
  Epoch: [310][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0108 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:38:17]
  Epoch: [310][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:38:28]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.180 Prec@5 99.810 Error@1 4.820

==>>[2018-05-04 16:38:36] [Epoch=311/540] [Need: 01:56:32] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [311][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:38:36]
  Epoch: [311][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:38:47]
  Epoch: [311][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:38:58]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.210 Prec@5 99.830 Error@1 4.790

==>>[2018-05-04 16:39:06] [Epoch=312/540] [Need: 01:56:02] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [312][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:39:06]
  Epoch: [312][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0057)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:39:17]
  Epoch: [312][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:39:28]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.210 Prec@5 99.820 Error@1 4.790

==>>[2018-05-04 16:39:36] [Epoch=313/540] [Need: 01:55:31] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [313][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:39:36]
  Epoch: [313][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:39:47]
  Epoch: [313][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:39:58]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.110 Prec@5 99.840 Error@1 4.890

==>>[2018-05-04 16:40:06] [Epoch=314/540] [Need: 01:55:00] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [314][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:40:06]
  Epoch: [314][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 16:40:17]
  Epoch: [314][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 16:40:28]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.210 Prec@5 99.830 Error@1 4.790

==>>[2018-05-04 16:40:36] [Epoch=315/540] [Need: 01:54:29] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [315][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:40:36]
  Epoch: [315][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:40:47]
  Epoch: [315][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0096 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:40:58]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.160 Prec@5 99.840 Error@1 4.840

==>>[2018-05-04 16:41:06] [Epoch=316/540] [Need: 01:53:58] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [316][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:41:06]
  Epoch: [316][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0055)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 16:41:17]
  Epoch: [316][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0080 (0.0054)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:41:28]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.160 Prec@5 99.800 Error@1 4.840

==>>[2018-05-04 16:41:36] [Epoch=317/540] [Need: 01:53:27] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [317][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0328 (0.0328)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:41:36]
  Epoch: [317][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0204 (0.0061)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:41:47]
  Epoch: [317][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:41:58]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.230 Prec@5 99.830 Error@1 4.770

==>>[2018-05-04 16:42:06] [Epoch=318/540] [Need: 01:52:56] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [318][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:42:06]
  Epoch: [318][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 16:42:17]
  Epoch: [318][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:42:28]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.180 Prec@5 99.820 Error@1 4.820

==>>[2018-05-04 16:42:36] [Epoch=319/540] [Need: 01:52:25] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [319][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:42:36]
  Epoch: [319][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:42:47]
  Epoch: [319][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0090 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:42:58]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.210 Prec@5 99.840 Error@1 4.790

==>>[2018-05-04 16:43:06] [Epoch=320/540] [Need: 01:51:54] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [320][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:43:06]
  Epoch: [320][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0075 (0.0051)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:43:17]
  Epoch: [320][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0056 (0.0053)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 16:43:28]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.170 Prec@5 99.770 Error@1 4.830

==>>[2018-05-04 16:43:36] [Epoch=321/540] [Need: 01:51:24] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [321][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:43:37]
  Epoch: [321][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:43:47]
  Epoch: [321][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:43:58]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.120 Prec@5 99.830 Error@1 4.880

==>>[2018-05-04 16:44:06] [Epoch=322/540] [Need: 01:50:53] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [322][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0072 (0.0072)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:44:06]
  Epoch: [322][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0050)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:44:17]
  Epoch: [322][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0054)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:44:28]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.250 Prec@5 99.830 Error@1 4.750

==>>[2018-05-04 16:44:36] [Epoch=323/540] [Need: 01:50:22] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [323][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:44:36]
  Epoch: [323][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:44:47]
  Epoch: [323][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:44:58]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.170 Prec@5 99.790 Error@1 4.830

==>>[2018-05-04 16:45:06] [Epoch=324/540] [Need: 01:49:51] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [324][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:45:06]
  Epoch: [324][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 16:45:17]
  Epoch: [324][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0059)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 16:45:28]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.200 Prec@5 99.800 Error@1 4.800

==>>[2018-05-04 16:45:36] [Epoch=325/540] [Need: 01:49:20] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [325][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:45:37]
  Epoch: [325][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:45:47]
  Epoch: [325][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0284 (0.0057)   Prec@1 99.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 16:45:58]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.170 Prec@5 99.790 Error@1 4.830

==>>[2018-05-04 16:46:06] [Epoch=326/540] [Need: 01:48:49] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [326][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:46:07]
  Epoch: [326][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:46:17]
  Epoch: [326][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:46:28]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.220 Prec@5 99.800 Error@1 4.780

==>>[2018-05-04 16:46:36] [Epoch=327/540] [Need: 01:48:18] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [327][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:46:37]
  Epoch: [327][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0077 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:46:47]
  Epoch: [327][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:46:58]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.110 Prec@5 99.850 Error@1 4.890

==>>[2018-05-04 16:47:06] [Epoch=328/540] [Need: 01:47:48] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [328][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:47:06]
  Epoch: [328][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:47:17]
  Epoch: [328][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 16:47:28]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.140 Prec@5 99.850 Error@1 4.860

==>>[2018-05-04 16:47:37] [Epoch=329/540] [Need: 01:47:17] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [329][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:47:37]
  Epoch: [329][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0061)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:47:48]
  Epoch: [329][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0061)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 16:47:58]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.200 Prec@5 99.820 Error@1 4.800

==>>[2018-05-04 16:48:07] [Epoch=330/540] [Need: 01:46:46] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [330][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:48:07]
  Epoch: [330][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:48:18]
  Epoch: [330][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0053 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:48:29]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.130 Prec@5 99.830 Error@1 4.870

==>>[2018-05-04 16:48:37] [Epoch=331/540] [Need: 01:46:16] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [331][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:48:37]
  Epoch: [331][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0025 (0.0051)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:48:48]
  Epoch: [331][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0059 (0.0050)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 16:48:59]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.160 Prec@5 99.830 Error@1 4.840

==>>[2018-05-04 16:49:08] [Epoch=332/540] [Need: 01:45:45] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [332][000/500]   Time 0.079 (0.079)   Data 0.051 (0.051)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:49:08]
  Epoch: [332][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0042 (0.0061)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:49:19]
  Epoch: [332][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0058)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:49:31]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.200 Prec@5 99.790 Error@1 4.800

==>>[2018-05-04 16:49:39] [Epoch=333/540] [Need: 01:45:15] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [333][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:49:39]
  Epoch: [333][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0050)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:49:50]
  Epoch: [333][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0116 (0.0055)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 16:50:02]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.190 Prec@5 99.830 Error@1 4.810

==>>[2018-05-04 16:50:10] [Epoch=334/540] [Need: 01:44:45] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [334][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:50:10]
  Epoch: [334][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:50:21]
  Epoch: [334][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:50:32]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.170 Prec@5 99.830 Error@1 4.830

==>>[2018-05-04 16:50:40] [Epoch=335/540] [Need: 01:44:14] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [335][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:50:40]
  Epoch: [335][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0051)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:50:51]
  Epoch: [335][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:51:02]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.150 Prec@5 99.820 Error@1 4.850

==>>[2018-05-04 16:51:11] [Epoch=336/540] [Need: 01:43:44] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [336][000/500]   Time 0.090 (0.090)   Data 0.061 (0.061)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:51:11]
  Epoch: [336][200/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.0033 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:51:22]
  Epoch: [336][400/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.0045 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 16:51:33]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.070 Prec@5 99.830 Error@1 4.930

==>>[2018-05-04 16:51:42] [Epoch=337/540] [Need: 01:43:13] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [337][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0190 (0.0190)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:51:42]
  Epoch: [337][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0455 (0.0061)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:51:53]
  Epoch: [337][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:52:04]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.230 Prec@5 99.810 Error@1 4.770

==>>[2018-05-04 16:52:12] [Epoch=338/540] [Need: 01:42:43] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [338][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:52:13]
  Epoch: [338][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:52:24]
  Epoch: [338][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 16:52:35]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.100 Prec@5 99.860 Error@1 4.900

==>>[2018-05-04 16:52:43] [Epoch=339/540] [Need: 01:42:12] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [339][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:52:43]
  Epoch: [339][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:52:54]
  Epoch: [339][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0171 (0.0052)   Prec@1 99.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 16:53:05]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.080 Prec@5 99.810 Error@1 4.920

==>>[2018-05-04 16:53:13] [Epoch=340/540] [Need: 01:41:42] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [340][000/500]   Time 0.081 (0.081)   Data 0.052 (0.052)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:53:13]
  Epoch: [340][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0056)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:53:24]
  Epoch: [340][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0047 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:53:35]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.140 Prec@5 99.800 Error@1 4.860

==>>[2018-05-04 16:53:44] [Epoch=341/540] [Need: 01:41:11] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [341][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:53:44]
  Epoch: [341][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0048 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:53:55]
  Epoch: [341][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0094 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 16:54:06]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.150 Prec@5 99.820 Error@1 4.850

==>>[2018-05-04 16:54:14] [Epoch=342/540] [Need: 01:40:41] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [342][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:54:14]
  Epoch: [342][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0062 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:54:25]
  Epoch: [342][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:54:36]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.160 Prec@5 99.810 Error@1 4.840

==>>[2018-05-04 16:54:45] [Epoch=343/540] [Need: 01:40:10] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [343][000/500]   Time 0.089 (0.089)   Data 0.063 (0.063)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:54:45]
  Epoch: [343][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:54:56]
  Epoch: [343][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0040 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:55:07]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.190 Prec@5 99.810 Error@1 4.810

==>>[2018-05-04 16:55:15] [Epoch=344/540] [Need: 01:39:40] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [344][000/500]   Time 0.075 (0.075)   Data 0.050 (0.050)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:55:15]
  Epoch: [344][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0051 (0.0061)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:55:26]
  Epoch: [344][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0029 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:55:37]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.190 Prec@5 99.820 Error@1 4.810

==>>[2018-05-04 16:55:46] [Epoch=345/540] [Need: 01:39:09] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [345][000/500]   Time 0.072 (0.072)   Data 0.045 (0.045)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:55:46]
  Epoch: [345][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0050 (0.0053)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:55:57]
  Epoch: [345][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0064 (0.0055)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:56:08]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.060 Prec@5 99.800 Error@1 4.940

==>>[2018-05-04 16:56:16] [Epoch=346/540] [Need: 01:38:39] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [346][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:56:16]
  Epoch: [346][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0043 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:56:27]
  Epoch: [346][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0099 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 16:56:38]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.190 Prec@5 99.850 Error@1 4.810

==>>[2018-05-04 16:56:46] [Epoch=347/540] [Need: 01:38:08] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [347][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:56:46]
  Epoch: [347][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 16:56:57]
  Epoch: [347][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0232 (0.0057)   Prec@1 99.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 16:57:08]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.110 Prec@5 99.820 Error@1 4.890

==>>[2018-05-04 16:57:16] [Epoch=348/540] [Need: 01:37:37] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [348][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:57:16]
  Epoch: [348][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0063)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:57:27]
  Epoch: [348][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0060)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 16:57:38]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.180 Prec@5 99.820 Error@1 4.820

==>>[2018-05-04 16:57:46] [Epoch=349/540] [Need: 01:37:06] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [349][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:57:46]
  Epoch: [349][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 16:57:57]
  Epoch: [349][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0058)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 16:58:08]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.100 Prec@5 99.810 Error@1 4.900

==>>[2018-05-04 16:58:16] [Epoch=350/540] [Need: 01:36:36] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [350][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:58:16]
  Epoch: [350][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0070 (0.0049)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 16:58:27]
  Epoch: [350][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0051)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 16:58:38]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.140 Prec@5 99.800 Error@1 4.860

==>>[2018-05-04 16:58:46] [Epoch=351/540] [Need: 01:36:05] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [351][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:58:46]
  Epoch: [351][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 16:58:57]
  Epoch: [351][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0054)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 16:59:08]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.100 Prec@5 99.810 Error@1 4.900

==>>[2018-05-04 16:59:16] [Epoch=352/540] [Need: 01:35:34] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [352][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:59:16]
  Epoch: [352][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0146 (0.0055)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 16:59:27]
  Epoch: [352][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0079 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 16:59:38]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.190 Prec@5 99.820 Error@1 4.810

==>>[2018-05-04 16:59:46] [Epoch=353/540] [Need: 01:35:03] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [353][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 16:59:46]
  Epoch: [353][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0054)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 16:59:57]
  Epoch: [353][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:00:08]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.230 Prec@5 99.790 Error@1 4.770

==>>[2018-05-04 17:00:16] [Epoch=354/540] [Need: 01:34:32] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [354][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:00:16]
  Epoch: [354][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0062)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:00:27]
  Epoch: [354][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:00:38]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.160 Prec@5 99.800 Error@1 4.840

==>>[2018-05-04 17:00:46] [Epoch=355/540] [Need: 01:34:02] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [355][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0194 (0.0194)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:00:46]
  Epoch: [355][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:00:57]
  Epoch: [355][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0128 (0.0056)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:01:08]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.180 Prec@5 99.780 Error@1 4.820

==>>[2018-05-04 17:01:16] [Epoch=356/540] [Need: 01:33:31] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [356][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:01:16]
  Epoch: [356][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:01:27]
  Epoch: [356][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:01:38]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.120 Prec@5 99.830 Error@1 4.880

==>>[2018-05-04 17:01:47] [Epoch=357/540] [Need: 01:33:00] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [357][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0230 (0.0230)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:01:47]
  Epoch: [357][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0060)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 17:01:58]
  Epoch: [357][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0065 (0.0062)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 17:02:09]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.200 Prec@5 99.820 Error@1 4.800

==>>[2018-05-04 17:02:17] [Epoch=358/540] [Need: 01:32:30] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [358][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:02:17]
  Epoch: [358][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0049)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 17:02:28]
  Epoch: [358][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:02:39]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.210 Prec@5 99.840 Error@1 4.790

==>>[2018-05-04 17:02:47] [Epoch=359/540] [Need: 01:31:59] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [359][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:02:47]
  Epoch: [359][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:02:58]
  Epoch: [359][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:03:08]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.080 Prec@5 99.840 Error@1 4.920

==>>[2018-05-04 17:03:17] [Epoch=360/540] [Need: 01:31:28] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [360][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:03:17]
  Epoch: [360][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:03:28]
  Epoch: [360][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:03:38]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.140 Prec@5 99.810 Error@1 4.860

==>>[2018-05-04 17:03:47] [Epoch=361/540] [Need: 01:30:57] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [361][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:03:47]
  Epoch: [361][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:03:58]
  Epoch: [361][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:04:09]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.190 Prec@5 99.820 Error@1 4.810

==>>[2018-05-04 17:04:17] [Epoch=362/540] [Need: 01:30:27] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [362][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:04:17]
  Epoch: [362][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:04:28]
  Epoch: [362][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0057)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 17:04:39]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.130 Prec@5 99.830 Error@1 4.870

==>>[2018-05-04 17:04:47] [Epoch=363/540] [Need: 01:29:56] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [363][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:04:47]
  Epoch: [363][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:04:58]
  Epoch: [363][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:05:09]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.210 Prec@5 99.800 Error@1 4.790

==>>[2018-05-04 17:05:17] [Epoch=364/540] [Need: 01:29:25] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [364][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:05:17]
  Epoch: [364][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:05:28]
  Epoch: [364][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0099 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:05:39]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.080 Prec@5 99.820 Error@1 4.920

==>>[2018-05-04 17:05:47] [Epoch=365/540] [Need: 01:28:55] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [365][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:05:47]
  Epoch: [365][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0059)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 17:05:58]
  Epoch: [365][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0059)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 17:06:09]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.130 Prec@5 99.810 Error@1 4.870

==>>[2018-05-04 17:06:17] [Epoch=366/540] [Need: 01:28:24] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [366][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:06:17]
  Epoch: [366][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:06:28]
  Epoch: [366][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:06:39]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.140 Prec@5 99.820 Error@1 4.860

==>>[2018-05-04 17:06:47] [Epoch=367/540] [Need: 01:27:53] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [367][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:06:47]
  Epoch: [367][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0047 (0.0050)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 17:06:58]
  Epoch: [367][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0053)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-04 17:07:09]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.200 Prec@5 99.820 Error@1 4.800

==>>[2018-05-04 17:07:17] [Epoch=368/540] [Need: 01:27:22] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [368][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:07:17]
  Epoch: [368][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:07:28]
  Epoch: [368][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:07:39]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.080 Prec@5 99.810 Error@1 4.920

==>>[2018-05-04 17:07:47] [Epoch=369/540] [Need: 01:26:52] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [369][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:07:47]
  Epoch: [369][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 17:07:58]
  Epoch: [369][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0056)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 17:08:09]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.090 Prec@5 99.820 Error@1 4.910

==>>[2018-05-04 17:08:17] [Epoch=370/540] [Need: 01:26:21] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [370][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:08:17]
  Epoch: [370][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:08:28]
  Epoch: [370][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:08:39]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.170 Prec@5 99.820 Error@1 4.830

==>>[2018-05-04 17:08:47] [Epoch=371/540] [Need: 01:25:50] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [371][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:08:47]
  Epoch: [371][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:08:58]
  Epoch: [371][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:09:09]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.130 Prec@5 99.800 Error@1 4.870

==>>[2018-05-04 17:09:17] [Epoch=372/540] [Need: 01:25:20] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [372][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:09:17]
  Epoch: [372][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0052)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 17:09:28]
  Epoch: [372][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:09:39]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.180 Prec@5 99.820 Error@1 4.820

==>>[2018-05-04 17:09:47] [Epoch=373/540] [Need: 01:24:49] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [373][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:09:47]
  Epoch: [373][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0174 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:09:58]
  Epoch: [373][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:10:09]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.190 Prec@5 99.800 Error@1 4.810

==>>[2018-05-04 17:10:17] [Epoch=374/540] [Need: 01:24:18] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [374][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:10:17]
  Epoch: [374][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0051)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:10:28]
  Epoch: [374][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0064 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:10:39]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.110 Prec@5 99.830 Error@1 4.890

==>>[2018-05-04 17:10:47] [Epoch=375/540] [Need: 01:23:48] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [375][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:10:47]
  Epoch: [375][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0063 (0.0053)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 17:10:58]
  Epoch: [375][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0104 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:11:09]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.140 Prec@5 99.820 Error@1 4.860

==>>[2018-05-04 17:11:17] [Epoch=376/540] [Need: 01:23:17] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [376][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:11:17]
  Epoch: [376][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0060)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:11:28]
  Epoch: [376][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0026 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:11:39]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.150 Prec@5 99.830 Error@1 4.850

==>>[2018-05-04 17:11:47] [Epoch=377/540] [Need: 01:22:46] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [377][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:11:47]
  Epoch: [377][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0063)   Prec@1 100.000 (99.920)   Prec@5 100.000 (99.995)   [2018-05-04 17:11:58]
  Epoch: [377][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0061)   Prec@1 100.000 (99.930)   Prec@5 100.000 (99.998)   [2018-05-04 17:12:09]
  **Train** Prec@1 99.930 Prec@5 99.998 Error@1 0.070
  **Test** Prec@1 95.090 Prec@5 99.820 Error@1 4.910

==>>[2018-05-04 17:12:17] [Epoch=378/540] [Need: 01:22:16] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [378][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:12:17]
  Epoch: [378][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:12:28]
  Epoch: [378][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0055)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:12:39]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.130 Prec@5 99.830 Error@1 4.870

==>>[2018-05-04 17:12:47] [Epoch=379/540] [Need: 01:21:45] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [379][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:12:47]
  Epoch: [379][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:12:58]
  Epoch: [379][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:13:09]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.190 Prec@5 99.850 Error@1 4.810

==>>[2018-05-04 17:13:17] [Epoch=380/540] [Need: 01:21:14] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [380][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:13:17]
  Epoch: [380][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0057)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:13:28]
  Epoch: [380][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:13:39]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.150 Prec@5 99.830 Error@1 4.850

==>>[2018-05-04 17:13:47] [Epoch=381/540] [Need: 01:20:44] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [381][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0116 (0.0116)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:13:47]
  Epoch: [381][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0241 (0.0058)   Prec@1 99.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:13:58]
  Epoch: [381][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0063 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:14:09]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.120 Prec@5 99.790 Error@1 4.880

==>>[2018-05-04 17:14:17] [Epoch=382/540] [Need: 01:20:13] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [382][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:14:17]
  Epoch: [382][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:14:28]
  Epoch: [382][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0061)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 17:14:39]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 95.110 Prec@5 99.830 Error@1 4.890

==>>[2018-05-04 17:14:47] [Epoch=383/540] [Need: 01:19:42] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [383][000/500]   Time 0.074 (0.074)   Data 0.049 (0.049)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:14:47]
  Epoch: [383][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0051 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:14:58]
  Epoch: [383][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0168 (0.0056)   Prec@1 99.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:15:09]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.110 Prec@5 99.830 Error@1 4.890

==>>[2018-05-04 17:15:17] [Epoch=384/540] [Need: 01:19:12] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [384][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:15:17]
  Epoch: [384][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:15:28]
  Epoch: [384][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0057)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 17:15:39]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.080 Prec@5 99.830 Error@1 4.920

==>>[2018-05-04 17:15:47] [Epoch=385/540] [Need: 01:18:41] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [385][000/500]   Time 0.072 (0.072)   Data 0.045 (0.045)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:15:47]
  Epoch: [385][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 17:15:58]
  Epoch: [385][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0052)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:16:09]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.210 Prec@5 99.830 Error@1 4.790

==>>[2018-05-04 17:16:17] [Epoch=386/540] [Need: 01:18:10] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [386][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:16:17]
  Epoch: [386][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0065 (0.0065)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:16:28]
  Epoch: [386][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0103 (0.0058)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:16:39]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.140 Prec@5 99.780 Error@1 4.860

==>>[2018-05-04 17:16:47] [Epoch=387/540] [Need: 01:17:40] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [387][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:16:47]
  Epoch: [387][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0097 (0.0055)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:16:58]
  Epoch: [387][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0085 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:17:09]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.210 Prec@5 99.820 Error@1 4.790

==>>[2018-05-04 17:17:17] [Epoch=388/540] [Need: 01:17:09] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [388][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:17:17]
  Epoch: [388][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0057)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 17:17:28]
  Epoch: [388][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0054)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:17:39]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.150 Prec@5 99.830 Error@1 4.850

==>>[2018-05-04 17:17:47] [Epoch=389/540] [Need: 01:16:38] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [389][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:17:47]
  Epoch: [389][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0091 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:17:58]
  Epoch: [389][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0058)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 17:18:09]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.130 Prec@5 99.820 Error@1 4.870

==>>[2018-05-04 17:18:17] [Epoch=390/540] [Need: 01:16:08] [learning_rate=0.000100] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [390][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:18:17]
  Epoch: [390][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0050)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:18:28]
  Epoch: [390][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0049)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 17:18:39]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.140 Prec@5 99.800 Error@1 4.860

==>>[2018-05-04 17:18:47] [Epoch=391/540] [Need: 01:15:37] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [391][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:18:47]
  Epoch: [391][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:18:58]
  Epoch: [391][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0052)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 17:19:09]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.150 Prec@5 99.820 Error@1 4.850

==>>[2018-05-04 17:19:17] [Epoch=392/540] [Need: 01:15:07] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [392][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:19:17]
  Epoch: [392][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:19:28]
  Epoch: [392][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0059)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 17:19:39]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.180 Prec@5 99.810 Error@1 4.820

==>>[2018-05-04 17:19:47] [Epoch=393/540] [Need: 01:14:36] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [393][000/500]   Time 0.073 (0.073)   Data 0.045 (0.045)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:19:47]
  Epoch: [393][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:19:58]
  Epoch: [393][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:20:09]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.180 Prec@5 99.810 Error@1 4.820

==>>[2018-05-04 17:20:17] [Epoch=394/540] [Need: 01:14:05] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [394][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:20:17]
  Epoch: [394][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 17:20:28]
  Epoch: [394][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0133 (0.0054)   Prec@1 99.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:20:39]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.140 Prec@5 99.800 Error@1 4.860

==>>[2018-05-04 17:20:47] [Epoch=395/540] [Need: 01:13:35] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [395][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:20:47]
  Epoch: [395][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0054)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:20:58]
  Epoch: [395][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:21:09]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.140 Prec@5 99.810 Error@1 4.860

==>>[2018-05-04 17:21:17] [Epoch=396/540] [Need: 01:13:04] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [396][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:21:17]
  Epoch: [396][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0050)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 17:21:28]
  Epoch: [396][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0052)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-04 17:21:39]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.190 Prec@5 99.820 Error@1 4.810

==>>[2018-05-04 17:21:47] [Epoch=397/540] [Need: 01:12:33] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [397][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:21:47]
  Epoch: [397][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:21:58]
  Epoch: [397][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:22:09]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.180 Prec@5 99.820 Error@1 4.820

==>>[2018-05-04 17:22:17] [Epoch=398/540] [Need: 01:12:03] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [398][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:22:17]
  Epoch: [398][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0073 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:22:28]
  Epoch: [398][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:22:39]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.170 Prec@5 99.810 Error@1 4.830

==>>[2018-05-04 17:22:47] [Epoch=399/540] [Need: 01:11:32] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [399][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:22:47]
  Epoch: [399][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0069)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-04 17:22:58]
  Epoch: [399][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0061)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:23:09]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.080 Prec@5 99.800 Error@1 4.920

==>>[2018-05-04 17:23:17] [Epoch=400/540] [Need: 01:11:02] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [400][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0025 (0.0025)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:23:17]
  Epoch: [400][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:23:28]
  Epoch: [400][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:23:39]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.150 Prec@5 99.840 Error@1 4.850

==>>[2018-05-04 17:23:47] [Epoch=401/540] [Need: 01:10:31] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [401][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:23:47]
  Epoch: [401][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0050)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:23:58]
  Epoch: [401][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:24:09]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.130 Prec@5 99.850 Error@1 4.870

==>>[2018-05-04 17:24:17] [Epoch=402/540] [Need: 01:10:00] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [402][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:24:17]
  Epoch: [402][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (99.995)   [2018-05-04 17:24:28]
  Epoch: [402][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0058)   Prec@1 100.000 (99.938)   Prec@5 100.000 (99.998)   [2018-05-04 17:24:39]
  **Train** Prec@1 99.932 Prec@5 99.998 Error@1 0.068
  **Test** Prec@1 95.150 Prec@5 99.810 Error@1 4.850

==>>[2018-05-04 17:24:47] [Epoch=403/540] [Need: 01:09:30] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [403][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:24:47]
  Epoch: [403][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:24:58]
  Epoch: [403][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0090 (0.0056)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:25:09]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.210 Prec@5 99.840 Error@1 4.790

==>>[2018-05-04 17:25:17] [Epoch=404/540] [Need: 01:08:59] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [404][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:25:17]
  Epoch: [404][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0050)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:25:28]
  Epoch: [404][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0050)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:25:39]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.160 Prec@5 99.850 Error@1 4.840

==>>[2018-05-04 17:25:47] [Epoch=405/540] [Need: 01:08:29] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [405][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:25:47]
  Epoch: [405][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:25:58]
  Epoch: [405][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0057)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 17:26:09]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.130 Prec@5 99.870 Error@1 4.870

==>>[2018-05-04 17:26:17] [Epoch=406/540] [Need: 01:07:58] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [406][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:26:17]
  Epoch: [406][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0049)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:26:28]
  Epoch: [406][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:26:39]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.170 Prec@5 99.830 Error@1 4.830

==>>[2018-05-04 17:26:48] [Epoch=407/540] [Need: 01:07:28] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [407][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:26:48]
  Epoch: [407][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:26:59]
  Epoch: [407][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0058)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:27:10]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.140 Prec@5 99.810 Error@1 4.860

==>>[2018-05-04 17:27:18] [Epoch=408/540] [Need: 01:06:57] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [408][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:27:18]
  Epoch: [408][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0063 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:27:29]
  Epoch: [408][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0050 (0.0052)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 17:27:40]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.160 Prec@5 99.810 Error@1 4.840

==>>[2018-05-04 17:27:48] [Epoch=409/540] [Need: 01:06:27] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [409][000/500]   Time 0.078 (0.078)   Data 0.049 (0.049)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:27:48]
  Epoch: [409][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:27:59]
  Epoch: [409][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0058)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:28:10]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-05-04 17:28:18] [Epoch=410/540] [Need: 01:05:56] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [410][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:28:18]
  Epoch: [410][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:28:30]
  Epoch: [410][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:28:41]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.110 Prec@5 99.780 Error@1 4.890

==>>[2018-05-04 17:28:49] [Epoch=411/540] [Need: 01:05:26] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [411][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:28:49]
  Epoch: [411][200/500]   Time 0.061 (0.055)   Data 0.000 (0.000)   Loss 0.0025 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:29:00]
  Epoch: [411][400/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.0027 (0.0058)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 17:29:11]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-05-04 17:29:20] [Epoch=412/540] [Need: 01:04:56] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [412][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:29:20]
  Epoch: [412][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:29:31]
  Epoch: [412][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0058)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:29:42]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.110 Prec@5 99.830 Error@1 4.890

==>>[2018-05-04 17:29:50] [Epoch=413/540] [Need: 01:04:25] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [413][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:29:50]
  Epoch: [413][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:30:01]
  Epoch: [413][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:30:12]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.240 Prec@5 99.840 Error@1 4.760

==>>[2018-05-04 17:30:21] [Epoch=414/540] [Need: 01:03:55] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [414][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:30:21]
  Epoch: [414][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0062)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 17:30:32]
  Epoch: [414][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0091 (0.0058)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 17:30:43]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.140 Prec@5 99.840 Error@1 4.860

==>>[2018-05-04 17:30:51] [Epoch=415/540] [Need: 01:03:24] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [415][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:30:51]
  Epoch: [415][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:31:02]
  Epoch: [415][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:31:13]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.200 Prec@5 99.800 Error@1 4.800

==>>[2018-05-04 17:31:21] [Epoch=416/540] [Need: 01:02:54] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [416][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:31:21]
  Epoch: [416][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0064 (0.0055)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:31:32]
  Epoch: [416][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0249 (0.0056)   Prec@1 99.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:31:43]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.150 Prec@5 99.790 Error@1 4.850

==>>[2018-05-04 17:31:51] [Epoch=417/540] [Need: 01:02:23] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [417][000/500]   Time 0.072 (0.072)   Data 0.047 (0.047)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:31:51]
  Epoch: [417][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:32:02]
  Epoch: [417][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0053)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:32:13]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.150 Prec@5 99.810 Error@1 4.850

==>>[2018-05-04 17:32:21] [Epoch=418/540] [Need: 01:01:53] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [418][000/500]   Time 0.072 (0.072)   Data 0.047 (0.047)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:32:21]
  Epoch: [418][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:32:32]
  Epoch: [418][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0108 (0.0054)   Prec@1 99.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 17:32:43]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.120 Prec@5 99.850 Error@1 4.880

==>>[2018-05-04 17:32:51] [Epoch=419/540] [Need: 01:01:22] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [419][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:32:52]
  Epoch: [419][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0029 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:33:03]
  Epoch: [419][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:33:14]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.150 Prec@5 99.830 Error@1 4.850

==>>[2018-05-04 17:33:22] [Epoch=420/540] [Need: 01:00:52] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [420][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:33:22]
  Epoch: [420][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:33:33]
  Epoch: [420][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:33:44]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.190 Prec@5 99.830 Error@1 4.810

==>>[2018-05-04 17:33:52] [Epoch=421/540] [Need: 01:00:21] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [421][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:33:52]
  Epoch: [421][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0100 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:34:03]
  Epoch: [421][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0581 (0.0056)   Prec@1 98.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:34:15]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.300 Prec@5 99.850 Error@1 4.700

==>>[2018-05-04 17:34:23] [Epoch=422/540] [Need: 00:59:51] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [422][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:34:23]
  Epoch: [422][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0060)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 17:34:34]
  Epoch: [422][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0056)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:34:45]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.140 Prec@5 99.830 Error@1 4.860

==>>[2018-05-04 17:34:53] [Epoch=423/540] [Need: 00:59:20] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [423][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:34:53]
  Epoch: [423][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0046 (0.0055)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:35:04]
  Epoch: [423][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:35:15]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.210 Prec@5 99.820 Error@1 4.790

==>>[2018-05-04 17:35:23] [Epoch=424/540] [Need: 00:58:50] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [424][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:35:23]
  Epoch: [424][200/500]   Time 0.054 (0.058)   Data 0.000 (0.000)   Loss 0.0049 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:35:35]
  Epoch: [424][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:35:46]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.150 Prec@5 99.820 Error@1 4.850

==>>[2018-05-04 17:35:54] [Epoch=425/540] [Need: 00:58:20] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [425][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:35:55]
  Epoch: [425][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0059)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 17:36:05]
  Epoch: [425][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0026 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:36:17]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.110 Prec@5 99.800 Error@1 4.890

==>>[2018-05-04 17:36:26] [Epoch=426/540] [Need: 00:57:49] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [426][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0120 (0.0120)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:36:26]
  Epoch: [426][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0079 (0.0049)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:36:37]
  Epoch: [426][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0228 (0.0053)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:36:48]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.060 Prec@5 99.820 Error@1 4.940

==>>[2018-05-04 17:36:56] [Epoch=427/540] [Need: 00:57:19] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [427][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:36:56]
  Epoch: [427][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:37:07]
  Epoch: [427][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0055)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 17:37:18]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.130 Prec@5 99.820 Error@1 4.870

==>>[2018-05-04 17:37:26] [Epoch=428/540] [Need: 00:56:48] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [428][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:37:26]
  Epoch: [428][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0067 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:37:37]
  Epoch: [428][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0037 (0.0053)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-04 17:37:48]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.110 Prec@5 99.770 Error@1 4.890

==>>[2018-05-04 17:37:57] [Epoch=429/540] [Need: 00:56:18] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [429][000/500]   Time 0.071 (0.071)   Data 0.045 (0.045)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:37:57]
  Epoch: [429][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:38:08]
  Epoch: [429][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:38:19]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.120 Prec@5 99.830 Error@1 4.880

==>>[2018-05-04 17:38:27] [Epoch=430/540] [Need: 00:55:48] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [430][000/500]   Time 0.073 (0.073)   Data 0.046 (0.046)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:38:27]
  Epoch: [430][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:38:38]
  Epoch: [430][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0057)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:38:49]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.170 Prec@5 99.810 Error@1 4.830

==>>[2018-05-04 17:38:57] [Epoch=431/540] [Need: 00:55:17] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [431][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:38:57]
  Epoch: [431][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:39:08]
  Epoch: [431][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:39:20]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.110 Prec@5 99.820 Error@1 4.890

==>>[2018-05-04 17:39:28] [Epoch=432/540] [Need: 00:54:47] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [432][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:39:28]
  Epoch: [432][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0033 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:39:39]
  Epoch: [432][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:39:50]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.100 Prec@5 99.830 Error@1 4.900

==>>[2018-05-04 17:39:58] [Epoch=433/540] [Need: 00:54:16] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [433][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0430 (0.0430)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:39:59]
  Epoch: [433][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0070 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:40:10]
  Epoch: [433][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:40:20]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.140 Prec@5 99.800 Error@1 4.860

==>>[2018-05-04 17:40:29] [Epoch=434/540] [Need: 00:53:46] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [434][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:40:29]
  Epoch: [434][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:40:40]
  Epoch: [434][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0065 (0.0052)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-04 17:40:51]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.210 Prec@5 99.810 Error@1 4.790

==>>[2018-05-04 17:40:59] [Epoch=435/540] [Need: 00:53:15] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [435][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:40:59]
  Epoch: [435][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0037 (0.0060)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 17:41:10]
  Epoch: [435][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0056)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 17:41:21]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.130 Prec@5 99.820 Error@1 4.870

==>>[2018-05-04 17:41:29] [Epoch=436/540] [Need: 00:52:45] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [436][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:41:29]
  Epoch: [436][200/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0060)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 17:41:40]
  Epoch: [436][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0056)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 17:41:51]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.160 Prec@5 99.790 Error@1 4.840

==>>[2018-05-04 17:41:59] [Epoch=437/540] [Need: 00:52:14] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [437][000/500]   Time 0.078 (0.078)   Data 0.049 (0.049)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:42:00]
  Epoch: [437][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:42:11]
  Epoch: [437][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0041 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:42:22]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.120 Prec@5 99.810 Error@1 4.880

==>>[2018-05-04 17:42:30] [Epoch=438/540] [Need: 00:51:44] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [438][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:42:30]
  Epoch: [438][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0060)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-05-04 17:42:42]
  Epoch: [438][400/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0058)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 17:42:53]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.200 Prec@5 99.800 Error@1 4.800

==>>[2018-05-04 17:43:01] [Epoch=439/540] [Need: 00:51:14] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [439][000/500]   Time 0.082 (0.082)   Data 0.052 (0.052)   Loss 0.0050 (0.0050)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:43:01]
  Epoch: [439][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:43:12]
  Epoch: [439][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:43:23]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.200 Prec@5 99.830 Error@1 4.800

==>>[2018-05-04 17:43:31] [Epoch=440/540] [Need: 00:50:43] [learning_rate=0.000010] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [440][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:43:31]
  Epoch: [440][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0055)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 17:43:42]
  Epoch: [440][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0075 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:43:53]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.140 Prec@5 99.840 Error@1 4.860

==>>[2018-05-04 17:44:02] [Epoch=441/540] [Need: 00:50:13] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [441][000/500]   Time 0.076 (0.076)   Data 0.047 (0.047)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:44:02]
  Epoch: [441][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:44:13]
  Epoch: [441][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:44:24]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.120 Prec@5 99.790 Error@1 4.880

==>>[2018-05-04 17:44:32] [Epoch=442/540] [Need: 00:49:42] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [442][000/500]   Time 0.078 (0.078)   Data 0.049 (0.049)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:44:32]
  Epoch: [442][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:44:44]
  Epoch: [442][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:44:55]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.140 Prec@5 99.830 Error@1 4.860

==>>[2018-05-04 17:45:03] [Epoch=443/540] [Need: 00:49:12] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [443][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:45:03]
  Epoch: [443][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:45:15]
  Epoch: [443][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0056)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 17:45:26]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.150 Prec@5 99.810 Error@1 4.850

==>>[2018-05-04 17:45:34] [Epoch=444/540] [Need: 00:48:42] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [444][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:45:34]
  Epoch: [444][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0052)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 17:45:46]
  Epoch: [444][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0051)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 17:45:57]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.150 Prec@5 99.790 Error@1 4.850

==>>[2018-05-04 17:46:05] [Epoch=445/540] [Need: 00:48:11] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [445][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:46:05]
  Epoch: [445][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0048 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:46:16]
  Epoch: [445][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 17:46:27]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.120 Prec@5 99.810 Error@1 4.880

==>>[2018-05-04 17:46:36] [Epoch=446/540] [Need: 00:47:41] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [446][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:46:36]
  Epoch: [446][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0050)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:46:47]
  Epoch: [446][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0037 (0.0053)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:46:58]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.180 Prec@5 99.820 Error@1 4.820

==>>[2018-05-04 17:47:06] [Epoch=447/540] [Need: 00:47:10] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [447][000/500]   Time 0.080 (0.080)   Data 0.050 (0.050)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:47:06]
  Epoch: [447][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0129 (0.0054)   Prec@1 99.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:47:17]
  Epoch: [447][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:47:28]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.160 Prec@5 99.810 Error@1 4.840

==>>[2018-05-04 17:47:36] [Epoch=448/540] [Need: 00:46:40] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [448][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:47:36]
  Epoch: [448][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:47:48]
  Epoch: [448][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0079 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:47:59]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.130 Prec@5 99.800 Error@1 4.870

==>>[2018-05-04 17:48:07] [Epoch=449/540] [Need: 00:46:10] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [449][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:48:07]
  Epoch: [449][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0058)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 17:48:18]
  Epoch: [449][400/500]   Time 0.061 (0.056)   Data 0.000 (0.000)   Loss 0.0041 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:48:29]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.200 Prec@5 99.850 Error@1 4.800

==>>[2018-05-04 17:48:38] [Epoch=450/540] [Need: 00:45:39] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [450][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:48:38]
  Epoch: [450][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0056)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:48:49]
  Epoch: [450][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0048 (0.0055)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 17:49:00]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.160 Prec@5 99.800 Error@1 4.840

==>>[2018-05-04 17:49:08] [Epoch=451/540] [Need: 00:45:09] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [451][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0139 (0.0139)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:49:08]
  Epoch: [451][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0051)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:49:19]
  Epoch: [451][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0065 (0.0053)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:49:30]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.070 Prec@5 99.800 Error@1 4.930

==>>[2018-05-04 17:49:38] [Epoch=452/540] [Need: 00:44:38] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [452][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:49:38]
  Epoch: [452][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 17:49:49]
  Epoch: [452][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0056)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 17:50:00]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.160 Prec@5 99.770 Error@1 4.840

==>>[2018-05-04 17:50:08] [Epoch=453/540] [Need: 00:44:08] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [453][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:50:08]
  Epoch: [453][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 17:50:20]
  Epoch: [453][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0083 (0.0052)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 17:50:30]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.150 Prec@5 99.840 Error@1 4.850

==>>[2018-05-04 17:50:39] [Epoch=454/540] [Need: 00:43:37] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [454][000/500]   Time 0.074 (0.074)   Data 0.046 (0.046)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:50:39]
  Epoch: [454][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0025 (0.0060)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:50:50]
  Epoch: [454][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0058)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 17:51:01]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.100 Prec@5 99.850 Error@1 4.900

==>>[2018-05-04 17:51:09] [Epoch=455/540] [Need: 00:43:07] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [455][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0050 (0.0050)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:51:09]
  Epoch: [455][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0048)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-05-04 17:51:20]
  Epoch: [455][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0243 (0.0053)   Prec@1 99.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:51:31]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.160 Prec@5 99.800 Error@1 4.840

==>>[2018-05-04 17:51:39] [Epoch=456/540] [Need: 00:42:36] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [456][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:51:39]
  Epoch: [456][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:51:50]
  Epoch: [456][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:52:01]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.150 Prec@5 99.840 Error@1 4.850

==>>[2018-05-04 17:52:09] [Epoch=457/540] [Need: 00:42:06] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [457][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:52:09]
  Epoch: [457][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0055 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:52:20]
  Epoch: [457][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0051)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:52:32]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.080 Prec@5 99.770 Error@1 4.920

==>>[2018-05-04 17:52:40] [Epoch=458/540] [Need: 00:41:35] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [458][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:52:40]
  Epoch: [458][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0074 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:52:51]
  Epoch: [458][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0060)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:53:02]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.240 Prec@5 99.800 Error@1 4.760

==>>[2018-05-04 17:53:10] [Epoch=459/540] [Need: 00:41:05] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [459][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0117 (0.0117)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:53:10]
  Epoch: [459][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0261 (0.0058)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 17:53:21]
  Epoch: [459][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:53:32]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.180 Prec@5 99.770 Error@1 4.820

==>>[2018-05-04 17:53:40] [Epoch=460/540] [Need: 00:40:34] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [460][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:53:40]
  Epoch: [460][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:53:51]
  Epoch: [460][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0057 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:54:03]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.090 Prec@5 99.820 Error@1 4.910

==>>[2018-05-04 17:54:11] [Epoch=461/540] [Need: 00:40:04] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [461][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:54:11]
  Epoch: [461][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 17:54:22]
  Epoch: [461][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:54:33]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.150 Prec@5 99.830 Error@1 4.850

==>>[2018-05-04 17:54:41] [Epoch=462/540] [Need: 00:39:34] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [462][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0175 (0.0175)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:54:41]
  Epoch: [462][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0055 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:54:52]
  Epoch: [462][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:55:03]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.150 Prec@5 99.870 Error@1 4.850

==>>[2018-05-04 17:55:11] [Epoch=463/540] [Need: 00:39:03] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [463][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:55:11]
  Epoch: [463][200/500]   Time 0.063 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0062)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 17:55:22]
  Epoch: [463][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0062)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-04 17:55:33]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 95.170 Prec@5 99.810 Error@1 4.830

==>>[2018-05-04 17:55:41] [Epoch=464/540] [Need: 00:38:33] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [464][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:55:41]
  Epoch: [464][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0057)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 17:55:52]
  Epoch: [464][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 17:56:03]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.110 Prec@5 99.800 Error@1 4.890

==>>[2018-05-04 17:56:11] [Epoch=465/540] [Need: 00:38:02] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [465][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0026 (0.0026)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:56:12]
  Epoch: [465][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0060)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 17:56:22]
  Epoch: [465][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0107 (0.0058)   Prec@1 99.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 17:56:33]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.060 Prec@5 99.810 Error@1 4.940

==>>[2018-05-04 17:56:41] [Epoch=466/540] [Need: 00:37:32] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [466][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:56:42]
  Epoch: [466][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:56:53]
  Epoch: [466][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:57:03]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.130 Prec@5 99.850 Error@1 4.870

==>>[2018-05-04 17:57:12] [Epoch=467/540] [Need: 00:37:01] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [467][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:57:12]
  Epoch: [467][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 17:57:23]
  Epoch: [467][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 17:57:34]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.160 Prec@5 99.810 Error@1 4.840

==>>[2018-05-04 17:57:42] [Epoch=468/540] [Need: 00:36:31] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [468][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:57:42]
  Epoch: [468][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0057)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 17:57:53]
  Epoch: [468][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0091 (0.0058)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 17:58:04]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.230 Prec@5 99.830 Error@1 4.770

==>>[2018-05-04 17:58:12] [Epoch=469/540] [Need: 00:36:00] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [469][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:58:12]
  Epoch: [469][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:58:23]
  Epoch: [469][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0134 (0.0055)   Prec@1 99.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 17:58:34]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.160 Prec@5 99.770 Error@1 4.840

==>>[2018-05-04 17:58:42] [Epoch=470/540] [Need: 00:35:30] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [470][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:58:42]
  Epoch: [470][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0026 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:58:53]
  Epoch: [470][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:59:04]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.130 Prec@5 99.810 Error@1 4.870

==>>[2018-05-04 17:59:12] [Epoch=471/540] [Need: 00:34:59] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [471][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:59:12]
  Epoch: [471][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 17:59:23]
  Epoch: [471][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0063 (0.0055)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 17:59:34]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.200 Prec@5 99.820 Error@1 4.800

==>>[2018-05-04 17:59:42] [Epoch=472/540] [Need: 00:34:29] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [472][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 17:59:42]
  Epoch: [472][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 17:59:53]
  Epoch: [472][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 18:00:04]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.200 Prec@5 99.820 Error@1 4.800

==>>[2018-05-04 18:00:13] [Epoch=473/540] [Need: 00:33:58] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [473][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:00:13]
  Epoch: [473][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:00:24]
  Epoch: [473][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:00:35]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.160 Prec@5 99.830 Error@1 4.840

==>>[2018-05-04 18:00:43] [Epoch=474/540] [Need: 00:33:28] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [474][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0113 (0.0113)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:00:43]
  Epoch: [474][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 18:00:54]
  Epoch: [474][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0132 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:01:05]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.160 Prec@5 99.850 Error@1 4.840

==>>[2018-05-04 18:01:14] [Epoch=475/540] [Need: 00:32:57] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [475][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0118 (0.0118)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:01:14]
  Epoch: [475][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0066 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:01:25]
  Epoch: [475][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:01:36]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.200 Prec@5 99.810 Error@1 4.800

==>>[2018-05-04 18:01:45] [Epoch=476/540] [Need: 00:32:27] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [476][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:01:45]
  Epoch: [476][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0059)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 18:01:57]
  Epoch: [476][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0052 (0.0057)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 18:02:08]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.190 Prec@5 99.800 Error@1 4.810

==>>[2018-05-04 18:02:17] [Epoch=477/540] [Need: 00:31:57] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [477][000/500]   Time 0.078 (0.078)   Data 0.049 (0.049)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:02:17]
  Epoch: [477][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0030 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 18:02:29]
  Epoch: [477][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0043 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 18:02:40]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.110 Prec@5 99.820 Error@1 4.890

==>>[2018-05-04 18:02:48] [Epoch=478/540] [Need: 00:31:27] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [478][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:02:48]
  Epoch: [478][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:03:00]
  Epoch: [478][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0083 (0.0055)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:03:11]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-05-04 18:03:19] [Epoch=479/540] [Need: 00:30:56] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [479][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0111 (0.0111)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:03:19]
  Epoch: [479][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 18:03:30]
  Epoch: [479][400/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.0044 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:03:42]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.180 Prec@5 99.830 Error@1 4.820

==>>[2018-05-04 18:03:50] [Epoch=480/540] [Need: 00:30:26] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [480][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:03:50]
  Epoch: [480][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:04:02]
  Epoch: [480][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 18:04:13]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.140 Prec@5 99.800 Error@1 4.860

==>>[2018-05-04 18:04:22] [Epoch=481/540] [Need: 00:29:56] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [481][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:04:22]
  Epoch: [481][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:04:33]
  Epoch: [481][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:04:44]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.200 Prec@5 99.830 Error@1 4.800

==>>[2018-05-04 18:04:53] [Epoch=482/540] [Need: 00:29:25] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [482][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:04:53]
  Epoch: [482][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0080 (0.0051)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 18:05:05]
  Epoch: [482][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0075 (0.0051)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-04 18:05:16]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.190 Prec@5 99.840 Error@1 4.810

==>>[2018-05-04 18:05:24] [Epoch=483/540] [Need: 00:28:55] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [483][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:05:24]
  Epoch: [483][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 18:05:36]
  Epoch: [483][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 18:05:47]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.030 Prec@5 99.840 Error@1 4.970

==>>[2018-05-04 18:05:55] [Epoch=484/540] [Need: 00:28:24] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [484][000/500]   Time 0.080 (0.080)   Data 0.051 (0.051)   Loss 0.0395 (0.0395)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:05:55]
  Epoch: [484][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0070 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:06:07]
  Epoch: [484][400/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.0028 (0.0058)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 18:06:19]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.140 Prec@5 99.820 Error@1 4.860

==>>[2018-05-04 18:06:28] [Epoch=485/540] [Need: 00:27:54] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [485][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:06:28]
  Epoch: [485][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0201 (0.0055)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:06:39]
  Epoch: [485][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 18:06:50]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.180 Prec@5 99.840 Error@1 4.820

==>>[2018-05-04 18:06:59] [Epoch=486/540] [Need: 00:27:24] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [486][000/500]   Time 0.081 (0.081)   Data 0.051 (0.051)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:06:59]
  Epoch: [486][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0038 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:07:11]
  Epoch: [486][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0050 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:07:22]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.170 Prec@5 99.830 Error@1 4.830

==>>[2018-05-04 18:07:31] [Epoch=487/540] [Need: 00:26:54] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [487][000/500]   Time 0.079 (0.079)   Data 0.051 (0.051)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:07:31]
  Epoch: [487][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0040 (0.0056)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 18:07:42]
  Epoch: [487][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0460 (0.0058)   Prec@1 98.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 18:07:54]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.180 Prec@5 99.820 Error@1 4.820

==>>[2018-05-04 18:08:02] [Epoch=488/540] [Need: 00:26:23] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [488][000/500]   Time 0.079 (0.079)   Data 0.050 (0.050)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:08:02]
  Epoch: [488][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:08:14]
  Epoch: [488][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0109 (0.0051)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:08:25]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.150 Prec@5 99.850 Error@1 4.850

==>>[2018-05-04 18:08:34] [Epoch=489/540] [Need: 00:25:53] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [489][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0118 (0.0118)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:08:34]
  Epoch: [489][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0072 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:08:46]
  Epoch: [489][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0030 (0.0059)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 18:08:57]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.130 Prec@5 99.800 Error@1 4.870

==>>[2018-05-04 18:09:06] [Epoch=490/540] [Need: 00:25:23] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [490][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:09:06]
  Epoch: [490][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0057)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 18:09:17]
  Epoch: [490][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0177 (0.0054)   Prec@1 99.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:09:29]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.170 Prec@5 99.840 Error@1 4.830

==>>[2018-05-04 18:09:37] [Epoch=491/540] [Need: 00:24:52] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [491][000/500]   Time 0.079 (0.079)   Data 0.051 (0.051)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:09:37]
  Epoch: [491][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0053 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:09:49]
  Epoch: [491][400/500]   Time 0.062 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:10:00]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.150 Prec@5 99.850 Error@1 4.850

==>>[2018-05-04 18:10:09] [Epoch=492/540] [Need: 00:24:22] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [492][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:10:09]
  Epoch: [492][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0039 (0.0059)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-04 18:10:21]
  Epoch: [492][400/500]   Time 0.067 (0.059)   Data 0.000 (0.000)   Loss 0.0035 (0.0059)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-04 18:10:32]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 95.200 Prec@5 99.840 Error@1 4.800

==>>[2018-05-04 18:10:41] [Epoch=493/540] [Need: 00:23:52] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [493][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:10:41]
  Epoch: [493][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:10:53]
  Epoch: [493][400/500]   Time 0.063 (0.058)   Data 0.000 (0.000)   Loss 0.0050 (0.0051)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 18:11:05]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.280 Prec@5 99.810 Error@1 4.720

==>>[2018-05-04 18:11:13] [Epoch=494/540] [Need: 00:23:21] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [494][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:11:13]
  Epoch: [494][200/500]   Time 0.066 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0049)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 18:11:25]
  Epoch: [494][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0047 (0.0050)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:11:37]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.230 Prec@5 99.850 Error@1 4.770

==>>[2018-05-04 18:11:46] [Epoch=495/540] [Need: 00:22:51] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [495][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0113 (0.0113)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:11:46]
  Epoch: [495][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0037 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:11:58]
  Epoch: [495][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0030 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 18:12:09]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.180 Prec@5 99.860 Error@1 4.820

==>>[2018-05-04 18:12:17] [Epoch=496/540] [Need: 00:22:21] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [496][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:12:18]
  Epoch: [496][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0063)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-04 18:12:29]
  Epoch: [496][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-04 18:12:40]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 95.140 Prec@5 99.830 Error@1 4.860

==>>[2018-05-04 18:12:49] [Epoch=497/540] [Need: 00:21:50] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [497][000/500]   Time 0.076 (0.076)   Data 0.048 (0.048)   Loss 0.0080 (0.0080)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:12:49]
  Epoch: [497][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:13:00]
  Epoch: [497][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 18:13:12]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.100 Prec@5 99.810 Error@1 4.900

==>>[2018-05-04 18:13:21] [Epoch=498/540] [Need: 00:21:20] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [498][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:13:21]
  Epoch: [498][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 18:13:32]
  Epoch: [498][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0038 (0.0054)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 18:13:44]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.110 Prec@5 99.800 Error@1 4.890

==>>[2018-05-04 18:13:52] [Epoch=499/540] [Need: 00:20:49] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [499][000/500]   Time 0.078 (0.078)   Data 0.050 (0.050)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:13:52]
  Epoch: [499][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:14:04]
  Epoch: [499][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0046 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 18:14:15]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.140 Prec@5 99.820 Error@1 4.860

==>>[2018-05-04 18:14:24] [Epoch=500/540] [Need: 00:20:19] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [500][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:14:24]
  Epoch: [500][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:14:35]
  Epoch: [500][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:14:47]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.120 Prec@5 99.810 Error@1 4.880

==>>[2018-05-04 18:14:55] [Epoch=501/540] [Need: 00:19:49] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [501][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:14:55]
  Epoch: [501][200/500]   Time 0.054 (0.058)   Data 0.000 (0.000)   Loss 0.0072 (0.0059)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 18:15:07]
  Epoch: [501][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0029 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 18:15:19]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.230 Prec@5 99.830 Error@1 4.770

==>>[2018-05-04 18:15:27] [Epoch=502/540] [Need: 00:19:18] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [502][000/500]   Time 0.079 (0.079)   Data 0.051 (0.051)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:15:27]
  Epoch: [502][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:15:39]
  Epoch: [502][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0033 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:15:51]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.180 Prec@5 99.780 Error@1 4.820

==>>[2018-05-04 18:15:59] [Epoch=503/540] [Need: 00:18:48] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [503][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:16:00]
  Epoch: [503][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 18:16:11]
  Epoch: [503][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0132 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 18:16:23]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.170 Prec@5 99.810 Error@1 4.830

==>>[2018-05-04 18:16:31] [Epoch=504/540] [Need: 00:18:17] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [504][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:16:31]
  Epoch: [504][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0438 (0.0055)   Prec@1 98.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 18:16:43]
  Epoch: [504][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0033 (0.0054)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:16:54]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.150 Prec@5 99.820 Error@1 4.850

==>>[2018-05-04 18:17:03] [Epoch=505/540] [Need: 00:17:47] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [505][000/500]   Time 0.075 (0.075)   Data 0.048 (0.048)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:17:03]
  Epoch: [505][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0060)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 18:17:14]
  Epoch: [505][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0067 (0.0057)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 18:17:26]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.140 Prec@5 99.810 Error@1 4.860

==>>[2018-05-04 18:17:34] [Epoch=506/540] [Need: 00:17:17] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [506][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:17:34]
  Epoch: [506][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0060 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 18:17:46]
  Epoch: [506][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0043 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 18:17:57]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.140 Prec@5 99.820 Error@1 4.860

==>>[2018-05-04 18:18:06] [Epoch=507/540] [Need: 00:16:46] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [507][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:18:06]
  Epoch: [507][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0512 (0.0052)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:18:17]
  Epoch: [507][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0051)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:18:28]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.140 Prec@5 99.830 Error@1 4.860

==>>[2018-05-04 18:18:37] [Epoch=508/540] [Need: 00:16:16] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [508][000/500]   Time 0.078 (0.078)   Data 0.050 (0.050)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:18:37]
  Epoch: [508][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:18:48]
  Epoch: [508][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:19:00]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.190 Prec@5 99.830 Error@1 4.810

==>>[2018-05-04 18:19:08] [Epoch=509/540] [Need: 00:15:45] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [509][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:19:08]
  Epoch: [509][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0081 (0.0052)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-05-04 18:19:19]
  Epoch: [509][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0054)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-04 18:19:30]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.180 Prec@5 99.810 Error@1 4.820

==>>[2018-05-04 18:19:38] [Epoch=510/540] [Need: 00:15:15] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [510][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:19:38]
  Epoch: [510][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0048 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:19:50]
  Epoch: [510][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0119 (0.0055)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:20:01]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.210 Prec@5 99.810 Error@1 4.790

==>>[2018-05-04 18:20:10] [Epoch=511/540] [Need: 00:14:44] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [511][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:20:10]
  Epoch: [511][200/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-04 18:20:22]
  Epoch: [511][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0032 (0.0054)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 18:20:34]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.110 Prec@5 99.850 Error@1 4.890

==>>[2018-05-04 18:20:42] [Epoch=512/540] [Need: 00:14:14] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [512][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:20:43]
  Epoch: [512][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0073 (0.0062)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:20:54]
  Epoch: [512][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0047 (0.0060)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 18:21:06]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.160 Prec@5 99.810 Error@1 4.840

==>>[2018-05-04 18:21:15] [Epoch=513/540] [Need: 00:13:43] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [513][000/500]   Time 0.077 (0.077)   Data 0.049 (0.049)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:21:15]
  Epoch: [513][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0052)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:21:26]
  Epoch: [513][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 18:21:38]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.060 Prec@5 99.830 Error@1 4.940

==>>[2018-05-04 18:21:46] [Epoch=514/540] [Need: 00:13:13] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [514][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0367 (0.0367)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:21:46]
  Epoch: [514][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:21:58]
  Epoch: [514][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 18:22:09]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.130 Prec@5 99.830 Error@1 4.870

==>>[2018-05-04 18:22:17] [Epoch=515/540] [Need: 00:12:42] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [515][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:22:17]
  Epoch: [515][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0227 (0.0053)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:22:28]
  Epoch: [515][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:22:39]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.090 Prec@5 99.780 Error@1 4.910

==>>[2018-05-04 18:22:47] [Epoch=516/540] [Need: 00:12:12] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [516][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:22:47]
  Epoch: [516][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0185 (0.0054)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:22:58]
  Epoch: [516][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0055)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 18:23:09]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.200 Prec@5 99.810 Error@1 4.800

==>>[2018-05-04 18:23:17] [Epoch=517/540] [Need: 00:11:41] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [517][000/500]   Time 0.073 (0.073)   Data 0.047 (0.047)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:23:17]
  Epoch: [517][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0086 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:23:28]
  Epoch: [517][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0059)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-04 18:23:39]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.100 Prec@5 99.810 Error@1 4.900

==>>[2018-05-04 18:23:47] [Epoch=518/540] [Need: 00:11:11] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [518][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:23:47]
  Epoch: [518][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0052)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 18:23:58]
  Epoch: [518][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0052)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 18:24:09]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.110 Prec@5 99.820 Error@1 4.890

==>>[2018-05-04 18:24:17] [Epoch=519/540] [Need: 00:10:40] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [519][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:24:17]
  Epoch: [519][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 18:24:28]
  Epoch: [519][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0055)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 18:24:39]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-05-04 18:24:47] [Epoch=520/540] [Need: 00:10:10] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [520][000/500]   Time 0.094 (0.094)   Data 0.068 (0.068)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:24:47]
  Epoch: [520][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-04 18:24:58]
  Epoch: [520][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0059 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 18:25:09]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.170 Prec@5 99.790 Error@1 4.830

==>>[2018-05-04 18:25:17] [Epoch=521/540] [Need: 00:09:39] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [521][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:25:17]
  Epoch: [521][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0059)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-04 18:25:28]
  Epoch: [521][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0062 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:25:39]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.060 Prec@5 99.820 Error@1 4.940

==>>[2018-05-04 18:25:47] [Epoch=522/540] [Need: 00:09:09] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [522][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:25:47]
  Epoch: [522][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:25:58]
  Epoch: [522][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0055)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 18:26:09]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.170 Prec@5 99.840 Error@1 4.830

==>>[2018-05-04 18:26:17] [Epoch=523/540] [Need: 00:08:38] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [523][000/500]   Time 0.076 (0.076)   Data 0.050 (0.050)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:26:17]
  Epoch: [523][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:26:28]
  Epoch: [523][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0055)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-04 18:26:39]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.150 Prec@5 99.820 Error@1 4.850

==>>[2018-05-04 18:26:47] [Epoch=524/540] [Need: 00:08:08] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [524][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:26:47]
  Epoch: [524][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0047)   Prec@1 100.000 (99.995)   Prec@5 100.000 (100.000)   [2018-05-04 18:26:58]
  Epoch: [524][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0045 (0.0052)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-05-04 18:27:09]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.100 Prec@5 99.830 Error@1 4.900

==>>[2018-05-04 18:27:17] [Epoch=525/540] [Need: 00:07:37] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [525][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:27:17]
  Epoch: [525][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0088 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:27:28]
  Epoch: [525][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 18:27:39]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.160 Prec@5 99.800 Error@1 4.840

==>>[2018-05-04 18:27:47] [Epoch=526/540] [Need: 00:07:07] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [526][000/500]   Time 0.080 (0.080)   Data 0.050 (0.050)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:27:47]
  Epoch: [526][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0060)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 18:27:59]
  Epoch: [526][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0056)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-04 18:28:09]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.150 Prec@5 99.810 Error@1 4.850

==>>[2018-05-04 18:28:18] [Epoch=527/540] [Need: 00:06:36] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [527][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:28:18]
  Epoch: [527][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:28:29]
  Epoch: [527][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 18:28:40]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.110 Prec@5 99.810 Error@1 4.890

==>>[2018-05-04 18:28:49] [Epoch=528/540] [Need: 00:06:06] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [528][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:28:49]
  Epoch: [528][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0050 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:29:00]
  Epoch: [528][400/500]   Time 0.054 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:29:12]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.130 Prec@5 99.820 Error@1 4.870

==>>[2018-05-04 18:29:21] [Epoch=529/540] [Need: 00:05:35] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [529][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:29:21]
  Epoch: [529][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:29:32]
  Epoch: [529][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-04 18:29:44]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.190 Prec@5 99.850 Error@1 4.810

==>>[2018-05-04 18:29:52] [Epoch=530/540] [Need: 00:05:05] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [530][000/500]   Time 0.074 (0.074)   Data 0.047 (0.047)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:29:52]
  Epoch: [530][200/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:30:03]
  Epoch: [530][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 18:30:15]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.150 Prec@5 99.830 Error@1 4.850

==>>[2018-05-04 18:30:24] [Epoch=531/540] [Need: 00:04:34] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [531][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0051 (0.0051)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:30:24]
  Epoch: [531][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0061 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:30:35]
  Epoch: [531][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-04 18:30:47]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.160 Prec@5 99.800 Error@1 4.840

==>>[2018-05-04 18:30:56] [Epoch=532/540] [Need: 00:04:04] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [532][000/500]   Time 0.081 (0.081)   Data 0.052 (0.052)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:30:56]
  Epoch: [532][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0052)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-04 18:31:07]
  Epoch: [532][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0165 (0.0051)   Prec@1 99.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-04 18:31:19]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.110 Prec@5 99.780 Error@1 4.890

==>>[2018-05-04 18:31:27] [Epoch=533/540] [Need: 00:03:33] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [533][000/500]   Time 0.072 (0.072)   Data 0.046 (0.046)   Loss 0.0115 (0.0115)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:31:27]
  Epoch: [533][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0052)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-04 18:31:39]
  Epoch: [533][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-04 18:31:50]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.120 Prec@5 99.830 Error@1 4.880

==>>[2018-05-04 18:31:59] [Epoch=534/540] [Need: 00:03:03] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [534][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:31:59]
  Epoch: [534][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0054 (0.0049)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-05-04 18:32:10]
  Epoch: [534][400/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.0091 (0.0052)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-04 18:32:21]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.140 Prec@5 99.820 Error@1 4.860

==>>[2018-05-04 18:32:29] [Epoch=535/540] [Need: 00:02:32] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [535][000/500]   Time 0.076 (0.076)   Data 0.049 (0.049)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:32:29]
  Epoch: [535][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0064)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-04 18:32:40]
  Epoch: [535][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0060)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-04 18:32:51]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.110 Prec@5 99.790 Error@1 4.890

==>>[2018-05-04 18:33:00] [Epoch=536/540] [Need: 00:02:02] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [536][000/500]   Time 0.081 (0.081)   Data 0.051 (0.051)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:33:00]
  Epoch: [536][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0036 (0.0059)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-04 18:33:12]
  Epoch: [536][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-04 18:33:23]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.130 Prec@5 99.840 Error@1 4.870

==>>[2018-05-04 18:33:31] [Epoch=537/540] [Need: 00:01:31] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [537][000/500]   Time 0.075 (0.075)   Data 0.049 (0.049)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:33:32]
  Epoch: [537][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:33:42]
  Epoch: [537][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-04 18:33:54]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.060 Prec@5 99.820 Error@1 4.940

==>>[2018-05-04 18:34:02] [Epoch=538/540] [Need: 00:01:01] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [538][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:34:03]
  Epoch: [538][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0052 (0.0050)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 18:34:14]
  Epoch: [538][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0086 (0.0053)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-04 18:34:25]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.110 Prec@5 99.810 Error@1 4.890

==>>[2018-05-04 18:34:34] [Epoch=539/540] [Need: 00:00:30] [learning_rate=0.000001] [Best : Accuracy=95.32, Error=4.68]
  Epoch: [539][000/500]   Time 0.079 (0.079)   Data 0.051 (0.051)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-04 18:34:34]
  Epoch: [539][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0090 (0.0050)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-04 18:34:45]
  Epoch: [539][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-04 18:34:57]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.140 Prec@5 99.820 Error@1 4.860
