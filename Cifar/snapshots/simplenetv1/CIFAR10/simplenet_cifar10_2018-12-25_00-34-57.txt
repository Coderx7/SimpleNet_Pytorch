save path : ./snapshots/simplenet
{'arch': 'simplenet', 'batch_size': 100, 'data_path': './data/cifar.python', 'dataset': 'cifar10', 'decay': 0.002, 'epochs': 550, 'evaluate': False, 'gammas': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1], 'learning_rate': 0.1, 'manualSeed': 971, 'momentum': 0.9, 'ngpu': 1, 'print_freq': 200, 'resume': '', 'save_path': './snapshots/simpnet', 'schedule': [100, 190, 306, 390, 440, 540], 'start_epoch': 0, 'use_cuda': True, 'workers': 2}
Random Seed: 971
python version : 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)  [GCC 7.2.0]
torch  version : 1.0.0
cudnn  version : 7401
=> creating model 'simplenet'
=> network :
 simplenet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)
    (13): Dropout2d(p=0.1)
    (14): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (16): ReLU(inplace)
    (17): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (19): ReLU(inplace)
    (20): Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (22): ReLU(inplace)
    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)
    (24): Dropout2d(p=0.1)
    (25): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (26): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (27): ReLU(inplace)
    (28): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (29): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (30): ReLU(inplace)
    (31): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)
    (32): Dropout2d(p=0.1)
    (33): Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (35): ReLU(inplace)
    (36): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)
    (37): Dropout2d(p=0.1)
    (38): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1))
    (39): BatchNorm2d(2048, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (40): ReLU(inplace)
    (41): Conv2d(2048, 256, kernel_size=[1, 1], stride=(1, 1))
    (42): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (43): ReLU(inplace)
    (44): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)
    (45): Dropout2d(p=0.1)
    (46): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (47): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)
    (48): ReLU(inplace)
  )
  (classifier): Linear(in_features=256, out_features=10, bias=True)
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,792
       BatchNorm2d-2           [-1, 64, 32, 32]             128
              ReLU-3           [-1, 64, 32, 32]               0
            Conv2d-4          [-1, 128, 32, 32]          73,856
       BatchNorm2d-5          [-1, 128, 32, 32]             256
              ReLU-6          [-1, 128, 32, 32]               0
            Conv2d-7          [-1, 128, 32, 32]         147,584
       BatchNorm2d-8          [-1, 128, 32, 32]             256
              ReLU-9          [-1, 128, 32, 32]               0
           Conv2d-10          [-1, 128, 32, 32]         147,584
      BatchNorm2d-11          [-1, 128, 32, 32]             256
             ReLU-12          [-1, 128, 32, 32]               0
        MaxPool2d-13          [-1, 128, 16, 16]               0
        Dropout2d-14          [-1, 128, 16, 16]               0
           Conv2d-15          [-1, 128, 16, 16]         147,584
      BatchNorm2d-16          [-1, 128, 16, 16]             256
             ReLU-17          [-1, 128, 16, 16]               0
           Conv2d-18          [-1, 128, 16, 16]         147,584
      BatchNorm2d-19          [-1, 128, 16, 16]             256
             ReLU-20          [-1, 128, 16, 16]               0
           Conv2d-21          [-1, 256, 16, 16]         295,168
      BatchNorm2d-22          [-1, 256, 16, 16]             512
             ReLU-23          [-1, 256, 16, 16]               0
        MaxPool2d-24            [-1, 256, 8, 8]               0
        Dropout2d-25            [-1, 256, 8, 8]               0
           Conv2d-26            [-1, 256, 8, 8]         590,080
      BatchNorm2d-27            [-1, 256, 8, 8]             512
             ReLU-28            [-1, 256, 8, 8]               0
           Conv2d-29            [-1, 256, 8, 8]         590,080
      BatchNorm2d-30            [-1, 256, 8, 8]             512
             ReLU-31            [-1, 256, 8, 8]               0
        MaxPool2d-32            [-1, 256, 4, 4]               0
        Dropout2d-33            [-1, 256, 4, 4]               0
           Conv2d-34            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-35            [-1, 512, 4, 4]           1,024
             ReLU-36            [-1, 512, 4, 4]               0
        MaxPool2d-37            [-1, 512, 2, 2]               0
        Dropout2d-38            [-1, 512, 2, 2]               0
           Conv2d-39           [-1, 2048, 2, 2]       1,050,624
      BatchNorm2d-40           [-1, 2048, 2, 2]           4,096
             ReLU-41           [-1, 2048, 2, 2]               0
           Conv2d-42            [-1, 256, 2, 2]         524,544
      BatchNorm2d-43            [-1, 256, 2, 2]             512
             ReLU-44            [-1, 256, 2, 2]               0
        MaxPool2d-45            [-1, 256, 1, 1]               0
        Dropout2d-46            [-1, 256, 1, 1]               0
           Conv2d-47            [-1, 256, 1, 1]         590,080
      BatchNorm2d-48            [-1, 256, 1, 1]             512
             ReLU-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 10]           2,570
        simplenet-51                   [-1, 10]               0
================================================================
Total params: 5,498,378
Trainable params: 5,498,378
Non-trainable params: 0
----------------------------------------------------------------
=> Seed '971'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> optimizer '{'optimizer': {'state': {}, 'param_groups': [{'lr': 0.1, 'rho': 0.9, 'eps': 0.001, 'weight_decay': 0.002, 'params': [140655709219720, 140655709219792, 140655709219936, 140655709220080, 140655709220440, 140655709220512, 140655709220656, 140655709220800, 140655709219288, 140655709302856, 140655709303000, 140655709303144, 140655709303432, 140655709303504, 140655709303576, 140655709303648, 140655709303936, 140655709304008, 140655709304080, 140655709304152, 140655709304440, 140655709304512, 140655709304584, 140655709304656, 140655709304944, 140655709305016, 140655709305088, 140655709305160, 140655709305448, 140655709305520, 140655709305592, 140655709305664, 140655709305952, 140655709306024, 140655709306096, 140655709306168, 140655709306456, 140655709306528, 140655709306600, 140655709306672, 140655607672976, 140655607673048, 140655607673120, 140655607673192, 140655607673480, 140655607673552, 140655607673624, 140655607673696, 140655607673984, 140655607674056, 140655607674200, 140655607674344, 140655607674704, 140655607674776]}]}}'
=> did not use any checkpoint for simplenet model

==>>[2018-12-25 00:34:59] [Epoch=000/550] [Need: 00:00:00] [learning_rate=0.100000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 1.146 (1.146)   Data 0.066 (0.066)   Loss 2.3547 (2.3547)   Prec@1 9.000 (9.000)   Prec@5 49.000 (49.000)   [2018-12-25 00:35:01]
  Epoch: [000][200/500]   Time 0.058 (0.065)   Data 0.000 (0.000)   Loss 1.7926 (1.8463)   Prec@1 30.000 (29.896)   Prec@5 88.000 (83.343)   [2018-12-25 00:35:12]
  Epoch: [000][400/500]   Time 0.061 (0.062)   Data 0.000 (0.000)   Loss 1.3622 (1.6854)   Prec@1 51.000 (36.594)   Prec@5 95.000 (87.364)   [2018-12-25 00:35:24]
  **Train** Prec@1 39.132 Prec@5 88.422 Error@1 60.868
  **Test** Prec@1 47.150 Prec@5 94.210 Error@1 52.850

==>>[2018-12-25 00:35:33] [Epoch=001/550] [Need: 05:01:10] [learning_rate=0.100000] [Best : Accuracy=47.15, Error=52.85]
  Epoch: [001][000/500]   Time 0.102 (0.102)   Data 0.067 (0.067)   Loss 1.4343 (1.4343)   Prec@1 45.000 (45.000)   Prec@5 90.000 (90.000)   [2018-12-25 00:35:33]
  Epoch: [001][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 1.2724 (1.2725)   Prec@1 53.000 (53.950)   Prec@5 95.000 (94.373)   [2018-12-25 00:35:45]
  Epoch: [001][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 1.0250 (1.2095)   Prec@1 59.000 (56.319)   Prec@5 98.000 (94.960)   [2018-12-25 00:35:57]
  **Train** Prec@1 57.346 Prec@5 95.144 Error@1 42.654
  **Test** Prec@1 62.510 Prec@5 96.720 Error@1 37.490

==>>[2018-12-25 00:36:06] [Epoch=002/550] [Need: 05:00:53] [learning_rate=0.100000] [Best : Accuracy=62.51, Error=37.49]
  Epoch: [002][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 1.1273 (1.1273)   Prec@1 59.000 (59.000)   Prec@5 96.000 (96.000)   [2018-12-25 00:36:06]
  Epoch: [002][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 1.1095 (1.0073)   Prec@1 64.000 (63.861)   Prec@5 93.000 (96.532)   [2018-12-25 00:36:18]
  Epoch: [002][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.8240 (0.9763)   Prec@1 70.000 (65.294)   Prec@5 99.000 (96.803)   [2018-12-25 00:36:30]
  **Train** Prec@1 65.940 Prec@5 96.920 Error@1 34.060
  **Test** Prec@1 71.780 Prec@5 97.440 Error@1 28.220

==>>[2018-12-25 00:36:39] [Epoch=003/550] [Need: 05:00:30] [learning_rate=0.100000] [Best : Accuracy=71.78, Error=28.22]
  Epoch: [003][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.8726 (0.8726)   Prec@1 70.000 (70.000)   Prec@5 98.000 (98.000)   [2018-12-25 00:36:39]
  Epoch: [003][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.8864 (0.8478)   Prec@1 70.000 (70.254)   Prec@5 96.000 (97.537)   [2018-12-25 00:36:51]
  Epoch: [003][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.7774 (0.8300)   Prec@1 69.000 (70.840)   Prec@5 97.000 (97.756)   [2018-12-25 00:37:03]
  **Train** Prec@1 71.214 Prec@5 97.874 Error@1 28.786
  **Test** Prec@1 75.960 Prec@5 98.700 Error@1 24.040

==>>[2018-12-25 00:37:12] [Epoch=004/550] [Need: 04:59:52] [learning_rate=0.100000] [Best : Accuracy=75.96, Error=24.04]
  Epoch: [004][000/500]   Time 0.097 (0.097)   Data 0.062 (0.062)   Loss 0.8133 (0.8133)   Prec@1 69.000 (69.000)   Prec@5 98.000 (98.000)   [2018-12-25 00:37:12]
  Epoch: [004][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.7990 (0.7456)   Prec@1 69.000 (74.303)   Prec@5 100.000 (98.219)   [2018-12-25 00:37:24]
  Epoch: [004][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.8178 (0.7334)   Prec@1 68.000 (74.763)   Prec@5 100.000 (98.212)   [2018-12-25 00:37:36]
  **Train** Prec@1 74.882 Prec@5 98.200 Error@1 25.118
  **Test** Prec@1 77.570 Prec@5 98.650 Error@1 22.430

==>>[2018-12-25 00:37:45] [Epoch=005/550] [Need: 04:59:16] [learning_rate=0.100000] [Best : Accuracy=77.57, Error=22.43]
  Epoch: [005][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.5950 (0.5950)   Prec@1 82.000 (82.000)   Prec@5 98.000 (98.000)   [2018-12-25 00:37:45]
  Epoch: [005][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.6118 (0.6708)   Prec@1 74.000 (76.900)   Prec@5 99.000 (98.522)   [2018-12-25 00:37:57]
  Epoch: [005][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.5408 (0.6624)   Prec@1 84.000 (77.224)   Prec@5 97.000 (98.521)   [2018-12-25 00:38:09]
  **Train** Prec@1 77.384 Prec@5 98.548 Error@1 22.616
  **Test** Prec@1 79.350 Prec@5 98.780 Error@1 20.650

==>>[2018-12-25 00:38:18] [Epoch=006/550] [Need: 04:58:40] [learning_rate=0.100000] [Best : Accuracy=79.35, Error=20.65]
  Epoch: [006][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.5574 (0.5574)   Prec@1 82.000 (82.000)   Prec@5 98.000 (98.000)   [2018-12-25 00:38:18]
  Epoch: [006][200/500]   Time 0.063 (0.060)   Data 0.000 (0.000)   Loss 0.5478 (0.6316)   Prec@1 81.000 (78.632)   Prec@5 100.000 (98.706)   [2018-12-25 00:38:30]
  Epoch: [006][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.6471 (0.6100)   Prec@1 78.000 (79.314)   Prec@5 98.000 (98.798)   [2018-12-25 00:38:42]
  **Train** Prec@1 79.390 Prec@5 98.782 Error@1 20.610
  **Test** Prec@1 79.580 Prec@5 98.760 Error@1 20.420

==>>[2018-12-25 00:38:51] [Epoch=007/550] [Need: 04:58:00] [learning_rate=0.100000] [Best : Accuracy=79.58, Error=20.42]
  Epoch: [007][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.6909 (0.6909)   Prec@1 72.000 (72.000)   Prec@5 98.000 (98.000)   [2018-12-25 00:38:51]
  Epoch: [007][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.6678 (0.5719)   Prec@1 74.000 (80.771)   Prec@5 99.000 (98.995)   [2018-12-25 00:39:03]
  Epoch: [007][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.4911 (0.5721)   Prec@1 84.000 (80.594)   Prec@5 99.000 (98.830)   [2018-12-25 00:39:15]
  **Train** Prec@1 80.746 Prec@5 98.872 Error@1 19.254
  **Test** Prec@1 83.150 Prec@5 99.150 Error@1 16.850

==>>[2018-12-25 00:39:24] [Epoch=008/550] [Need: 04:57:40] [learning_rate=0.100000] [Best : Accuracy=83.15, Error=16.85]
  Epoch: [008][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.3985 (0.3985)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:39:24]
  Epoch: [008][200/500]   Time 0.062 (0.060)   Data 0.000 (0.000)   Loss 0.4354 (0.5284)   Prec@1 84.000 (82.189)   Prec@5 99.000 (98.965)   [2018-12-25 00:39:36]
  Epoch: [008][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.5215 (0.5331)   Prec@1 81.000 (82.057)   Prec@5 100.000 (98.968)   [2018-12-25 00:39:48]
  **Train** Prec@1 82.048 Prec@5 98.956 Error@1 17.952
  **Test** Prec@1 80.500 Prec@5 99.140 Error@1 19.500

==>>[2018-12-25 00:39:56] [Epoch=009/550] [Need: 04:56:52] [learning_rate=0.100000] [Best : Accuracy=83.15, Error=16.85]
  Epoch: [009][000/500]   Time 0.094 (0.094)   Data 0.062 (0.062)   Loss 0.5195 (0.5195)   Prec@1 83.000 (83.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:39:56]
  Epoch: [009][200/500]   Time 0.059 (0.061)   Data 0.000 (0.000)   Loss 0.3824 (0.5061)   Prec@1 87.000 (83.169)   Prec@5 100.000 (99.065)   [2018-12-25 00:40:09]
  Epoch: [009][400/500]   Time 0.060 (0.061)   Data 0.000 (0.000)   Loss 0.5991 (0.5117)   Prec@1 84.000 (82.855)   Prec@5 99.000 (99.050)   [2018-12-25 00:40:21]
  **Train** Prec@1 82.894 Prec@5 99.058 Error@1 17.106
  **Test** Prec@1 81.350 Prec@5 99.220 Error@1 18.650

==>>[2018-12-25 00:40:29] [Epoch=010/550] [Need: 04:56:18] [learning_rate=0.100000] [Best : Accuracy=83.15, Error=16.85]
  Epoch: [010][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.5593 (0.5593)   Prec@1 83.000 (83.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:40:29]
  Epoch: [010][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.4035 (0.4768)   Prec@1 90.000 (84.144)   Prec@5 100.000 (99.179)   [2018-12-25 00:40:41]
  Epoch: [010][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.4637 (0.4758)   Prec@1 83.000 (84.175)   Prec@5 100.000 (99.202)   [2018-12-25 00:40:53]
  **Train** Prec@1 84.192 Prec@5 99.200 Error@1 15.808
  **Test** Prec@1 81.800 Prec@5 99.160 Error@1 18.200

==>>[2018-12-25 00:41:02] [Epoch=011/550] [Need: 04:55:31] [learning_rate=0.100000] [Best : Accuracy=83.15, Error=16.85]
  Epoch: [011][000/500]   Time 0.097 (0.097)   Data 0.064 (0.064)   Loss 0.3978 (0.3978)   Prec@1 86.000 (86.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:41:02]
  Epoch: [011][200/500]   Time 0.065 (0.060)   Data 0.000 (0.000)   Loss 0.5228 (0.4621)   Prec@1 82.000 (84.692)   Prec@5 100.000 (99.184)   [2018-12-25 00:41:14]
  Epoch: [011][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3430 (0.4655)   Prec@1 87.000 (84.594)   Prec@5 100.000 (99.187)   [2018-12-25 00:41:26]
  **Train** Prec@1 84.414 Prec@5 99.184 Error@1 15.586
  **Test** Prec@1 84.030 Prec@5 99.350 Error@1 15.970

==>>[2018-12-25 00:41:35] [Epoch=012/550] [Need: 04:55:08] [learning_rate=0.100000] [Best : Accuracy=84.03, Error=15.97]
  Epoch: [012][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.3399 (0.3399)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:41:35]
  Epoch: [012][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3750 (0.4425)   Prec@1 88.000 (85.164)   Prec@5 100.000 (99.363)   [2018-12-25 00:41:47]
  Epoch: [012][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.5609 (0.4498)   Prec@1 78.000 (85.010)   Prec@5 99.000 (99.274)   [2018-12-25 00:41:59]
  **Train** Prec@1 85.082 Prec@5 99.272 Error@1 14.918
  **Test** Prec@1 83.560 Prec@5 98.970 Error@1 16.440

==>>[2018-12-25 00:42:08] [Epoch=013/550] [Need: 04:54:26] [learning_rate=0.100000] [Best : Accuracy=84.03, Error=15.97]
  Epoch: [013][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.3080 (0.3080)   Prec@1 90.000 (90.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:42:08]
  Epoch: [013][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3723 (0.4353)   Prec@1 83.000 (85.562)   Prec@5 100.000 (99.234)   [2018-12-25 00:42:20]
  Epoch: [013][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3331 (0.4363)   Prec@1 89.000 (85.449)   Prec@5 100.000 (99.262)   [2018-12-25 00:42:32]
  **Train** Prec@1 85.458 Prec@5 99.258 Error@1 14.542
  **Test** Prec@1 84.610 Prec@5 99.390 Error@1 15.390

==>>[2018-12-25 00:42:41] [Epoch=014/550] [Need: 04:54:03] [learning_rate=0.100000] [Best : Accuracy=84.61, Error=15.39]
  Epoch: [014][000/500]   Time 0.100 (0.100)   Data 0.065 (0.065)   Loss 0.2784 (0.2784)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:42:41]
  Epoch: [014][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.4816 (0.4296)   Prec@1 86.000 (85.597)   Prec@5 100.000 (99.393)   [2018-12-25 00:42:53]
  Epoch: [014][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.3810 (0.4227)   Prec@1 86.000 (85.848)   Prec@5 100.000 (99.364)   [2018-12-25 00:43:05]
  **Train** Prec@1 85.750 Prec@5 99.352 Error@1 14.250
  **Test** Prec@1 84.700 Prec@5 99.300 Error@1 15.300

==>>[2018-12-25 00:43:14] [Epoch=015/550] [Need: 04:53:37] [learning_rate=0.100000] [Best : Accuracy=84.70, Error=15.30]
  Epoch: [015][000/500]   Time 0.098 (0.098)   Data 0.066 (0.066)   Loss 0.4461 (0.4461)   Prec@1 87.000 (87.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:43:14]
  Epoch: [015][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.4417 (0.4086)   Prec@1 86.000 (86.443)   Prec@5 100.000 (99.388)   [2018-12-25 00:43:26]
  Epoch: [015][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.5274 (0.4163)   Prec@1 83.000 (86.120)   Prec@5 100.000 (99.369)   [2018-12-25 00:43:38]
  **Train** Prec@1 86.142 Prec@5 99.392 Error@1 13.858
  **Test** Prec@1 84.930 Prec@5 99.330 Error@1 15.070

==>>[2018-12-25 00:43:47] [Epoch=016/550] [Need: 04:53:09] [learning_rate=0.100000] [Best : Accuracy=84.93, Error=15.07]
  Epoch: [016][000/500]   Time 0.094 (0.094)   Data 0.062 (0.062)   Loss 0.4188 (0.4188)   Prec@1 87.000 (87.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:43:47]
  Epoch: [016][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.5140 (0.4055)   Prec@1 85.000 (86.627)   Prec@5 100.000 (99.348)   [2018-12-25 00:43:59]
  Epoch: [016][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.4331 (0.4010)   Prec@1 84.000 (86.840)   Prec@5 99.000 (99.384)   [2018-12-25 00:44:11]
  **Train** Prec@1 86.738 Prec@5 99.422 Error@1 13.262
  **Test** Prec@1 86.840 Prec@5 99.240 Error@1 13.160

==>>[2018-12-25 00:44:20] [Epoch=017/550] [Need: 04:52:37] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [017][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.3604 (0.3604)   Prec@1 89.000 (89.000)   Prec@5 98.000 (98.000)   [2018-12-25 00:44:20]
  Epoch: [017][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.3982 (0.3963)   Prec@1 89.000 (86.975)   Prec@5 100.000 (99.398)   [2018-12-25 00:44:32]
  Epoch: [017][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.4309 (0.4015)   Prec@1 86.000 (86.681)   Prec@5 98.000 (99.411)   [2018-12-25 00:44:44]
  **Train** Prec@1 86.696 Prec@5 99.418 Error@1 13.304
  **Test** Prec@1 83.730 Prec@5 99.370 Error@1 16.270

==>>[2018-12-25 00:44:53] [Epoch=018/550] [Need: 04:51:55] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [018][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.3112 (0.3112)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:44:53]
  Epoch: [018][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.2370 (0.3872)   Prec@1 94.000 (87.090)   Prec@5 100.000 (99.493)   [2018-12-25 00:45:05]
  Epoch: [018][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3082 (0.3909)   Prec@1 93.000 (87.035)   Prec@5 100.000 (99.424)   [2018-12-25 00:45:17]
  **Train** Prec@1 86.924 Prec@5 99.406 Error@1 13.076
  **Test** Prec@1 84.980 Prec@5 99.280 Error@1 15.020

==>>[2018-12-25 00:45:25] [Epoch=019/550] [Need: 04:51:14] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [019][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.2769 (0.2769)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:45:25]
  Epoch: [019][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.4664 (0.3792)   Prec@1 84.000 (87.443)   Prec@5 100.000 (99.502)   [2018-12-25 00:45:37]
  Epoch: [019][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.2941 (0.3822)   Prec@1 92.000 (87.444)   Prec@5 100.000 (99.456)   [2018-12-25 00:45:49]
  **Train** Prec@1 87.418 Prec@5 99.436 Error@1 12.582
  **Test** Prec@1 83.200 Prec@5 99.240 Error@1 16.800

==>>[2018-12-25 00:45:58] [Epoch=020/550] [Need: 04:50:33] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [020][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.2489 (0.2489)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:45:58]
  Epoch: [020][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.4432 (0.3707)   Prec@1 86.000 (87.796)   Prec@5 100.000 (99.403)   [2018-12-25 00:46:10]
  Epoch: [020][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.4018 (0.3760)   Prec@1 86.000 (87.569)   Prec@5 100.000 (99.431)   [2018-12-25 00:46:22]
  **Train** Prec@1 87.478 Prec@5 99.434 Error@1 12.522
  **Test** Prec@1 80.890 Prec@5 99.040 Error@1 19.110

==>>[2018-12-25 00:46:31] [Epoch=021/550] [Need: 04:49:53] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [021][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.3535 (0.3535)   Prec@1 87.000 (87.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:46:31]
  Epoch: [021][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.2343 (0.3629)   Prec@1 93.000 (87.990)   Prec@5 100.000 (99.557)   [2018-12-25 00:46:43]
  Epoch: [021][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.4314 (0.3629)   Prec@1 89.000 (88.035)   Prec@5 98.000 (99.494)   [2018-12-25 00:46:55]
  **Train** Prec@1 87.852 Prec@5 99.488 Error@1 12.148
  **Test** Prec@1 86.070 Prec@5 99.130 Error@1 13.930

==>>[2018-12-25 00:47:03] [Epoch=022/550] [Need: 04:49:17] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [022][000/500]   Time 0.090 (0.090)   Data 0.063 (0.063)   Loss 0.2686 (0.2686)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:47:03]
  Epoch: [022][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.2863 (0.3531)   Prec@1 89.000 (88.114)   Prec@5 100.000 (99.617)   [2018-12-25 00:47:15]
  Epoch: [022][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.4692 (0.3593)   Prec@1 88.000 (88.020)   Prec@5 98.000 (99.504)   [2018-12-25 00:47:27]
  **Train** Prec@1 87.804 Prec@5 99.508 Error@1 12.196
  **Test** Prec@1 85.540 Prec@5 99.320 Error@1 14.460

==>>[2018-12-25 00:47:36] [Epoch=023/550] [Need: 04:48:41] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [023][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.4133 (0.4133)   Prec@1 85.000 (85.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:47:36]
  Epoch: [023][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.2813 (0.3547)   Prec@1 92.000 (88.279)   Prec@5 100.000 (99.562)   [2018-12-25 00:47:48]
  Epoch: [023][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.2758 (0.3609)   Prec@1 90.000 (87.995)   Prec@5 100.000 (99.494)   [2018-12-25 00:48:00]
  **Train** Prec@1 87.962 Prec@5 99.496 Error@1 12.038
  **Test** Prec@1 86.510 Prec@5 99.380 Error@1 13.490

==>>[2018-12-25 00:48:09] [Epoch=024/550] [Need: 04:48:04] [learning_rate=0.100000] [Best : Accuracy=86.84, Error=13.16]
  Epoch: [024][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.1980 (0.1980)   Prec@1 96.000 (96.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:48:09]
  Epoch: [024][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.4659 (0.3512)   Prec@1 86.000 (88.652)   Prec@5 100.000 (99.542)   [2018-12-25 00:48:21]
  Epoch: [024][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3096 (0.3494)   Prec@1 89.000 (88.623)   Prec@5 100.000 (99.504)   [2018-12-25 00:48:33]
  **Train** Prec@1 88.500 Prec@5 99.482 Error@1 11.500
  **Test** Prec@1 87.300 Prec@5 99.460 Error@1 12.700

==>>[2018-12-25 00:48:42] [Epoch=025/550] [Need: 04:47:36] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [025][000/500]   Time 0.101 (0.101)   Data 0.066 (0.066)   Loss 0.3146 (0.3146)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:48:42]
  Epoch: [025][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3738 (0.3309)   Prec@1 85.000 (89.005)   Prec@5 100.000 (99.602)   [2018-12-25 00:48:54]
  Epoch: [025][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.4447 (0.3438)   Prec@1 86.000 (88.594)   Prec@5 100.000 (99.571)   [2018-12-25 00:49:06]
  **Train** Prec@1 88.488 Prec@5 99.550 Error@1 11.512
  **Test** Prec@1 81.750 Prec@5 99.230 Error@1 18.250

==>>[2018-12-25 00:49:15] [Epoch=026/550] [Need: 04:47:00] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [026][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.3301 (0.3301)   Prec@1 88.000 (88.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:49:15]
  Epoch: [026][200/500]   Time 0.062 (0.060)   Data 0.000 (0.000)   Loss 0.2849 (0.3318)   Prec@1 89.000 (89.095)   Prec@5 100.000 (99.622)   [2018-12-25 00:49:27]
  Epoch: [026][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.3532 (0.3403)   Prec@1 85.000 (88.833)   Prec@5 100.000 (99.574)   [2018-12-25 00:49:39]
  **Train** Prec@1 88.752 Prec@5 99.576 Error@1 11.248
  **Test** Prec@1 86.560 Prec@5 99.570 Error@1 13.440

==>>[2018-12-25 00:49:47] [Epoch=027/550] [Need: 04:46:23] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [027][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.3197 (0.3197)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:49:47]
  Epoch: [027][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.2754 (0.3359)   Prec@1 91.000 (88.960)   Prec@5 100.000 (99.522)   [2018-12-25 00:49:59]
  Epoch: [027][400/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.2401 (0.3368)   Prec@1 91.000 (88.930)   Prec@5 100.000 (99.579)   [2018-12-25 00:50:11]
  **Train** Prec@1 88.986 Prec@5 99.572 Error@1 11.014
  **Test** Prec@1 82.850 Prec@5 99.280 Error@1 17.150

==>>[2018-12-25 00:50:20] [Epoch=028/550] [Need: 04:45:46] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [028][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.4999 (0.4999)   Prec@1 84.000 (84.000)   Prec@5 98.000 (98.000)   [2018-12-25 00:50:20]
  Epoch: [028][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.3151 (0.3318)   Prec@1 90.000 (89.085)   Prec@5 100.000 (99.607)   [2018-12-25 00:50:32]
  Epoch: [028][400/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.3019 (0.3391)   Prec@1 90.000 (88.781)   Prec@5 100.000 (99.546)   [2018-12-25 00:50:44]
  **Train** Prec@1 88.882 Prec@5 99.546 Error@1 11.118
  **Test** Prec@1 86.000 Prec@5 99.410 Error@1 14.000

==>>[2018-12-25 00:50:52] [Epoch=029/550] [Need: 04:45:10] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [029][000/500]   Time 0.095 (0.095)   Data 0.067 (0.067)   Loss 0.3104 (0.3104)   Prec@1 87.000 (87.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:50:53]
  Epoch: [029][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.2855 (0.3222)   Prec@1 93.000 (89.299)   Prec@5 99.000 (99.632)   [2018-12-25 00:51:05]
  Epoch: [029][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.4118 (0.3350)   Prec@1 87.000 (88.880)   Prec@5 100.000 (99.613)   [2018-12-25 00:51:17]
  **Train** Prec@1 88.814 Prec@5 99.584 Error@1 11.186
  **Test** Prec@1 85.630 Prec@5 98.980 Error@1 14.370

==>>[2018-12-25 00:51:25] [Epoch=030/550] [Need: 04:44:36] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [030][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.3210 (0.3210)   Prec@1 89.000 (89.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:51:25]
  Epoch: [030][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.5075 (0.3207)   Prec@1 81.000 (89.607)   Prec@5 99.000 (99.587)   [2018-12-25 00:51:37]
  Epoch: [030][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.2404 (0.3273)   Prec@1 94.000 (89.359)   Prec@5 100.000 (99.554)   [2018-12-25 00:51:49]
  **Train** Prec@1 89.368 Prec@5 99.556 Error@1 10.632
  **Test** Prec@1 83.520 Prec@5 98.940 Error@1 16.480

==>>[2018-12-25 00:51:58] [Epoch=031/550] [Need: 04:44:00] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [031][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.2300 (0.2300)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:51:58]
  Epoch: [031][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3609 (0.3150)   Prec@1 88.000 (89.801)   Prec@5 99.000 (99.572)   [2018-12-25 00:52:10]
  Epoch: [031][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.3528 (0.3199)   Prec@1 88.000 (89.534)   Prec@5 99.000 (99.586)   [2018-12-25 00:52:22]
  **Train** Prec@1 89.378 Prec@5 99.586 Error@1 10.622
  **Test** Prec@1 84.540 Prec@5 99.280 Error@1 15.460

==>>[2018-12-25 00:52:30] [Epoch=032/550] [Need: 04:43:23] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [032][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.2264 (0.2264)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:52:31]
  Epoch: [032][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3798 (0.3064)   Prec@1 89.000 (90.055)   Prec@5 99.000 (99.607)   [2018-12-25 00:52:43]
  Epoch: [032][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3089 (0.3182)   Prec@1 91.000 (89.621)   Prec@5 100.000 (99.599)   [2018-12-25 00:52:55]
  **Train** Prec@1 89.392 Prec@5 99.598 Error@1 10.608
  **Test** Prec@1 83.270 Prec@5 99.100 Error@1 16.730

==>>[2018-12-25 00:53:03] [Epoch=033/550] [Need: 04:42:49] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [033][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.2624 (0.2624)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:53:03]
  Epoch: [033][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.2939 (0.3096)   Prec@1 93.000 (89.647)   Prec@5 100.000 (99.711)   [2018-12-25 00:53:15]
  Epoch: [033][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.2173 (0.3208)   Prec@1 94.000 (89.359)   Prec@5 100.000 (99.683)   [2018-12-25 00:53:27]
  **Train** Prec@1 89.444 Prec@5 99.678 Error@1 10.556
  **Test** Prec@1 84.050 Prec@5 99.380 Error@1 15.950

==>>[2018-12-25 00:53:36] [Epoch=034/550] [Need: 04:42:14] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [034][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.1425 (0.1425)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:53:36]
  Epoch: [034][200/500]   Time 0.054 (0.060)   Data 0.000 (0.000)   Loss 0.2962 (0.3089)   Prec@1 90.000 (89.761)   Prec@5 99.000 (99.662)   [2018-12-25 00:53:48]
  Epoch: [034][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.3815 (0.3195)   Prec@1 89.000 (89.367)   Prec@5 100.000 (99.631)   [2018-12-25 00:54:00]
  **Train** Prec@1 89.358 Prec@5 99.618 Error@1 10.642
  **Test** Prec@1 86.460 Prec@5 99.300 Error@1 13.540

==>>[2018-12-25 00:54:09] [Epoch=035/550] [Need: 04:41:40] [learning_rate=0.100000] [Best : Accuracy=87.30, Error=12.70]
  Epoch: [035][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.1553 (0.1553)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:54:09]
  Epoch: [035][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.3482 (0.3090)   Prec@1 89.000 (89.930)   Prec@5 100.000 (99.642)   [2018-12-25 00:54:21]
  Epoch: [035][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.3372 (0.3136)   Prec@1 88.000 (89.696)   Prec@5 99.000 (99.636)   [2018-12-25 00:54:33]
  **Train** Prec@1 89.632 Prec@5 99.626 Error@1 10.368
  **Test** Prec@1 87.560 Prec@5 99.520 Error@1 12.440

==>>[2018-12-25 00:54:42] [Epoch=036/550] [Need: 04:41:11] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [036][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.2514 (0.2514)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:54:42]
  Epoch: [036][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.2434 (0.3043)   Prec@1 92.000 (89.980)   Prec@5 100.000 (99.672)   [2018-12-25 00:54:54]
  Epoch: [036][400/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.3537 (0.3165)   Prec@1 86.000 (89.546)   Prec@5 99.000 (99.628)   [2018-12-25 00:55:06]
  **Train** Prec@1 89.476 Prec@5 99.598 Error@1 10.524
  **Test** Prec@1 85.800 Prec@5 99.330 Error@1 14.200

==>>[2018-12-25 00:55:14] [Epoch=037/550] [Need: 04:40:35] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [037][000/500]   Time 0.092 (0.092)   Data 0.061 (0.061)   Loss 0.1674 (0.1674)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:55:14]
  Epoch: [037][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.2425 (0.3040)   Prec@1 93.000 (90.025)   Prec@5 99.000 (99.587)   [2018-12-25 00:55:26]
  Epoch: [037][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.3509 (0.3099)   Prec@1 90.000 (89.898)   Prec@5 99.000 (99.586)   [2018-12-25 00:55:38]
  **Train** Prec@1 89.836 Prec@5 99.576 Error@1 10.164
  **Test** Prec@1 83.450 Prec@5 98.870 Error@1 16.550

==>>[2018-12-25 00:55:47] [Epoch=038/550] [Need: 04:39:58] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [038][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.2121 (0.2121)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:55:47]
  Epoch: [038][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.3366 (0.3006)   Prec@1 90.000 (90.194)   Prec@5 100.000 (99.672)   [2018-12-25 00:55:59]
  Epoch: [038][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.4960 (0.3093)   Prec@1 83.000 (89.873)   Prec@5 99.000 (99.623)   [2018-12-25 00:56:11]
  **Train** Prec@1 89.854 Prec@5 99.630 Error@1 10.146
  **Test** Prec@1 84.160 Prec@5 99.240 Error@1 15.840

==>>[2018-12-25 00:56:19] [Epoch=039/550] [Need: 04:39:20] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [039][000/500]   Time 0.098 (0.098)   Data 0.063 (0.063)   Loss 0.3253 (0.3253)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:56:19]
  Epoch: [039][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.4757 (0.3019)   Prec@1 84.000 (89.935)   Prec@5 99.000 (99.701)   [2018-12-25 00:56:31]
  Epoch: [039][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.5686 (0.3077)   Prec@1 81.000 (89.858)   Prec@5 99.000 (99.671)   [2018-12-25 00:56:43]
  **Train** Prec@1 89.770 Prec@5 99.662 Error@1 10.230
  **Test** Prec@1 86.220 Prec@5 99.440 Error@1 13.780

==>>[2018-12-25 00:56:52] [Epoch=040/550] [Need: 04:38:42] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [040][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.2266 (0.2266)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:56:52]
  Epoch: [040][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.2585 (0.3037)   Prec@1 92.000 (90.224)   Prec@5 100.000 (99.567)   [2018-12-25 00:57:04]
  Epoch: [040][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3615 (0.3046)   Prec@1 87.000 (90.087)   Prec@5 98.000 (99.601)   [2018-12-25 00:57:15]
  **Train** Prec@1 90.034 Prec@5 99.618 Error@1 9.966
  **Test** Prec@1 83.480 Prec@5 99.080 Error@1 16.520

==>>[2018-12-25 00:57:24] [Epoch=041/550] [Need: 04:38:05] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [041][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.2902 (0.2902)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:57:24]
  Epoch: [041][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2350 (0.3029)   Prec@1 94.000 (90.234)   Prec@5 100.000 (99.612)   [2018-12-25 00:57:36]
  Epoch: [041][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.3387 (0.3102)   Prec@1 88.000 (89.805)   Prec@5 100.000 (99.606)   [2018-12-25 00:57:48]
  **Train** Prec@1 89.878 Prec@5 99.624 Error@1 10.122
  **Test** Prec@1 86.970 Prec@5 99.270 Error@1 13.030

==>>[2018-12-25 00:57:56] [Epoch=042/550] [Need: 04:37:27] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [042][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.3826 (0.3826)   Prec@1 88.000 (88.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:57:56]
  Epoch: [042][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1867 (0.2878)   Prec@1 95.000 (90.478)   Prec@5 100.000 (99.711)   [2018-12-25 00:58:08]
  Epoch: [042][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2569 (0.2970)   Prec@1 90.000 (90.172)   Prec@5 100.000 (99.701)   [2018-12-25 00:58:20]
  **Train** Prec@1 90.124 Prec@5 99.686 Error@1 9.876
  **Test** Prec@1 85.960 Prec@5 99.330 Error@1 14.040

==>>[2018-12-25 00:58:29] [Epoch=043/550] [Need: 04:36:49] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [043][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.3626 (0.3626)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:58:29]
  Epoch: [043][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2720 (0.2986)   Prec@1 93.000 (90.199)   Prec@5 100.000 (99.667)   [2018-12-25 00:58:41]
  Epoch: [043][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2352 (0.3040)   Prec@1 93.000 (90.045)   Prec@5 100.000 (99.633)   [2018-12-25 00:58:53]
  **Train** Prec@1 89.970 Prec@5 99.624 Error@1 10.030
  **Test** Prec@1 84.760 Prec@5 99.240 Error@1 15.240

==>>[2018-12-25 00:59:01] [Epoch=044/550] [Need: 04:36:11] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [044][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.2457 (0.2457)   Prec@1 93.000 (93.000)   Prec@5 99.000 (99.000)   [2018-12-25 00:59:01]
  Epoch: [044][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3284 (0.2882)   Prec@1 88.000 (90.527)   Prec@5 100.000 (99.657)   [2018-12-25 00:59:13]
  Epoch: [044][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2804 (0.2981)   Prec@1 91.000 (90.204)   Prec@5 100.000 (99.641)   [2018-12-25 00:59:25]
  **Train** Prec@1 90.094 Prec@5 99.638 Error@1 9.906
  **Test** Prec@1 86.300 Prec@5 99.390 Error@1 13.700

==>>[2018-12-25 00:59:33] [Epoch=045/550] [Need: 04:35:34] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [045][000/500]   Time 0.097 (0.097)   Data 0.065 (0.065)   Loss 0.3232 (0.3232)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-12-25 00:59:34]
  Epoch: [045][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2413 (0.2989)   Prec@1 91.000 (90.254)   Prec@5 100.000 (99.687)   [2018-12-25 00:59:45]
  Epoch: [045][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3595 (0.2978)   Prec@1 88.000 (90.289)   Prec@5 98.000 (99.641)   [2018-12-25 00:59:57]
  **Train** Prec@1 90.156 Prec@5 99.628 Error@1 9.844
  **Test** Prec@1 83.500 Prec@5 99.130 Error@1 16.500

==>>[2018-12-25 01:00:06] [Epoch=046/550] [Need: 04:34:56] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [046][000/500]   Time 0.096 (0.096)   Data 0.068 (0.068)   Loss 0.1900 (0.1900)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:00:06]
  Epoch: [046][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.1834 (0.2945)   Prec@1 97.000 (90.184)   Prec@5 99.000 (99.682)   [2018-12-25 01:00:18]
  Epoch: [046][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2583 (0.2975)   Prec@1 91.000 (90.075)   Prec@5 100.000 (99.711)   [2018-12-25 01:00:29]
  **Train** Prec@1 90.086 Prec@5 99.680 Error@1 9.914
  **Test** Prec@1 85.790 Prec@5 99.180 Error@1 14.210

==>>[2018-12-25 01:00:38] [Epoch=047/550] [Need: 04:34:19] [learning_rate=0.100000] [Best : Accuracy=87.56, Error=12.44]
  Epoch: [047][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.2555 (0.2555)   Prec@1 94.000 (94.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:00:38]
  Epoch: [047][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3454 (0.2926)   Prec@1 90.000 (90.408)   Prec@5 99.000 (99.706)   [2018-12-25 01:00:50]
  Epoch: [047][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.1966 (0.2942)   Prec@1 94.000 (90.314)   Prec@5 100.000 (99.676)   [2018-12-25 01:01:02]
  **Train** Prec@1 90.354 Prec@5 99.664 Error@1 9.646
  **Test** Prec@1 88.310 Prec@5 99.480 Error@1 11.690

==>>[2018-12-25 01:01:11] [Epoch=048/550] [Need: 04:33:45] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [048][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.3510 (0.3510)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:01:11]
  Epoch: [048][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2593 (0.2883)   Prec@1 93.000 (90.701)   Prec@5 100.000 (99.687)   [2018-12-25 01:01:23]
  Epoch: [048][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2262 (0.2986)   Prec@1 92.000 (90.319)   Prec@5 100.000 (99.668)   [2018-12-25 01:01:34]
  **Train** Prec@1 90.310 Prec@5 99.664 Error@1 9.690
  **Test** Prec@1 86.040 Prec@5 99.440 Error@1 13.960

==>>[2018-12-25 01:01:43] [Epoch=049/550] [Need: 04:33:08] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [049][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.2928 (0.2928)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:01:43]
  Epoch: [049][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2600 (0.2841)   Prec@1 89.000 (90.602)   Prec@5 100.000 (99.647)   [2018-12-25 01:01:55]
  Epoch: [049][400/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.2933 (0.2883)   Prec@1 91.000 (90.454)   Prec@5 99.000 (99.678)   [2018-12-25 01:02:07]
  **Train** Prec@1 90.390 Prec@5 99.658 Error@1 9.610
  **Test** Prec@1 86.330 Prec@5 99.420 Error@1 13.670

==>>[2018-12-25 01:02:15] [Epoch=050/550] [Need: 04:32:31] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [050][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.3767 (0.3767)   Prec@1 86.000 (86.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:02:15]
  Epoch: [050][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2911 (0.2810)   Prec@1 91.000 (90.771)   Prec@5 100.000 (99.692)   [2018-12-25 01:02:27]
  Epoch: [050][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2896 (0.2878)   Prec@1 89.000 (90.541)   Prec@5 100.000 (99.678)   [2018-12-25 01:02:39]
  **Train** Prec@1 90.328 Prec@5 99.658 Error@1 9.672
  **Test** Prec@1 86.020 Prec@5 98.910 Error@1 13.980

==>>[2018-12-25 01:02:47] [Epoch=051/550] [Need: 04:31:54] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [051][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.1898 (0.1898)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:02:48]
  Epoch: [051][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2338 (0.2813)   Prec@1 91.000 (90.527)   Prec@5 100.000 (99.726)   [2018-12-25 01:02:59]
  Epoch: [051][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2981 (0.2847)   Prec@1 91.000 (90.511)   Prec@5 99.000 (99.676)   [2018-12-25 01:03:11]
  **Train** Prec@1 90.416 Prec@5 99.672 Error@1 9.584
  **Test** Prec@1 87.060 Prec@5 99.360 Error@1 12.940

==>>[2018-12-25 01:03:20] [Epoch=052/550] [Need: 04:31:18] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [052][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.1888 (0.1888)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:03:20]
  Epoch: [052][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3147 (0.2802)   Prec@1 89.000 (90.965)   Prec@5 100.000 (99.761)   [2018-12-25 01:03:32]
  Epoch: [052][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2302 (0.2911)   Prec@1 94.000 (90.469)   Prec@5 99.000 (99.691)   [2018-12-25 01:03:43]
  **Train** Prec@1 90.416 Prec@5 99.686 Error@1 9.584
  **Test** Prec@1 83.960 Prec@5 99.030 Error@1 16.040

==>>[2018-12-25 01:03:52] [Epoch=053/550] [Need: 04:30:40] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [053][000/500]   Time 0.096 (0.096)   Data 0.061 (0.061)   Loss 0.3066 (0.3066)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:03:52]
  Epoch: [053][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2202 (0.2850)   Prec@1 93.000 (90.811)   Prec@5 100.000 (99.721)   [2018-12-25 01:04:04]
  Epoch: [053][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3201 (0.2836)   Prec@1 88.000 (90.758)   Prec@5 99.000 (99.703)   [2018-12-25 01:04:16]
  **Train** Prec@1 90.560 Prec@5 99.686 Error@1 9.440
  **Test** Prec@1 86.180 Prec@5 99.340 Error@1 13.820

==>>[2018-12-25 01:04:24] [Epoch=054/550] [Need: 04:30:03] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [054][000/500]   Time 0.094 (0.094)   Data 0.062 (0.062)   Loss 0.2067 (0.2067)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:04:24]
  Epoch: [054][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.5329 (0.2860)   Prec@1 82.000 (90.632)   Prec@5 100.000 (99.672)   [2018-12-25 01:04:36]
  Epoch: [054][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3312 (0.2902)   Prec@1 89.000 (90.439)   Prec@5 98.000 (99.668)   [2018-12-25 01:04:48]
  **Train** Prec@1 90.346 Prec@5 99.656 Error@1 9.654
  **Test** Prec@1 86.750 Prec@5 99.340 Error@1 13.250

==>>[2018-12-25 01:04:56] [Epoch=055/550] [Need: 04:29:27] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [055][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.2181 (0.2181)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:04:57]
  Epoch: [055][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2726 (0.2817)   Prec@1 93.000 (90.721)   Prec@5 100.000 (99.652)   [2018-12-25 01:05:08]
  Epoch: [055][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1482 (0.2806)   Prec@1 96.000 (90.761)   Prec@5 99.000 (99.691)   [2018-12-25 01:05:20]
  **Train** Prec@1 90.488 Prec@5 99.672 Error@1 9.512
  **Test** Prec@1 85.870 Prec@5 99.510 Error@1 14.130

==>>[2018-12-25 01:05:29] [Epoch=056/550] [Need: 04:28:51] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [056][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.3117 (0.3117)   Prec@1 87.000 (87.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:05:29]
  Epoch: [056][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.3829 (0.2748)   Prec@1 87.000 (90.905)   Prec@5 100.000 (99.731)   [2018-12-25 01:05:41]
  Epoch: [056][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2449 (0.2837)   Prec@1 92.000 (90.611)   Prec@5 100.000 (99.701)   [2018-12-25 01:05:52]
  **Train** Prec@1 90.414 Prec@5 99.702 Error@1 9.586
  **Test** Prec@1 85.400 Prec@5 99.160 Error@1 14.600

==>>[2018-12-25 01:06:01] [Epoch=057/550] [Need: 04:28:14] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [057][000/500]   Time 0.101 (0.101)   Data 0.072 (0.072)   Loss 0.2378 (0.2378)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:06:01]
  Epoch: [057][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.3360 (0.2685)   Prec@1 87.000 (91.289)   Prec@5 100.000 (99.682)   [2018-12-25 01:06:13]
  Epoch: [057][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.2586 (0.2809)   Prec@1 89.000 (90.803)   Prec@5 100.000 (99.666)   [2018-12-25 01:06:25]
  **Train** Prec@1 90.710 Prec@5 99.674 Error@1 9.290
  **Test** Prec@1 87.320 Prec@5 99.520 Error@1 12.680

==>>[2018-12-25 01:06:33] [Epoch=058/550] [Need: 04:27:39] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [058][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.2480 (0.2480)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:06:33]
  Epoch: [058][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3145 (0.2799)   Prec@1 90.000 (90.861)   Prec@5 100.000 (99.672)   [2018-12-25 01:06:45]
  Epoch: [058][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.4719 (0.2817)   Prec@1 84.000 (90.793)   Prec@5 100.000 (99.668)   [2018-12-25 01:06:57]
  **Train** Prec@1 90.586 Prec@5 99.656 Error@1 9.414
  **Test** Prec@1 86.580 Prec@5 99.280 Error@1 13.420

==>>[2018-12-25 01:07:06] [Epoch=059/550] [Need: 04:27:03] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [059][000/500]   Time 0.093 (0.093)   Data 0.061 (0.061)   Loss 0.3598 (0.3598)   Prec@1 89.000 (89.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:07:06]
  Epoch: [059][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3280 (0.2792)   Prec@1 87.000 (90.806)   Prec@5 100.000 (99.687)   [2018-12-25 01:07:17]
  Epoch: [059][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2542 (0.2843)   Prec@1 91.000 (90.668)   Prec@5 100.000 (99.693)   [2018-12-25 01:07:29]
  **Train** Prec@1 90.712 Prec@5 99.712 Error@1 9.288
  **Test** Prec@1 84.330 Prec@5 98.430 Error@1 15.670

==>>[2018-12-25 01:07:38] [Epoch=060/550] [Need: 04:26:28] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [060][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.2621 (0.2621)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:07:38]
  Epoch: [060][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2305 (0.2744)   Prec@1 92.000 (91.015)   Prec@5 100.000 (99.692)   [2018-12-25 01:07:50]
  Epoch: [060][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3012 (0.2825)   Prec@1 87.000 (90.833)   Prec@5 99.000 (99.686)   [2018-12-25 01:08:02]
  **Train** Prec@1 90.700 Prec@5 99.672 Error@1 9.300
  **Test** Prec@1 87.630 Prec@5 99.430 Error@1 12.370

==>>[2018-12-25 01:08:10] [Epoch=061/550] [Need: 04:25:52] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [061][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.2024 (0.2024)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:08:10]
  Epoch: [061][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2593 (0.2738)   Prec@1 91.000 (91.100)   Prec@5 100.000 (99.736)   [2018-12-25 01:08:22]
  Epoch: [061][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2581 (0.2809)   Prec@1 89.000 (90.805)   Prec@5 100.000 (99.711)   [2018-12-25 01:08:34]
  **Train** Prec@1 90.680 Prec@5 99.692 Error@1 9.320
  **Test** Prec@1 86.120 Prec@5 99.200 Error@1 13.880

==>>[2018-12-25 01:08:42] [Epoch=062/550] [Need: 04:25:17] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [062][000/500]   Time 0.098 (0.098)   Data 0.065 (0.065)   Loss 0.3463 (0.3463)   Prec@1 88.000 (88.000)   Prec@5 98.000 (98.000)   [2018-12-25 01:08:42]
  Epoch: [062][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.2278 (0.2683)   Prec@1 96.000 (91.204)   Prec@5 99.000 (99.692)   [2018-12-25 01:08:54]
  Epoch: [062][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3012 (0.2770)   Prec@1 88.000 (90.858)   Prec@5 100.000 (99.681)   [2018-12-25 01:09:06]
  **Train** Prec@1 90.744 Prec@5 99.682 Error@1 9.256
  **Test** Prec@1 83.120 Prec@5 99.310 Error@1 16.880

==>>[2018-12-25 01:09:15] [Epoch=063/550] [Need: 04:24:42] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [063][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.2879 (0.2879)   Prec@1 90.000 (90.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:09:15]
  Epoch: [063][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2910 (0.2637)   Prec@1 88.000 (91.284)   Prec@5 100.000 (99.791)   [2018-12-25 01:09:27]
  Epoch: [063][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3297 (0.2713)   Prec@1 87.000 (91.130)   Prec@5 99.000 (99.708)   [2018-12-25 01:09:38]
  **Train** Prec@1 91.004 Prec@5 99.678 Error@1 8.996
  **Test** Prec@1 85.580 Prec@5 99.150 Error@1 14.420

==>>[2018-12-25 01:09:47] [Epoch=064/550] [Need: 04:24:06] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [064][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.3415 (0.3415)   Prec@1 88.000 (88.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:09:47]
  Epoch: [064][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.2304 (0.2814)   Prec@1 93.000 (90.721)   Prec@5 99.000 (99.637)   [2018-12-25 01:09:59]
  Epoch: [064][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.2101 (0.2802)   Prec@1 92.000 (90.763)   Prec@5 100.000 (99.648)   [2018-12-25 01:10:11]
  **Train** Prec@1 90.664 Prec@5 99.630 Error@1 9.336
  **Test** Prec@1 87.790 Prec@5 99.350 Error@1 12.210

==>>[2018-12-25 01:10:19] [Epoch=065/550] [Need: 04:23:31] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [065][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.2338 (0.2338)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:10:19]
  Epoch: [065][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.3028 (0.2728)   Prec@1 91.000 (91.065)   Prec@5 99.000 (99.692)   [2018-12-25 01:10:31]
  Epoch: [065][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2310 (0.2849)   Prec@1 93.000 (90.628)   Prec@5 100.000 (99.671)   [2018-12-25 01:10:43]
  **Train** Prec@1 90.676 Prec@5 99.662 Error@1 9.324
  **Test** Prec@1 87.170 Prec@5 99.370 Error@1 12.830

==>>[2018-12-25 01:10:51] [Epoch=066/550] [Need: 04:22:56] [learning_rate=0.100000] [Best : Accuracy=88.31, Error=11.69]
  Epoch: [066][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.1730 (0.1730)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:10:52]
  Epoch: [066][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2653 (0.2682)   Prec@1 95.000 (91.323)   Prec@5 100.000 (99.697)   [2018-12-25 01:11:03]
  Epoch: [066][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2391 (0.2749)   Prec@1 91.000 (91.022)   Prec@5 100.000 (99.683)   [2018-12-25 01:11:15]
  **Train** Prec@1 90.872 Prec@5 99.664 Error@1 9.128
  **Test** Prec@1 88.480 Prec@5 99.510 Error@1 11.520

==>>[2018-12-25 01:11:24] [Epoch=067/550] [Need: 04:22:25] [learning_rate=0.100000] [Best : Accuracy=88.48, Error=11.52]
  Epoch: [067][000/500]   Time 0.095 (0.095)   Data 0.062 (0.062)   Loss 0.1731 (0.1731)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:11:24]
  Epoch: [067][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.3070 (0.2678)   Prec@1 92.000 (91.164)   Prec@5 100.000 (99.721)   [2018-12-25 01:11:36]
  Epoch: [067][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2355 (0.2744)   Prec@1 91.000 (90.985)   Prec@5 100.000 (99.678)   [2018-12-25 01:11:48]
  **Train** Prec@1 90.886 Prec@5 99.664 Error@1 9.114
  **Test** Prec@1 88.520 Prec@5 99.650 Error@1 11.480

==>>[2018-12-25 01:11:57] [Epoch=068/550] [Need: 04:21:53] [learning_rate=0.100000] [Best : Accuracy=88.52, Error=11.48]
  Epoch: [068][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.3924 (0.3924)   Prec@1 86.000 (86.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:11:57]
  Epoch: [068][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3727 (0.2644)   Prec@1 86.000 (91.373)   Prec@5 99.000 (99.731)   [2018-12-25 01:12:09]
  Epoch: [068][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2837 (0.2768)   Prec@1 90.000 (90.838)   Prec@5 100.000 (99.693)   [2018-12-25 01:12:21]
  **Train** Prec@1 90.838 Prec@5 99.706 Error@1 9.162
  **Test** Prec@1 84.110 Prec@5 99.120 Error@1 15.890

==>>[2018-12-25 01:12:29] [Epoch=069/550] [Need: 04:21:18] [learning_rate=0.100000] [Best : Accuracy=88.52, Error=11.48]
  Epoch: [069][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.4383 (0.4383)   Prec@1 84.000 (84.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:12:29]
  Epoch: [069][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2899 (0.2609)   Prec@1 90.000 (91.522)   Prec@5 100.000 (99.736)   [2018-12-25 01:12:41]
  Epoch: [069][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2419 (0.2717)   Prec@1 93.000 (91.055)   Prec@5 100.000 (99.696)   [2018-12-25 01:12:53]
  **Train** Prec@1 90.990 Prec@5 99.682 Error@1 9.010
  **Test** Prec@1 85.950 Prec@5 99.170 Error@1 14.050

==>>[2018-12-25 01:13:01] [Epoch=070/550] [Need: 04:20:43] [learning_rate=0.100000] [Best : Accuracy=88.52, Error=11.48]
  Epoch: [070][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.2352 (0.2352)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:13:02]
  Epoch: [070][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2411 (0.2672)   Prec@1 89.000 (91.174)   Prec@5 100.000 (99.726)   [2018-12-25 01:13:13]
  Epoch: [070][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3583 (0.2752)   Prec@1 88.000 (90.940)   Prec@5 99.000 (99.688)   [2018-12-25 01:13:25]
  **Train** Prec@1 90.954 Prec@5 99.686 Error@1 9.046
  **Test** Prec@1 85.620 Prec@5 99.540 Error@1 14.380

==>>[2018-12-25 01:13:34] [Epoch=071/550] [Need: 04:20:09] [learning_rate=0.100000] [Best : Accuracy=88.52, Error=11.48]
  Epoch: [071][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.1672 (0.1672)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:13:34]
  Epoch: [071][200/500]   Time 0.065 (0.059)   Data 0.000 (0.000)   Loss 0.4347 (0.2555)   Prec@1 87.000 (91.642)   Prec@5 100.000 (99.751)   [2018-12-25 01:13:46]
  Epoch: [071][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2415 (0.2713)   Prec@1 93.000 (91.204)   Prec@5 100.000 (99.676)   [2018-12-25 01:13:58]
  **Train** Prec@1 90.990 Prec@5 99.686 Error@1 9.010
  **Test** Prec@1 85.710 Prec@5 99.360 Error@1 14.290

==>>[2018-12-25 01:14:06] [Epoch=072/550] [Need: 04:19:34] [learning_rate=0.100000] [Best : Accuracy=88.52, Error=11.48]
  Epoch: [072][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.1717 (0.1717)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:14:06]
  Epoch: [072][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.3101 (0.2726)   Prec@1 90.000 (90.955)   Prec@5 100.000 (99.706)   [2018-12-25 01:14:18]
  Epoch: [072][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.5119 (0.2765)   Prec@1 83.000 (90.905)   Prec@5 98.000 (99.731)   [2018-12-25 01:14:30]
  **Train** Prec@1 90.960 Prec@5 99.704 Error@1 9.040
  **Test** Prec@1 88.640 Prec@5 99.640 Error@1 11.360

==>>[2018-12-25 01:14:39] [Epoch=073/550] [Need: 04:19:03] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [073][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.1718 (0.1718)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:14:39]
  Epoch: [073][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2142 (0.2693)   Prec@1 91.000 (91.179)   Prec@5 100.000 (99.766)   [2018-12-25 01:14:51]
  Epoch: [073][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1944 (0.2768)   Prec@1 95.000 (91.055)   Prec@5 99.000 (99.686)   [2018-12-25 01:15:03]
  **Train** Prec@1 91.024 Prec@5 99.686 Error@1 8.976
  **Test** Prec@1 86.680 Prec@5 99.320 Error@1 13.320

==>>[2018-12-25 01:15:11] [Epoch=074/550] [Need: 04:18:29] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [074][000/500]   Time 0.090 (0.090)   Data 0.061 (0.061)   Loss 0.2253 (0.2253)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:15:11]
  Epoch: [074][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2586 (0.2574)   Prec@1 90.000 (91.657)   Prec@5 100.000 (99.736)   [2018-12-25 01:15:23]
  Epoch: [074][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2508 (0.2678)   Prec@1 92.000 (91.304)   Prec@5 100.000 (99.738)   [2018-12-25 01:15:35]
  **Train** Prec@1 91.060 Prec@5 99.712 Error@1 8.940
  **Test** Prec@1 85.480 Prec@5 99.310 Error@1 14.520

==>>[2018-12-25 01:15:44] [Epoch=075/550] [Need: 04:17:55] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [075][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.2427 (0.2427)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:15:44]
  Epoch: [075][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.2816 (0.2661)   Prec@1 89.000 (91.363)   Prec@5 100.000 (99.697)   [2018-12-25 01:15:55]
  Epoch: [075][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2885 (0.2774)   Prec@1 91.000 (90.965)   Prec@5 99.000 (99.721)   [2018-12-25 01:16:07]
  **Train** Prec@1 90.920 Prec@5 99.720 Error@1 9.080
  **Test** Prec@1 87.150 Prec@5 99.330 Error@1 12.850

==>>[2018-12-25 01:16:16] [Epoch=076/550] [Need: 04:17:21] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [076][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.2373 (0.2373)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:16:16]
  Epoch: [076][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2603 (0.2656)   Prec@1 92.000 (91.378)   Prec@5 100.000 (99.771)   [2018-12-25 01:16:28]
  Epoch: [076][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.3692 (0.2706)   Prec@1 88.000 (91.209)   Prec@5 99.000 (99.751)   [2018-12-25 01:16:40]
  **Train** Prec@1 91.034 Prec@5 99.738 Error@1 8.966
  **Test** Prec@1 88.370 Prec@5 99.610 Error@1 11.630

==>>[2018-12-25 01:16:48] [Epoch=077/550] [Need: 04:16:46] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [077][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.1849 (0.1849)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:16:48]
  Epoch: [077][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.1832 (0.2699)   Prec@1 93.000 (91.174)   Prec@5 100.000 (99.746)   [2018-12-25 01:17:00]
  Epoch: [077][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.3482 (0.2756)   Prec@1 89.000 (91.110)   Prec@5 99.000 (99.701)   [2018-12-25 01:17:12]
  **Train** Prec@1 91.046 Prec@5 99.688 Error@1 8.954
  **Test** Prec@1 83.910 Prec@5 98.820 Error@1 16.090

==>>[2018-12-25 01:17:21] [Epoch=078/550] [Need: 04:16:12] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [078][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.3912 (0.3912)   Prec@1 87.000 (87.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:17:21]
  Epoch: [078][200/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.2132 (0.2634)   Prec@1 94.000 (91.378)   Prec@5 100.000 (99.721)   [2018-12-25 01:17:32]
  Epoch: [078][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.3322 (0.2729)   Prec@1 87.000 (91.112)   Prec@5 100.000 (99.718)   [2018-12-25 01:17:44]
  **Train** Prec@1 90.952 Prec@5 99.732 Error@1 9.048
  **Test** Prec@1 87.500 Prec@5 99.570 Error@1 12.500

==>>[2018-12-25 01:17:53] [Epoch=079/550] [Need: 04:15:39] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [079][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.4203 (0.4203)   Prec@1 85.000 (85.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:17:53]
  Epoch: [079][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.3380 (0.2632)   Prec@1 89.000 (91.507)   Prec@5 100.000 (99.701)   [2018-12-25 01:18:05]
  Epoch: [079][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2064 (0.2651)   Prec@1 94.000 (91.299)   Prec@5 100.000 (99.721)   [2018-12-25 01:18:17]
  **Train** Prec@1 91.170 Prec@5 99.734 Error@1 8.830
  **Test** Prec@1 84.970 Prec@5 99.150 Error@1 15.030

==>>[2018-12-25 01:18:25] [Epoch=080/550] [Need: 04:15:05] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [080][000/500]   Time 0.102 (0.102)   Data 0.066 (0.066)   Loss 0.3074 (0.3074)   Prec@1 87.000 (87.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:18:25]
  Epoch: [080][200/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.2504 (0.2641)   Prec@1 94.000 (91.269)   Prec@5 100.000 (99.746)   [2018-12-25 01:18:37]
  Epoch: [080][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.2800 (0.2703)   Prec@1 89.000 (91.185)   Prec@5 100.000 (99.703)   [2018-12-25 01:18:49]
  **Train** Prec@1 91.208 Prec@5 99.706 Error@1 8.792
  **Test** Prec@1 87.230 Prec@5 99.450 Error@1 12.770

==>>[2018-12-25 01:18:58] [Epoch=081/550] [Need: 04:14:31] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [081][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.3133 (0.3133)   Prec@1 93.000 (93.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:18:58]
  Epoch: [081][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.1968 (0.2645)   Prec@1 94.000 (91.542)   Prec@5 99.000 (99.706)   [2018-12-25 01:19:10]
  Epoch: [081][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2516 (0.2701)   Prec@1 92.000 (91.377)   Prec@5 100.000 (99.703)   [2018-12-25 01:19:22]
  **Train** Prec@1 91.336 Prec@5 99.702 Error@1 8.664
  **Test** Prec@1 85.860 Prec@5 99.270 Error@1 14.140

==>>[2018-12-25 01:19:30] [Epoch=082/550] [Need: 04:13:58] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [082][000/500]   Time 0.096 (0.096)   Data 0.064 (0.064)   Loss 0.1512 (0.1512)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:19:30]
  Epoch: [082][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.1829 (0.2640)   Prec@1 95.000 (91.547)   Prec@5 100.000 (99.721)   [2018-12-25 01:19:42]
  Epoch: [082][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3681 (0.2720)   Prec@1 87.000 (91.195)   Prec@5 100.000 (99.718)   [2018-12-25 01:19:54]
  **Train** Prec@1 91.188 Prec@5 99.718 Error@1 8.812
  **Test** Prec@1 86.920 Prec@5 99.350 Error@1 13.080

==>>[2018-12-25 01:20:02] [Epoch=083/550] [Need: 04:13:25] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [083][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.3821 (0.3821)   Prec@1 88.000 (88.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:20:03]
  Epoch: [083][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3139 (0.2583)   Prec@1 90.000 (91.791)   Prec@5 100.000 (99.801)   [2018-12-25 01:20:14]
  Epoch: [083][400/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.3311 (0.2680)   Prec@1 86.000 (91.327)   Prec@5 100.000 (99.751)   [2018-12-25 01:20:26]
  **Train** Prec@1 91.078 Prec@5 99.752 Error@1 8.922
  **Test** Prec@1 85.340 Prec@5 99.450 Error@1 14.660

==>>[2018-12-25 01:20:35] [Epoch=084/550] [Need: 04:12:51] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [084][000/500]   Time 0.099 (0.099)   Data 0.065 (0.065)   Loss 0.1904 (0.1904)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:20:35]
  Epoch: [084][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0894 (0.2665)   Prec@1 97.000 (91.299)   Prec@5 100.000 (99.726)   [2018-12-25 01:20:47]
  Epoch: [084][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3131 (0.2740)   Prec@1 89.000 (91.002)   Prec@5 99.000 (99.716)   [2018-12-25 01:20:59]
  **Train** Prec@1 90.922 Prec@5 99.700 Error@1 9.078
  **Test** Prec@1 87.540 Prec@5 99.490 Error@1 12.460

==>>[2018-12-25 01:21:07] [Epoch=085/550] [Need: 04:12:17] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [085][000/500]   Time 0.090 (0.090)   Data 0.061 (0.061)   Loss 0.3241 (0.3241)   Prec@1 88.000 (88.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:21:07]
  Epoch: [085][200/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.2798 (0.2490)   Prec@1 90.000 (91.930)   Prec@5 100.000 (99.701)   [2018-12-25 01:21:19]
  Epoch: [085][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2397 (0.2614)   Prec@1 94.000 (91.471)   Prec@5 99.000 (99.668)   [2018-12-25 01:21:31]
  **Train** Prec@1 91.326 Prec@5 99.668 Error@1 8.674
  **Test** Prec@1 86.870 Prec@5 99.280 Error@1 13.130

==>>[2018-12-25 01:21:40] [Epoch=086/550] [Need: 04:11:44] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [086][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.2751 (0.2751)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:21:40]
  Epoch: [086][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3293 (0.2699)   Prec@1 90.000 (91.343)   Prec@5 99.000 (99.721)   [2018-12-25 01:21:52]
  Epoch: [086][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2843 (0.2730)   Prec@1 91.000 (91.110)   Prec@5 100.000 (99.668)   [2018-12-25 01:22:03]
  **Train** Prec@1 91.126 Prec@5 99.694 Error@1 8.874
  **Test** Prec@1 88.390 Prec@5 99.570 Error@1 11.610

==>>[2018-12-25 01:22:12] [Epoch=087/550] [Need: 04:11:10] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [087][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.3796 (0.3796)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:22:12]
  Epoch: [087][200/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.3048 (0.2617)   Prec@1 93.000 (91.363)   Prec@5 100.000 (99.721)   [2018-12-25 01:22:24]
  Epoch: [087][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.2660 (0.2635)   Prec@1 92.000 (91.369)   Prec@5 100.000 (99.723)   [2018-12-25 01:22:36]
  **Train** Prec@1 91.272 Prec@5 99.714 Error@1 8.728
  **Test** Prec@1 88.470 Prec@5 99.420 Error@1 11.530

==>>[2018-12-25 01:22:44] [Epoch=088/550] [Need: 04:10:36] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [088][000/500]   Time 0.091 (0.091)   Data 0.061 (0.061)   Loss 0.2587 (0.2587)   Prec@1 95.000 (95.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:22:44]
  Epoch: [088][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.4434 (0.2574)   Prec@1 86.000 (91.726)   Prec@5 100.000 (99.721)   [2018-12-25 01:22:56]
  Epoch: [088][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2933 (0.2680)   Prec@1 90.000 (91.269)   Prec@5 100.000 (99.698)   [2018-12-25 01:23:08]
  **Train** Prec@1 91.234 Prec@5 99.690 Error@1 8.766
  **Test** Prec@1 87.750 Prec@5 99.490 Error@1 12.250

==>>[2018-12-25 01:23:17] [Epoch=089/550] [Need: 04:10:03] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [089][000/500]   Time 0.094 (0.094)   Data 0.062 (0.062)   Loss 0.4079 (0.4079)   Prec@1 84.000 (84.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:23:17]
  Epoch: [089][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2661 (0.2641)   Prec@1 91.000 (91.353)   Prec@5 100.000 (99.756)   [2018-12-25 01:23:29]
  Epoch: [089][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.4185 (0.2642)   Prec@1 90.000 (91.354)   Prec@5 100.000 (99.758)   [2018-12-25 01:23:40]
  **Train** Prec@1 91.274 Prec@5 99.754 Error@1 8.726
  **Test** Prec@1 86.770 Prec@5 99.520 Error@1 13.230

==>>[2018-12-25 01:23:49] [Epoch=090/550] [Need: 04:09:29] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [090][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.3506 (0.3506)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:23:49]
  Epoch: [090][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.3502 (0.2564)   Prec@1 86.000 (91.642)   Prec@5 100.000 (99.781)   [2018-12-25 01:24:01]
  Epoch: [090][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2194 (0.2706)   Prec@1 92.000 (91.080)   Prec@5 100.000 (99.713)   [2018-12-25 01:24:13]
  **Train** Prec@1 91.040 Prec@5 99.720 Error@1 8.960
  **Test** Prec@1 87.900 Prec@5 99.570 Error@1 12.100

==>>[2018-12-25 01:24:21] [Epoch=091/550] [Need: 04:08:55] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [091][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.2934 (0.2934)   Prec@1 90.000 (90.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:24:21]
  Epoch: [091][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1905 (0.2597)   Prec@1 93.000 (91.373)   Prec@5 100.000 (99.741)   [2018-12-25 01:24:33]
  Epoch: [091][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3185 (0.2651)   Prec@1 90.000 (91.292)   Prec@5 100.000 (99.726)   [2018-12-25 01:24:45]
  **Train** Prec@1 91.164 Prec@5 99.720 Error@1 8.836
  **Test** Prec@1 84.920 Prec@5 99.430 Error@1 15.080

==>>[2018-12-25 01:24:54] [Epoch=092/550] [Need: 04:08:21] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [092][000/500]   Time 0.099 (0.099)   Data 0.070 (0.070)   Loss 0.3635 (0.3635)   Prec@1 85.000 (85.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:24:54]
  Epoch: [092][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.4223 (0.2572)   Prec@1 87.000 (91.687)   Prec@5 100.000 (99.771)   [2018-12-25 01:25:06]
  Epoch: [092][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.2711 (0.2637)   Prec@1 90.000 (91.454)   Prec@5 100.000 (99.703)   [2018-12-25 01:25:17]
  **Train** Prec@1 91.302 Prec@5 99.696 Error@1 8.698
  **Test** Prec@1 83.780 Prec@5 98.780 Error@1 16.220

==>>[2018-12-25 01:25:26] [Epoch=093/550] [Need: 04:07:48] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [093][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.2529 (0.2529)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:25:26]
  Epoch: [093][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.3034 (0.2639)   Prec@1 90.000 (91.378)   Prec@5 100.000 (99.711)   [2018-12-25 01:25:38]
  Epoch: [093][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2071 (0.2678)   Prec@1 94.000 (91.209)   Prec@5 100.000 (99.698)   [2018-12-25 01:25:50]
  **Train** Prec@1 91.144 Prec@5 99.672 Error@1 8.856
  **Test** Prec@1 87.510 Prec@5 99.260 Error@1 12.490

==>>[2018-12-25 01:25:58] [Epoch=094/550] [Need: 04:07:14] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [094][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.1130 (0.1130)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:25:58]
  Epoch: [094][200/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.5597 (0.2585)   Prec@1 83.000 (91.672)   Prec@5 100.000 (99.721)   [2018-12-25 01:26:10]
  Epoch: [094][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2931 (0.2663)   Prec@1 90.000 (91.289)   Prec@5 99.000 (99.716)   [2018-12-25 01:26:22]
  **Train** Prec@1 91.118 Prec@5 99.702 Error@1 8.882
  **Test** Prec@1 88.290 Prec@5 99.590 Error@1 11.710

==>>[2018-12-25 01:26:30] [Epoch=095/550] [Need: 04:06:41] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [095][000/500]   Time 0.102 (0.102)   Data 0.073 (0.073)   Loss 0.2249 (0.2249)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:26:31]
  Epoch: [095][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.3858 (0.2529)   Prec@1 88.000 (91.672)   Prec@5 100.000 (99.756)   [2018-12-25 01:26:42]
  Epoch: [095][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.1850 (0.2636)   Prec@1 95.000 (91.436)   Prec@5 99.000 (99.716)   [2018-12-25 01:26:54]
  **Train** Prec@1 91.232 Prec@5 99.716 Error@1 8.768
  **Test** Prec@1 86.030 Prec@5 99.430 Error@1 13.970

==>>[2018-12-25 01:27:03] [Epoch=096/550] [Need: 04:06:08] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [096][000/500]   Time 0.091 (0.091)   Data 0.061 (0.061)   Loss 0.2082 (0.2082)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:27:03]
  Epoch: [096][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1881 (0.2565)   Prec@1 96.000 (91.647)   Prec@5 100.000 (99.776)   [2018-12-25 01:27:15]
  Epoch: [096][400/500]   Time 0.063 (0.059)   Data 0.000 (0.000)   Loss 0.2325 (0.2594)   Prec@1 91.000 (91.551)   Prec@5 100.000 (99.768)   [2018-12-25 01:27:27]
  **Train** Prec@1 91.456 Prec@5 99.742 Error@1 8.544
  **Test** Prec@1 83.680 Prec@5 99.360 Error@1 16.320

==>>[2018-12-25 01:27:35] [Epoch=097/550] [Need: 04:05:34] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [097][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.2852 (0.2852)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:27:35]
  Epoch: [097][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.2204 (0.2542)   Prec@1 94.000 (91.721)   Prec@5 100.000 (99.751)   [2018-12-25 01:27:47]
  Epoch: [097][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3205 (0.2633)   Prec@1 90.000 (91.426)   Prec@5 99.000 (99.718)   [2018-12-25 01:27:59]
  **Train** Prec@1 91.274 Prec@5 99.704 Error@1 8.726
  **Test** Prec@1 86.600 Prec@5 99.460 Error@1 13.400

==>>[2018-12-25 01:28:07] [Epoch=098/550] [Need: 04:05:00] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [098][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.4207 (0.4207)   Prec@1 88.000 (88.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:28:07]
  Epoch: [098][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.3253 (0.2613)   Prec@1 89.000 (91.398)   Prec@5 100.000 (99.692)   [2018-12-25 01:28:19]
  Epoch: [098][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.2223 (0.2647)   Prec@1 92.000 (91.307)   Prec@5 100.000 (99.676)   [2018-12-25 01:28:31]
  **Train** Prec@1 91.294 Prec@5 99.674 Error@1 8.706
  **Test** Prec@1 86.160 Prec@5 99.410 Error@1 13.840

==>>[2018-12-25 01:28:40] [Epoch=099/550] [Need: 04:04:26] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [099][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.2206 (0.2206)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:28:40]
  Epoch: [099][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.1833 (0.2489)   Prec@1 95.000 (92.060)   Prec@5 100.000 (99.786)   [2018-12-25 01:28:52]
  Epoch: [099][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.4101 (0.2610)   Prec@1 82.000 (91.566)   Prec@5 99.000 (99.738)   [2018-12-25 01:29:03]
  **Train** Prec@1 91.386 Prec@5 99.734 Error@1 8.614
  **Test** Prec@1 87.940 Prec@5 99.660 Error@1 12.060

==>>[2018-12-25 01:29:12] [Epoch=100/550] [Need: 04:03:53] [learning_rate=0.100000] [Best : Accuracy=88.64, Error=11.36]
  Epoch: [100][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.4259 (0.4259)   Prec@1 86.000 (86.000)   Prec@5 99.000 (99.000)   [2018-12-25 01:29:12]
  Epoch: [100][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1312 (0.1790)   Prec@1 95.000 (94.582)   Prec@5 100.000 (99.861)   [2018-12-25 01:29:24]
  Epoch: [100][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.2613 (0.1588)   Prec@1 92.000 (95.175)   Prec@5 100.000 (99.890)   [2018-12-25 01:29:36]
  **Train** Prec@1 95.284 Prec@5 99.898 Error@1 4.716
  **Test** Prec@1 93.740 Prec@5 99.860 Error@1 6.260

==>>[2018-12-25 01:29:45] [Epoch=101/550] [Need: 04:03:21] [learning_rate=0.010000] [Best : Accuracy=93.74, Error=6.26]
  Epoch: [101][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.1197 (0.1197)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:29:45]
  Epoch: [101][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1222 (0.1249)   Prec@1 95.000 (96.149)   Prec@5 100.000 (99.925)   [2018-12-25 01:29:57]
  Epoch: [101][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0835 (0.1207)   Prec@1 99.000 (96.362)   Prec@5 100.000 (99.923)   [2018-12-25 01:30:08]
  **Train** Prec@1 96.370 Prec@5 99.922 Error@1 3.630
  **Test** Prec@1 94.200 Prec@5 99.890 Error@1 5.800

==>>[2018-12-25 01:30:17] [Epoch=102/550] [Need: 04:02:50] [learning_rate=0.010000] [Best : Accuracy=94.20, Error=5.80]
  Epoch: [102][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.1606 (0.1606)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:30:17]
  Epoch: [102][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0912 (0.1067)   Prec@1 98.000 (96.716)   Prec@5 100.000 (99.950)   [2018-12-25 01:30:29]
  Epoch: [102][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.1236 (0.1085)   Prec@1 96.000 (96.688)   Prec@5 100.000 (99.960)   [2018-12-25 01:30:41]
  **Train** Prec@1 96.706 Prec@5 99.966 Error@1 3.294
  **Test** Prec@1 94.100 Prec@5 99.930 Error@1 5.900

==>>[2018-12-25 01:30:50] [Epoch=103/550] [Need: 04:02:16] [learning_rate=0.010000] [Best : Accuracy=94.20, Error=5.80]
  Epoch: [103][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0829 (0.0829)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:30:50]
  Epoch: [103][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0709 (0.0939)   Prec@1 99.000 (97.199)   Prec@5 100.000 (99.955)   [2018-12-25 01:31:02]
  Epoch: [103][400/500]   Time 0.054 (0.059)   Data 0.000 (0.000)   Loss 0.0590 (0.0940)   Prec@1 98.000 (97.214)   Prec@5 100.000 (99.953)   [2018-12-25 01:31:13]
  **Train** Prec@1 97.168 Prec@5 99.954 Error@1 2.832
  **Test** Prec@1 94.330 Prec@5 99.910 Error@1 5.670

==>>[2018-12-25 01:31:22] [Epoch=104/550] [Need: 04:01:44] [learning_rate=0.010000] [Best : Accuracy=94.33, Error=5.67]
  Epoch: [104][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.1244 (0.1244)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:31:22]
  Epoch: [104][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.1026 (0.0910)   Prec@1 96.000 (97.363)   Prec@5 100.000 (99.970)   [2018-12-25 01:31:34]
  Epoch: [104][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0503 (0.0901)   Prec@1 99.000 (97.377)   Prec@5 100.000 (99.965)   [2018-12-25 01:31:46]
  **Train** Prec@1 97.418 Prec@5 99.960 Error@1 2.582
  **Test** Prec@1 94.350 Prec@5 99.890 Error@1 5.650

==>>[2018-12-25 01:31:55] [Epoch=105/550] [Need: 04:01:13] [learning_rate=0.010000] [Best : Accuracy=94.35, Error=5.65]
  Epoch: [105][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0947 (0.0947)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:31:55]
  Epoch: [105][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0835 (0.0813)   Prec@1 99.000 (97.488)   Prec@5 100.000 (99.960)   [2018-12-25 01:32:07]
  Epoch: [105][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.1291 (0.0834)   Prec@1 97.000 (97.494)   Prec@5 100.000 (99.963)   [2018-12-25 01:32:19]
  **Train** Prec@1 97.520 Prec@5 99.968 Error@1 2.480
  **Test** Prec@1 94.640 Prec@5 99.860 Error@1 5.360

==>>[2018-12-25 01:32:28] [Epoch=106/550] [Need: 04:00:41] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [106][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0740 (0.0740)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:32:28]
  Epoch: [106][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0301 (0.0763)   Prec@1 100.000 (97.776)   Prec@5 100.000 (99.970)   [2018-12-25 01:32:40]
  Epoch: [106][400/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.0858 (0.0752)   Prec@1 97.000 (97.698)   Prec@5 100.000 (99.978)   [2018-12-25 01:32:52]
  **Train** Prec@1 97.650 Prec@5 99.982 Error@1 2.350
  **Test** Prec@1 94.350 Prec@5 99.910 Error@1 5.650

==>>[2018-12-25 01:33:00] [Epoch=107/550] [Need: 04:00:08] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [107][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0645 (0.0645)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:33:00]
  Epoch: [107][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0290 (0.0722)   Prec@1 100.000 (97.930)   Prec@5 100.000 (99.985)   [2018-12-25 01:33:12]
  Epoch: [107][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.1166 (0.0706)   Prec@1 97.000 (97.953)   Prec@5 100.000 (99.973)   [2018-12-25 01:33:24]
  **Train** Prec@1 97.920 Prec@5 99.976 Error@1 2.080
  **Test** Prec@1 94.620 Prec@5 99.890 Error@1 5.380

==>>[2018-12-25 01:33:32] [Epoch=108/550] [Need: 03:59:34] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [108][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0497 (0.0497)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:33:32]
  Epoch: [108][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0522 (0.0664)   Prec@1 99.000 (98.109)   Prec@5 100.000 (99.980)   [2018-12-25 01:33:44]
  Epoch: [108][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0277 (0.0669)   Prec@1 99.000 (98.070)   Prec@5 100.000 (99.980)   [2018-12-25 01:33:56]
  **Train** Prec@1 98.076 Prec@5 99.982 Error@1 1.924
  **Test** Prec@1 94.480 Prec@5 99.900 Error@1 5.520

==>>[2018-12-25 01:34:05] [Epoch=109/550] [Need: 03:59:00] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [109][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0180 (0.0180)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:34:05]
  Epoch: [109][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0487 (0.0603)   Prec@1 99.000 (98.363)   Prec@5 100.000 (99.975)   [2018-12-25 01:34:16]
  Epoch: [109][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0579 (0.0657)   Prec@1 99.000 (98.132)   Prec@5 100.000 (99.975)   [2018-12-25 01:34:28]
  **Train** Prec@1 98.130 Prec@5 99.974 Error@1 1.870
  **Test** Prec@1 94.300 Prec@5 99.910 Error@1 5.700

==>>[2018-12-25 01:34:37] [Epoch=110/550] [Need: 03:58:27] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [110][000/500]   Time 0.091 (0.091)   Data 0.061 (0.061)   Loss 0.0568 (0.0568)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:34:37]
  Epoch: [110][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0884 (0.0571)   Prec@1 97.000 (98.388)   Prec@5 100.000 (99.970)   [2018-12-25 01:34:49]
  Epoch: [110][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0307 (0.0574)   Prec@1 100.000 (98.337)   Prec@5 100.000 (99.980)   [2018-12-25 01:35:01]
  **Train** Prec@1 98.338 Prec@5 99.980 Error@1 1.662
  **Test** Prec@1 94.490 Prec@5 99.890 Error@1 5.510

==>>[2018-12-25 01:35:09] [Epoch=111/550] [Need: 03:57:53] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [111][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0942 (0.0942)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:35:09]
  Epoch: [111][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0275 (0.0595)   Prec@1 99.000 (98.323)   Prec@5 100.000 (99.985)   [2018-12-25 01:35:21]
  Epoch: [111][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0531 (0.0604)   Prec@1 99.000 (98.287)   Prec@5 100.000 (99.975)   [2018-12-25 01:35:33]
  **Train** Prec@1 98.274 Prec@5 99.978 Error@1 1.726
  **Test** Prec@1 94.470 Prec@5 99.900 Error@1 5.530

==>>[2018-12-25 01:35:41] [Epoch=112/550] [Need: 03:57:19] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [112][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0724 (0.0724)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:35:41]
  Epoch: [112][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0343 (0.0547)   Prec@1 100.000 (98.453)   Prec@5 100.000 (99.985)   [2018-12-25 01:35:53]
  Epoch: [112][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0963 (0.0552)   Prec@1 97.000 (98.349)   Prec@5 100.000 (99.988)   [2018-12-25 01:36:05]
  **Train** Prec@1 98.326 Prec@5 99.990 Error@1 1.674
  **Test** Prec@1 94.400 Prec@5 99.870 Error@1 5.600

==>>[2018-12-25 01:36:13] [Epoch=113/550] [Need: 03:56:46] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [113][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0290 (0.0290)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:36:14]
  Epoch: [113][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0544 (0.0496)   Prec@1 99.000 (98.607)   Prec@5 100.000 (99.970)   [2018-12-25 01:36:25]
  Epoch: [113][400/500]   Time 0.066 (0.059)   Data 0.000 (0.000)   Loss 0.0483 (0.0536)   Prec@1 99.000 (98.439)   Prec@5 100.000 (99.980)   [2018-12-25 01:36:37]
  **Train** Prec@1 98.464 Prec@5 99.980 Error@1 1.536
  **Test** Prec@1 94.500 Prec@5 99.900 Error@1 5.500

==>>[2018-12-25 01:36:46] [Epoch=114/550] [Need: 03:56:12] [learning_rate=0.010000] [Best : Accuracy=94.64, Error=5.36]
  Epoch: [114][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0700 (0.0700)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:36:46]
  Epoch: [114][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0440 (0.0486)   Prec@1 98.000 (98.642)   Prec@5 100.000 (99.990)   [2018-12-25 01:36:58]
  Epoch: [114][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0275 (0.0520)   Prec@1 99.000 (98.554)   Prec@5 100.000 (99.990)   [2018-12-25 01:37:10]
  **Train** Prec@1 98.534 Prec@5 99.990 Error@1 1.466
  **Test** Prec@1 94.710 Prec@5 99.890 Error@1 5.290

==>>[2018-12-25 01:37:18] [Epoch=115/550] [Need: 03:55:41] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [115][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0204 (0.0204)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:37:19]
  Epoch: [115][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0220 (0.0487)   Prec@1 100.000 (98.617)   Prec@5 100.000 (99.995)   [2018-12-25 01:37:30]
  Epoch: [115][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0295 (0.0499)   Prec@1 100.000 (98.564)   Prec@5 100.000 (99.993)   [2018-12-25 01:37:42]
  **Train** Prec@1 98.536 Prec@5 99.990 Error@1 1.464
  **Test** Prec@1 94.390 Prec@5 99.880 Error@1 5.610

==>>[2018-12-25 01:37:51] [Epoch=116/550] [Need: 03:55:07] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [116][000/500]   Time 0.100 (0.100)   Data 0.064 (0.064)   Loss 0.0210 (0.0210)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:37:51]
  Epoch: [116][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0375 (0.0470)   Prec@1 99.000 (98.672)   Prec@5 100.000 (99.990)   [2018-12-25 01:38:03]
  Epoch: [116][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0713 (0.0486)   Prec@1 97.000 (98.618)   Prec@5 100.000 (99.990)   [2018-12-25 01:38:15]
  **Train** Prec@1 98.632 Prec@5 99.988 Error@1 1.368
  **Test** Prec@1 94.650 Prec@5 99.870 Error@1 5.350

==>>[2018-12-25 01:38:23] [Epoch=117/550] [Need: 03:54:34] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [117][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0189 (0.0189)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:38:23]
  Epoch: [117][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0270 (0.0442)   Prec@1 100.000 (98.831)   Prec@5 100.000 (99.990)   [2018-12-25 01:38:35]
  Epoch: [117][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0458 (0.0442)   Prec@1 99.000 (98.818)   Prec@5 100.000 (99.990)   [2018-12-25 01:38:47]
  **Train** Prec@1 98.778 Prec@5 99.988 Error@1 1.222
  **Test** Prec@1 94.610 Prec@5 99.870 Error@1 5.390

==>>[2018-12-25 01:38:55] [Epoch=118/550] [Need: 03:54:01] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [118][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0330 (0.0330)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:38:55]
  Epoch: [118][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0259 (0.0429)   Prec@1 100.000 (98.910)   Prec@5 100.000 (99.995)   [2018-12-25 01:39:07]
  Epoch: [118][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0596 (0.0436)   Prec@1 98.000 (98.858)   Prec@5 100.000 (99.995)   [2018-12-25 01:39:19]
  **Train** Prec@1 98.836 Prec@5 99.994 Error@1 1.164
  **Test** Prec@1 94.520 Prec@5 99.880 Error@1 5.480

==>>[2018-12-25 01:39:28] [Epoch=119/550] [Need: 03:53:27] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [119][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0557 (0.0557)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:39:28]
  Epoch: [119][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0281 (0.0419)   Prec@1 100.000 (98.985)   Prec@5 100.000 (99.990)   [2018-12-25 01:39:40]
  Epoch: [119][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0813 (0.0422)   Prec@1 97.000 (98.933)   Prec@5 100.000 (99.990)   [2018-12-25 01:39:51]
  **Train** Prec@1 98.916 Prec@5 99.984 Error@1 1.084
  **Test** Prec@1 94.560 Prec@5 99.860 Error@1 5.440

==>>[2018-12-25 01:40:00] [Epoch=120/550] [Need: 03:52:54] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [120][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0322 (0.0322)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:40:00]
  Epoch: [120][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0251 (0.0389)   Prec@1 100.000 (98.945)   Prec@5 100.000 (99.995)   [2018-12-25 01:40:12]
  Epoch: [120][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0856 (0.0395)   Prec@1 98.000 (98.943)   Prec@5 100.000 (99.995)   [2018-12-25 01:40:23]
  **Train** Prec@1 98.914 Prec@5 99.996 Error@1 1.086
  **Test** Prec@1 94.220 Prec@5 99.900 Error@1 5.780

==>>[2018-12-25 01:40:32] [Epoch=121/550] [Need: 03:52:20] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [121][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0248 (0.0248)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:40:32]
  Epoch: [121][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0219 (0.0387)   Prec@1 100.000 (98.980)   Prec@5 100.000 (100.000)   [2018-12-25 01:40:44]
  Epoch: [121][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0491 (0.0409)   Prec@1 99.000 (98.885)   Prec@5 100.000 (99.995)   [2018-12-25 01:40:55]
  **Train** Prec@1 98.830 Prec@5 99.994 Error@1 1.170
  **Test** Prec@1 94.560 Prec@5 99.880 Error@1 5.440

==>>[2018-12-25 01:41:04] [Epoch=122/550] [Need: 03:51:45] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [122][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.1073 (0.1073)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:41:04]
  Epoch: [122][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0215 (0.0373)   Prec@1 100.000 (99.025)   Prec@5 100.000 (99.995)   [2018-12-25 01:41:15]
  Epoch: [122][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0683 (0.0390)   Prec@1 98.000 (98.973)   Prec@5 100.000 (99.998)   [2018-12-25 01:41:27]
  **Train** Prec@1 98.980 Prec@5 99.998 Error@1 1.020
  **Test** Prec@1 94.390 Prec@5 99.840 Error@1 5.610

==>>[2018-12-25 01:41:36] [Epoch=123/550] [Need: 03:51:10] [learning_rate=0.010000] [Best : Accuracy=94.71, Error=5.29]
  Epoch: [123][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0302 (0.0302)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:41:36]
  Epoch: [123][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0292 (0.0410)   Prec@1 98.000 (98.831)   Prec@5 100.000 (99.990)   [2018-12-25 01:41:47]
  Epoch: [123][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0242 (0.0400)   Prec@1 100.000 (98.915)   Prec@5 100.000 (99.995)   [2018-12-25 01:41:59]
  **Train** Prec@1 98.934 Prec@5 99.994 Error@1 1.066
  **Test** Prec@1 94.720 Prec@5 99.870 Error@1 5.280

==>>[2018-12-25 01:42:08] [Epoch=124/550] [Need: 03:50:37] [learning_rate=0.010000] [Best : Accuracy=94.72, Error=5.28]
  Epoch: [124][000/500]   Time 0.099 (0.099)   Data 0.066 (0.066)   Loss 0.0259 (0.0259)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:42:08]
  Epoch: [124][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0425 (0.0379)   Prec@1 99.000 (98.995)   Prec@5 100.000 (99.990)   [2018-12-25 01:42:20]
  Epoch: [124][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0234 (0.0375)   Prec@1 100.000 (98.985)   Prec@5 100.000 (99.990)   [2018-12-25 01:42:31]
  **Train** Prec@1 98.980 Prec@5 99.992 Error@1 1.020
  **Test** Prec@1 94.530 Prec@5 99.900 Error@1 5.470

==>>[2018-12-25 01:42:40] [Epoch=125/550] [Need: 03:50:02] [learning_rate=0.010000] [Best : Accuracy=94.72, Error=5.28]
  Epoch: [125][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0149 (0.0149)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:42:40]
  Epoch: [125][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0268 (0.0386)   Prec@1 99.000 (99.005)   Prec@5 100.000 (100.000)   [2018-12-25 01:42:51]
  Epoch: [125][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0207 (0.0417)   Prec@1 100.000 (98.855)   Prec@5 100.000 (99.995)   [2018-12-25 01:43:03]
  **Train** Prec@1 98.834 Prec@5 99.996 Error@1 1.166
  **Test** Prec@1 94.690 Prec@5 99.900 Error@1 5.310

==>>[2018-12-25 01:43:11] [Epoch=126/550] [Need: 03:49:27] [learning_rate=0.010000] [Best : Accuracy=94.72, Error=5.28]
  Epoch: [126][000/500]   Time 0.092 (0.092)   Data 0.061 (0.061)   Loss 0.0456 (0.0456)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:43:12]
  Epoch: [126][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0994 (0.0353)   Prec@1 97.000 (99.144)   Prec@5 100.000 (99.995)   [2018-12-25 01:43:23]
  Epoch: [126][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0174 (0.0369)   Prec@1 100.000 (99.050)   Prec@5 100.000 (99.998)   [2018-12-25 01:43:35]
  **Train** Prec@1 99.040 Prec@5 99.998 Error@1 0.960
  **Test** Prec@1 94.770 Prec@5 99.880 Error@1 5.230

==>>[2018-12-25 01:43:44] [Epoch=127/550] [Need: 03:48:54] [learning_rate=0.010000] [Best : Accuracy=94.77, Error=5.23]
  Epoch: [127][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0379 (0.0379)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:43:44]
  Epoch: [127][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0228 (0.0384)   Prec@1 100.000 (98.940)   Prec@5 100.000 (100.000)   [2018-12-25 01:43:56]
  Epoch: [127][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0123 (0.0386)   Prec@1 100.000 (98.923)   Prec@5 100.000 (99.998)   [2018-12-25 01:44:07]
  **Train** Prec@1 98.962 Prec@5 99.998 Error@1 1.038
  **Test** Prec@1 94.670 Prec@5 99.850 Error@1 5.330

==>>[2018-12-25 01:44:16] [Epoch=128/550] [Need: 03:48:20] [learning_rate=0.010000] [Best : Accuracy=94.77, Error=5.23]
  Epoch: [128][000/500]   Time 0.096 (0.096)   Data 0.063 (0.063)   Loss 0.0483 (0.0483)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:44:16]
  Epoch: [128][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0397 (0.0383)   Prec@1 99.000 (99.010)   Prec@5 100.000 (99.985)   [2018-12-25 01:44:27]
  Epoch: [128][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0262 (0.0380)   Prec@1 100.000 (98.998)   Prec@5 100.000 (99.993)   [2018-12-25 01:44:39]
  **Train** Prec@1 98.944 Prec@5 99.992 Error@1 1.056
  **Test** Prec@1 94.480 Prec@5 99.830 Error@1 5.520

==>>[2018-12-25 01:44:47] [Epoch=129/550] [Need: 03:47:45] [learning_rate=0.010000] [Best : Accuracy=94.77, Error=5.23]
  Epoch: [129][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0266 (0.0266)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:44:48]
  Epoch: [129][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0537 (0.0404)   Prec@1 99.000 (98.881)   Prec@5 100.000 (99.990)   [2018-12-25 01:44:59]
  Epoch: [129][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0171 (0.0374)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.993)   [2018-12-25 01:45:11]
  **Train** Prec@1 98.998 Prec@5 99.992 Error@1 1.002
  **Test** Prec@1 94.200 Prec@5 99.810 Error@1 5.800

==>>[2018-12-25 01:45:19] [Epoch=130/550] [Need: 03:47:11] [learning_rate=0.010000] [Best : Accuracy=94.77, Error=5.23]
  Epoch: [130][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0158 (0.0158)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:45:19]
  Epoch: [130][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0125 (0.0361)   Prec@1 100.000 (99.050)   Prec@5 100.000 (100.000)   [2018-12-25 01:45:31]
  Epoch: [130][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0456 (0.0364)   Prec@1 99.000 (99.060)   Prec@5 100.000 (99.998)   [2018-12-25 01:45:43]
  **Train** Prec@1 99.006 Prec@5 99.998 Error@1 0.994
  **Test** Prec@1 94.410 Prec@5 99.870 Error@1 5.590

==>>[2018-12-25 01:45:51] [Epoch=131/550] [Need: 03:46:36] [learning_rate=0.010000] [Best : Accuracy=94.77, Error=5.23]
  Epoch: [131][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0572 (0.0572)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:45:51]
  Epoch: [131][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0186 (0.0360)   Prec@1 100.000 (99.104)   Prec@5 100.000 (99.995)   [2018-12-25 01:46:03]
  Epoch: [131][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0135 (0.0348)   Prec@1 100.000 (99.145)   Prec@5 100.000 (99.995)   [2018-12-25 01:46:15]
  **Train** Prec@1 99.106 Prec@5 99.996 Error@1 0.894
  **Test** Prec@1 94.520 Prec@5 99.890 Error@1 5.480

==>>[2018-12-25 01:46:23] [Epoch=132/550] [Need: 03:46:02] [learning_rate=0.010000] [Best : Accuracy=94.77, Error=5.23]
  Epoch: [132][000/500]   Time 0.098 (0.098)   Data 0.064 (0.064)   Loss 0.0322 (0.0322)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:46:23]
  Epoch: [132][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0372 (0.0306)   Prec@1 99.000 (99.269)   Prec@5 100.000 (100.000)   [2018-12-25 01:46:35]
  Epoch: [132][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0222 (0.0330)   Prec@1 100.000 (99.172)   Prec@5 100.000 (100.000)   [2018-12-25 01:46:46]
  **Train** Prec@1 99.132 Prec@5 100.000 Error@1 0.868
  **Test** Prec@1 94.830 Prec@5 99.860 Error@1 5.170

==>>[2018-12-25 01:46:55] [Epoch=133/550] [Need: 03:45:29] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [133][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0124 (0.0124)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:46:55]
  Epoch: [133][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0268 (0.0320)   Prec@1 99.000 (99.204)   Prec@5 100.000 (100.000)   [2018-12-25 01:47:07]
  Epoch: [133][400/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0178 (0.0330)   Prec@1 99.000 (99.167)   Prec@5 100.000 (99.995)   [2018-12-25 01:47:19]
  **Train** Prec@1 99.136 Prec@5 99.996 Error@1 0.864
  **Test** Prec@1 94.220 Prec@5 99.910 Error@1 5.780

==>>[2018-12-25 01:47:27] [Epoch=134/550] [Need: 03:44:55] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [134][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.1037 (0.1037)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:47:27]
  Epoch: [134][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0467 (0.0335)   Prec@1 98.000 (99.124)   Prec@5 100.000 (100.000)   [2018-12-25 01:47:39]
  Epoch: [134][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0175 (0.0356)   Prec@1 100.000 (99.082)   Prec@5 100.000 (99.998)   [2018-12-25 01:47:50]
  **Train** Prec@1 99.078 Prec@5 99.996 Error@1 0.922
  **Test** Prec@1 94.160 Prec@5 99.900 Error@1 5.840

==>>[2018-12-25 01:47:59] [Epoch=135/550] [Need: 03:44:20] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [135][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0781 (0.0781)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:47:59]
  Epoch: [135][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0476 (0.0349)   Prec@1 99.000 (99.114)   Prec@5 100.000 (99.995)   [2018-12-25 01:48:11]
  Epoch: [135][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0092 (0.0368)   Prec@1 100.000 (99.017)   Prec@5 100.000 (99.998)   [2018-12-25 01:48:22]
  **Train** Prec@1 98.996 Prec@5 99.998 Error@1 1.004
  **Test** Prec@1 94.670 Prec@5 99.900 Error@1 5.330

==>>[2018-12-25 01:48:31] [Epoch=136/550] [Need: 03:43:46] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [136][000/500]   Time 0.091 (0.091)   Data 0.061 (0.061)   Loss 0.0487 (0.0487)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:48:31]
  Epoch: [136][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0802 (0.0354)   Prec@1 98.000 (99.119)   Prec@5 99.000 (99.990)   [2018-12-25 01:48:43]
  Epoch: [136][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0330 (0.0361)   Prec@1 99.000 (99.085)   Prec@5 100.000 (99.995)   [2018-12-25 01:48:54]
  **Train** Prec@1 99.050 Prec@5 99.996 Error@1 0.950
  **Test** Prec@1 94.350 Prec@5 99.900 Error@1 5.650

==>>[2018-12-25 01:49:03] [Epoch=137/550] [Need: 03:43:12] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [137][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0208 (0.0208)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:49:03]
  Epoch: [137][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0619 (0.0381)   Prec@1 99.000 (99.045)   Prec@5 100.000 (99.995)   [2018-12-25 01:49:14]
  Epoch: [137][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0403 (0.0384)   Prec@1 98.000 (98.978)   Prec@5 100.000 (99.998)   [2018-12-25 01:49:26]
  **Train** Prec@1 99.008 Prec@5 99.998 Error@1 0.992
  **Test** Prec@1 94.220 Prec@5 99.870 Error@1 5.780

==>>[2018-12-25 01:49:35] [Epoch=138/550] [Need: 03:42:38] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [138][000/500]   Time 0.100 (0.100)   Data 0.066 (0.066)   Loss 0.0194 (0.0194)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:49:35]
  Epoch: [138][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0153 (0.0387)   Prec@1 100.000 (98.955)   Prec@5 100.000 (99.990)   [2018-12-25 01:49:46]
  Epoch: [138][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0332 (0.0375)   Prec@1 99.000 (98.978)   Prec@5 100.000 (99.995)   [2018-12-25 01:49:58]
  **Train** Prec@1 98.986 Prec@5 99.992 Error@1 1.014
  **Test** Prec@1 94.640 Prec@5 99.880 Error@1 5.360

==>>[2018-12-25 01:50:06] [Epoch=139/550] [Need: 03:42:04] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [139][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0270 (0.0270)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:50:06]
  Epoch: [139][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0295 (0.0348)   Prec@1 99.000 (99.100)   Prec@5 100.000 (100.000)   [2018-12-25 01:50:18]
  Epoch: [139][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0729 (0.0341)   Prec@1 98.000 (99.125)   Prec@5 100.000 (100.000)   [2018-12-25 01:50:30]
  **Train** Prec@1 99.096 Prec@5 100.000 Error@1 0.904
  **Test** Prec@1 94.390 Prec@5 99.850 Error@1 5.610

==>>[2018-12-25 01:50:38] [Epoch=140/550] [Need: 03:41:30] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [140][000/500]   Time 0.091 (0.091)   Data 0.060 (0.060)   Loss 0.0423 (0.0423)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:50:38]
  Epoch: [140][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0372 (0.0346)   Prec@1 99.000 (99.129)   Prec@5 100.000 (99.995)   [2018-12-25 01:50:50]
  Epoch: [140][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0510 (0.0348)   Prec@1 98.000 (99.120)   Prec@5 100.000 (99.998)   [2018-12-25 01:51:02]
  **Train** Prec@1 99.114 Prec@5 99.998 Error@1 0.886
  **Test** Prec@1 94.410 Prec@5 99.870 Error@1 5.590

==>>[2018-12-25 01:51:10] [Epoch=141/550] [Need: 03:40:56] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [141][000/500]   Time 0.095 (0.095)   Data 0.063 (0.063)   Loss 0.0203 (0.0203)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:51:10]
  Epoch: [141][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0562 (0.0333)   Prec@1 99.000 (99.095)   Prec@5 100.000 (100.000)   [2018-12-25 01:51:22]
  Epoch: [141][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0250 (0.0330)   Prec@1 100.000 (99.145)   Prec@5 100.000 (100.000)   [2018-12-25 01:51:34]
  **Train** Prec@1 99.108 Prec@5 100.000 Error@1 0.892
  **Test** Prec@1 94.460 Prec@5 99.900 Error@1 5.540

==>>[2018-12-25 01:51:42] [Epoch=142/550] [Need: 03:40:22] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [142][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0190 (0.0190)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:51:42]
  Epoch: [142][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0159 (0.0319)   Prec@1 100.000 (99.169)   Prec@5 100.000 (99.995)   [2018-12-25 01:51:54]
  Epoch: [142][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0135 (0.0326)   Prec@1 100.000 (99.170)   Prec@5 100.000 (99.998)   [2018-12-25 01:52:06]
  **Train** Prec@1 99.128 Prec@5 99.996 Error@1 0.872
  **Test** Prec@1 94.080 Prec@5 99.850 Error@1 5.920

==>>[2018-12-25 01:52:14] [Epoch=143/550] [Need: 03:39:48] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [143][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0597 (0.0597)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:52:14]
  Epoch: [143][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0276 (0.0325)   Prec@1 99.000 (99.114)   Prec@5 100.000 (99.995)   [2018-12-25 01:52:26]
  Epoch: [143][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0921 (0.0347)   Prec@1 97.000 (99.087)   Prec@5 100.000 (99.995)   [2018-12-25 01:52:38]
  **Train** Prec@1 99.088 Prec@5 99.996 Error@1 0.912
  **Test** Prec@1 93.890 Prec@5 99.880 Error@1 6.110

==>>[2018-12-25 01:52:46] [Epoch=144/550] [Need: 03:39:15] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [144][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0289 (0.0289)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:52:46]
  Epoch: [144][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0262 (0.0368)   Prec@1 100.000 (99.005)   Prec@5 100.000 (100.000)   [2018-12-25 01:52:58]
  Epoch: [144][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0085 (0.0367)   Prec@1 100.000 (99.005)   Prec@5 100.000 (99.998)   [2018-12-25 01:53:09]
  **Train** Prec@1 99.000 Prec@5 99.996 Error@1 1.000
  **Test** Prec@1 94.130 Prec@5 99.860 Error@1 5.870

==>>[2018-12-25 01:53:18] [Epoch=145/550] [Need: 03:38:41] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [145][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0225 (0.0225)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:53:18]
  Epoch: [145][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0363 (0.0337)   Prec@1 99.000 (99.104)   Prec@5 100.000 (100.000)   [2018-12-25 01:53:30]
  Epoch: [145][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0346 (0.0375)   Prec@1 98.000 (98.943)   Prec@5 100.000 (100.000)   [2018-12-25 01:53:41]
  **Train** Prec@1 98.932 Prec@5 99.998 Error@1 1.068
  **Test** Prec@1 94.010 Prec@5 99.840 Error@1 5.990

==>>[2018-12-25 01:53:50] [Epoch=146/550] [Need: 03:38:07] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [146][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0320 (0.0320)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:53:50]
  Epoch: [146][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0195 (0.0350)   Prec@1 100.000 (99.085)   Prec@5 100.000 (100.000)   [2018-12-25 01:54:02]
  Epoch: [146][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0606 (0.0368)   Prec@1 98.000 (99.012)   Prec@5 100.000 (100.000)   [2018-12-25 01:54:13]
  **Train** Prec@1 98.992 Prec@5 99.998 Error@1 1.008
  **Test** Prec@1 94.300 Prec@5 99.810 Error@1 5.700

==>>[2018-12-25 01:54:22] [Epoch=147/550] [Need: 03:37:34] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [147][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:54:22]
  Epoch: [147][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0420 (0.0356)   Prec@1 99.000 (99.055)   Prec@5 100.000 (99.995)   [2018-12-25 01:54:34]
  Epoch: [147][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0383 (0.0354)   Prec@1 99.000 (99.085)   Prec@5 100.000 (99.995)   [2018-12-25 01:54:45]
  **Train** Prec@1 99.102 Prec@5 99.996 Error@1 0.898
  **Test** Prec@1 94.370 Prec@5 99.880 Error@1 5.630

==>>[2018-12-25 01:54:54] [Epoch=148/550] [Need: 03:37:00] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [148][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0288 (0.0288)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:54:54]
  Epoch: [148][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0709 (0.0307)   Prec@1 99.000 (99.199)   Prec@5 100.000 (100.000)   [2018-12-25 01:55:05]
  Epoch: [148][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0148 (0.0336)   Prec@1 100.000 (99.095)   Prec@5 100.000 (99.993)   [2018-12-25 01:55:17]
  **Train** Prec@1 99.080 Prec@5 99.994 Error@1 0.920
  **Test** Prec@1 94.280 Prec@5 99.860 Error@1 5.720

==>>[2018-12-25 01:55:26] [Epoch=149/550] [Need: 03:36:26] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [149][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:55:26]
  Epoch: [149][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0127 (0.0357)   Prec@1 100.000 (99.090)   Prec@5 100.000 (99.995)   [2018-12-25 01:55:37]
  Epoch: [149][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0095 (0.0349)   Prec@1 100.000 (99.085)   Prec@5 100.000 (99.995)   [2018-12-25 01:55:49]
  **Train** Prec@1 99.080 Prec@5 99.996 Error@1 0.920
  **Test** Prec@1 93.850 Prec@5 99.810 Error@1 6.150

==>>[2018-12-25 01:55:58] [Epoch=150/550] [Need: 03:35:53] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [150][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0321 (0.0321)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:55:58]
  Epoch: [150][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0103 (0.0370)   Prec@1 100.000 (99.045)   Prec@5 100.000 (99.995)   [2018-12-25 01:56:09]
  Epoch: [150][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0297 (0.0373)   Prec@1 99.000 (99.012)   Prec@5 100.000 (99.993)   [2018-12-25 01:56:21]
  **Train** Prec@1 99.034 Prec@5 99.994 Error@1 0.966
  **Test** Prec@1 94.500 Prec@5 99.860 Error@1 5.500

==>>[2018-12-25 01:56:30] [Epoch=151/550] [Need: 03:35:19] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [151][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0296 (0.0296)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:56:30]
  Epoch: [151][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0475 (0.0379)   Prec@1 99.000 (98.985)   Prec@5 100.000 (99.995)   [2018-12-25 01:56:41]
  Epoch: [151][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0282 (0.0390)   Prec@1 100.000 (98.968)   Prec@5 100.000 (99.998)   [2018-12-25 01:56:53]
  **Train** Prec@1 98.960 Prec@5 99.996 Error@1 1.040
  **Test** Prec@1 94.330 Prec@5 99.880 Error@1 5.670

==>>[2018-12-25 01:57:01] [Epoch=152/550] [Need: 03:34:46] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [152][000/500]   Time 0.098 (0.098)   Data 0.069 (0.069)   Loss 0.0198 (0.0198)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:57:02]
  Epoch: [152][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.1108 (0.0367)   Prec@1 96.000 (99.005)   Prec@5 100.000 (100.000)   [2018-12-25 01:57:13]
  Epoch: [152][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0905 (0.0389)   Prec@1 97.000 (98.915)   Prec@5 100.000 (99.998)   [2018-12-25 01:57:25]
  **Train** Prec@1 98.892 Prec@5 99.998 Error@1 1.108
  **Test** Prec@1 93.770 Prec@5 99.800 Error@1 6.230

==>>[2018-12-25 01:57:33] [Epoch=153/550] [Need: 03:34:12] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [153][000/500]   Time 0.100 (0.100)   Data 0.072 (0.072)   Loss 0.0205 (0.0205)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:57:33]
  Epoch: [153][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0254 (0.0386)   Prec@1 99.000 (99.040)   Prec@5 100.000 (100.000)   [2018-12-25 01:57:45]
  Epoch: [153][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0283 (0.0387)   Prec@1 99.000 (99.010)   Prec@5 100.000 (100.000)   [2018-12-25 01:57:57]
  **Train** Prec@1 99.006 Prec@5 99.998 Error@1 0.994
  **Test** Prec@1 94.060 Prec@5 99.840 Error@1 5.940

==>>[2018-12-25 01:58:05] [Epoch=154/550] [Need: 03:33:39] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [154][000/500]   Time 0.096 (0.096)   Data 0.062 (0.062)   Loss 0.0160 (0.0160)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:58:05]
  Epoch: [154][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0556 (0.0375)   Prec@1 98.000 (98.990)   Prec@5 100.000 (99.995)   [2018-12-25 01:58:17]
  Epoch: [154][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.1117 (0.0370)   Prec@1 96.000 (99.002)   Prec@5 100.000 (99.998)   [2018-12-25 01:58:29]
  **Train** Prec@1 98.958 Prec@5 99.996 Error@1 1.042
  **Test** Prec@1 94.380 Prec@5 99.860 Error@1 5.620

==>>[2018-12-25 01:58:37] [Epoch=155/550] [Need: 03:33:05] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [155][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0153 (0.0153)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:58:37]
  Epoch: [155][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.1328 (0.0375)   Prec@1 97.000 (98.965)   Prec@5 100.000 (100.000)   [2018-12-25 01:58:49]
  Epoch: [155][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0301 (0.0387)   Prec@1 99.000 (98.930)   Prec@5 100.000 (99.990)   [2018-12-25 01:59:01]
  **Train** Prec@1 98.880 Prec@5 99.992 Error@1 1.120
  **Test** Prec@1 93.880 Prec@5 99.780 Error@1 6.120

==>>[2018-12-25 01:59:09] [Epoch=156/550] [Need: 03:32:32] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [156][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0213 (0.0213)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:59:09]
  Epoch: [156][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0547 (0.0379)   Prec@1 99.000 (98.960)   Prec@5 100.000 (99.995)   [2018-12-25 01:59:21]
  Epoch: [156][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0474 (0.0391)   Prec@1 99.000 (98.905)   Prec@5 100.000 (99.998)   [2018-12-25 01:59:33]
  **Train** Prec@1 98.896 Prec@5 99.998 Error@1 1.104
  **Test** Prec@1 94.180 Prec@5 99.800 Error@1 5.820

==>>[2018-12-25 01:59:41] [Epoch=157/550] [Need: 03:31:58] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [157][000/500]   Time 0.097 (0.097)   Data 0.066 (0.066)   Loss 0.0132 (0.0132)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 01:59:41]
  Epoch: [157][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0454 (0.0355)   Prec@1 99.000 (99.065)   Prec@5 100.000 (99.990)   [2018-12-25 01:59:53]
  Epoch: [157][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0286 (0.0375)   Prec@1 100.000 (99.005)   Prec@5 100.000 (99.995)   [2018-12-25 02:00:05]
  **Train** Prec@1 99.002 Prec@5 99.996 Error@1 0.998
  **Test** Prec@1 94.160 Prec@5 99.860 Error@1 5.840

==>>[2018-12-25 02:00:13] [Epoch=158/550] [Need: 03:31:25] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [158][000/500]   Time 0.096 (0.096)   Data 0.062 (0.062)   Loss 0.0874 (0.0874)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:00:13]
  Epoch: [158][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0501 (0.0355)   Prec@1 98.000 (99.015)   Prec@5 100.000 (99.995)   [2018-12-25 02:00:25]
  Epoch: [158][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0980 (0.0378)   Prec@1 96.000 (98.955)   Prec@5 100.000 (99.993)   [2018-12-25 02:00:37]
  **Train** Prec@1 98.986 Prec@5 99.992 Error@1 1.014
  **Test** Prec@1 94.160 Prec@5 99.760 Error@1 5.840

==>>[2018-12-25 02:00:45] [Epoch=159/550] [Need: 03:30:52] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [159][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0326 (0.0326)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:00:45]
  Epoch: [159][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0735 (0.0401)   Prec@1 96.000 (98.881)   Prec@5 100.000 (100.000)   [2018-12-25 02:00:57]
  Epoch: [159][400/500]   Time 0.064 (0.059)   Data 0.000 (0.000)   Loss 0.0865 (0.0397)   Prec@1 96.000 (98.940)   Prec@5 100.000 (100.000)   [2018-12-25 02:01:09]
  **Train** Prec@1 98.944 Prec@5 99.998 Error@1 1.056
  **Test** Prec@1 94.260 Prec@5 99.860 Error@1 5.740

==>>[2018-12-25 02:01:17] [Epoch=160/550] [Need: 03:30:19] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [160][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0765 (0.0765)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:01:17]
  Epoch: [160][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0574 (0.0418)   Prec@1 97.000 (98.871)   Prec@5 100.000 (99.995)   [2018-12-25 02:01:29]
  Epoch: [160][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0306 (0.0405)   Prec@1 99.000 (98.925)   Prec@5 100.000 (99.990)   [2018-12-25 02:01:41]
  **Train** Prec@1 98.870 Prec@5 99.992 Error@1 1.130
  **Test** Prec@1 94.010 Prec@5 99.910 Error@1 5.990

==>>[2018-12-25 02:01:49] [Epoch=161/550] [Need: 03:29:45] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [161][000/500]   Time 0.100 (0.100)   Data 0.063 (0.063)   Loss 0.0583 (0.0583)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:01:49]
  Epoch: [161][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0190 (0.0419)   Prec@1 99.000 (98.905)   Prec@5 100.000 (100.000)   [2018-12-25 02:02:01]
  Epoch: [161][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0339 (0.0425)   Prec@1 99.000 (98.900)   Prec@5 100.000 (99.998)   [2018-12-25 02:02:13]
  **Train** Prec@1 98.866 Prec@5 99.998 Error@1 1.134
  **Test** Prec@1 94.280 Prec@5 99.850 Error@1 5.720

==>>[2018-12-25 02:02:21] [Epoch=162/550] [Need: 03:29:12] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [162][000/500]   Time 0.090 (0.090)   Data 0.061 (0.061)   Loss 0.0324 (0.0324)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:02:21]
  Epoch: [162][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0966 (0.0385)   Prec@1 97.000 (98.975)   Prec@5 99.000 (99.990)   [2018-12-25 02:02:33]
  Epoch: [162][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0150 (0.0413)   Prec@1 100.000 (98.890)   Prec@5 100.000 (99.988)   [2018-12-25 02:02:45]
  **Train** Prec@1 98.874 Prec@5 99.988 Error@1 1.126
  **Test** Prec@1 94.210 Prec@5 99.840 Error@1 5.790

==>>[2018-12-25 02:02:53] [Epoch=163/550] [Need: 03:28:39] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [163][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0493 (0.0493)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:02:53]
  Epoch: [163][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0617 (0.0370)   Prec@1 98.000 (99.050)   Prec@5 100.000 (100.000)   [2018-12-25 02:03:05]
  Epoch: [163][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0652 (0.0390)   Prec@1 98.000 (98.955)   Prec@5 100.000 (99.998)   [2018-12-25 02:03:17]
  **Train** Prec@1 98.940 Prec@5 99.996 Error@1 1.060
  **Test** Prec@1 93.820 Prec@5 99.840 Error@1 6.180

==>>[2018-12-25 02:03:25] [Epoch=164/550] [Need: 03:28:06] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [164][000/500]   Time 0.095 (0.095)   Data 0.067 (0.067)   Loss 0.0232 (0.0232)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:03:25]
  Epoch: [164][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0437 (0.0399)   Prec@1 98.000 (98.955)   Prec@5 100.000 (99.990)   [2018-12-25 02:03:37]
  Epoch: [164][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0596 (0.0403)   Prec@1 98.000 (98.945)   Prec@5 100.000 (99.993)   [2018-12-25 02:03:49]
  **Train** Prec@1 98.932 Prec@5 99.992 Error@1 1.068
  **Test** Prec@1 94.290 Prec@5 99.910 Error@1 5.710

==>>[2018-12-25 02:03:57] [Epoch=165/550] [Need: 03:27:32] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [165][000/500]   Time 0.095 (0.095)   Data 0.063 (0.063)   Loss 0.0264 (0.0264)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:03:57]
  Epoch: [165][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0501 (0.0403)   Prec@1 99.000 (98.910)   Prec@5 100.000 (99.995)   [2018-12-25 02:04:09]
  Epoch: [165][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0231 (0.0416)   Prec@1 100.000 (98.885)   Prec@5 100.000 (99.998)   [2018-12-25 02:04:21]
  **Train** Prec@1 98.826 Prec@5 99.998 Error@1 1.174
  **Test** Prec@1 94.030 Prec@5 99.870 Error@1 5.970

==>>[2018-12-25 02:04:29] [Epoch=166/550] [Need: 03:26:59] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [166][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0572 (0.0572)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:04:29]
  Epoch: [166][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0313 (0.0435)   Prec@1 99.000 (98.826)   Prec@5 100.000 (99.990)   [2018-12-25 02:04:41]
  Epoch: [166][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0806 (0.0448)   Prec@1 98.000 (98.756)   Prec@5 100.000 (99.995)   [2018-12-25 02:04:53]
  **Train** Prec@1 98.718 Prec@5 99.992 Error@1 1.282
  **Test** Prec@1 93.920 Prec@5 99.870 Error@1 6.080

==>>[2018-12-25 02:05:01] [Epoch=167/550] [Need: 03:26:26] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [167][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0189 (0.0189)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:05:01]
  Epoch: [167][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0263 (0.0405)   Prec@1 100.000 (98.930)   Prec@5 100.000 (99.995)   [2018-12-25 02:05:13]
  Epoch: [167][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0413 (0.0419)   Prec@1 99.000 (98.878)   Prec@5 100.000 (99.993)   [2018-12-25 02:05:24]
  **Train** Prec@1 98.816 Prec@5 99.990 Error@1 1.184
  **Test** Prec@1 93.570 Prec@5 99.800 Error@1 6.430

==>>[2018-12-25 02:05:33] [Epoch=168/550] [Need: 03:25:53] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [168][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0312 (0.0312)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:05:33]
  Epoch: [168][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0812 (0.0441)   Prec@1 98.000 (98.836)   Prec@5 100.000 (99.995)   [2018-12-25 02:05:45]
  Epoch: [168][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0199 (0.0429)   Prec@1 100.000 (98.853)   Prec@5 100.000 (99.998)   [2018-12-25 02:05:56]
  **Train** Prec@1 98.800 Prec@5 99.996 Error@1 1.200
  **Test** Prec@1 93.500 Prec@5 99.810 Error@1 6.500

==>>[2018-12-25 02:06:05] [Epoch=169/550] [Need: 03:25:20] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [169][000/500]   Time 0.095 (0.095)   Data 0.062 (0.062)   Loss 0.0176 (0.0176)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:06:05]
  Epoch: [169][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0211 (0.0404)   Prec@1 100.000 (98.910)   Prec@5 100.000 (100.000)   [2018-12-25 02:06:17]
  Epoch: [169][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0425 (0.0415)   Prec@1 99.000 (98.863)   Prec@5 100.000 (100.000)   [2018-12-25 02:06:28]
  **Train** Prec@1 98.826 Prec@5 100.000 Error@1 1.174
  **Test** Prec@1 94.020 Prec@5 99.860 Error@1 5.980

==>>[2018-12-25 02:06:37] [Epoch=170/550] [Need: 03:24:46] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [170][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0317 (0.0317)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:06:37]
  Epoch: [170][200/500]   Time 0.063 (0.059)   Data 0.000 (0.000)   Loss 0.0165 (0.0409)   Prec@1 100.000 (98.920)   Prec@5 100.000 (100.000)   [2018-12-25 02:06:49]
  Epoch: [170][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0163 (0.0404)   Prec@1 100.000 (98.980)   Prec@5 100.000 (99.998)   [2018-12-25 02:07:00]
  **Train** Prec@1 98.948 Prec@5 99.998 Error@1 1.052
  **Test** Prec@1 94.070 Prec@5 99.840 Error@1 5.930

==>>[2018-12-25 02:07:09] [Epoch=171/550] [Need: 03:24:13] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [171][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0812 (0.0812)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:07:09]
  Epoch: [171][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0585 (0.0466)   Prec@1 98.000 (98.617)   Prec@5 100.000 (99.995)   [2018-12-25 02:07:21]
  Epoch: [171][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0854 (0.0472)   Prec@1 98.000 (98.631)   Prec@5 100.000 (99.990)   [2018-12-25 02:07:32]
  **Train** Prec@1 98.642 Prec@5 99.992 Error@1 1.358
  **Test** Prec@1 93.240 Prec@5 99.740 Error@1 6.760

==>>[2018-12-25 02:07:41] [Epoch=172/550] [Need: 03:23:40] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [172][000/500]   Time 0.095 (0.095)   Data 0.068 (0.068)   Loss 0.0669 (0.0669)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:07:41]
  Epoch: [172][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0185 (0.0441)   Prec@1 100.000 (98.731)   Prec@5 100.000 (100.000)   [2018-12-25 02:07:53]
  Epoch: [172][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0527 (0.0447)   Prec@1 98.000 (98.743)   Prec@5 100.000 (99.993)   [2018-12-25 02:08:04]
  **Train** Prec@1 98.734 Prec@5 99.994 Error@1 1.266
  **Test** Prec@1 93.550 Prec@5 99.800 Error@1 6.450

==>>[2018-12-25 02:08:13] [Epoch=173/550] [Need: 03:23:07] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [173][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0363 (0.0363)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:08:13]
  Epoch: [173][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0244 (0.0429)   Prec@1 99.000 (98.811)   Prec@5 100.000 (100.000)   [2018-12-25 02:08:25]
  Epoch: [173][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0806 (0.0438)   Prec@1 98.000 (98.808)   Prec@5 100.000 (99.995)   [2018-12-25 02:08:36]
  **Train** Prec@1 98.742 Prec@5 99.994 Error@1 1.258
  **Test** Prec@1 93.390 Prec@5 99.800 Error@1 6.610

==>>[2018-12-25 02:08:45] [Epoch=174/550] [Need: 03:22:34] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [174][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0587 (0.0587)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:08:45]
  Epoch: [174][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0804 (0.0456)   Prec@1 99.000 (98.756)   Prec@5 100.000 (100.000)   [2018-12-25 02:08:57]
  Epoch: [174][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0310 (0.0484)   Prec@1 100.000 (98.581)   Prec@5 100.000 (99.995)   [2018-12-25 02:09:08]
  **Train** Prec@1 98.528 Prec@5 99.992 Error@1 1.472
  **Test** Prec@1 93.450 Prec@5 99.760 Error@1 6.550

==>>[2018-12-25 02:09:17] [Epoch=175/550] [Need: 03:22:01] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [175][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0384 (0.0384)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:09:17]
  Epoch: [175][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0906 (0.0446)   Prec@1 98.000 (98.741)   Prec@5 100.000 (99.995)   [2018-12-25 02:09:29]
  Epoch: [175][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0576 (0.0433)   Prec@1 97.000 (98.798)   Prec@5 100.000 (99.995)   [2018-12-25 02:09:40]
  **Train** Prec@1 98.762 Prec@5 99.996 Error@1 1.238
  **Test** Prec@1 93.000 Prec@5 99.820 Error@1 7.000

==>>[2018-12-25 02:09:49] [Epoch=176/550] [Need: 03:21:28] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [176][000/500]   Time 0.097 (0.097)   Data 0.065 (0.065)   Loss 0.0753 (0.0753)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:09:49]
  Epoch: [176][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0316 (0.0438)   Prec@1 100.000 (98.716)   Prec@5 100.000 (99.985)   [2018-12-25 02:10:01]
  Epoch: [176][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0300 (0.0450)   Prec@1 99.000 (98.703)   Prec@5 100.000 (99.993)   [2018-12-25 02:10:12]
  **Train** Prec@1 98.694 Prec@5 99.994 Error@1 1.306
  **Test** Prec@1 93.480 Prec@5 99.780 Error@1 6.520

==>>[2018-12-25 02:10:21] [Epoch=177/550] [Need: 03:20:55] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [177][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0164 (0.0164)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:10:21]
  Epoch: [177][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0111 (0.0471)   Prec@1 100.000 (98.687)   Prec@5 100.000 (99.995)   [2018-12-25 02:10:33]
  Epoch: [177][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0693 (0.0466)   Prec@1 99.000 (98.713)   Prec@5 100.000 (99.993)   [2018-12-25 02:10:44]
  **Train** Prec@1 98.736 Prec@5 99.994 Error@1 1.264
  **Test** Prec@1 93.550 Prec@5 99.800 Error@1 6.450

==>>[2018-12-25 02:10:53] [Epoch=178/550] [Need: 03:20:22] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [178][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0901 (0.0901)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:10:53]
  Epoch: [178][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0214 (0.0445)   Prec@1 99.000 (98.761)   Prec@5 100.000 (99.980)   [2018-12-25 02:11:05]
  Epoch: [178][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0301 (0.0429)   Prec@1 99.000 (98.818)   Prec@5 100.000 (99.980)   [2018-12-25 02:11:16]
  **Train** Prec@1 98.704 Prec@5 99.984 Error@1 1.296
  **Test** Prec@1 93.580 Prec@5 99.820 Error@1 6.420

==>>[2018-12-25 02:11:25] [Epoch=179/550] [Need: 03:19:49] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [179][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0396 (0.0396)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:11:25]
  Epoch: [179][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0322 (0.0422)   Prec@1 99.000 (98.811)   Prec@5 100.000 (99.995)   [2018-12-25 02:11:36]
  Epoch: [179][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0465 (0.0458)   Prec@1 98.000 (98.673)   Prec@5 100.000 (99.998)   [2018-12-25 02:11:48]
  **Train** Prec@1 98.656 Prec@5 99.994 Error@1 1.344
  **Test** Prec@1 93.480 Prec@5 99.760 Error@1 6.520

==>>[2018-12-25 02:11:57] [Epoch=180/550] [Need: 03:19:16] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [180][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0800 (0.0800)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:11:57]
  Epoch: [180][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0661 (0.0450)   Prec@1 99.000 (98.776)   Prec@5 100.000 (99.995)   [2018-12-25 02:12:08]
  Epoch: [180][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0446 (0.0462)   Prec@1 99.000 (98.713)   Prec@5 100.000 (99.993)   [2018-12-25 02:12:20]
  **Train** Prec@1 98.688 Prec@5 99.992 Error@1 1.312
  **Test** Prec@1 93.710 Prec@5 99.810 Error@1 6.290

==>>[2018-12-25 02:12:29] [Epoch=181/550] [Need: 03:18:43] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [181][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0172 (0.0172)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:12:29]
  Epoch: [181][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0644 (0.0484)   Prec@1 99.000 (98.697)   Prec@5 100.000 (100.000)   [2018-12-25 02:12:40]
  Epoch: [181][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0295 (0.0480)   Prec@1 99.000 (98.696)   Prec@5 100.000 (99.995)   [2018-12-25 02:12:52]
  **Train** Prec@1 98.676 Prec@5 99.994 Error@1 1.324
  **Test** Prec@1 93.560 Prec@5 99.810 Error@1 6.440

==>>[2018-12-25 02:13:00] [Epoch=182/550] [Need: 03:18:10] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [182][000/500]   Time 0.095 (0.095)   Data 0.063 (0.063)   Loss 0.0537 (0.0537)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:13:01]
  Epoch: [182][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0111 (0.0478)   Prec@1 100.000 (98.682)   Prec@5 100.000 (99.995)   [2018-12-25 02:13:12]
  Epoch: [182][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0161 (0.0504)   Prec@1 100.000 (98.566)   Prec@5 100.000 (99.988)   [2018-12-25 02:13:24]
  **Train** Prec@1 98.574 Prec@5 99.990 Error@1 1.426
  **Test** Prec@1 93.590 Prec@5 99.700 Error@1 6.410

==>>[2018-12-25 02:13:32] [Epoch=183/550] [Need: 03:17:36] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [183][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0246 (0.0246)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:13:32]
  Epoch: [183][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0161 (0.0441)   Prec@1 100.000 (98.736)   Prec@5 100.000 (99.995)   [2018-12-25 02:13:44]
  Epoch: [183][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0208 (0.0441)   Prec@1 100.000 (98.758)   Prec@5 100.000 (99.995)   [2018-12-25 02:13:56]
  **Train** Prec@1 98.772 Prec@5 99.996 Error@1 1.228
  **Test** Prec@1 93.410 Prec@5 99.840 Error@1 6.590

==>>[2018-12-25 02:14:04] [Epoch=184/550] [Need: 03:17:04] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [184][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0351 (0.0351)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:14:04]
  Epoch: [184][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0265 (0.0423)   Prec@1 99.000 (98.851)   Prec@5 100.000 (99.995)   [2018-12-25 02:14:16]
  Epoch: [184][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0178 (0.0447)   Prec@1 100.000 (98.773)   Prec@5 100.000 (99.995)   [2018-12-25 02:14:28]
  **Train** Prec@1 98.736 Prec@5 99.996 Error@1 1.264
  **Test** Prec@1 94.080 Prec@5 99.790 Error@1 5.920

==>>[2018-12-25 02:14:36] [Epoch=185/550] [Need: 03:16:30] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [185][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0105 (0.0105)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:14:36]
  Epoch: [185][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0663 (0.0405)   Prec@1 97.000 (98.896)   Prec@5 100.000 (99.995)   [2018-12-25 02:14:48]
  Epoch: [185][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1075 (0.0430)   Prec@1 97.000 (98.818)   Prec@5 100.000 (99.998)   [2018-12-25 02:15:00]
  **Train** Prec@1 98.818 Prec@5 99.998 Error@1 1.182
  **Test** Prec@1 93.720 Prec@5 99.800 Error@1 6.280

==>>[2018-12-25 02:15:08] [Epoch=186/550] [Need: 03:15:57] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [186][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0415 (0.0415)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:15:08]
  Epoch: [186][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0198 (0.0502)   Prec@1 100.000 (98.607)   Prec@5 100.000 (100.000)   [2018-12-25 02:15:20]
  Epoch: [186][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0214 (0.0511)   Prec@1 100.000 (98.566)   Prec@5 100.000 (99.995)   [2018-12-25 02:15:32]
  **Train** Prec@1 98.574 Prec@5 99.996 Error@1 1.426
  **Test** Prec@1 93.300 Prec@5 99.720 Error@1 6.700

==>>[2018-12-25 02:15:40] [Epoch=187/550] [Need: 03:15:24] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [187][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0205 (0.0205)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:15:40]
  Epoch: [187][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0624 (0.0445)   Prec@1 97.000 (98.826)   Prec@5 100.000 (99.995)   [2018-12-25 02:15:52]
  Epoch: [187][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1232 (0.0481)   Prec@1 96.000 (98.658)   Prec@5 100.000 (99.995)   [2018-12-25 02:16:04]
  **Train** Prec@1 98.604 Prec@5 99.996 Error@1 1.396
  **Test** Prec@1 93.500 Prec@5 99.600 Error@1 6.500

==>>[2018-12-25 02:16:12] [Epoch=188/550] [Need: 03:14:51] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [188][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0312 (0.0312)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:16:12]
  Epoch: [188][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0159 (0.0451)   Prec@1 100.000 (98.796)   Prec@5 100.000 (99.995)   [2018-12-25 02:16:24]
  Epoch: [188][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0201 (0.0475)   Prec@1 100.000 (98.673)   Prec@5 100.000 (99.995)   [2018-12-25 02:16:36]
  **Train** Prec@1 98.632 Prec@5 99.996 Error@1 1.368
  **Test** Prec@1 93.420 Prec@5 99.760 Error@1 6.580

==>>[2018-12-25 02:16:44] [Epoch=189/550] [Need: 03:14:18] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [189][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0135 (0.0135)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:16:44]
  Epoch: [189][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.1207 (0.0445)   Prec@1 97.000 (98.796)   Prec@5 100.000 (99.995)   [2018-12-25 02:16:56]
  Epoch: [189][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.1025 (0.0469)   Prec@1 97.000 (98.716)   Prec@5 100.000 (99.993)   [2018-12-25 02:17:07]
  **Train** Prec@1 98.684 Prec@5 99.990 Error@1 1.316
  **Test** Prec@1 93.650 Prec@5 99.680 Error@1 6.350

==>>[2018-12-25 02:17:16] [Epoch=190/550] [Need: 03:13:45] [learning_rate=0.010000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [190][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0519 (0.0519)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:17:16]
  Epoch: [190][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0094 (0.0373)   Prec@1 100.000 (99.035)   Prec@5 100.000 (99.990)   [2018-12-25 02:17:28]
  Epoch: [190][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0160 (0.0350)   Prec@1 100.000 (99.125)   Prec@5 100.000 (99.990)   [2018-12-25 02:17:39]
  **Train** Prec@1 99.180 Prec@5 99.992 Error@1 0.820
  **Test** Prec@1 94.500 Prec@5 99.790 Error@1 5.500

==>>[2018-12-25 02:17:48] [Epoch=191/550] [Need: 03:13:12] [learning_rate=0.001000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [191][000/500]   Time 0.092 (0.092)   Data 0.061 (0.061)   Loss 0.0210 (0.0210)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:17:48]
  Epoch: [191][200/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.0189 (0.0268)   Prec@1 100.000 (99.363)   Prec@5 100.000 (100.000)   [2018-12-25 02:18:00]
  Epoch: [191][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0330 (0.0265)   Prec@1 99.000 (99.382)   Prec@5 100.000 (100.000)   [2018-12-25 02:18:11]
  **Train** Prec@1 99.438 Prec@5 100.000 Error@1 0.562
  **Test** Prec@1 94.660 Prec@5 99.800 Error@1 5.340

==>>[2018-12-25 02:18:20] [Epoch=192/550] [Need: 03:12:39] [learning_rate=0.001000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [192][000/500]   Time 0.092 (0.092)   Data 0.065 (0.065)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:18:20]
  Epoch: [192][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0098 (0.0252)   Prec@1 100.000 (99.428)   Prec@5 100.000 (99.995)   [2018-12-25 02:18:31]
  Epoch: [192][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0174 (0.0246)   Prec@1 100.000 (99.451)   Prec@5 100.000 (99.998)   [2018-12-25 02:18:43]
  **Train** Prec@1 99.442 Prec@5 99.998 Error@1 0.558
  **Test** Prec@1 94.600 Prec@5 99.840 Error@1 5.400

==>>[2018-12-25 02:18:52] [Epoch=193/550] [Need: 03:12:06] [learning_rate=0.001000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [193][000/500]   Time 0.100 (0.100)   Data 0.064 (0.064)   Loss 0.0164 (0.0164)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:18:52]
  Epoch: [193][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0298 (0.0227)   Prec@1 98.000 (99.512)   Prec@5 100.000 (100.000)   [2018-12-25 02:19:03]
  Epoch: [193][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0219)   Prec@1 100.000 (99.536)   Prec@5 100.000 (100.000)   [2018-12-25 02:19:15]
  **Train** Prec@1 99.540 Prec@5 100.000 Error@1 0.460
  **Test** Prec@1 94.720 Prec@5 99.840 Error@1 5.280

==>>[2018-12-25 02:19:23] [Epoch=194/550] [Need: 03:11:33] [learning_rate=0.001000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [194][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:19:24]
  Epoch: [194][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0112 (0.0197)   Prec@1 100.000 (99.637)   Prec@5 100.000 (100.000)   [2018-12-25 02:19:35]
  Epoch: [194][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0263 (0.0200)   Prec@1 99.000 (99.628)   Prec@5 100.000 (99.998)   [2018-12-25 02:19:47]
  **Train** Prec@1 99.630 Prec@5 99.998 Error@1 0.370
  **Test** Prec@1 94.620 Prec@5 99.830 Error@1 5.380

==>>[2018-12-25 02:19:55] [Epoch=195/550] [Need: 03:11:00] [learning_rate=0.001000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [195][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0163 (0.0163)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:19:55]
  Epoch: [195][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0133 (0.0197)   Prec@1 100.000 (99.567)   Prec@5 100.000 (100.000)   [2018-12-25 02:20:07]
  Epoch: [195][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0660 (0.0202)   Prec@1 98.000 (99.581)   Prec@5 100.000 (100.000)   [2018-12-25 02:20:19]
  **Train** Prec@1 99.608 Prec@5 100.000 Error@1 0.392
  **Test** Prec@1 94.700 Prec@5 99.840 Error@1 5.300

==>>[2018-12-25 02:20:27] [Epoch=196/550] [Need: 03:10:27] [learning_rate=0.001000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [196][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:20:27]
  Epoch: [196][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0192 (0.0191)   Prec@1 100.000 (99.637)   Prec@5 100.000 (100.000)   [2018-12-25 02:20:39]
  Epoch: [196][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0185 (0.0183)   Prec@1 99.000 (99.668)   Prec@5 100.000 (100.000)   [2018-12-25 02:20:51]
  **Train** Prec@1 99.654 Prec@5 100.000 Error@1 0.346
  **Test** Prec@1 94.740 Prec@5 99.850 Error@1 5.260

==>>[2018-12-25 02:20:59] [Epoch=197/550] [Need: 03:09:54] [learning_rate=0.001000] [Best : Accuracy=94.83, Error=5.17]
  Epoch: [197][000/500]   Time 0.098 (0.098)   Data 0.066 (0.066)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:20:59]
  Epoch: [197][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0121 (0.0166)   Prec@1 100.000 (99.701)   Prec@5 100.000 (100.000)   [2018-12-25 02:21:11]
  Epoch: [197][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0317 (0.0172)   Prec@1 99.000 (99.681)   Prec@5 100.000 (100.000)   [2018-12-25 02:21:23]
  **Train** Prec@1 99.678 Prec@5 100.000 Error@1 0.322
  **Test** Prec@1 94.880 Prec@5 99.830 Error@1 5.120

==>>[2018-12-25 02:21:31] [Epoch=198/550] [Need: 03:09:22] [learning_rate=0.001000] [Best : Accuracy=94.88, Error=5.12]
  Epoch: [198][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0213 (0.0213)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:21:32]
  Epoch: [198][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0283 (0.0162)   Prec@1 99.000 (99.731)   Prec@5 100.000 (100.000)   [2018-12-25 02:21:43]
  Epoch: [198][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0210 (0.0165)   Prec@1 100.000 (99.716)   Prec@5 100.000 (100.000)   [2018-12-25 02:21:55]
  **Train** Prec@1 99.722 Prec@5 100.000 Error@1 0.278
  **Test** Prec@1 95.000 Prec@5 99.880 Error@1 5.000

==>>[2018-12-25 02:22:04] [Epoch=199/550] [Need: 03:08:50] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [199][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0482 (0.0482)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:22:04]
  Epoch: [199][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0127 (0.0154)   Prec@1 100.000 (99.766)   Prec@5 100.000 (100.000)   [2018-12-25 02:22:16]
  Epoch: [199][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0266 (0.0158)   Prec@1 100.000 (99.746)   Prec@5 100.000 (99.998)   [2018-12-25 02:22:27]
  **Train** Prec@1 99.726 Prec@5 99.998 Error@1 0.274
  **Test** Prec@1 94.870 Prec@5 99.840 Error@1 5.130

==>>[2018-12-25 02:22:36] [Epoch=200/550] [Need: 03:08:17] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [200][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0186 (0.0186)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:22:36]
  Epoch: [200][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0183 (0.0153)   Prec@1 100.000 (99.781)   Prec@5 100.000 (100.000)   [2018-12-25 02:22:47]
  Epoch: [200][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0535 (0.0157)   Prec@1 99.000 (99.756)   Prec@5 100.000 (100.000)   [2018-12-25 02:22:59]
  **Train** Prec@1 99.756 Prec@5 100.000 Error@1 0.244
  **Test** Prec@1 94.980 Prec@5 99.820 Error@1 5.020

==>>[2018-12-25 02:23:08] [Epoch=201/550] [Need: 03:07:44] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [201][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:23:08]
  Epoch: [201][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0117 (0.0152)   Prec@1 100.000 (99.786)   Prec@5 100.000 (100.000)   [2018-12-25 02:23:19]
  Epoch: [201][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0189 (0.0158)   Prec@1 99.000 (99.756)   Prec@5 100.000 (100.000)   [2018-12-25 02:23:31]
  **Train** Prec@1 99.738 Prec@5 100.000 Error@1 0.262
  **Test** Prec@1 94.890 Prec@5 99.830 Error@1 5.110

==>>[2018-12-25 02:23:39] [Epoch=202/550] [Need: 03:07:11] [learning_rate=0.001000] [Best : Accuracy=95.00, Error=5.00]
  Epoch: [202][000/500]   Time 0.090 (0.090)   Data 0.061 (0.061)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:23:40]
  Epoch: [202][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0079 (0.0141)   Prec@1 100.000 (99.811)   Prec@5 100.000 (100.000)   [2018-12-25 02:23:51]
  Epoch: [202][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0106 (0.0150)   Prec@1 100.000 (99.776)   Prec@5 100.000 (100.000)   [2018-12-25 02:24:03]
  **Train** Prec@1 99.764 Prec@5 100.000 Error@1 0.236
  **Test** Prec@1 95.010 Prec@5 99.820 Error@1 4.990

==>>[2018-12-25 02:24:12] [Epoch=203/550] [Need: 03:06:39] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [203][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0110 (0.0110)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:24:12]
  Epoch: [203][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0162)   Prec@1 100.000 (99.746)   Prec@5 100.000 (99.995)   [2018-12-25 02:24:23]
  Epoch: [203][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0134 (0.0159)   Prec@1 100.000 (99.748)   Prec@5 100.000 (99.998)   [2018-12-25 02:24:35]
  **Train** Prec@1 99.760 Prec@5 99.998 Error@1 0.240
  **Test** Prec@1 95.020 Prec@5 99.830 Error@1 4.980

==>>[2018-12-25 02:24:44] [Epoch=204/550] [Need: 03:06:06] [learning_rate=0.001000] [Best : Accuracy=95.02, Error=4.98]
  Epoch: [204][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0464 (0.0464)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:24:44]
  Epoch: [204][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0148)   Prec@1 100.000 (99.781)   Prec@5 100.000 (100.000)   [2018-12-25 02:24:56]
  Epoch: [204][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0088 (0.0150)   Prec@1 100.000 (99.751)   Prec@5 100.000 (100.000)   [2018-12-25 02:25:07]
  **Train** Prec@1 99.764 Prec@5 100.000 Error@1 0.236
  **Test** Prec@1 95.060 Prec@5 99.850 Error@1 4.940

==>>[2018-12-25 02:25:16] [Epoch=205/550] [Need: 03:05:34] [learning_rate=0.001000] [Best : Accuracy=95.06, Error=4.94]
  Epoch: [205][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0097 (0.0097)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:25:16]
  Epoch: [205][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0342 (0.0142)   Prec@1 99.000 (99.786)   Prec@5 100.000 (100.000)   [2018-12-25 02:25:28]
  Epoch: [205][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0143 (0.0151)   Prec@1 100.000 (99.746)   Prec@5 100.000 (100.000)   [2018-12-25 02:25:40]
  **Train** Prec@1 99.740 Prec@5 100.000 Error@1 0.260
  **Test** Prec@1 95.110 Prec@5 99.830 Error@1 4.890

==>>[2018-12-25 02:25:49] [Epoch=206/550] [Need: 03:05:02] [learning_rate=0.001000] [Best : Accuracy=95.11, Error=4.89]
  Epoch: [206][000/500]   Time 0.094 (0.094)   Data 0.061 (0.061)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:25:49]
  Epoch: [206][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0140 (0.0142)   Prec@1 100.000 (99.781)   Prec@5 100.000 (100.000)   [2018-12-25 02:26:01]
  Epoch: [206][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0234 (0.0142)   Prec@1 99.000 (99.776)   Prec@5 100.000 (100.000)   [2018-12-25 02:26:12]
  **Train** Prec@1 99.786 Prec@5 100.000 Error@1 0.214
  **Test** Prec@1 95.030 Prec@5 99.840 Error@1 4.970

==>>[2018-12-25 02:26:21] [Epoch=207/550] [Need: 03:04:29] [learning_rate=0.001000] [Best : Accuracy=95.11, Error=4.89]
  Epoch: [207][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:26:21]
  Epoch: [207][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0139)   Prec@1 100.000 (99.791)   Prec@5 100.000 (100.000)   [2018-12-25 02:26:32]
  Epoch: [207][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0099 (0.0140)   Prec@1 100.000 (99.793)   Prec@5 100.000 (100.000)   [2018-12-25 02:26:44]
  **Train** Prec@1 99.792 Prec@5 100.000 Error@1 0.208
  **Test** Prec@1 95.000 Prec@5 99.850 Error@1 5.000

==>>[2018-12-25 02:26:52] [Epoch=208/550] [Need: 03:03:56] [learning_rate=0.001000] [Best : Accuracy=95.11, Error=4.89]
  Epoch: [208][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0228 (0.0228)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:26:53]
  Epoch: [208][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0097 (0.0134)   Prec@1 100.000 (99.806)   Prec@5 100.000 (100.000)   [2018-12-25 02:27:04]
  Epoch: [208][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0270 (0.0134)   Prec@1 99.000 (99.808)   Prec@5 100.000 (100.000)   [2018-12-25 02:27:16]
  **Train** Prec@1 99.804 Prec@5 100.000 Error@1 0.196
  **Test** Prec@1 95.130 Prec@5 99.840 Error@1 4.870

==>>[2018-12-25 02:27:25] [Epoch=209/550] [Need: 03:03:24] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [209][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0105 (0.0105)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:27:25]
  Epoch: [209][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0110 (0.0138)   Prec@1 100.000 (99.786)   Prec@5 100.000 (100.000)   [2018-12-25 02:27:36]
  Epoch: [209][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0075 (0.0138)   Prec@1 100.000 (99.786)   Prec@5 100.000 (100.000)   [2018-12-25 02:27:48]
  **Train** Prec@1 99.788 Prec@5 100.000 Error@1 0.212
  **Test** Prec@1 95.060 Prec@5 99.800 Error@1 4.940

==>>[2018-12-25 02:27:57] [Epoch=210/550] [Need: 03:02:51] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [210][000/500]   Time 0.101 (0.101)   Data 0.066 (0.066)   Loss 0.0142 (0.0142)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:27:57]
  Epoch: [210][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0591 (0.0140)   Prec@1 99.000 (99.816)   Prec@5 100.000 (100.000)   [2018-12-25 02:28:08]
  Epoch: [210][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0135 (0.0144)   Prec@1 100.000 (99.796)   Prec@5 100.000 (100.000)   [2018-12-25 02:28:20]
  **Train** Prec@1 99.798 Prec@5 100.000 Error@1 0.202
  **Test** Prec@1 95.100 Prec@5 99.830 Error@1 4.900

==>>[2018-12-25 02:28:28] [Epoch=211/550] [Need: 03:02:18] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [211][000/500]   Time 0.096 (0.096)   Data 0.067 (0.067)   Loss 0.0142 (0.0142)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:28:29]
  Epoch: [211][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0114 (0.0127)   Prec@1 100.000 (99.836)   Prec@5 100.000 (100.000)   [2018-12-25 02:28:40]
  Epoch: [211][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0106 (0.0133)   Prec@1 100.000 (99.805)   Prec@5 100.000 (99.998)   [2018-12-25 02:28:52]
  **Train** Prec@1 99.806 Prec@5 99.998 Error@1 0.194
  **Test** Prec@1 95.140 Prec@5 99.830 Error@1 4.860

==>>[2018-12-25 02:29:01] [Epoch=212/550] [Need: 03:01:46] [learning_rate=0.001000] [Best : Accuracy=95.14, Error=4.86]
  Epoch: [212][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:29:01]
  Epoch: [212][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0297 (0.0135)   Prec@1 99.000 (99.816)   Prec@5 100.000 (100.000)   [2018-12-25 02:29:13]
  Epoch: [212][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0082 (0.0131)   Prec@1 100.000 (99.820)   Prec@5 100.000 (100.000)   [2018-12-25 02:29:24]
  **Train** Prec@1 99.832 Prec@5 100.000 Error@1 0.168
  **Test** Prec@1 95.010 Prec@5 99.840 Error@1 4.990

==>>[2018-12-25 02:29:33] [Epoch=213/550] [Need: 03:01:13] [learning_rate=0.001000] [Best : Accuracy=95.14, Error=4.86]
  Epoch: [213][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0177 (0.0177)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:29:33]
  Epoch: [213][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0089 (0.0140)   Prec@1 100.000 (99.806)   Prec@5 100.000 (100.000)   [2018-12-25 02:29:44]
  Epoch: [213][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0177 (0.0133)   Prec@1 99.000 (99.823)   Prec@5 100.000 (100.000)   [2018-12-25 02:29:56]
  **Train** Prec@1 99.818 Prec@5 100.000 Error@1 0.182
  **Test** Prec@1 95.070 Prec@5 99.830 Error@1 4.930

==>>[2018-12-25 02:30:05] [Epoch=214/550] [Need: 03:00:40] [learning_rate=0.001000] [Best : Accuracy=95.14, Error=4.86]
  Epoch: [214][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:30:05]
  Epoch: [214][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0111 (0.0124)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-12-25 02:30:16]
  Epoch: [214][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0138 (0.0125)   Prec@1 100.000 (99.855)   Prec@5 100.000 (100.000)   [2018-12-25 02:30:28]
  **Train** Prec@1 99.860 Prec@5 100.000 Error@1 0.140
  **Test** Prec@1 94.950 Prec@5 99.860 Error@1 5.050

==>>[2018-12-25 02:30:36] [Epoch=215/550] [Need: 03:00:07] [learning_rate=0.001000] [Best : Accuracy=95.14, Error=4.86]
  Epoch: [215][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0084 (0.0084)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:30:36]
  Epoch: [215][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0085 (0.0119)   Prec@1 100.000 (99.831)   Prec@5 100.000 (100.000)   [2018-12-25 02:30:48]
  Epoch: [215][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0121)   Prec@1 100.000 (99.848)   Prec@5 100.000 (100.000)   [2018-12-25 02:31:00]
  **Train** Prec@1 99.838 Prec@5 100.000 Error@1 0.162
  **Test** Prec@1 95.170 Prec@5 99.840 Error@1 4.830

==>>[2018-12-25 02:31:09] [Epoch=216/550] [Need: 02:59:35] [learning_rate=0.001000] [Best : Accuracy=95.17, Error=4.83]
  Epoch: [216][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:31:09]
  Epoch: [216][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0235 (0.0130)   Prec@1 99.000 (99.786)   Prec@5 100.000 (100.000)   [2018-12-25 02:31:21]
  Epoch: [216][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0126)   Prec@1 100.000 (99.815)   Prec@5 100.000 (100.000)   [2018-12-25 02:31:32]
  **Train** Prec@1 99.830 Prec@5 100.000 Error@1 0.170
  **Test** Prec@1 95.060 Prec@5 99.820 Error@1 4.940

==>>[2018-12-25 02:31:41] [Epoch=217/550] [Need: 02:59:02] [learning_rate=0.001000] [Best : Accuracy=95.17, Error=4.83]
  Epoch: [217][000/500]   Time 0.096 (0.096)   Data 0.062 (0.062)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:31:41]
  Epoch: [217][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0137)   Prec@1 100.000 (99.761)   Prec@5 100.000 (100.000)   [2018-12-25 02:31:52]
  Epoch: [217][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0096 (0.0130)   Prec@1 100.000 (99.808)   Prec@5 100.000 (100.000)   [2018-12-25 02:32:04]
  **Train** Prec@1 99.814 Prec@5 100.000 Error@1 0.186
  **Test** Prec@1 94.980 Prec@5 99.840 Error@1 5.020

==>>[2018-12-25 02:32:13] [Epoch=218/550] [Need: 02:58:30] [learning_rate=0.001000] [Best : Accuracy=95.17, Error=4.83]
  Epoch: [218][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:32:13]
  Epoch: [218][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0072 (0.0121)   Prec@1 100.000 (99.796)   Prec@5 100.000 (100.000)   [2018-12-25 02:32:24]
  Epoch: [218][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0104 (0.0128)   Prec@1 100.000 (99.808)   Prec@5 100.000 (100.000)   [2018-12-25 02:32:36]
  **Train** Prec@1 99.818 Prec@5 100.000 Error@1 0.182
  **Test** Prec@1 95.060 Prec@5 99.870 Error@1 4.940

==>>[2018-12-25 02:32:44] [Epoch=219/550] [Need: 02:57:57] [learning_rate=0.001000] [Best : Accuracy=95.17, Error=4.83]
  Epoch: [219][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0248 (0.0248)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:32:45]
  Epoch: [219][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0226 (0.0120)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-12-25 02:32:56]
  Epoch: [219][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0137 (0.0121)   Prec@1 100.000 (99.855)   Prec@5 100.000 (100.000)   [2018-12-25 02:33:08]
  **Train** Prec@1 99.866 Prec@5 100.000 Error@1 0.134
  **Test** Prec@1 95.070 Prec@5 99.860 Error@1 4.930

==>>[2018-12-25 02:33:16] [Epoch=220/550] [Need: 02:57:24] [learning_rate=0.001000] [Best : Accuracy=95.17, Error=4.83]
  Epoch: [220][000/500]   Time 0.096 (0.096)   Data 0.062 (0.062)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:33:16]
  Epoch: [220][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0122)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-12-25 02:33:28]
  Epoch: [220][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0093 (0.0123)   Prec@1 100.000 (99.853)   Prec@5 100.000 (100.000)   [2018-12-25 02:33:40]
  **Train** Prec@1 99.844 Prec@5 100.000 Error@1 0.156
  **Test** Prec@1 95.180 Prec@5 99.850 Error@1 4.820

==>>[2018-12-25 02:33:49] [Epoch=221/550] [Need: 02:56:52] [learning_rate=0.001000] [Best : Accuracy=95.18, Error=4.82]
  Epoch: [221][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0113 (0.0113)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:33:49]
  Epoch: [221][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0133 (0.0117)   Prec@1 100.000 (99.866)   Prec@5 100.000 (100.000)   [2018-12-25 02:34:00]
  Epoch: [221][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0117)   Prec@1 100.000 (99.873)   Prec@5 100.000 (100.000)   [2018-12-25 02:34:12]
  **Train** Prec@1 99.870 Prec@5 100.000 Error@1 0.130
  **Test** Prec@1 95.010 Prec@5 99.860 Error@1 4.990

==>>[2018-12-25 02:34:21] [Epoch=222/550] [Need: 02:56:19] [learning_rate=0.001000] [Best : Accuracy=95.18, Error=4.82]
  Epoch: [222][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:34:21]
  Epoch: [222][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0227 (0.0117)   Prec@1 99.000 (99.856)   Prec@5 100.000 (100.000)   [2018-12-25 02:34:32]
  Epoch: [222][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0115 (0.0118)   Prec@1 100.000 (99.850)   Prec@5 100.000 (100.000)   [2018-12-25 02:34:44]
  **Train** Prec@1 99.854 Prec@5 100.000 Error@1 0.146
  **Test** Prec@1 95.150 Prec@5 99.870 Error@1 4.850

==>>[2018-12-25 02:34:52] [Epoch=223/550] [Need: 02:55:46] [learning_rate=0.001000] [Best : Accuracy=95.18, Error=4.82]
  Epoch: [223][000/500]   Time 0.097 (0.097)   Data 0.065 (0.065)   Loss 0.0124 (0.0124)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:34:53]
  Epoch: [223][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0120)   Prec@1 100.000 (99.836)   Prec@5 100.000 (100.000)   [2018-12-25 02:35:04]
  Epoch: [223][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0322 (0.0129)   Prec@1 99.000 (99.833)   Prec@5 100.000 (100.000)   [2018-12-25 02:35:16]
  **Train** Prec@1 99.838 Prec@5 100.000 Error@1 0.162
  **Test** Prec@1 95.210 Prec@5 99.840 Error@1 4.790

==>>[2018-12-25 02:35:25] [Epoch=224/550] [Need: 02:55:14] [learning_rate=0.001000] [Best : Accuracy=95.21, Error=4.79]
  Epoch: [224][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0137 (0.0137)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:35:25]
  Epoch: [224][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0097 (0.0113)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-12-25 02:35:37]
  Epoch: [224][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0081 (0.0116)   Prec@1 100.000 (99.870)   Prec@5 100.000 (100.000)   [2018-12-25 02:35:48]
  **Train** Prec@1 99.868 Prec@5 100.000 Error@1 0.132
  **Test** Prec@1 95.300 Prec@5 99.860 Error@1 4.700

==>>[2018-12-25 02:35:57] [Epoch=225/550] [Need: 02:54:42] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [225][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0136 (0.0136)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:35:57]
  Epoch: [225][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0079 (0.0115)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-12-25 02:36:09]
  Epoch: [225][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0078 (0.0119)   Prec@1 100.000 (99.860)   Prec@5 100.000 (100.000)   [2018-12-25 02:36:21]
  **Train** Prec@1 99.856 Prec@5 100.000 Error@1 0.144
  **Test** Prec@1 95.240 Prec@5 99.830 Error@1 4.760

==>>[2018-12-25 02:36:29] [Epoch=226/550] [Need: 02:54:09] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [226][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:36:29]
  Epoch: [226][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0111 (0.0115)   Prec@1 100.000 (99.856)   Prec@5 100.000 (100.000)   [2018-12-25 02:36:41]
  Epoch: [226][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0059 (0.0117)   Prec@1 100.000 (99.850)   Prec@5 100.000 (100.000)   [2018-12-25 02:36:53]
  **Train** Prec@1 99.856 Prec@5 100.000 Error@1 0.144
  **Test** Prec@1 95.230 Prec@5 99.840 Error@1 4.770

==>>[2018-12-25 02:37:01] [Epoch=227/550] [Need: 02:53:36] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [227][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0097 (0.0097)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:37:01]
  Epoch: [227][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0120)   Prec@1 100.000 (99.876)   Prec@5 100.000 (100.000)   [2018-12-25 02:37:13]
  Epoch: [227][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0114)   Prec@1 100.000 (99.878)   Prec@5 100.000 (100.000)   [2018-12-25 02:37:24]
  **Train** Prec@1 99.864 Prec@5 100.000 Error@1 0.136
  **Test** Prec@1 95.200 Prec@5 99.800 Error@1 4.800

==>>[2018-12-25 02:37:33] [Epoch=228/550] [Need: 02:53:04] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [228][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0266 (0.0266)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:37:33]
  Epoch: [228][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0161 (0.0112)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-12-25 02:37:45]
  Epoch: [228][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0111)   Prec@1 100.000 (99.885)   Prec@5 100.000 (100.000)   [2018-12-25 02:37:56]
  **Train** Prec@1 99.892 Prec@5 100.000 Error@1 0.108
  **Test** Prec@1 95.240 Prec@5 99.780 Error@1 4.760

==>>[2018-12-25 02:38:05] [Epoch=229/550] [Need: 02:52:31] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [229][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0124 (0.0124)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:38:05]
  Epoch: [229][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0104 (0.0122)   Prec@1 100.000 (99.856)   Prec@5 100.000 (100.000)   [2018-12-25 02:38:17]
  Epoch: [229][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0086 (0.0120)   Prec@1 100.000 (99.863)   Prec@5 100.000 (100.000)   [2018-12-25 02:38:28]
  **Train** Prec@1 99.864 Prec@5 100.000 Error@1 0.136
  **Test** Prec@1 95.210 Prec@5 99.870 Error@1 4.790

==>>[2018-12-25 02:38:37] [Epoch=230/550] [Need: 02:51:58] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [230][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0159 (0.0159)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:38:37]
  Epoch: [230][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0085 (0.0121)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-12-25 02:38:48]
  Epoch: [230][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0130 (0.0112)   Prec@1 100.000 (99.880)   Prec@5 100.000 (100.000)   [2018-12-25 02:39:00]
  **Train** Prec@1 99.880 Prec@5 100.000 Error@1 0.120
  **Test** Prec@1 95.210 Prec@5 99.800 Error@1 4.790

==>>[2018-12-25 02:39:09] [Epoch=231/550] [Need: 02:51:26] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [231][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:39:09]
  Epoch: [231][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0201 (0.0106)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:39:20]
  Epoch: [231][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0110)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-12-25 02:39:32]
  **Train** Prec@1 99.904 Prec@5 100.000 Error@1 0.096
  **Test** Prec@1 95.100 Prec@5 99.800 Error@1 4.900

==>>[2018-12-25 02:39:41] [Epoch=232/550] [Need: 02:50:53] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [232][000/500]   Time 0.096 (0.096)   Data 0.064 (0.064)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:39:41]
  Epoch: [232][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0183 (0.0114)   Prec@1 99.000 (99.846)   Prec@5 100.000 (100.000)   [2018-12-25 02:39:52]
  Epoch: [232][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0114)   Prec@1 100.000 (99.848)   Prec@5 100.000 (100.000)   [2018-12-25 02:40:04]
  **Train** Prec@1 99.848 Prec@5 100.000 Error@1 0.152
  **Test** Prec@1 95.110 Prec@5 99.820 Error@1 4.890

==>>[2018-12-25 02:40:13] [Epoch=233/550] [Need: 02:50:20] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [233][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0110 (0.0110)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:40:13]
  Epoch: [233][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0126)   Prec@1 100.000 (99.791)   Prec@5 100.000 (100.000)   [2018-12-25 02:40:24]
  Epoch: [233][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0098 (0.0119)   Prec@1 100.000 (99.825)   Prec@5 100.000 (100.000)   [2018-12-25 02:40:36]
  **Train** Prec@1 99.834 Prec@5 100.000 Error@1 0.166
  **Test** Prec@1 95.170 Prec@5 99.840 Error@1 4.830

==>>[2018-12-25 02:40:44] [Epoch=234/550] [Need: 02:49:48] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [234][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0201 (0.0201)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:40:45]
  Epoch: [234][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0112)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-12-25 02:40:56]
  Epoch: [234][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0113)   Prec@1 100.000 (99.878)   Prec@5 100.000 (100.000)   [2018-12-25 02:41:08]
  **Train** Prec@1 99.872 Prec@5 100.000 Error@1 0.128
  **Test** Prec@1 95.220 Prec@5 99.820 Error@1 4.780

==>>[2018-12-25 02:41:16] [Epoch=235/550] [Need: 02:49:15] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [235][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0255 (0.0255)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:41:17]
  Epoch: [235][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0111)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:41:28]
  Epoch: [235][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0096 (0.0111)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:41:40]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 95.140 Prec@5 99.830 Error@1 4.860

==>>[2018-12-25 02:41:48] [Epoch=236/550] [Need: 02:48:42] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [236][000/500]   Time 0.094 (0.094)   Data 0.066 (0.066)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:41:48]
  Epoch: [236][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0114)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-12-25 02:42:00]
  Epoch: [236][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0204 (0.0112)   Prec@1 100.000 (99.878)   Prec@5 100.000 (100.000)   [2018-12-25 02:42:12]
  **Train** Prec@1 99.874 Prec@5 100.000 Error@1 0.126
  **Test** Prec@1 95.240 Prec@5 99.850 Error@1 4.760

==>>[2018-12-25 02:42:20] [Epoch=237/550] [Need: 02:48:10] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [237][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0114 (0.0114)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:42:20]
  Epoch: [237][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0116 (0.0115)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-12-25 02:42:32]
  Epoch: [237][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0092 (0.0115)   Prec@1 100.000 (99.870)   Prec@5 100.000 (100.000)   [2018-12-25 02:42:44]
  **Train** Prec@1 99.882 Prec@5 100.000 Error@1 0.118
  **Test** Prec@1 95.300 Prec@5 99.870 Error@1 4.700

==>>[2018-12-25 02:42:53] [Epoch=238/550] [Need: 02:47:38] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [238][000/500]   Time 0.103 (0.103)   Data 0.074 (0.074)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:42:53]
  Epoch: [238][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0104)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 02:43:04]
  Epoch: [238][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0107)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:43:16]
  **Train** Prec@1 99.890 Prec@5 100.000 Error@1 0.110
  **Test** Prec@1 95.180 Prec@5 99.850 Error@1 4.820

==>>[2018-12-25 02:43:25] [Epoch=239/550] [Need: 02:47:05] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [239][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:43:25]
  Epoch: [239][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0102 (0.0108)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-12-25 02:43:36]
  Epoch: [239][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0088 (0.0102)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:43:48]
  **Train** Prec@1 99.894 Prec@5 100.000 Error@1 0.106
  **Test** Prec@1 95.190 Prec@5 99.840 Error@1 4.810

==>>[2018-12-25 02:43:57] [Epoch=240/550] [Need: 02:46:33] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [240][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0072 (0.0072)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:43:57]
  Epoch: [240][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0093 (0.0106)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:44:08]
  Epoch: [240][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0192 (0.0106)   Prec@1 100.000 (99.890)   Prec@5 100.000 (100.000)   [2018-12-25 02:44:20]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 95.250 Prec@5 99.830 Error@1 4.750

==>>[2018-12-25 02:44:29] [Epoch=241/550] [Need: 02:46:00] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [241][000/500]   Time 0.097 (0.097)   Data 0.064 (0.064)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:44:29]
  Epoch: [241][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0108)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:44:40]
  Epoch: [241][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0086 (0.0111)   Prec@1 100.000 (99.880)   Prec@5 100.000 (100.000)   [2018-12-25 02:44:52]
  **Train** Prec@1 99.872 Prec@5 100.000 Error@1 0.128
  **Test** Prec@1 95.220 Prec@5 99.860 Error@1 4.780

==>>[2018-12-25 02:45:00] [Epoch=242/550] [Need: 02:45:27] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [242][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0120 (0.0120)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:45:01]
  Epoch: [242][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0105)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:45:12]
  Epoch: [242][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0133 (0.0102)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-12-25 02:45:24]
  **Train** Prec@1 99.902 Prec@5 99.998 Error@1 0.098
  **Test** Prec@1 95.110 Prec@5 99.850 Error@1 4.890

==>>[2018-12-25 02:45:32] [Epoch=243/550] [Need: 02:44:55] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [243][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:45:32]
  Epoch: [243][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0108 (0.0106)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-12-25 02:45:44]
  Epoch: [243][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0090 (0.0107)   Prec@1 100.000 (99.893)   Prec@5 100.000 (100.000)   [2018-12-25 02:45:56]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 95.040 Prec@5 99.830 Error@1 4.960

==>>[2018-12-25 02:46:04] [Epoch=244/550] [Need: 02:44:22] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [244][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:46:04]
  Epoch: [244][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0158 (0.0110)   Prec@1 100.000 (99.846)   Prec@5 100.000 (100.000)   [2018-12-25 02:46:16]
  Epoch: [244][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0109)   Prec@1 100.000 (99.863)   Prec@5 100.000 (100.000)   [2018-12-25 02:46:28]
  **Train** Prec@1 99.872 Prec@5 100.000 Error@1 0.128
  **Test** Prec@1 95.230 Prec@5 99.780 Error@1 4.770

==>>[2018-12-25 02:46:36] [Epoch=245/550] [Need: 02:43:49] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [245][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:46:36]
  Epoch: [245][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0107)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-12-25 02:46:48]
  Epoch: [245][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0107)   Prec@1 100.000 (99.883)   Prec@5 100.000 (100.000)   [2018-12-25 02:47:00]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 95.220 Prec@5 99.810 Error@1 4.780

==>>[2018-12-25 02:47:08] [Epoch=246/550] [Need: 02:43:17] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [246][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:47:08]
  Epoch: [246][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0234 (0.0101)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 02:47:20]
  Epoch: [246][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0105)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-12-25 02:47:32]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 95.120 Prec@5 99.830 Error@1 4.880

==>>[2018-12-25 02:47:40] [Epoch=247/550] [Need: 02:42:44] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [247][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:47:40]
  Epoch: [247][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0090 (0.0101)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-12-25 02:47:52]
  Epoch: [247][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0104)   Prec@1 100.000 (99.898)   Prec@5 100.000 (100.000)   [2018-12-25 02:48:04]
  **Train** Prec@1 99.892 Prec@5 100.000 Error@1 0.108
  **Test** Prec@1 95.170 Prec@5 99.850 Error@1 4.830

==>>[2018-12-25 02:48:12] [Epoch=248/550] [Need: 02:42:12] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [248][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:48:12]
  Epoch: [248][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0102)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 02:48:24]
  Epoch: [248][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0109)   Prec@1 100.000 (99.885)   Prec@5 100.000 (100.000)   [2018-12-25 02:48:36]
  **Train** Prec@1 99.904 Prec@5 100.000 Error@1 0.096
  **Test** Prec@1 95.130 Prec@5 99.840 Error@1 4.870

==>>[2018-12-25 02:48:44] [Epoch=249/550] [Need: 02:41:39] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [249][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0311 (0.0311)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:48:44]
  Epoch: [249][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0102)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-12-25 02:48:56]
  Epoch: [249][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0100)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-12-25 02:49:08]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 95.170 Prec@5 99.880 Error@1 4.830

==>>[2018-12-25 02:49:16] [Epoch=250/550] [Need: 02:41:07] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [250][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:49:16]
  Epoch: [250][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0105)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-12-25 02:49:28]
  Epoch: [250][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0140 (0.0104)   Prec@1 100.000 (99.893)   Prec@5 100.000 (100.000)   [2018-12-25 02:49:40]
  **Train** Prec@1 99.894 Prec@5 100.000 Error@1 0.106
  **Test** Prec@1 95.220 Prec@5 99.830 Error@1 4.780

==>>[2018-12-25 02:49:48] [Epoch=251/550] [Need: 02:40:34] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [251][000/500]   Time 0.092 (0.092)   Data 0.061 (0.061)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:49:48]
  Epoch: [251][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0104)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-12-25 02:50:00]
  Epoch: [251][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0173 (0.0103)   Prec@1 99.000 (99.885)   Prec@5 100.000 (100.000)   [2018-12-25 02:50:12]
  **Train** Prec@1 99.894 Prec@5 100.000 Error@1 0.106
  **Test** Prec@1 95.260 Prec@5 99.860 Error@1 4.740

==>>[2018-12-25 02:50:20] [Epoch=252/550] [Need: 02:40:02] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [252][000/500]   Time 0.098 (0.098)   Data 0.063 (0.063)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:50:20]
  Epoch: [252][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0099 (0.0110)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-12-25 02:50:32]
  Epoch: [252][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0102 (0.0107)   Prec@1 100.000 (99.883)   Prec@5 100.000 (100.000)   [2018-12-25 02:50:44]
  **Train** Prec@1 99.886 Prec@5 100.000 Error@1 0.114
  **Test** Prec@1 95.300 Prec@5 99.800 Error@1 4.700

==>>[2018-12-25 02:50:53] [Epoch=253/550] [Need: 02:39:30] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [253][000/500]   Time 0.093 (0.093)   Data 0.061 (0.061)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:50:53]
  Epoch: [253][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0103)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:51:04]
  Epoch: [253][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0106 (0.0105)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-12-25 02:51:16]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 95.120 Prec@5 99.820 Error@1 4.880

==>>[2018-12-25 02:51:25] [Epoch=254/550] [Need: 02:38:57] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [254][000/500]   Time 0.096 (0.096)   Data 0.064 (0.064)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:51:25]
  Epoch: [254][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0078 (0.0103)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-12-25 02:51:36]
  Epoch: [254][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0105)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:51:48]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 95.130 Prec@5 99.850 Error@1 4.870

==>>[2018-12-25 02:51:57] [Epoch=255/550] [Need: 02:38:25] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [255][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0201 (0.0201)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:51:57]
  Epoch: [255][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0103)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:52:08]
  Epoch: [255][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0129 (0.0102)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-12-25 02:52:20]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.100 Prec@5 99.860 Error@1 4.900

==>>[2018-12-25 02:52:28] [Epoch=256/550] [Need: 02:37:52] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [256][000/500]   Time 0.095 (0.095)   Data 0.063 (0.063)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:52:29]
  Epoch: [256][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0100)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 02:52:40]
  Epoch: [256][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0100)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-12-25 02:52:52]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 94.980 Prec@5 99.800 Error@1 5.020

==>>[2018-12-25 02:53:01] [Epoch=257/550] [Need: 02:37:20] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [257][000/500]   Time 0.098 (0.098)   Data 0.062 (0.062)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:53:01]
  Epoch: [257][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0088 (0.0102)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 02:53:12]
  Epoch: [257][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0103)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 02:53:24]
  **Train** Prec@1 99.894 Prec@5 100.000 Error@1 0.106
  **Test** Prec@1 95.180 Prec@5 99.810 Error@1 4.820

==>>[2018-12-25 02:53:33] [Epoch=258/550] [Need: 02:36:47] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [258][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:53:33]
  Epoch: [258][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0097 (0.0099)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 02:53:44]
  Epoch: [258][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0102)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 02:53:56]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 95.090 Prec@5 99.800 Error@1 4.910

==>>[2018-12-25 02:54:04] [Epoch=259/550] [Need: 02:36:15] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [259][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:54:05]
  Epoch: [259][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0104)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 02:54:16]
  Epoch: [259][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0140 (0.0101)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 02:54:28]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 95.050 Prec@5 99.840 Error@1 4.950

==>>[2018-12-25 02:54:36] [Epoch=260/550] [Need: 02:35:42] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [260][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:54:36]
  Epoch: [260][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0097)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:54:48]
  Epoch: [260][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0103)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-12-25 02:55:00]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 95.210 Prec@5 99.850 Error@1 4.790

==>>[2018-12-25 02:55:08] [Epoch=261/550] [Need: 02:35:10] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [261][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:55:08]
  Epoch: [261][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0201 (0.0100)   Prec@1 99.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 02:55:20]
  Epoch: [261][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0086 (0.0102)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-12-25 02:55:32]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 95.130 Prec@5 99.860 Error@1 4.870

==>>[2018-12-25 02:55:40] [Epoch=262/550] [Need: 02:34:37] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [262][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0175 (0.0175)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:55:41]
  Epoch: [262][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0362 (0.0109)   Prec@1 99.000 (99.891)   Prec@5 100.000 (100.000)   [2018-12-25 02:55:52]
  Epoch: [262][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0106 (0.0106)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:56:04]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 95.160 Prec@5 99.840 Error@1 4.840

==>>[2018-12-25 02:56:12] [Epoch=263/550] [Need: 02:34:05] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [263][000/500]   Time 0.098 (0.098)   Data 0.064 (0.064)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:56:13]
  Epoch: [263][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0097)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 02:56:24]
  Epoch: [263][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0106 (0.0101)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:56:36]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 95.160 Prec@5 99.840 Error@1 4.840

==>>[2018-12-25 02:56:44] [Epoch=264/550] [Need: 02:33:32] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [264][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:56:44]
  Epoch: [264][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0101)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:56:56]
  Epoch: [264][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0098)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 02:57:08]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.230 Prec@5 99.820 Error@1 4.770

==>>[2018-12-25 02:57:16] [Epoch=265/550] [Need: 02:33:00] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [265][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:57:16]
  Epoch: [265][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0112)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-12-25 02:57:28]
  Epoch: [265][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0109)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:57:40]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 95.210 Prec@5 99.830 Error@1 4.790

==>>[2018-12-25 02:57:48] [Epoch=266/550] [Need: 02:32:27] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [266][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:57:48]
  Epoch: [266][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0097 (0.0098)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 02:58:00]
  Epoch: [266][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0062 (0.0098)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-12-25 02:58:12]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 95.150 Prec@5 99.820 Error@1 4.850

==>>[2018-12-25 02:58:20] [Epoch=267/550] [Need: 02:31:55] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [267][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0107 (0.0107)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:58:20]
  Epoch: [267][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0099)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 02:58:32]
  Epoch: [267][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0097)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-12-25 02:58:44]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.130 Prec@5 99.800 Error@1 4.870

==>>[2018-12-25 02:58:52] [Epoch=268/550] [Need: 02:31:22] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [268][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:58:52]
  Epoch: [268][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0057 (0.0093)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 02:59:04]
  Epoch: [268][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0095)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 02:59:16]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.060 Prec@5 99.820 Error@1 4.940

==>>[2018-12-25 02:59:24] [Epoch=269/550] [Need: 02:30:50] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [269][000/500]   Time 0.097 (0.097)   Data 0.064 (0.064)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:59:24]
  Epoch: [269][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0094 (0.0104)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 02:59:36]
  Epoch: [269][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0107 (0.0101)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-12-25 02:59:48]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 95.120 Prec@5 99.850 Error@1 4.880

==>>[2018-12-25 02:59:56] [Epoch=270/550] [Need: 02:30:17] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [270][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 02:59:56]
  Epoch: [270][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0102)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:00:08]
  Epoch: [270][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0101)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:00:19]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.190 Prec@5 99.830 Error@1 4.810

==>>[2018-12-25 03:00:28] [Epoch=271/550] [Need: 02:29:45] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [271][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:00:28]
  Epoch: [271][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0092)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:00:40]
  Epoch: [271][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0099 (0.0098)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:00:51]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.130 Prec@5 99.830 Error@1 4.870

==>>[2018-12-25 03:01:00] [Epoch=272/550] [Need: 02:29:13] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [272][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:01:00]
  Epoch: [272][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0100 (0.0099)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:01:12]
  Epoch: [272][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0097)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:01:23]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 95.170 Prec@5 99.810 Error@1 4.830

==>>[2018-12-25 03:01:32] [Epoch=273/550] [Need: 02:28:40] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [273][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:01:32]
  Epoch: [273][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0096 (0.0096)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:01:44]
  Epoch: [273][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0149 (0.0100)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 03:01:55]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 95.160 Prec@5 99.820 Error@1 4.840

==>>[2018-12-25 03:02:04] [Epoch=274/550] [Need: 02:28:08] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [274][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:02:04]
  Epoch: [274][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0092)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:02:15]
  Epoch: [274][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0094)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:02:27]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.170 Prec@5 99.840 Error@1 4.830

==>>[2018-12-25 03:02:36] [Epoch=275/550] [Need: 02:27:35] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [275][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:02:36]
  Epoch: [275][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0101)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-12-25 03:02:47]
  Epoch: [275][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0103 (0.0101)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:02:59]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.080 Prec@5 99.800 Error@1 4.920

==>>[2018-12-25 03:03:08] [Epoch=276/550] [Need: 02:27:03] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [276][000/500]   Time 0.101 (0.101)   Data 0.065 (0.065)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:03:08]
  Epoch: [276][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0089)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 03:03:19]
  Epoch: [276][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0090)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:03:31]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.180 Prec@5 99.860 Error@1 4.820

==>>[2018-12-25 03:03:39] [Epoch=277/550] [Need: 02:26:30] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [277][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:03:40]
  Epoch: [277][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0095)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:03:51]
  Epoch: [277][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0096)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:04:03]
  **Train** Prec@1 99.920 Prec@5 99.998 Error@1 0.080
  **Test** Prec@1 95.260 Prec@5 99.870 Error@1 4.740

==>>[2018-12-25 03:04:11] [Epoch=278/550] [Need: 02:25:58] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [278][000/500]   Time 0.096 (0.096)   Data 0.064 (0.064)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:04:11]
  Epoch: [278][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0100)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 03:04:23]
  Epoch: [278][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0098)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:04:35]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 95.200 Prec@5 99.890 Error@1 4.800

==>>[2018-12-25 03:04:43] [Epoch=279/550] [Need: 02:25:25] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [279][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0285 (0.0285)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:04:43]
  Epoch: [279][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0231 (0.0090)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:04:55]
  Epoch: [279][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0096)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:05:07]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.120 Prec@5 99.840 Error@1 4.880

==>>[2018-12-25 03:05:15] [Epoch=280/550] [Need: 02:24:53] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [280][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0125 (0.0125)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:05:15]
  Epoch: [280][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0308 (0.0101)   Prec@1 99.000 (99.905)   Prec@5 100.000 (100.000)   [2018-12-25 03:05:27]
  Epoch: [280][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0116 (0.0099)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:05:39]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.300 Prec@5 99.830 Error@1 4.700

==>>[2018-12-25 03:05:47] [Epoch=281/550] [Need: 02:24:21] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [281][000/500]   Time 0.095 (0.095)   Data 0.063 (0.063)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:05:48]
  Epoch: [281][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0094)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:05:59]
  Epoch: [281][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0100 (0.0099)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:06:11]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 95.210 Prec@5 99.860 Error@1 4.790

==>>[2018-12-25 03:06:19] [Epoch=282/550] [Need: 02:23:48] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [282][000/500]   Time 0.096 (0.096)   Data 0.067 (0.067)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:06:19]
  Epoch: [282][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0106)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 03:06:31]
  Epoch: [282][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0064 (0.0103)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:06:43]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.220 Prec@5 99.870 Error@1 4.780

==>>[2018-12-25 03:06:51] [Epoch=283/550] [Need: 02:23:16] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [283][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:06:51]
  Epoch: [283][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0099)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 03:07:03]
  Epoch: [283][400/500]   Time 0.064 (0.058)   Data 0.000 (0.000)   Loss 0.0060 (0.0096)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:07:15]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.240 Prec@5 99.810 Error@1 4.760

==>>[2018-12-25 03:07:23] [Epoch=284/550] [Need: 02:22:43] [learning_rate=0.001000] [Best : Accuracy=95.30, Error=4.70]
  Epoch: [284][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0167 (0.0167)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:07:23]
  Epoch: [284][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0102)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 03:07:35]
  Epoch: [284][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0066 (0.0097)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-12-25 03:07:46]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.310 Prec@5 99.840 Error@1 4.690

==>>[2018-12-25 03:07:55] [Epoch=285/550] [Need: 02:22:11] [learning_rate=0.001000] [Best : Accuracy=95.31, Error=4.69]
  Epoch: [285][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0095 (0.0095)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:07:55]
  Epoch: [285][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0087 (0.0096)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 03:08:07]
  Epoch: [285][400/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:08:19]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.350 Prec@5 99.820 Error@1 4.650

==>>[2018-12-25 03:08:28] [Epoch=286/550] [Need: 02:21:39] [learning_rate=0.001000] [Best : Accuracy=95.35, Error=4.65]
  Epoch: [286][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:08:28]
  Epoch: [286][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0093)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:08:40]
  Epoch: [286][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0092)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 03:08:51]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.300 Prec@5 99.870 Error@1 4.700

==>>[2018-12-25 03:09:00] [Epoch=287/550] [Need: 02:21:06] [learning_rate=0.001000] [Best : Accuracy=95.35, Error=4.65]
  Epoch: [287][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:09:00]
  Epoch: [287][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0079 (0.0097)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 03:09:11]
  Epoch: [287][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0102 (0.0096)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:09:23]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.320 Prec@5 99.830 Error@1 4.680

==>>[2018-12-25 03:09:32] [Epoch=288/550] [Need: 02:20:34] [learning_rate=0.001000] [Best : Accuracy=95.35, Error=4.65]
  Epoch: [288][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:09:32]
  Epoch: [288][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0096)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:09:43]
  Epoch: [288][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0093)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:09:55]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.230 Prec@5 99.830 Error@1 4.770

==>>[2018-12-25 03:10:04] [Epoch=289/550] [Need: 02:20:02] [learning_rate=0.001000] [Best : Accuracy=95.35, Error=4.65]
  Epoch: [289][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:10:04]
  Epoch: [289][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0116 (0.0097)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:10:15]
  Epoch: [289][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0215 (0.0094)   Prec@1 99.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:10:27]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.160 Prec@5 99.870 Error@1 4.840

==>>[2018-12-25 03:10:35] [Epoch=290/550] [Need: 02:19:29] [learning_rate=0.001000] [Best : Accuracy=95.35, Error=4.65]
  Epoch: [290][000/500]   Time 0.095 (0.095)   Data 0.062 (0.062)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:10:36]
  Epoch: [290][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0100)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 03:10:47]
  Epoch: [290][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0132 (0.0099)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 03:10:59]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.320 Prec@5 99.850 Error@1 4.680

==>>[2018-12-25 03:11:07] [Epoch=291/550] [Need: 02:18:57] [learning_rate=0.001000] [Best : Accuracy=95.35, Error=4.65]
  Epoch: [291][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0220 (0.0220)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:11:07]
  Epoch: [291][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0091)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:11:19]
  Epoch: [291][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0318 (0.0099)   Prec@1 99.000 (99.908)   Prec@5 100.000 (100.000)   [2018-12-25 03:11:31]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 95.230 Prec@5 99.810 Error@1 4.770

==>>[2018-12-25 03:11:39] [Epoch=292/550] [Need: 02:18:24] [learning_rate=0.001000] [Best : Accuracy=95.35, Error=4.65]
  Epoch: [292][000/500]   Time 0.100 (0.100)   Data 0.066 (0.066)   Loss 0.0095 (0.0095)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:11:39]
  Epoch: [292][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0219 (0.0093)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:11:51]
  Epoch: [292][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0062 (0.0091)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:12:03]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.380 Prec@5 99.870 Error@1 4.620

==>>[2018-12-25 03:12:11] [Epoch=293/550] [Need: 02:17:52] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [293][000/500]   Time 0.096 (0.096)   Data 0.067 (0.067)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:12:12]
  Epoch: [293][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0069 (0.0093)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:12:23]
  Epoch: [293][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0076 (0.0091)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 03:12:35]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.280 Prec@5 99.810 Error@1 4.720

==>>[2018-12-25 03:12:43] [Epoch=294/550] [Need: 02:17:20] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [294][000/500]   Time 0.098 (0.098)   Data 0.062 (0.062)   Loss 0.0101 (0.0101)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:12:43]
  Epoch: [294][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0096)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:12:55]
  Epoch: [294][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0077 (0.0100)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 03:13:07]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 95.250 Prec@5 99.810 Error@1 4.750

==>>[2018-12-25 03:13:15] [Epoch=295/550] [Need: 02:16:47] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [295][000/500]   Time 0.094 (0.094)   Data 0.062 (0.062)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:13:15]
  Epoch: [295][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0099)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:13:27]
  Epoch: [295][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0092 (0.0096)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:13:39]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.310 Prec@5 99.890 Error@1 4.690

==>>[2018-12-25 03:13:47] [Epoch=296/550] [Need: 02:16:15] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [296][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:13:47]
  Epoch: [296][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0096)   Prec@1 100.000 (99.915)   Prec@5 100.000 (99.995)   [2018-12-25 03:13:59]
  Epoch: [296][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0135 (0.0092)   Prec@1 100.000 (99.935)   Prec@5 100.000 (99.998)   [2018-12-25 03:14:10]
  **Train** Prec@1 99.936 Prec@5 99.998 Error@1 0.064
  **Test** Prec@1 95.360 Prec@5 99.860 Error@1 4.640

==>>[2018-12-25 03:14:19] [Epoch=297/550] [Need: 02:15:42] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [297][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:14:19]
  Epoch: [297][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0086 (0.0092)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:14:31]
  Epoch: [297][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0092)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:14:42]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.280 Prec@5 99.850 Error@1 4.720

==>>[2018-12-25 03:14:51] [Epoch=298/550] [Need: 02:15:10] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [298][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:14:51]
  Epoch: [298][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0089)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:15:03]
  Epoch: [298][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0110 (0.0091)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:15:14]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.350 Prec@5 99.850 Error@1 4.650

==>>[2018-12-25 03:15:23] [Epoch=299/550] [Need: 02:14:37] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [299][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:15:23]
  Epoch: [299][200/500]   Time 0.065 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0093)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:15:35]
  Epoch: [299][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0103 (0.0093)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:15:46]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.330 Prec@5 99.840 Error@1 4.670

==>>[2018-12-25 03:15:55] [Epoch=300/550] [Need: 02:14:05] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [300][000/500]   Time 0.102 (0.102)   Data 0.073 (0.073)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:15:55]
  Epoch: [300][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0102 (0.0095)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:16:07]
  Epoch: [300][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0092 (0.0094)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-12-25 03:16:18]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.370 Prec@5 99.860 Error@1 4.630

==>>[2018-12-25 03:16:27] [Epoch=301/550] [Need: 02:13:33] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [301][000/500]   Time 0.094 (0.094)   Data 0.061 (0.061)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:16:27]
  Epoch: [301][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0102)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-12-25 03:16:39]
  Epoch: [301][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0106)   Prec@1 100.000 (99.883)   Prec@5 100.000 (100.000)   [2018-12-25 03:16:50]
  **Train** Prec@1 99.894 Prec@5 100.000 Error@1 0.106
  **Test** Prec@1 95.290 Prec@5 99.860 Error@1 4.710

==>>[2018-12-25 03:16:59] [Epoch=302/550] [Need: 02:13:00] [learning_rate=0.001000] [Best : Accuracy=95.38, Error=4.62]
  Epoch: [302][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:16:59]
  Epoch: [302][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0091)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:17:10]
  Epoch: [302][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0091)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:17:22]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.410 Prec@5 99.850 Error@1 4.590

==>>[2018-12-25 03:17:31] [Epoch=303/550] [Need: 02:12:28] [learning_rate=0.001000] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [303][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:17:31]
  Epoch: [303][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0092)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:17:43]
  Epoch: [303][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0091)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:17:54]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.130 Prec@5 99.800 Error@1 4.870

==>>[2018-12-25 03:18:03] [Epoch=304/550] [Need: 02:11:56] [learning_rate=0.001000] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [304][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:18:03]
  Epoch: [304][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0091)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:18:15]
  Epoch: [304][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0078 (0.0089)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:18:26]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.310 Prec@5 99.870 Error@1 4.690

==>>[2018-12-25 03:18:35] [Epoch=305/550] [Need: 02:11:23] [learning_rate=0.001000] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [305][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:18:35]
  Epoch: [305][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:18:47]
  Epoch: [305][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0102 (0.0092)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:18:58]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.250 Prec@5 99.810 Error@1 4.750

==>>[2018-12-25 03:19:07] [Epoch=306/550] [Need: 02:10:51] [learning_rate=0.001000] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [306][000/500]   Time 0.097 (0.097)   Data 0.066 (0.066)   Loss 0.0201 (0.0201)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:19:07]
  Epoch: [306][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0095)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-12-25 03:19:18]
  Epoch: [306][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0091 (0.0094)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-12-25 03:19:30]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.270 Prec@5 99.840 Error@1 4.730

==>>[2018-12-25 03:19:39] [Epoch=307/550] [Need: 02:10:19] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [307][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:19:39]
  Epoch: [307][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0093)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:19:50]
  Epoch: [307][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0090)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:20:02]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.230 Prec@5 99.830 Error@1 4.770

==>>[2018-12-25 03:20:11] [Epoch=308/550] [Need: 02:09:46] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [308][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:20:11]
  Epoch: [308][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0094)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:20:22]
  Epoch: [308][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0094)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:20:34]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.340 Prec@5 99.820 Error@1 4.660

==>>[2018-12-25 03:20:42] [Epoch=309/550] [Need: 02:09:14] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [309][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:20:43]
  Epoch: [309][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0096)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:20:54]
  Epoch: [309][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0257 (0.0093)   Prec@1 99.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:21:06]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.310 Prec@5 99.820 Error@1 4.690

==>>[2018-12-25 03:21:14] [Epoch=310/550] [Need: 02:08:42] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [310][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:21:14]
  Epoch: [310][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:21:26]
  Epoch: [310][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0125 (0.0093)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:21:38]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.250 Prec@5 99.830 Error@1 4.750

==>>[2018-12-25 03:21:46] [Epoch=311/550] [Need: 02:08:09] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [311][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:21:46]
  Epoch: [311][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0090)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:21:58]
  Epoch: [311][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0091)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:22:10]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.240 Prec@5 99.820 Error@1 4.760

==>>[2018-12-25 03:22:18] [Epoch=312/550] [Need: 02:07:37] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [312][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0432 (0.0432)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:22:18]
  Epoch: [312][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:22:30]
  Epoch: [312][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0091)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 03:22:42]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.270 Prec@5 99.810 Error@1 4.730

==>>[2018-12-25 03:22:50] [Epoch=313/550] [Need: 02:07:04] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [313][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:22:50]
  Epoch: [313][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0096 (0.0094)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:23:02]
  Epoch: [313][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0091)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:23:14]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.270 Prec@5 99.860 Error@1 4.730

==>>[2018-12-25 03:23:22] [Epoch=314/550] [Need: 02:06:32] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [314][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:23:22]
  Epoch: [314][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0281 (0.0094)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:23:34]
  Epoch: [314][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0092)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:23:46]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.280 Prec@5 99.840 Error@1 4.720

==>>[2018-12-25 03:23:54] [Epoch=315/550] [Need: 02:06:00] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [315][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0104 (0.0104)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:23:54]
  Epoch: [315][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0078 (0.0099)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-12-25 03:24:06]
  Epoch: [315][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0092)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:24:17]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.280 Prec@5 99.850 Error@1 4.720

==>>[2018-12-25 03:24:26] [Epoch=316/550] [Need: 02:05:27] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [316][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:24:26]
  Epoch: [316][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0143 (0.0084)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 03:24:38]
  Epoch: [316][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0090)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:24:49]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.330 Prec@5 99.810 Error@1 4.670

==>>[2018-12-25 03:24:58] [Epoch=317/550] [Need: 02:04:55] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [317][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0168 (0.0168)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:24:58]
  Epoch: [317][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0090)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:25:10]
  Epoch: [317][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0089)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 03:25:21]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.230 Prec@5 99.770 Error@1 4.770

==>>[2018-12-25 03:25:30] [Epoch=318/550] [Need: 02:04:23] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [318][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:25:30]
  Epoch: [318][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0098)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-12-25 03:25:42]
  Epoch: [318][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0132 (0.0098)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-12-25 03:25:53]
  **Train** Prec@1 99.906 Prec@5 99.998 Error@1 0.094
  **Test** Prec@1 95.360 Prec@5 99.830 Error@1 4.640

==>>[2018-12-25 03:26:02] [Epoch=319/550] [Need: 02:03:50] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [319][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0102 (0.0102)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:26:02]
  Epoch: [319][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:26:14]
  Epoch: [319][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0090)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:26:25]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.350 Prec@5 99.860 Error@1 4.650

==>>[2018-12-25 03:26:34] [Epoch=320/550] [Need: 02:03:18] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [320][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0127 (0.0127)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:26:34]
  Epoch: [320][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0123 (0.0093)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:26:46]
  Epoch: [320][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0088)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 03:26:57]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.370 Prec@5 99.860 Error@1 4.630

==>>[2018-12-25 03:27:06] [Epoch=321/550] [Need: 02:02:46] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [321][000/500]   Time 0.099 (0.099)   Data 0.064 (0.064)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:27:06]
  Epoch: [321][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0095)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:27:17]
  Epoch: [321][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0118 (0.0091)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:27:29]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.300 Prec@5 99.840 Error@1 4.700

==>>[2018-12-25 03:27:38] [Epoch=322/550] [Need: 02:02:13] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [322][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:27:38]
  Epoch: [322][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0087 (0.0097)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:27:49]
  Epoch: [322][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0093 (0.0094)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 03:28:01]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.280 Prec@5 99.840 Error@1 4.720

==>>[2018-12-25 03:28:10] [Epoch=323/550] [Need: 02:01:41] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [323][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:28:10]
  Epoch: [323][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0094)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:28:21]
  Epoch: [323][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0095)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:28:33]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.350 Prec@5 99.790 Error@1 4.650

==>>[2018-12-25 03:28:42] [Epoch=324/550] [Need: 02:01:09] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [324][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0111 (0.0111)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:28:42]
  Epoch: [324][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0092)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:28:53]
  Epoch: [324][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0093)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:29:05]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.240 Prec@5 99.800 Error@1 4.760

==>>[2018-12-25 03:29:13] [Epoch=325/550] [Need: 02:00:36] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [325][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:29:13]
  Epoch: [325][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0086)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:29:25]
  Epoch: [325][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0153 (0.0091)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:29:37]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.350 Prec@5 99.820 Error@1 4.650

==>>[2018-12-25 03:29:45] [Epoch=326/550] [Need: 02:00:04] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [326][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:29:45]
  Epoch: [326][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0095)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 03:29:57]
  Epoch: [326][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0093)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 03:30:09]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.280 Prec@5 99.800 Error@1 4.720

==>>[2018-12-25 03:30:17] [Epoch=327/550] [Need: 01:59:32] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [327][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:30:17]
  Epoch: [327][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0095)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:30:29]
  Epoch: [327][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0455 (0.0097)   Prec@1 99.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 03:30:41]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.300 Prec@5 99.840 Error@1 4.700

==>>[2018-12-25 03:30:49] [Epoch=328/550] [Need: 01:58:59] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [328][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:30:49]
  Epoch: [328][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0091)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:31:01]
  Epoch: [328][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0091)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:31:13]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.200 Prec@5 99.800 Error@1 4.800

==>>[2018-12-25 03:31:21] [Epoch=329/550] [Need: 01:58:27] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [329][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:31:21]
  Epoch: [329][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0151 (0.0086)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:31:33]
  Epoch: [329][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0200 (0.0088)   Prec@1 99.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:31:44]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.320 Prec@5 99.870 Error@1 4.680

==>>[2018-12-25 03:31:53] [Epoch=330/550] [Need: 01:57:55] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [330][000/500]   Time 0.097 (0.097)   Data 0.064 (0.064)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:31:53]
  Epoch: [330][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0084)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 03:32:05]
  Epoch: [330][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0095 (0.0086)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 03:32:16]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.390 Prec@5 99.770 Error@1 4.610

==>>[2018-12-25 03:32:25] [Epoch=331/550] [Need: 01:57:22] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [331][000/500]   Time 0.099 (0.099)   Data 0.064 (0.064)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:32:25]
  Epoch: [331][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0086)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:32:37]
  Epoch: [331][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0086)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:32:48]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.310 Prec@5 99.820 Error@1 4.690

==>>[2018-12-25 03:32:57] [Epoch=332/550] [Need: 01:56:50] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [332][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:32:57]
  Epoch: [332][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0110 (0.0097)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:33:08]
  Epoch: [332][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0091 (0.0094)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 03:33:20]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.310 Prec@5 99.830 Error@1 4.690

==>>[2018-12-25 03:33:29] [Epoch=333/550] [Need: 01:56:18] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [333][000/500]   Time 0.094 (0.094)   Data 0.066 (0.066)   Loss 0.0339 (0.0339)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:33:29]
  Epoch: [333][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0091 (0.0090)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:33:40]
  Epoch: [333][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0157 (0.0090)   Prec@1 99.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:33:52]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.320 Prec@5 99.830 Error@1 4.680

==>>[2018-12-25 03:34:00] [Epoch=334/550] [Need: 01:55:45] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [334][000/500]   Time 0.098 (0.098)   Data 0.063 (0.063)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:34:01]
  Epoch: [334][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0087)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:34:12]
  Epoch: [334][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0138 (0.0090)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:34:24]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.340 Prec@5 99.820 Error@1 4.660

==>>[2018-12-25 03:34:32] [Epoch=335/550] [Need: 01:55:13] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [335][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:34:32]
  Epoch: [335][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0055 (0.0089)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:34:44]
  Epoch: [335][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0090)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:34:56]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.350 Prec@5 99.790 Error@1 4.650

==>>[2018-12-25 03:35:04] [Epoch=336/550] [Need: 01:54:41] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [336][000/500]   Time 0.097 (0.097)   Data 0.064 (0.064)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:35:04]
  Epoch: [336][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0091)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:35:16]
  Epoch: [336][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0219 (0.0095)   Prec@1 99.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:35:28]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.370 Prec@5 99.810 Error@1 4.630

==>>[2018-12-25 03:35:36] [Epoch=337/550] [Need: 01:54:08] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [337][000/500]   Time 0.096 (0.096)   Data 0.063 (0.063)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:35:36]
  Epoch: [337][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0086)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 03:35:48]
  Epoch: [337][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0088)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 03:36:00]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.320 Prec@5 99.800 Error@1 4.680

==>>[2018-12-25 03:36:08] [Epoch=338/550] [Need: 01:53:36] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [338][000/500]   Time 0.091 (0.091)   Data 0.061 (0.061)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:36:08]
  Epoch: [338][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0235 (0.0087)   Prec@1 99.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:36:20]
  Epoch: [338][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0078 (0.0091)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:36:32]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.410 Prec@5 99.820 Error@1 4.590

==>>[2018-12-25 03:36:40] [Epoch=339/550] [Need: 01:53:04] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [339][000/500]   Time 0.100 (0.100)   Data 0.065 (0.065)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:36:41]
  Epoch: [339][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0087)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:36:52]
  Epoch: [339][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0133 (0.0086)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 03:37:04]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.360 Prec@5 99.830 Error@1 4.640

==>>[2018-12-25 03:37:12] [Epoch=340/550] [Need: 01:52:32] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [340][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:37:12]
  Epoch: [340][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0103 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:37:24]
  Epoch: [340][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0086)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:37:36]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.360 Prec@5 99.810 Error@1 4.640

==>>[2018-12-25 03:37:44] [Epoch=341/550] [Need: 01:52:00] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [341][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0169 (0.0169)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:37:44]
  Epoch: [341][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0096)   Prec@1 100.000 (99.940)   Prec@5 100.000 (99.995)   [2018-12-25 03:37:56]
  Epoch: [341][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0092)   Prec@1 100.000 (99.943)   Prec@5 100.000 (99.998)   [2018-12-25 03:38:08]
  **Train** Prec@1 99.940 Prec@5 99.998 Error@1 0.060
  **Test** Prec@1 95.330 Prec@5 99.830 Error@1 4.670

==>>[2018-12-25 03:38:16] [Epoch=342/550] [Need: 01:51:27] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [342][000/500]   Time 0.098 (0.098)   Data 0.063 (0.063)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:38:16]
  Epoch: [342][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0089)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:38:28]
  Epoch: [342][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0087)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 03:38:40]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.360 Prec@5 99.820 Error@1 4.640

==>>[2018-12-25 03:38:48] [Epoch=343/550] [Need: 01:50:55] [learning_rate=0.000100] [Best : Accuracy=95.41, Error=4.59]
  Epoch: [343][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0131 (0.0131)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:38:48]
  Epoch: [343][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0092)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:39:00]
  Epoch: [343][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0091)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:39:12]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.450 Prec@5 99.800 Error@1 4.550

==>>[2018-12-25 03:39:21] [Epoch=344/550] [Need: 01:50:23] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [344][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:39:21]
  Epoch: [344][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0087)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 03:39:32]
  Epoch: [344][400/500]   Time 0.056 (0.059)   Data 0.000 (0.000)   Loss 0.0085 (0.0087)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 03:39:44]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.280 Prec@5 99.810 Error@1 4.720

==>>[2018-12-25 03:39:53] [Epoch=345/550] [Need: 01:49:51] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [345][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0072 (0.0072)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:39:53]
  Epoch: [345][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0113 (0.0090)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:40:04]
  Epoch: [345][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0065 (0.0089)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:40:16]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.420 Prec@5 99.850 Error@1 4.580

==>>[2018-12-25 03:40:24] [Epoch=346/550] [Need: 01:49:18] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [346][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0184 (0.0184)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:40:24]
  Epoch: [346][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0085)   Prec@1 100.000 (99.980)   Prec@5 100.000 (100.000)   [2018-12-25 03:40:36]
  Epoch: [346][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0087 (0.0086)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 03:40:48]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.280 Prec@5 99.820 Error@1 4.720

==>>[2018-12-25 03:40:56] [Epoch=347/550] [Need: 01:48:46] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [347][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:40:56]
  Epoch: [347][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0090)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:41:08]
  Epoch: [347][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:41:20]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.350 Prec@5 99.780 Error@1 4.650

==>>[2018-12-25 03:41:28] [Epoch=348/550] [Need: 01:48:14] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [348][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:41:28]
  Epoch: [348][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0101)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-12-25 03:41:40]
  Epoch: [348][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0090 (0.0093)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 03:41:52]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.340 Prec@5 99.850 Error@1 4.660

==>>[2018-12-25 03:42:00] [Epoch=349/550] [Need: 01:47:42] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [349][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:42:00]
  Epoch: [349][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0091)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:42:12]
  Epoch: [349][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0091)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 03:42:24]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.430 Prec@5 99.850 Error@1 4.570

==>>[2018-12-25 03:42:32] [Epoch=350/550] [Need: 01:47:09] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [350][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:42:32]
  Epoch: [350][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0094)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-12-25 03:42:44]
  Epoch: [350][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0184 (0.0091)   Prec@1 99.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 03:42:56]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.350 Prec@5 99.800 Error@1 4.650

==>>[2018-12-25 03:43:04] [Epoch=351/550] [Need: 01:46:37] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [351][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:43:04]
  Epoch: [351][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0088)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:43:16]
  Epoch: [351][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0129 (0.0086)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 03:43:28]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.440 Prec@5 99.830 Error@1 4.560

==>>[2018-12-25 03:43:36] [Epoch=352/550] [Need: 01:46:05] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [352][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:43:36]
  Epoch: [352][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:43:48]
  Epoch: [352][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0088)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:43:59]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.420 Prec@5 99.820 Error@1 4.580

==>>[2018-12-25 03:44:08] [Epoch=353/550] [Need: 01:45:32] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [353][000/500]   Time 0.096 (0.096)   Data 0.061 (0.061)   Loss 0.0092 (0.0092)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:44:08]
  Epoch: [353][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0142 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 03:44:20]
  Epoch: [353][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0092)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 03:44:31]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.370 Prec@5 99.840 Error@1 4.630

==>>[2018-12-25 03:44:40] [Epoch=354/550] [Need: 01:45:00] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [354][000/500]   Time 0.096 (0.096)   Data 0.063 (0.063)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:44:40]
  Epoch: [354][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0092 (0.0093)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 03:44:52]
  Epoch: [354][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0091)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:45:03]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.360 Prec@5 99.850 Error@1 4.640

==>>[2018-12-25 03:45:12] [Epoch=355/550] [Need: 01:44:28] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [355][000/500]   Time 0.097 (0.097)   Data 0.067 (0.067)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:45:12]
  Epoch: [355][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0091 (0.0092)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 03:45:24]
  Epoch: [355][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0055 (0.0090)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:45:35]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.370 Prec@5 99.850 Error@1 4.630

==>>[2018-12-25 03:45:44] [Epoch=356/550] [Need: 01:43:56] [learning_rate=0.000100] [Best : Accuracy=95.45, Error=4.55]
  Epoch: [356][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0115 (0.0115)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:45:44]
  Epoch: [356][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0091)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:45:56]
  Epoch: [356][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0089 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:46:07]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.480 Prec@5 99.780 Error@1 4.520

==>>[2018-12-25 03:46:16] [Epoch=357/550] [Need: 01:43:24] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [357][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:46:16]
  Epoch: [357][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0087)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:46:28]
  Epoch: [357][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0089)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:46:40]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.350 Prec@5 99.810 Error@1 4.650

==>>[2018-12-25 03:46:48] [Epoch=358/550] [Need: 01:42:51] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [358][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:46:48]
  Epoch: [358][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0091)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:47:00]
  Epoch: [358][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:47:11]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.410 Prec@5 99.790 Error@1 4.590

==>>[2018-12-25 03:47:20] [Epoch=359/550] [Need: 01:42:19] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [359][000/500]   Time 0.097 (0.097)   Data 0.066 (0.066)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:47:20]
  Epoch: [359][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0125 (0.0091)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:47:32]
  Epoch: [359][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0101 (0.0093)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:47:43]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 95.350 Prec@5 99.840 Error@1 4.650

==>>[2018-12-25 03:47:52] [Epoch=360/550] [Need: 01:41:47] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [360][000/500]   Time 0.089 (0.089)   Data 0.062 (0.062)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:47:52]
  Epoch: [360][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0091)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 03:48:04]
  Epoch: [360][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0086 (0.0090)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:48:15]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.380 Prec@5 99.790 Error@1 4.620

==>>[2018-12-25 03:48:24] [Epoch=361/550] [Need: 01:41:15] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [361][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:48:24]
  Epoch: [361][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0135 (0.0094)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 03:48:36]
  Epoch: [361][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0100 (0.0092)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 03:48:47]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.350 Prec@5 99.790 Error@1 4.650

==>>[2018-12-25 03:48:56] [Epoch=362/550] [Need: 01:40:42] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [362][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:48:56]
  Epoch: [362][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0086)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:49:08]
  Epoch: [362][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0076 (0.0091)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:49:19]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.420 Prec@5 99.810 Error@1 4.580

==>>[2018-12-25 03:49:28] [Epoch=363/550] [Need: 01:40:10] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [363][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:49:28]
  Epoch: [363][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0087)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:49:39]
  Epoch: [363][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0090)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 03:49:51]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.380 Prec@5 99.800 Error@1 4.620

==>>[2018-12-25 03:50:00] [Epoch=364/550] [Need: 01:39:38] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [364][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:50:00]
  Epoch: [364][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0099)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 03:50:11]
  Epoch: [364][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0094)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-12-25 03:50:23]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.350 Prec@5 99.800 Error@1 4.650

==>>[2018-12-25 03:50:31] [Epoch=365/550] [Need: 01:39:06] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [365][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0105 (0.0105)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:50:32]
  Epoch: [365][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0082)   Prec@1 100.000 (99.980)   Prec@5 100.000 (100.000)   [2018-12-25 03:50:43]
  Epoch: [365][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0185 (0.0084)   Prec@1 99.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:50:55]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.350 Prec@5 99.820 Error@1 4.650

==>>[2018-12-25 03:51:03] [Epoch=366/550] [Need: 01:38:33] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [366][000/500]   Time 0.097 (0.097)   Data 0.068 (0.068)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:51:04]
  Epoch: [366][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0085)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:51:15]
  Epoch: [366][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0199 (0.0088)   Prec@1 99.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 03:51:27]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.360 Prec@5 99.830 Error@1 4.640

==>>[2018-12-25 03:51:35] [Epoch=367/550] [Need: 01:38:01] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [367][000/500]   Time 0.098 (0.098)   Data 0.063 (0.063)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:51:36]
  Epoch: [367][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0090)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:51:47]
  Epoch: [367][400/500]   Time 0.056 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0090)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 03:51:59]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.360 Prec@5 99.790 Error@1 4.640

==>>[2018-12-25 03:52:07] [Epoch=368/550] [Need: 01:37:29] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [368][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:52:07]
  Epoch: [368][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0119 (0.0088)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:52:19]
  Epoch: [368][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0097 (0.0087)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:52:31]
  **Train** Prec@1 99.942 Prec@5 99.998 Error@1 0.058
  **Test** Prec@1 95.300 Prec@5 99.820 Error@1 4.700

==>>[2018-12-25 03:52:39] [Epoch=369/550] [Need: 01:36:57] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [369][000/500]   Time 0.097 (0.097)   Data 0.066 (0.066)   Loss 0.0238 (0.0238)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:52:39]
  Epoch: [369][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0084)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:52:51]
  Epoch: [369][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0169 (0.0084)   Prec@1 99.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 03:53:03]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.390 Prec@5 99.820 Error@1 4.610

==>>[2018-12-25 03:53:11] [Epoch=370/550] [Need: 01:36:24] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [370][000/500]   Time 0.097 (0.097)   Data 0.067 (0.067)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:53:11]
  Epoch: [370][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0084)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 03:53:23]
  Epoch: [370][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0142 (0.0085)   Prec@1 99.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 03:53:35]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.360 Prec@5 99.840 Error@1 4.640

==>>[2018-12-25 03:53:43] [Epoch=371/550] [Need: 01:35:52] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [371][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:53:43]
  Epoch: [371][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0089)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:53:55]
  Epoch: [371][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0087 (0.0088)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:54:07]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.350 Prec@5 99.820 Error@1 4.650

==>>[2018-12-25 03:54:15] [Epoch=372/550] [Need: 01:35:20] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [372][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:54:15]
  Epoch: [372][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0111 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (99.995)   [2018-12-25 03:54:27]
  Epoch: [372][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0089)   Prec@1 100.000 (99.958)   Prec@5 100.000 (99.998)   [2018-12-25 03:54:38]
  **Train** Prec@1 99.948 Prec@5 99.998 Error@1 0.052
  **Test** Prec@1 95.280 Prec@5 99.810 Error@1 4.720

==>>[2018-12-25 03:54:47] [Epoch=373/550] [Need: 01:34:48] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [373][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:54:47]
  Epoch: [373][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0400 (0.0091)   Prec@1 99.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:54:59]
  Epoch: [373][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0091)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:55:10]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.410 Prec@5 99.810 Error@1 4.590

==>>[2018-12-25 03:55:19] [Epoch=374/550] [Need: 01:34:15] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [374][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0072 (0.0072)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:55:19]
  Epoch: [374][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0052 (0.0090)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:55:31]
  Epoch: [374][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0089)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 03:55:42]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.390 Prec@5 99.820 Error@1 4.610

==>>[2018-12-25 03:55:51] [Epoch=375/550] [Need: 01:33:43] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [375][000/500]   Time 0.089 (0.089)   Data 0.062 (0.062)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:55:51]
  Epoch: [375][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0079 (0.0088)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 03:56:02]
  Epoch: [375][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0054 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:56:14]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.290 Prec@5 99.810 Error@1 4.710

==>>[2018-12-25 03:56:23] [Epoch=376/550] [Need: 01:33:11] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [376][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0111 (0.0111)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:56:23]
  Epoch: [376][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0108 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:56:34]
  Epoch: [376][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0091)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 03:56:46]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.360 Prec@5 99.780 Error@1 4.640

==>>[2018-12-25 03:56:55] [Epoch=377/550] [Need: 01:32:39] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [377][000/500]   Time 0.099 (0.099)   Data 0.071 (0.071)   Loss 0.0106 (0.0106)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:56:55]
  Epoch: [377][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0091)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 03:57:06]
  Epoch: [377][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0097 (0.0089)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 03:57:18]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.470 Prec@5 99.830 Error@1 4.530

==>>[2018-12-25 03:57:26] [Epoch=378/550] [Need: 01:32:06] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [378][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0117 (0.0117)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:57:27]
  Epoch: [378][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0095 (0.0094)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 03:57:38]
  Epoch: [378][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0089)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 03:57:50]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.400 Prec@5 99.830 Error@1 4.600

==>>[2018-12-25 03:57:58] [Epoch=379/550] [Need: 01:31:34] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [379][000/500]   Time 0.095 (0.095)   Data 0.063 (0.063)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:57:59]
  Epoch: [379][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0093)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:58:10]
  Epoch: [379][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0088)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 03:58:22]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.420 Prec@5 99.800 Error@1 4.580

==>>[2018-12-25 03:58:30] [Epoch=380/550] [Need: 01:31:02] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [380][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:58:30]
  Epoch: [380][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0088)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:58:42]
  Epoch: [380][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:58:54]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.430 Prec@5 99.800 Error@1 4.570

==>>[2018-12-25 03:59:02] [Epoch=381/550] [Need: 01:30:30] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [381][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:59:02]
  Epoch: [381][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0088)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:59:14]
  Epoch: [381][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0057 (0.0092)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 03:59:26]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.460 Prec@5 99.840 Error@1 4.540

==>>[2018-12-25 03:59:34] [Epoch=382/550] [Need: 01:29:58] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [382][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 03:59:34]
  Epoch: [382][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0197 (0.0087)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 03:59:46]
  Epoch: [382][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 03:59:58]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.430 Prec@5 99.800 Error@1 4.570

==>>[2018-12-25 04:00:06] [Epoch=383/550] [Need: 01:29:25] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [383][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:00:06]
  Epoch: [383][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0089)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:00:18]
  Epoch: [383][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0092)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:00:30]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.460 Prec@5 99.850 Error@1 4.540

==>>[2018-12-25 04:00:38] [Epoch=384/550] [Need: 01:28:53] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [384][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:00:38]
  Epoch: [384][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0094 (0.0085)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:00:50]
  Epoch: [384][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0088)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 04:01:01]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.360 Prec@5 99.820 Error@1 4.640

==>>[2018-12-25 04:01:10] [Epoch=385/550] [Need: 01:28:21] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [385][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:01:10]
  Epoch: [385][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:01:22]
  Epoch: [385][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0164 (0.0088)   Prec@1 99.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 04:01:33]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.400 Prec@5 99.820 Error@1 4.600

==>>[2018-12-25 04:01:42] [Epoch=386/550] [Need: 01:27:49] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [386][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:01:42]
  Epoch: [386][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0108 (0.0084)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:01:54]
  Epoch: [386][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:02:05]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.450 Prec@5 99.810 Error@1 4.550

==>>[2018-12-25 04:02:14] [Epoch=387/550] [Need: 01:27:16] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [387][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0151 (0.0151)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:02:14]
  Epoch: [387][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0069 (0.0088)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:02:26]
  Epoch: [387][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0087)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:02:37]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.360 Prec@5 99.800 Error@1 4.640

==>>[2018-12-25 04:02:46] [Epoch=388/550] [Need: 01:26:44] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [388][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:02:46]
  Epoch: [388][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0188 (0.0088)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:02:57]
  Epoch: [388][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0089)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:03:09]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.400 Prec@5 99.840 Error@1 4.600

==>>[2018-12-25 04:03:18] [Epoch=389/550] [Need: 01:26:12] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [389][000/500]   Time 0.098 (0.098)   Data 0.064 (0.064)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:03:18]
  Epoch: [389][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0090)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:03:29]
  Epoch: [389][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0091 (0.0089)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:03:41]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.330 Prec@5 99.820 Error@1 4.670

==>>[2018-12-25 04:03:49] [Epoch=390/550] [Need: 01:25:40] [learning_rate=0.000100] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [390][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:03:50]
  Epoch: [390][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0085)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:04:01]
  Epoch: [390][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0139 (0.0083)   Prec@1 100.000 (99.978)   Prec@5 100.000 (100.000)   [2018-12-25 04:04:13]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.410 Prec@5 99.820 Error@1 4.590

==>>[2018-12-25 04:04:21] [Epoch=391/550] [Need: 01:25:08] [learning_rate=0.000010] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [391][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:04:21]
  Epoch: [391][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0089)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:04:33]
  Epoch: [391][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0071 (0.0087)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:04:45]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.420 Prec@5 99.820 Error@1 4.580

==>>[2018-12-25 04:04:53] [Epoch=392/550] [Need: 01:24:35] [learning_rate=0.000010] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [392][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:04:53]
  Epoch: [392][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0091)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 04:05:05]
  Epoch: [392][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0063 (0.0086)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:05:17]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.450 Prec@5 99.830 Error@1 4.550

==>>[2018-12-25 04:05:25] [Epoch=393/550] [Need: 01:24:03] [learning_rate=0.000010] [Best : Accuracy=95.48, Error=4.52]
  Epoch: [393][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:05:25]
  Epoch: [393][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0276 (0.0092)   Prec@1 99.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 04:05:37]
  Epoch: [393][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0083 (0.0091)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:05:49]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 95.490 Prec@5 99.790 Error@1 4.510

==>>[2018-12-25 04:05:57] [Epoch=394/550] [Need: 01:23:31] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [394][000/500]   Time 0.098 (0.098)   Data 0.063 (0.063)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:05:58]
  Epoch: [394][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0086)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:06:09]
  Epoch: [394][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0106 (0.0085)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 04:06:21]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.410 Prec@5 99.800 Error@1 4.590

==>>[2018-12-25 04:06:29] [Epoch=395/550] [Need: 01:22:59] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [395][000/500]   Time 0.096 (0.096)   Data 0.064 (0.064)   Loss 0.0072 (0.0072)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:06:29]
  Epoch: [395][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0091 (0.0088)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:06:41]
  Epoch: [395][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0086 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:06:53]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.410 Prec@5 99.860 Error@1 4.590

==>>[2018-12-25 04:07:01] [Epoch=396/550] [Need: 01:22:27] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [396][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0102 (0.0102)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:07:01]
  Epoch: [396][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0089)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:07:13]
  Epoch: [396][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0091)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:07:25]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.400 Prec@5 99.780 Error@1 4.600

==>>[2018-12-25 04:07:33] [Epoch=397/550] [Need: 01:21:54] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [397][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0120 (0.0120)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:07:33]
  Epoch: [397][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0085)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:07:45]
  Epoch: [397][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0088)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:07:57]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.350 Prec@5 99.790 Error@1 4.650

==>>[2018-12-25 04:08:05] [Epoch=398/550] [Need: 01:21:22] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [398][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:08:05]
  Epoch: [398][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0092)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:08:17]
  Epoch: [398][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0090 (0.0091)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:08:28]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.370 Prec@5 99.820 Error@1 4.630

==>>[2018-12-25 04:08:37] [Epoch=399/550] [Need: 01:20:50] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [399][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:08:37]
  Epoch: [399][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0090)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:08:49]
  Epoch: [399][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0063 (0.0090)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:09:00]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.320 Prec@5 99.810 Error@1 4.680

==>>[2018-12-25 04:09:09] [Epoch=400/550] [Need: 01:20:18] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [400][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:09:09]
  Epoch: [400][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0091)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:09:21]
  Epoch: [400][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0117 (0.0091)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:09:32]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.390 Prec@5 99.760 Error@1 4.610

==>>[2018-12-25 04:09:41] [Epoch=401/550] [Need: 01:19:46] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [401][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:09:41]
  Epoch: [401][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:09:53]
  Epoch: [401][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0194 (0.0088)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:10:04]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.390 Prec@5 99.840 Error@1 4.610

==>>[2018-12-25 04:10:13] [Epoch=402/550] [Need: 01:19:13] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [402][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:10:13]
  Epoch: [402][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0082)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:10:25]
  Epoch: [402][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0083)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:10:36]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.260 Prec@5 99.850 Error@1 4.740

==>>[2018-12-25 04:10:45] [Epoch=403/550] [Need: 01:18:41] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [403][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:10:45]
  Epoch: [403][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0097)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 04:10:56]
  Epoch: [403][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0092)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:11:08]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.380 Prec@5 99.810 Error@1 4.620

==>>[2018-12-25 04:11:17] [Epoch=404/550] [Need: 01:18:09] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [404][000/500]   Time 0.092 (0.092)   Data 0.061 (0.061)   Loss 0.0098 (0.0098)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:11:17]
  Epoch: [404][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0089 (0.0093)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:11:28]
  Epoch: [404][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0090)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:11:40]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.460 Prec@5 99.800 Error@1 4.540

==>>[2018-12-25 04:11:49] [Epoch=405/550] [Need: 01:17:37] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [405][000/500]   Time 0.095 (0.095)   Data 0.063 (0.063)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:11:49]
  Epoch: [405][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0113 (0.0090)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:12:00]
  Epoch: [405][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0059 (0.0088)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:12:12]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.440 Prec@5 99.820 Error@1 4.560

==>>[2018-12-25 04:12:20] [Epoch=406/550] [Need: 01:17:05] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [406][000/500]   Time 0.097 (0.097)   Data 0.067 (0.067)   Loss 0.0097 (0.0097)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:12:21]
  Epoch: [406][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0466 (0.0090)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:12:32]
  Epoch: [406][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0065 (0.0092)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 04:12:44]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.410 Prec@5 99.800 Error@1 4.590

==>>[2018-12-25 04:12:52] [Epoch=407/550] [Need: 01:16:32] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [407][000/500]   Time 0.099 (0.099)   Data 0.064 (0.064)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:12:52]
  Epoch: [407][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0092)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:13:04]
  Epoch: [407][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0061 (0.0090)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:13:16]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.450 Prec@5 99.860 Error@1 4.550

==>>[2018-12-25 04:13:24] [Epoch=408/550] [Need: 01:16:00] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [408][000/500]   Time 0.098 (0.098)   Data 0.064 (0.064)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:13:24]
  Epoch: [408][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0091)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:13:36]
  Epoch: [408][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0091)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:13:48]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.360 Prec@5 99.810 Error@1 4.640

==>>[2018-12-25 04:13:56] [Epoch=409/550] [Need: 01:15:28] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [409][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:13:56]
  Epoch: [409][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0210 (0.0095)   Prec@1 99.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 04:14:08]
  Epoch: [409][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0093)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 04:14:20]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.380 Prec@5 99.790 Error@1 4.620

==>>[2018-12-25 04:14:28] [Epoch=410/550] [Need: 01:14:56] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [410][000/500]   Time 0.097 (0.097)   Data 0.066 (0.066)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:14:28]
  Epoch: [410][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0089)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:14:40]
  Epoch: [410][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0171 (0.0086)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:14:51]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.380 Prec@5 99.790 Error@1 4.620

==>>[2018-12-25 04:15:00] [Epoch=411/550] [Need: 01:14:24] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [411][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:15:00]
  Epoch: [411][200/500]   Time 0.064 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:15:12]
  Epoch: [411][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0084)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 04:15:23]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.330 Prec@5 99.820 Error@1 4.670

==>>[2018-12-25 04:15:32] [Epoch=412/550] [Need: 01:13:51] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [412][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:15:32]
  Epoch: [412][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0095)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 04:15:44]
  Epoch: [412][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0091)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:15:55]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.340 Prec@5 99.840 Error@1 4.660

==>>[2018-12-25 04:16:04] [Epoch=413/550] [Need: 01:13:19] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [413][000/500]   Time 0.095 (0.095)   Data 0.067 (0.067)   Loss 0.0080 (0.0080)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:16:04]
  Epoch: [413][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0281 (0.0084)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:16:16]
  Epoch: [413][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0085)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 04:16:27]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.490 Prec@5 99.830 Error@1 4.510

==>>[2018-12-25 04:16:36] [Epoch=414/550] [Need: 01:12:47] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [414][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:16:36]
  Epoch: [414][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0086)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:16:48]
  Epoch: [414][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0087)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 04:17:00]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.430 Prec@5 99.820 Error@1 4.570

==>>[2018-12-25 04:17:08] [Epoch=415/550] [Need: 01:12:15] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [415][000/500]   Time 0.092 (0.092)   Data 0.060 (0.060)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:17:08]
  Epoch: [415][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0092)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:17:20]
  Epoch: [415][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0076 (0.0092)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:17:31]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.350 Prec@5 99.820 Error@1 4.650

==>>[2018-12-25 04:17:40] [Epoch=416/550] [Need: 01:11:43] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [416][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0228 (0.0228)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:17:40]
  Epoch: [416][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0092)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:17:52]
  Epoch: [416][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0075 (0.0091)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:18:03]
  **Train** Prec@1 99.958 Prec@5 99.998 Error@1 0.042
  **Test** Prec@1 95.470 Prec@5 99.780 Error@1 4.530

==>>[2018-12-25 04:18:12] [Epoch=417/550] [Need: 01:11:11] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [417][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0097 (0.0097)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:18:12]
  Epoch: [417][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0219 (0.0088)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:18:24]
  Epoch: [417][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0088)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:18:35]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.370 Prec@5 99.800 Error@1 4.630

==>>[2018-12-25 04:18:44] [Epoch=418/550] [Need: 01:10:39] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [418][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:18:44]
  Epoch: [418][200/500]   Time 0.064 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0094)   Prec@1 100.000 (99.925)   Prec@5 100.000 (99.995)   [2018-12-25 04:18:56]
  Epoch: [418][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0089)   Prec@1 100.000 (99.940)   Prec@5 100.000 (99.998)   [2018-12-25 04:19:07]
  **Train** Prec@1 99.940 Prec@5 99.998 Error@1 0.060
  **Test** Prec@1 95.380 Prec@5 99.810 Error@1 4.620

==>>[2018-12-25 04:19:16] [Epoch=419/550] [Need: 01:10:06] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [419][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:19:16]
  Epoch: [419][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0086)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:19:27]
  Epoch: [419][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0134 (0.0089)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:19:39]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.360 Prec@5 99.800 Error@1 4.640

==>>[2018-12-25 04:19:48] [Epoch=420/550] [Need: 01:09:34] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [420][000/500]   Time 0.097 (0.097)   Data 0.067 (0.067)   Loss 0.0094 (0.0094)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:19:48]
  Epoch: [420][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:19:59]
  Epoch: [420][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0088 (0.0088)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 04:20:11]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.420 Prec@5 99.780 Error@1 4.580

==>>[2018-12-25 04:20:19] [Epoch=421/550] [Need: 01:09:02] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [421][000/500]   Time 0.096 (0.096)   Data 0.067 (0.067)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:20:20]
  Epoch: [421][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0090)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:20:31]
  Epoch: [421][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0089)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:20:43]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.430 Prec@5 99.820 Error@1 4.570

==>>[2018-12-25 04:20:51] [Epoch=422/550] [Need: 01:08:30] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [422][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:20:52]
  Epoch: [422][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0085)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:21:03]
  Epoch: [422][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0106 (0.0085)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:21:15]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.480 Prec@5 99.820 Error@1 4.520

==>>[2018-12-25 04:21:23] [Epoch=423/550] [Need: 01:07:58] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [423][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:21:23]
  Epoch: [423][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0054 (0.0090)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:21:35]
  Epoch: [423][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0145 (0.0091)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:21:47]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.430 Prec@5 99.850 Error@1 4.570

==>>[2018-12-25 04:21:55] [Epoch=424/550] [Need: 01:07:26] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [424][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:21:55]
  Epoch: [424][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:22:07]
  Epoch: [424][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0066 (0.0090)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:22:19]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.370 Prec@5 99.850 Error@1 4.630

==>>[2018-12-25 04:22:27] [Epoch=425/550] [Need: 01:06:53] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [425][000/500]   Time 0.100 (0.100)   Data 0.066 (0.066)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:22:27]
  Epoch: [425][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0092)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:22:39]
  Epoch: [425][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0131 (0.0093)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:22:51]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.300 Prec@5 99.850 Error@1 4.700

==>>[2018-12-25 04:22:59] [Epoch=426/550] [Need: 01:06:21] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [426][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:22:59]
  Epoch: [426][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0063 (0.0089)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 04:23:11]
  Epoch: [426][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0071 (0.0090)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 04:23:22]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.370 Prec@5 99.770 Error@1 4.630

==>>[2018-12-25 04:23:31] [Epoch=427/550] [Need: 01:05:49] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [427][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0124 (0.0124)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:23:31]
  Epoch: [427][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0064 (0.0090)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 04:23:43]
  Epoch: [427][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0069 (0.0089)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:23:54]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.420 Prec@5 99.850 Error@1 4.580

==>>[2018-12-25 04:24:03] [Epoch=428/550] [Need: 01:05:17] [learning_rate=0.000010] [Best : Accuracy=95.49, Error=4.51]
  Epoch: [428][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0137 (0.0137)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:24:03]
  Epoch: [428][200/500]   Time 0.063 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0084)   Prec@1 100.000 (99.980)   Prec@5 100.000 (100.000)   [2018-12-25 04:24:14]
  Epoch: [428][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0119 (0.0084)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2018-12-25 04:24:26]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 95.500 Prec@5 99.790 Error@1 4.500

==>>[2018-12-25 04:24:35] [Epoch=429/550] [Need: 01:04:45] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [429][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:24:35]
  Epoch: [429][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0071 (0.0092)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:24:47]
  Epoch: [429][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0070 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:24:58]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.340 Prec@5 99.840 Error@1 4.660

==>>[2018-12-25 04:25:07] [Epoch=430/550] [Need: 01:04:13] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [430][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:25:07]
  Epoch: [430][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0103 (0.0087)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:25:19]
  Epoch: [430][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0108 (0.0084)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:25:30]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.370 Prec@5 99.820 Error@1 4.630

==>>[2018-12-25 04:25:39] [Epoch=431/550] [Need: 01:03:40] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [431][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:25:39]
  Epoch: [431][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:25:50]
  Epoch: [431][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0096 (0.0090)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 04:26:02]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.490 Prec@5 99.800 Error@1 4.510

==>>[2018-12-25 04:26:11] [Epoch=432/550] [Need: 01:03:08] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [432][000/500]   Time 0.098 (0.098)   Data 0.068 (0.068)   Loss 0.0952 (0.0952)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:26:11]
  Epoch: [432][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0091 (0.0090)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 04:26:22]
  Epoch: [432][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0200 (0.0086)   Prec@1 99.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:26:34]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.450 Prec@5 99.850 Error@1 4.550

==>>[2018-12-25 04:26:42] [Epoch=433/550] [Need: 01:02:36] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [433][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:26:43]
  Epoch: [433][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0086 (0.0088)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:26:54]
  Epoch: [433][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0055 (0.0086)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:27:06]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.390 Prec@5 99.810 Error@1 4.610

==>>[2018-12-25 04:27:14] [Epoch=434/550] [Need: 01:02:04] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [434][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0084 (0.0084)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:27:14]
  Epoch: [434][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0092)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:27:26]
  Epoch: [434][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0070 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:27:38]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.420 Prec@5 99.830 Error@1 4.580

==>>[2018-12-25 04:27:46] [Epoch=435/550] [Need: 01:01:32] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [435][000/500]   Time 0.096 (0.096)   Data 0.067 (0.067)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:27:46]
  Epoch: [435][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0086)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:27:58]
  Epoch: [435][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0062 (0.0086)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-12-25 04:28:10]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.390 Prec@5 99.840 Error@1 4.610

==>>[2018-12-25 04:28:18] [Epoch=436/550] [Need: 01:01:00] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [436][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0114 (0.0114)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:28:18]
  Epoch: [436][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0090)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-12-25 04:28:30]
  Epoch: [436][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0054 (0.0091)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 04:28:41]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.390 Prec@5 99.830 Error@1 4.610

==>>[2018-12-25 04:28:50] [Epoch=437/550] [Need: 01:00:27] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [437][000/500]   Time 0.096 (0.096)   Data 0.063 (0.063)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:28:50]
  Epoch: [437][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0093 (0.0094)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 04:29:02]
  Epoch: [437][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0070 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:29:13]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.400 Prec@5 99.850 Error@1 4.600

==>>[2018-12-25 04:29:22] [Epoch=438/550] [Need: 00:59:55] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [438][000/500]   Time 0.097 (0.097)   Data 0.064 (0.064)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:29:22]
  Epoch: [438][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0124 (0.0092)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:29:33]
  Epoch: [438][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0064 (0.0090)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:29:45]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.330 Prec@5 99.760 Error@1 4.670

==>>[2018-12-25 04:29:54] [Epoch=439/550] [Need: 00:59:23] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [439][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:29:54]
  Epoch: [439][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0101 (0.0090)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:30:05]
  Epoch: [439][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0070 (0.0088)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:30:17]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.400 Prec@5 99.800 Error@1 4.600

==>>[2018-12-25 04:30:25] [Epoch=440/550] [Need: 00:58:51] [learning_rate=0.000010] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [440][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0193 (0.0193)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:30:25]
  Epoch: [440][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0067 (0.0088)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:30:37]
  Epoch: [440][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0060 (0.0088)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 04:30:49]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.390 Prec@5 99.830 Error@1 4.610

==>>[2018-12-25 04:30:57] [Epoch=441/550] [Need: 00:58:19] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [441][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:30:57]
  Epoch: [441][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0323 (0.0091)   Prec@1 98.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:31:09]
  Epoch: [441][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0073 (0.0089)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:31:21]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.420 Prec@5 99.850 Error@1 4.580

==>>[2018-12-25 04:31:29] [Epoch=442/550] [Need: 00:57:46] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [442][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:31:29]
  Epoch: [442][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0141 (0.0086)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:31:41]
  Epoch: [442][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0063 (0.0086)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 04:31:52]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.390 Prec@5 99.790 Error@1 4.610

==>>[2018-12-25 04:32:01] [Epoch=443/550] [Need: 00:57:14] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [443][000/500]   Time 0.097 (0.097)   Data 0.067 (0.067)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:32:01]
  Epoch: [443][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0069 (0.0083)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:32:13]
  Epoch: [443][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0090 (0.0084)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 04:32:24]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.430 Prec@5 99.790 Error@1 4.570

==>>[2018-12-25 04:32:33] [Epoch=444/550] [Need: 00:56:42] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [444][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:32:33]
  Epoch: [444][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:32:45]
  Epoch: [444][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0067 (0.0086)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:32:56]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.420 Prec@5 99.820 Error@1 4.580

==>>[2018-12-25 04:33:05] [Epoch=445/550] [Need: 00:56:10] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [445][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:33:05]
  Epoch: [445][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0089)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:33:16]
  Epoch: [445][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:33:28]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.390 Prec@5 99.770 Error@1 4.610

==>>[2018-12-25 04:33:37] [Epoch=446/550] [Need: 00:55:38] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [446][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0101 (0.0101)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:33:37]
  Epoch: [446][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0082)   Prec@1 100.000 (99.985)   Prec@5 100.000 (100.000)   [2018-12-25 04:33:48]
  Epoch: [446][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0084 (0.0086)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2018-12-25 04:34:00]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 95.370 Prec@5 99.830 Error@1 4.630

==>>[2018-12-25 04:34:08] [Epoch=447/550] [Need: 00:55:06] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [447][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0118 (0.0118)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:34:08]
  Epoch: [447][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:34:20]
  Epoch: [447][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0082 (0.0083)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 04:34:32]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.460 Prec@5 99.860 Error@1 4.540

==>>[2018-12-25 04:34:40] [Epoch=448/550] [Need: 00:54:34] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [448][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:34:40]
  Epoch: [448][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0090)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:34:52]
  Epoch: [448][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0062 (0.0092)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 04:35:04]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.380 Prec@5 99.800 Error@1 4.620

==>>[2018-12-25 04:35:12] [Epoch=449/550] [Need: 00:54:01] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [449][000/500]   Time 0.094 (0.094)   Data 0.062 (0.062)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:35:12]
  Epoch: [449][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0085)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 04:35:24]
  Epoch: [449][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0079 (0.0084)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:35:36]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.310 Prec@5 99.770 Error@1 4.690

==>>[2018-12-25 04:35:44] [Epoch=450/550] [Need: 00:53:29] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [450][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:35:44]
  Epoch: [450][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0090)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:35:56]
  Epoch: [450][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0086)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 04:36:08]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.400 Prec@5 99.820 Error@1 4.600

==>>[2018-12-25 04:36:16] [Epoch=451/550] [Need: 00:52:57] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [451][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:36:16]
  Epoch: [451][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:36:28]
  Epoch: [451][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:36:39]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.400 Prec@5 99.800 Error@1 4.600

==>>[2018-12-25 04:36:48] [Epoch=452/550] [Need: 00:52:25] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [452][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:36:48]
  Epoch: [452][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0084 (0.0089)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:37:00]
  Epoch: [452][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0060 (0.0087)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 04:37:11]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.410 Prec@5 99.770 Error@1 4.590

==>>[2018-12-25 04:37:20] [Epoch=453/550] [Need: 00:51:53] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [453][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:37:20]
  Epoch: [453][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0085)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:37:31]
  Epoch: [453][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:37:43]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.370 Prec@5 99.830 Error@1 4.630

==>>[2018-12-25 04:37:52] [Epoch=454/550] [Need: 00:51:21] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [454][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:37:52]
  Epoch: [454][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0086)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:38:03]
  Epoch: [454][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0060 (0.0085)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:38:15]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.460 Prec@5 99.870 Error@1 4.540

==>>[2018-12-25 04:38:24] [Epoch=455/550] [Need: 00:50:49] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [455][000/500]   Time 0.096 (0.096)   Data 0.063 (0.063)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:38:24]
  Epoch: [455][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0088)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:38:35]
  Epoch: [455][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0138 (0.0089)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:38:47]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.400 Prec@5 99.830 Error@1 4.600

==>>[2018-12-25 04:38:55] [Epoch=456/550] [Need: 00:50:16] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [456][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:38:55]
  Epoch: [456][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0057 (0.0086)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:39:07]
  Epoch: [456][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0173 (0.0087)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 04:39:19]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.420 Prec@5 99.840 Error@1 4.580

==>>[2018-12-25 04:39:27] [Epoch=457/550] [Need: 00:49:44] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [457][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0115 (0.0115)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:39:27]
  Epoch: [457][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0088)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:39:39]
  Epoch: [457][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0089)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:39:51]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.450 Prec@5 99.800 Error@1 4.550

==>>[2018-12-25 04:39:59] [Epoch=458/550] [Need: 00:49:12] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [458][000/500]   Time 0.097 (0.097)   Data 0.067 (0.067)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:39:59]
  Epoch: [458][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0087)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:40:11]
  Epoch: [458][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0090 (0.0088)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:40:23]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.440 Prec@5 99.780 Error@1 4.560

==>>[2018-12-25 04:40:31] [Epoch=459/550] [Need: 00:48:40] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [459][000/500]   Time 0.097 (0.097)   Data 0.062 (0.062)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:40:31]
  Epoch: [459][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0086)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:40:43]
  Epoch: [459][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0062 (0.0087)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:40:55]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.350 Prec@5 99.840 Error@1 4.650

==>>[2018-12-25 04:41:03] [Epoch=460/550] [Need: 00:48:08] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [460][000/500]   Time 0.095 (0.095)   Data 0.064 (0.064)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:41:03]
  Epoch: [460][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0094)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 04:41:15]
  Epoch: [460][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0095 (0.0089)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:41:26]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.420 Prec@5 99.800 Error@1 4.580

==>>[2018-12-25 04:41:35] [Epoch=461/550] [Need: 00:47:36] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [461][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:41:35]
  Epoch: [461][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0090)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:41:47]
  Epoch: [461][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0101 (0.0089)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:41:58]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.340 Prec@5 99.810 Error@1 4.660

==>>[2018-12-25 04:42:07] [Epoch=462/550] [Need: 00:47:04] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [462][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:42:07]
  Epoch: [462][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:42:19]
  Epoch: [462][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:42:30]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.360 Prec@5 99.780 Error@1 4.640

==>>[2018-12-25 04:42:39] [Epoch=463/550] [Need: 00:46:32] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [463][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:42:39]
  Epoch: [463][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:42:51]
  Epoch: [463][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0085)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2018-12-25 04:43:02]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.350 Prec@5 99.830 Error@1 4.650

==>>[2018-12-25 04:43:11] [Epoch=464/550] [Need: 00:45:59] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [464][000/500]   Time 0.108 (0.108)   Data 0.077 (0.077)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:43:11]
  Epoch: [464][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0088 (0.0086)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:43:22]
  Epoch: [464][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0088)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:43:34]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.320 Prec@5 99.800 Error@1 4.680

==>>[2018-12-25 04:43:43] [Epoch=465/550] [Need: 00:45:27] [learning_rate=0.000001] [Best : Accuracy=95.50, Error=4.50]
  Epoch: [465][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:43:43]
  Epoch: [465][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0111 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:43:54]
  Epoch: [465][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0088)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:44:06]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.510 Prec@5 99.820 Error@1 4.490

==>>[2018-12-25 04:44:15] [Epoch=466/550] [Need: 00:44:55] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [466][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0113 (0.0113)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:44:15]
  Epoch: [466][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0091)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:44:27]
  Epoch: [466][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0090)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:44:38]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.390 Prec@5 99.790 Error@1 4.610

==>>[2018-12-25 04:44:47] [Epoch=467/550] [Need: 00:44:23] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [467][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0147 (0.0147)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:44:47]
  Epoch: [467][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0084)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 04:44:59]
  Epoch: [467][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0088)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:45:10]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.410 Prec@5 99.770 Error@1 4.590

==>>[2018-12-25 04:45:19] [Epoch=468/550] [Need: 00:43:51] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [468][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:45:19]
  Epoch: [468][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:45:31]
  Epoch: [468][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:45:42]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.360 Prec@5 99.810 Error@1 4.640

==>>[2018-12-25 04:45:51] [Epoch=469/550] [Need: 00:43:19] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [469][000/500]   Time 0.100 (0.100)   Data 0.066 (0.066)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:45:51]
  Epoch: [469][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0107 (0.0090)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:46:02]
  Epoch: [469][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0061 (0.0088)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:46:14]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.350 Prec@5 99.850 Error@1 4.650

==>>[2018-12-25 04:46:23] [Epoch=470/550] [Need: 00:42:47] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [470][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:46:23]
  Epoch: [470][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:46:34]
  Epoch: [470][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0091)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:46:46]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.420 Prec@5 99.820 Error@1 4.580

==>>[2018-12-25 04:46:55] [Epoch=471/550] [Need: 00:42:15] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [471][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:46:55]
  Epoch: [471][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0115 (0.0089)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:47:06]
  Epoch: [471][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0087)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 04:47:18]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.410 Prec@5 99.830 Error@1 4.590

==>>[2018-12-25 04:47:26] [Epoch=472/550] [Need: 00:41:43] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [472][000/500]   Time 0.103 (0.103)   Data 0.074 (0.074)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:47:27]
  Epoch: [472][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:47:38]
  Epoch: [472][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0097 (0.0088)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:47:50]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.400 Prec@5 99.800 Error@1 4.600

==>>[2018-12-25 04:47:58] [Epoch=473/550] [Need: 00:41:10] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [473][000/500]   Time 0.108 (0.108)   Data 0.079 (0.079)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:47:59]
  Epoch: [473][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0087)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:48:10]
  Epoch: [473][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0085)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-12-25 04:48:22]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.420 Prec@5 99.810 Error@1 4.580

==>>[2018-12-25 04:48:30] [Epoch=474/550] [Need: 00:40:38] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [474][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:48:31]
  Epoch: [474][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0087 (0.0090)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:48:42]
  Epoch: [474][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0087 (0.0089)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 04:48:54]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.340 Prec@5 99.850 Error@1 4.660

==>>[2018-12-25 04:49:02] [Epoch=475/550] [Need: 00:40:06] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [475][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:49:02]
  Epoch: [475][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0150 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:49:14]
  Epoch: [475][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0091)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:49:26]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.370 Prec@5 99.810 Error@1 4.630

==>>[2018-12-25 04:49:34] [Epoch=476/550] [Need: 00:39:34] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [476][000/500]   Time 0.106 (0.106)   Data 0.078 (0.078)   Loss 0.0163 (0.0163)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:49:34]
  Epoch: [476][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 04:49:46]
  Epoch: [476][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0148 (0.0090)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:49:58]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.340 Prec@5 99.810 Error@1 4.660

==>>[2018-12-25 04:50:06] [Epoch=477/550] [Need: 00:39:02] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [477][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:50:06]
  Epoch: [477][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0112 (0.0093)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:50:18]
  Epoch: [477][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0090)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:50:30]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.350 Prec@5 99.820 Error@1 4.650

==>>[2018-12-25 04:50:38] [Epoch=478/550] [Need: 00:38:30] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [478][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:50:38]
  Epoch: [478][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0088)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:50:50]
  Epoch: [478][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:51:02]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.450 Prec@5 99.820 Error@1 4.550

==>>[2018-12-25 04:51:10] [Epoch=479/550] [Need: 00:37:58] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [479][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:51:10]
  Epoch: [479][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0082)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:51:22]
  Epoch: [479][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0113 (0.0085)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 04:51:34]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.400 Prec@5 99.790 Error@1 4.600

==>>[2018-12-25 04:51:42] [Epoch=480/550] [Need: 00:37:26] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [480][000/500]   Time 0.100 (0.100)   Data 0.065 (0.065)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:51:42]
  Epoch: [480][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0091)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:51:54]
  Epoch: [480][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0283 (0.0092)   Prec@1 99.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 04:52:05]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.420 Prec@5 99.840 Error@1 4.580

==>>[2018-12-25 04:52:14] [Epoch=481/550] [Need: 00:36:54] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [481][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:52:14]
  Epoch: [481][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0091)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 04:52:26]
  Epoch: [481][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0457 (0.0090)   Prec@1 98.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:52:37]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.400 Prec@5 99.810 Error@1 4.600

==>>[2018-12-25 04:52:46] [Epoch=482/550] [Need: 00:36:21] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [482][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0133 (0.0133)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:52:46]
  Epoch: [482][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0081)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 04:52:58]
  Epoch: [482][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0085 (0.0083)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 04:53:09]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.370 Prec@5 99.790 Error@1 4.630

==>>[2018-12-25 04:53:18] [Epoch=483/550] [Need: 00:35:49] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [483][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:53:18]
  Epoch: [483][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0219 (0.0087)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:53:30]
  Epoch: [483][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0086)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:53:41]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.420 Prec@5 99.820 Error@1 4.580

==>>[2018-12-25 04:53:50] [Epoch=484/550] [Need: 00:35:17] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [484][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0095 (0.0095)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:53:50]
  Epoch: [484][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0089)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:54:02]
  Epoch: [484][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0405 (0.0088)   Prec@1 99.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 04:54:13]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.360 Prec@5 99.810 Error@1 4.640

==>>[2018-12-25 04:54:22] [Epoch=485/550] [Need: 00:34:45] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [485][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:54:22]
  Epoch: [485][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0083)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 04:54:33]
  Epoch: [485][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0079 (0.0087)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:54:45]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.320 Prec@5 99.760 Error@1 4.680

==>>[2018-12-25 04:54:54] [Epoch=486/550] [Need: 00:34:13] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [486][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:54:54]
  Epoch: [486][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:55:05]
  Epoch: [486][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0085)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-12-25 04:55:17]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.460 Prec@5 99.810 Error@1 4.540

==>>[2018-12-25 04:55:25] [Epoch=487/550] [Need: 00:33:41] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [487][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0095 (0.0095)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:55:26]
  Epoch: [487][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0079 (0.0086)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 04:55:37]
  Epoch: [487][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0087)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 04:55:49]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.370 Prec@5 99.820 Error@1 4.630

==>>[2018-12-25 04:55:57] [Epoch=488/550] [Need: 00:33:09] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [488][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:55:58]
  Epoch: [488][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0086)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:56:09]
  Epoch: [488][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0063 (0.0088)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:56:21]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.400 Prec@5 99.820 Error@1 4.600

==>>[2018-12-25 04:56:29] [Epoch=489/550] [Need: 00:32:37] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [489][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:56:30]
  Epoch: [489][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0086)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:56:41]
  Epoch: [489][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0197 (0.0090)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:56:53]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.420 Prec@5 99.860 Error@1 4.580

==>>[2018-12-25 04:57:01] [Epoch=490/550] [Need: 00:32:05] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [490][000/500]   Time 0.097 (0.097)   Data 0.070 (0.070)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:57:01]
  Epoch: [490][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0100 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 04:57:13]
  Epoch: [490][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0087)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 04:57:25]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.400 Prec@5 99.800 Error@1 4.600

==>>[2018-12-25 04:57:33] [Epoch=491/550] [Need: 00:31:32] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [491][000/500]   Time 0.100 (0.100)   Data 0.065 (0.065)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:57:33]
  Epoch: [491][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0088)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 04:57:45]
  Epoch: [491][400/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.0101 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 04:57:57]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.450 Prec@5 99.820 Error@1 4.550

==>>[2018-12-25 04:58:05] [Epoch=492/550] [Need: 00:31:00] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [492][000/500]   Time 0.090 (0.090)   Data 0.061 (0.061)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:58:05]
  Epoch: [492][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0133 (0.0090)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 04:58:17]
  Epoch: [492][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0091)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 04:58:29]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.340 Prec@5 99.820 Error@1 4.660

==>>[2018-12-25 04:58:37] [Epoch=493/550] [Need: 00:30:28] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [493][000/500]   Time 0.099 (0.099)   Data 0.064 (0.064)   Loss 0.0417 (0.0417)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:58:37]
  Epoch: [493][200/500]   Time 0.063 (0.059)   Data 0.000 (0.000)   Loss 0.0122 (0.0092)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 04:58:49]
  Epoch: [493][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0089)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 04:59:01]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.380 Prec@5 99.780 Error@1 4.620

==>>[2018-12-25 04:59:09] [Epoch=494/550] [Need: 00:29:56] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [494][000/500]   Time 0.099 (0.099)   Data 0.064 (0.064)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:59:09]
  Epoch: [494][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0118 (0.0093)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 04:59:21]
  Epoch: [494][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0091)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 04:59:33]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.310 Prec@5 99.860 Error@1 4.690

==>>[2018-12-25 04:59:41] [Epoch=495/550] [Need: 00:29:24] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [495][000/500]   Time 0.092 (0.092)   Data 0.062 (0.062)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 04:59:41]
  Epoch: [495][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0095)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 04:59:53]
  Epoch: [495][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0104 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 05:00:04]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.320 Prec@5 99.810 Error@1 4.680

==>>[2018-12-25 05:00:13] [Epoch=496/550] [Need: 00:28:52] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [496][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:00:13]
  Epoch: [496][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0077 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:00:25]
  Epoch: [496][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0175 (0.0092)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 05:00:36]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.400 Prec@5 99.830 Error@1 4.600

==>>[2018-12-25 05:00:45] [Epoch=497/550] [Need: 00:28:20] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [497][000/500]   Time 0.104 (0.104)   Data 0.075 (0.075)   Loss 0.0084 (0.0084)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:00:45]
  Epoch: [497][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0219 (0.0089)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 05:00:57]
  Epoch: [497][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:01:08]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.340 Prec@5 99.760 Error@1 4.660

==>>[2018-12-25 05:01:17] [Epoch=498/550] [Need: 00:27:48] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [498][000/500]   Time 0.096 (0.096)   Data 0.068 (0.068)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:01:17]
  Epoch: [498][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0089)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 05:01:29]
  Epoch: [498][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0087)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 05:01:40]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.430 Prec@5 99.820 Error@1 4.570

==>>[2018-12-25 05:01:49] [Epoch=499/550] [Need: 00:27:16] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [499][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:01:49]
  Epoch: [499][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0088)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 05:02:01]
  Epoch: [499][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0168 (0.0088)   Prec@1 99.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 05:02:12]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.390 Prec@5 99.790 Error@1 4.610

==>>[2018-12-25 05:02:21] [Epoch=500/550] [Need: 00:26:44] [learning_rate=0.000001] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [500][000/500]   Time 0.097 (0.097)   Data 0.066 (0.066)   Loss 0.0094 (0.0094)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:02:21]
  Epoch: [500][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0087)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:02:32]
  Epoch: [500][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0096 (0.0087)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:02:44]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.490 Prec@5 99.850 Error@1 4.510

==>>[2018-12-25 05:02:53] [Epoch=501/550] [Need: 00:26:11] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [501][000/500]   Time 0.097 (0.097)   Data 0.065 (0.065)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:02:53]
  Epoch: [501][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0088 (0.0087)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:03:04]
  Epoch: [501][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0086 (0.0086)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:03:16]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.290 Prec@5 99.820 Error@1 4.710

==>>[2018-12-25 05:03:25] [Epoch=502/550] [Need: 00:25:39] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [502][000/500]   Time 0.101 (0.101)   Data 0.067 (0.067)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:03:25]
  Epoch: [502][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0099 (0.0082)   Prec@1 100.000 (99.980)   Prec@5 100.000 (100.000)   [2018-12-25 05:03:36]
  Epoch: [502][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0086)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-12-25 05:03:48]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.360 Prec@5 99.840 Error@1 4.640

==>>[2018-12-25 05:03:57] [Epoch=503/550] [Need: 00:25:07] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [503][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0170 (0.0170)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:03:57]
  Epoch: [503][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0085)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 05:04:08]
  Epoch: [503][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0261 (0.0089)   Prec@1 99.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:04:20]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.380 Prec@5 99.820 Error@1 4.620

==>>[2018-12-25 05:04:28] [Epoch=504/550] [Need: 00:24:35] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [504][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:04:29]
  Epoch: [504][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0294 (0.0091)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:04:40]
  Epoch: [504][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:04:52]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.490 Prec@5 99.820 Error@1 4.510

==>>[2018-12-25 05:05:00] [Epoch=505/550] [Need: 00:24:03] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [505][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:05:00]
  Epoch: [505][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:05:12]
  Epoch: [505][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0056 (0.0088)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 05:05:24]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.450 Prec@5 99.820 Error@1 4.550

==>>[2018-12-25 05:05:32] [Epoch=506/550] [Need: 00:23:31] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [506][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:05:32]
  Epoch: [506][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0089)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:05:44]
  Epoch: [506][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 05:05:56]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.400 Prec@5 99.810 Error@1 4.600

==>>[2018-12-25 05:06:04] [Epoch=507/550] [Need: 00:22:59] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [507][000/500]   Time 0.097 (0.097)   Data 0.064 (0.064)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:06:04]
  Epoch: [507][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0087)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 05:06:16]
  Epoch: [507][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0085)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 05:06:28]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.430 Prec@5 99.830 Error@1 4.570

==>>[2018-12-25 05:06:36] [Epoch=508/550] [Need: 00:22:27] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [508][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:06:36]
  Epoch: [508][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0078 (0.0098)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 05:06:48]
  Epoch: [508][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0093)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 05:07:00]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.370 Prec@5 99.810 Error@1 4.630

==>>[2018-12-25 05:07:08] [Epoch=509/550] [Need: 00:21:55] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [509][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0131 (0.0131)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:07:08]
  Epoch: [509][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0093)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 05:07:20]
  Epoch: [509][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0090)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 05:07:32]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.450 Prec@5 99.760 Error@1 4.550

==>>[2018-12-25 05:07:40] [Epoch=510/550] [Need: 00:21:23] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [510][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:07:40]
  Epoch: [510][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0090)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:07:52]
  Epoch: [510][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:08:04]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.500 Prec@5 99.820 Error@1 4.500

==>>[2018-12-25 05:08:12] [Epoch=511/550] [Need: 00:20:51] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [511][000/500]   Time 0.093 (0.093)   Data 0.065 (0.065)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:08:12]
  Epoch: [511][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0085)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:08:24]
  Epoch: [511][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0087)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:08:36]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.380 Prec@5 99.840 Error@1 4.620

==>>[2018-12-25 05:08:44] [Epoch=512/550] [Need: 00:20:18] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [512][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0361 (0.0361)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:08:44]
  Epoch: [512][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0092)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 05:08:56]
  Epoch: [512][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-12-25 05:09:08]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.400 Prec@5 99.840 Error@1 4.600

==>>[2018-12-25 05:09:16] [Epoch=513/550] [Need: 00:19:46] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [513][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0351 (0.0351)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:09:16]
  Epoch: [513][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0096 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:09:28]
  Epoch: [513][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0085)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 05:09:40]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.440 Prec@5 99.780 Error@1 4.560

==>>[2018-12-25 05:09:48] [Epoch=514/550] [Need: 00:19:14] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [514][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0112 (0.0112)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:09:48]
  Epoch: [514][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0090)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:10:00]
  Epoch: [514][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0086 (0.0087)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 05:10:12]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.470 Prec@5 99.790 Error@1 4.530

==>>[2018-12-25 05:10:20] [Epoch=515/550] [Need: 00:18:42] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [515][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0383 (0.0383)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:10:20]
  Epoch: [515][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0089 (0.0090)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 05:10:32]
  Epoch: [515][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0087)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 05:10:43]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.380 Prec@5 99.740 Error@1 4.620

==>>[2018-12-25 05:10:52] [Epoch=516/550] [Need: 00:18:10] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [516][000/500]   Time 0.094 (0.094)   Data 0.066 (0.066)   Loss 0.0131 (0.0131)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:10:52]
  Epoch: [516][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0078 (0.0090)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:11:04]
  Epoch: [516][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0091)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 05:11:15]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.400 Prec@5 99.820 Error@1 4.600

==>>[2018-12-25 05:11:24] [Epoch=517/550] [Need: 00:17:38] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [517][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0230 (0.0230)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:11:24]
  Epoch: [517][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0085)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 05:11:36]
  Epoch: [517][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0086)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 05:11:47]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.380 Prec@5 99.800 Error@1 4.620

==>>[2018-12-25 05:11:56] [Epoch=518/550] [Need: 00:17:06] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [518][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:11:56]
  Epoch: [518][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0100 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:12:08]
  Epoch: [518][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0088)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:12:19]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.370 Prec@5 99.790 Error@1 4.630

==>>[2018-12-25 05:12:28] [Epoch=519/550] [Need: 00:16:34] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [519][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:12:28]
  Epoch: [519][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0075 (0.0091)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:12:40]
  Epoch: [519][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0080 (0.0094)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 05:12:51]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.370 Prec@5 99.840 Error@1 4.630

==>>[2018-12-25 05:13:00] [Epoch=520/550] [Need: 00:16:02] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [520][000/500]   Time 0.092 (0.092)   Data 0.063 (0.063)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:13:00]
  Epoch: [520][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0086)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 05:13:11]
  Epoch: [520][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0086)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 05:13:23]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.300 Prec@5 99.800 Error@1 4.700

==>>[2018-12-25 05:13:32] [Epoch=521/550] [Need: 00:15:30] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [521][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0158 (0.0158)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:13:32]
  Epoch: [521][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:13:43]
  Epoch: [521][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0088 (0.0086)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 05:13:55]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.360 Prec@5 99.860 Error@1 4.640

==>>[2018-12-25 05:14:04] [Epoch=522/550] [Need: 00:14:58] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [522][000/500]   Time 0.098 (0.098)   Data 0.064 (0.064)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:14:04]
  Epoch: [522][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0186 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 05:14:15]
  Epoch: [522][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0091 (0.0085)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-12-25 05:14:27]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.350 Prec@5 99.790 Error@1 4.650

==>>[2018-12-25 05:14:36] [Epoch=523/550] [Need: 00:14:26] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [523][000/500]   Time 0.096 (0.096)   Data 0.065 (0.065)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:14:36]
  Epoch: [523][200/500]   Time 0.056 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0088)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:14:47]
  Epoch: [523][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0098 (0.0088)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 05:14:59]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.440 Prec@5 99.820 Error@1 4.560

==>>[2018-12-25 05:15:08] [Epoch=524/550] [Need: 00:13:53] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [524][000/500]   Time 0.094 (0.094)   Data 0.065 (0.065)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:15:08]
  Epoch: [524][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0064 (0.0096)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 05:15:19]
  Epoch: [524][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0090)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 05:15:31]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.400 Prec@5 99.830 Error@1 4.600

==>>[2018-12-25 05:15:40] [Epoch=525/550] [Need: 00:13:21] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [525][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0094 (0.0094)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:15:40]
  Epoch: [525][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0134 (0.0095)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 05:15:51]
  Epoch: [525][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0073 (0.0094)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 05:16:03]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.340 Prec@5 99.820 Error@1 4.660

==>>[2018-12-25 05:16:11] [Epoch=526/550] [Need: 00:12:49] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [526][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:16:12]
  Epoch: [526][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0342 (0.0089)   Prec@1 98.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:16:23]
  Epoch: [526][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0066 (0.0088)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:16:35]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.450 Prec@5 99.780 Error@1 4.550

==>>[2018-12-25 05:16:43] [Epoch=527/550] [Need: 00:12:17] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [527][000/500]   Time 0.096 (0.096)   Data 0.066 (0.066)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:16:43]
  Epoch: [527][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0083)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 05:16:55]
  Epoch: [527][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0132 (0.0086)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-12-25 05:17:07]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.390 Prec@5 99.800 Error@1 4.610

==>>[2018-12-25 05:17:15] [Epoch=528/550] [Need: 00:11:45] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [528][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.0097 (0.0097)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:17:15]
  Epoch: [528][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0124 (0.0094)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 05:17:27]
  Epoch: [528][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0061 (0.0092)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 05:17:39]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.330 Prec@5 99.840 Error@1 4.670

==>>[2018-12-25 05:17:47] [Epoch=529/550] [Need: 00:11:13] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [529][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:17:47]
  Epoch: [529][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0068 (0.0087)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:17:59]
  Epoch: [529][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0067 (0.0087)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 05:18:11]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.380 Prec@5 99.830 Error@1 4.620

==>>[2018-12-25 05:18:19] [Epoch=530/550] [Need: 00:10:41] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [530][000/500]   Time 0.099 (0.099)   Data 0.065 (0.065)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:18:19]
  Epoch: [530][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0274 (0.0092)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:18:31]
  Epoch: [530][400/500]   Time 0.067 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0090)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 05:18:43]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.440 Prec@5 99.820 Error@1 4.560

==>>[2018-12-25 05:18:51] [Epoch=531/550] [Need: 00:10:09] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [531][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:18:51]
  Epoch: [531][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0059 (0.0088)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 05:19:03]
  Epoch: [531][400/500]   Time 0.053 (0.058)   Data 0.000 (0.000)   Loss 0.0127 (0.0093)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-12-25 05:19:15]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.400 Prec@5 99.840 Error@1 4.600

==>>[2018-12-25 05:19:23] [Epoch=532/550] [Need: 00:09:37] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [532][000/500]   Time 0.093 (0.093)   Data 0.062 (0.062)   Loss 0.0109 (0.0109)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:19:23]
  Epoch: [532][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0143 (0.0092)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:19:35]
  Epoch: [532][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:19:47]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.420 Prec@5 99.790 Error@1 4.580

==>>[2018-12-25 05:19:55] [Epoch=533/550] [Need: 00:09:05] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [533][000/500]   Time 0.099 (0.099)   Data 0.063 (0.063)   Loss 0.0094 (0.0094)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:19:55]
  Epoch: [533][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0215 (0.0085)   Prec@1 99.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 05:20:07]
  Epoch: [533][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0058 (0.0083)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2018-12-25 05:20:18]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.390 Prec@5 99.840 Error@1 4.610

==>>[2018-12-25 05:20:27] [Epoch=534/550] [Need: 00:08:33] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [534][000/500]   Time 0.097 (0.097)   Data 0.065 (0.065)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:20:27]
  Epoch: [534][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0085)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 05:20:39]
  Epoch: [534][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0089 (0.0087)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-12-25 05:20:50]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.410 Prec@5 99.830 Error@1 4.590

==>>[2018-12-25 05:20:59] [Epoch=535/550] [Need: 00:08:01] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [535][000/500]   Time 0.095 (0.095)   Data 0.067 (0.067)   Loss 0.0109 (0.0109)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:20:59]
  Epoch: [535][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0078 (0.0085)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:21:10]
  Epoch: [535][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0079 (0.0084)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-12-25 05:21:22]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.390 Prec@5 99.780 Error@1 4.610

==>>[2018-12-25 05:21:31] [Epoch=536/550] [Need: 00:07:29] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [536][000/500]   Time 0.098 (0.098)   Data 0.062 (0.062)   Loss 0.0092 (0.0092)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:21:31]
  Epoch: [536][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0086)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:21:42]
  Epoch: [536][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0078 (0.0088)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:21:54]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.390 Prec@5 99.820 Error@1 4.610

==>>[2018-12-25 05:22:02] [Epoch=537/550] [Need: 00:06:56] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [537][000/500]   Time 0.094 (0.094)   Data 0.066 (0.066)   Loss 0.0234 (0.0234)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:22:03]
  Epoch: [537][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0097)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-12-25 05:22:14]
  Epoch: [537][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0107 (0.0092)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-12-25 05:22:26]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.420 Prec@5 99.790 Error@1 4.580

==>>[2018-12-25 05:22:34] [Epoch=538/550] [Need: 00:06:24] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [538][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:22:34]
  Epoch: [538][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0117 (0.0088)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:22:46]
  Epoch: [538][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0084 (0.0090)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 05:22:58]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.400 Prec@5 99.800 Error@1 4.600

==>>[2018-12-25 05:23:06] [Epoch=539/550] [Need: 00:05:52] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [539][000/500]   Time 0.093 (0.093)   Data 0.063 (0.063)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:23:06]
  Epoch: [539][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0082 (0.0093)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 05:23:18]
  Epoch: [539][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0089)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-12-25 05:23:30]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.430 Prec@5 99.850 Error@1 4.570

==>>[2018-12-25 05:23:38] [Epoch=540/550] [Need: 00:05:20] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [540][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0581 (0.0581)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:23:38]
  Epoch: [540][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0065 (0.0087)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-12-25 05:23:50]
  Epoch: [540][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0070 (0.0086)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-12-25 05:24:02]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.410 Prec@5 99.780 Error@1 4.590

==>>[2018-12-25 05:24:10] [Epoch=541/550] [Need: 00:04:48] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [541][000/500]   Time 0.095 (0.095)   Data 0.065 (0.065)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:24:10]
  Epoch: [541][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0083 (0.0088)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-12-25 05:24:22]
  Epoch: [541][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0060 (0.0089)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 05:24:33]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.380 Prec@5 99.840 Error@1 4.620

==>>[2018-12-25 05:24:42] [Epoch=542/550] [Need: 00:04:16] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [542][000/500]   Time 0.095 (0.095)   Data 0.066 (0.066)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:24:42]
  Epoch: [542][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0076 (0.0090)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-12-25 05:24:54]
  Epoch: [542][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0100 (0.0093)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-12-25 05:25:05]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.410 Prec@5 99.860 Error@1 4.590

==>>[2018-12-25 05:25:14] [Epoch=543/550] [Need: 00:03:44] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [543][000/500]   Time 0.094 (0.094)   Data 0.063 (0.063)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:25:14]
  Epoch: [543][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0089 (0.0087)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:25:26]
  Epoch: [543][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-12-25 05:25:37]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.360 Prec@5 99.820 Error@1 4.640

==>>[2018-12-25 05:25:46] [Epoch=544/550] [Need: 00:03:12] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [544][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:25:46]
  Epoch: [544][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0084 (0.0090)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-12-25 05:25:58]
  Epoch: [544][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0060 (0.0092)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-12-25 05:26:09]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.380 Prec@5 99.820 Error@1 4.620

==>>[2018-12-25 05:26:18] [Epoch=545/550] [Need: 00:02:40] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [545][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:26:18]
  Epoch: [545][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0125 (0.0084)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-12-25 05:26:29]
  Epoch: [545][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0071 (0.0085)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 05:26:41]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.330 Prec@5 99.840 Error@1 4.670

==>>[2018-12-25 05:26:50] [Epoch=546/550] [Need: 00:02:08] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [546][000/500]   Time 0.092 (0.092)   Data 0.064 (0.064)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:26:50]
  Epoch: [546][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0075 (0.0083)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-12-25 05:27:01]
  Epoch: [546][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0078 (0.0088)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-12-25 05:27:13]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.380 Prec@5 99.800 Error@1 4.620

==>>[2018-12-25 05:27:21] [Epoch=547/550] [Need: 00:01:36] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [547][000/500]   Time 0.094 (0.094)   Data 0.064 (0.064)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:27:22]
  Epoch: [547][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0069 (0.0089)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-12-25 05:27:33]
  Epoch: [547][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0089)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:27:45]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.490 Prec@5 99.830 Error@1 4.510

==>>[2018-12-25 05:27:53] [Epoch=548/550] [Need: 00:01:04] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [548][000/500]   Time 0.097 (0.097)   Data 0.063 (0.063)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:27:53]
  Epoch: [548][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0074 (0.0086)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-12-25 05:28:05]
  Epoch: [548][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0064 (0.0086)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-12-25 05:28:17]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.380 Prec@5 99.820 Error@1 4.620

==>>[2018-12-25 05:28:25] [Epoch=549/550] [Need: 00:00:32] [learning_rate=0.000000] [Best : Accuracy=95.51, Error=4.49]
  Epoch: [549][000/500]   Time 0.101 (0.101)   Data 0.065 (0.065)   Loss 0.0240 (0.0240)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-12-25 05:28:25]
  Epoch: [549][200/500]   Time 0.063 (0.059)   Data 0.000 (0.000)   Loss 0.0070 (0.0093)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-12-25 05:28:37]
  Epoch: [549][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0079 (0.0092)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-12-25 05:28:49]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.430 Prec@5 99.830 Error@1 4.570
