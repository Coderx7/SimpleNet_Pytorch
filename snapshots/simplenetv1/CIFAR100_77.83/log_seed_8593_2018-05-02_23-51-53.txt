save path : ./snapshots/simpnet
{'arch': 'simplenet', 'batch_size': 100, 'data_path': './data/cifar.python', 'dataset': 'cifar100', 'decay': 0.002, 'epochs': 540, 'evaluate': False, 'gammas': [0.1, 0.1, 0.1, 0.1, 0.1], 'learning_rate': 0.1, 'manualSeed': 8593, 'momentum': 0.9, 'ngpu': 1, 'print_freq': 200, 'resume': '', 'save_path': './snapshots/simpnet', 'schedule': [100, 190, 306, 390, 440, 540], 'start_epoch': 0, 'use_cuda': True, 'workers': 2}
Random Seed: 8593
python version : 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)  [GCC 7.2.0]
torch  version : 0.3.1
cudnn  version : 7005
=> creating model 'simplenet'
=> network :
 simplenet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (5): ReLU(inplace)
    (6): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (8): ReLU(inplace)
    (9): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (13): Dropout2d(p=0.1)
    (14): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (16): ReLU(inplace)
    (17): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (19): ReLU(inplace)
    (20): Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (22): ReLU(inplace)
    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (24): Dropout2d(p=0.1)
    (25): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (26): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (27): ReLU(inplace)
    (28): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (29): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (30): ReLU(inplace)
    (31): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (32): Dropout2d(p=0.1)
    (33): Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.05, affine=True)
    (35): ReLU(inplace)
    (36): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (37): Dropout2d(p=0.1)
    (38): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1))
    (39): BatchNorm2d(2048, eps=1e-05, momentum=0.05, affine=True)
    (40): ReLU(inplace)
    (41): Conv2d(2048, 256, kernel_size=[1, 1], stride=(1, 1))
    (42): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (43): ReLU(inplace)
    (44): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (45): Dropout2d(p=0.1)
    (46): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (47): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (48): ReLU(inplace)
  )
  (classifier): Linear(in_features=256, out_features=100, bias=True)
)
=> Seed '8593'
=> dataset mean and std '[0.5070588235294118, 0.48666666666666664, 0.4407843137254902] - [0.26745098039215687, 0.2564705882352941, 0.27607843137254906]'
=> optimizer '{'optimizer': {'state': {}, 'param_groups': [{'lr': 0.1, 'rho': 0.9, 'eps': 0.001, 'weight_decay': 0.001, 'params': [140662585754552, 140662585754712, 140662433948520, 140662433948600, 140662433948680, 140662433948760, 140662433948840, 140662433948920, 140662433949000, 140662433949080, 140662433949160, 140662433949240, 140662433949320, 140662433949400, 140662433949480, 140662433949560, 140662433949720, 140662433949800, 140662433949880, 140662433949960, 140662433950040, 140662433950120, 140662433950200, 140662433950280, 140662433950360, 140662433950440, 140662433950520, 140662433950600, 140662433950760, 140662433950840, 140662433950920, 140662433951000, 140662433951080, 140662433951160, 140662433951240, 140662433951480, 140662538073416, 140662538073496, 140662538073576, 140662538073656, 140662538073816, 140662538073896, 140662538073976, 140662538074056, 140662538074136, 140662538074216, 140662538074296, 140662538074376, 140662538074536, 140662538074616, 140662538074696, 140662538074776, 140662538075016, 140662538075096]}]}}'
=> did not use any checkpoint for simplenet model

==>>[2018-05-02 19:21:56] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.100000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 1.638 (1.638)   Data 0.052 (0.052)   Loss 4.6111 (4.6111)   Prec@1 0.000 (0.000)   Prec@5 8.000 (8.000)   [2018-05-02 19:21:57]
  Epoch: [000][200/500]   Time 0.059 (0.066)   Data 0.000 (0.000)   Loss 4.0811 (4.3017)   Prec@1 12.000 (4.851)   Prec@5 28.000 (18.114)   [2018-05-02 19:22:09]
  Epoch: [000][400/500]   Time 0.057 (0.062)   Data 0.000 (0.000)   Loss 3.7306 (4.1249)   Prec@1 14.000 (6.963)   Prec@5 36.000 (23.818)   [2018-05-02 19:22:20]
  **Train** Prec@1 7.884 Prec@5 25.834 Error@1 92.116
  **Test** Prec@1 13.820 Prec@5 38.430 Error@1 86.180

==>>[2018-05-02 19:22:29] [Epoch=001/540] [Need: 04:53:32] [learning_rate=0.100000] [Best : Accuracy=13.82, Error=86.18]
  Epoch: [001][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 3.8518 (3.8518)   Prec@1 6.000 (6.000)   Prec@5 27.000 (27.000)   [2018-05-02 19:22:29]
  Epoch: [001][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 3.6028 (3.6606)   Prec@1 17.000 (13.264)   Prec@5 35.000 (37.552)   [2018-05-02 19:22:40]
  Epoch: [001][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 3.1742 (3.5776)   Prec@1 25.000 (14.668)   Prec@5 52.000 (39.958)   [2018-05-02 19:22:52]
  **Train** Prec@1 15.302 Prec@5 41.188 Error@1 84.698
  **Test** Prec@1 20.530 Prec@5 49.760 Error@1 79.470

==>>[2018-05-02 19:23:00] [Epoch=002/540] [Need: 04:48:03] [learning_rate=0.100000] [Best : Accuracy=20.53, Error=79.47]
  Epoch: [002][000/500]   Time 0.087 (0.087)   Data 0.057 (0.057)   Loss 3.4833 (3.4833)   Prec@1 13.000 (13.000)   Prec@5 39.000 (39.000)   [2018-05-02 19:23:01]
  Epoch: [002][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 2.9814 (3.2608)   Prec@1 29.000 (19.667)   Prec@5 58.000 (48.791)   [2018-05-02 19:23:12]
  Epoch: [002][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 3.2575 (3.1890)   Prec@1 23.000 (21.105)   Prec@5 52.000 (50.733)   [2018-05-02 19:23:23]
  **Train** Prec@1 21.696 Prec@5 51.632 Error@1 78.304
  **Test** Prec@1 27.240 Prec@5 59.100 Error@1 72.760

==>>[2018-05-02 19:23:32] [Epoch=003/540] [Need: 04:45:12] [learning_rate=0.100000] [Best : Accuracy=27.24, Error=72.76]
  Epoch: [003][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 3.0575 (3.0575)   Prec@1 17.000 (17.000)   Prec@5 49.000 (49.000)   [2018-05-02 19:23:32]
  Epoch: [003][200/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 2.7942 (2.8912)   Prec@1 23.000 (25.955)   Prec@5 58.000 (58.403)   [2018-05-02 19:23:43]
  Epoch: [003][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 2.7182 (2.8396)   Prec@1 29.000 (27.150)   Prec@5 55.000 (59.623)   [2018-05-02 19:23:55]
  **Train** Prec@1 27.608 Prec@5 60.334 Error@1 72.392
  **Test** Prec@1 33.420 Prec@5 67.520 Error@1 66.580

==>>[2018-05-02 19:24:03] [Epoch=004/540] [Need: 04:43:23] [learning_rate=0.100000] [Best : Accuracy=33.42, Error=66.58]
  Epoch: [004][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 2.6966 (2.6966)   Prec@1 30.000 (30.000)   Prec@5 66.000 (66.000)   [2018-05-02 19:24:03]
  Epoch: [004][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 2.5204 (2.6053)   Prec@1 34.000 (31.896)   Prec@5 64.000 (65.493)   [2018-05-02 19:24:15]
  Epoch: [004][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 2.5861 (2.5678)   Prec@1 33.000 (32.434)   Prec@5 63.000 (66.267)   [2018-05-02 19:24:26]
  **Train** Prec@1 32.762 Prec@5 66.706 Error@1 67.238
  **Test** Prec@1 32.160 Prec@5 64.660 Error@1 67.840

==>>[2018-05-02 19:24:35] [Epoch=005/540] [Need: 04:43:08] [learning_rate=0.100000] [Best : Accuracy=33.42, Error=66.58]
  Epoch: [005][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 2.5379 (2.5379)   Prec@1 33.000 (33.000)   Prec@5 67.000 (67.000)   [2018-05-02 19:24:35]
  Epoch: [005][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 2.7243 (2.3772)   Prec@1 26.000 (37.065)   Prec@5 64.000 (70.343)   [2018-05-02 19:24:47]
  Epoch: [005][400/500]   Time 0.062 (0.058)   Data 0.000 (0.000)   Loss 2.2464 (2.3583)   Prec@1 41.000 (37.289)   Prec@5 71.000 (70.803)   [2018-05-02 19:24:58]
  **Train** Prec@1 37.478 Prec@5 70.962 Error@1 62.522
  **Test** Prec@1 40.330 Prec@5 74.220 Error@1 59.670

==>>[2018-05-02 19:25:07] [Epoch=006/540] [Need: 04:43:05] [learning_rate=0.100000] [Best : Accuracy=40.33, Error=59.67]
  Epoch: [006][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 2.1057 (2.1057)   Prec@1 37.000 (37.000)   Prec@5 74.000 (74.000)   [2018-05-02 19:25:07]
  Epoch: [006][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 2.6906 (2.2235)   Prec@1 30.000 (40.129)   Prec@5 67.000 (73.567)   [2018-05-02 19:25:19]
  Epoch: [006][400/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 2.0601 (2.2065)   Prec@1 45.000 (40.469)   Prec@5 77.000 (73.868)   [2018-05-02 19:25:31]
  **Train** Prec@1 40.536 Prec@5 74.150 Error@1 59.464
  **Test** Prec@1 44.300 Prec@5 77.240 Error@1 55.700

==>>[2018-05-02 19:25:39] [Epoch=007/540] [Need: 04:42:53] [learning_rate=0.100000] [Best : Accuracy=44.30, Error=55.70]
  Epoch: [007][000/500]   Time 0.107 (0.107)   Data 0.079 (0.079)   Loss 2.1816 (2.1816)   Prec@1 47.000 (47.000)   Prec@5 77.000 (77.000)   [2018-05-02 19:25:39]
  Epoch: [007][200/500]   Time 0.057 (0.059)   Data 0.000 (0.001)   Loss 1.8751 (2.0917)   Prec@1 48.000 (43.254)   Prec@5 80.000 (76.224)   [2018-05-02 19:25:51]
  Epoch: [007][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 2.0227 (2.0765)   Prec@1 42.000 (43.369)   Prec@5 74.000 (76.561)   [2018-05-02 19:26:03]
  **Train** Prec@1 43.618 Prec@5 76.858 Error@1 56.382
  **Test** Prec@1 47.280 Prec@5 78.670 Error@1 52.720

==>>[2018-05-02 19:26:11] [Epoch=008/540] [Need: 04:42:35] [learning_rate=0.100000] [Best : Accuracy=47.28, Error=52.72]
  Epoch: [008][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 2.0369 (2.0369)   Prec@1 44.000 (44.000)   Prec@5 78.000 (78.000)   [2018-05-02 19:26:11]
  Epoch: [008][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 2.1989 (1.9778)   Prec@1 37.000 (45.811)   Prec@5 74.000 (78.338)   [2018-05-02 19:26:23]
  Epoch: [008][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 1.7757 (1.9674)   Prec@1 52.000 (46.127)   Prec@5 82.000 (78.556)   [2018-05-02 19:26:34]
  **Train** Prec@1 46.354 Prec@5 78.706 Error@1 53.646
  **Test** Prec@1 48.440 Prec@5 79.920 Error@1 51.560

==>>[2018-05-02 19:26:43] [Epoch=009/540] [Need: 04:41:37] [learning_rate=0.100000] [Best : Accuracy=48.44, Error=51.56]
  Epoch: [009][000/500]   Time 0.080 (0.080)   Data 0.055 (0.055)   Loss 1.7752 (1.7752)   Prec@1 46.000 (46.000)   Prec@5 85.000 (85.000)   [2018-05-02 19:26:43]
  Epoch: [009][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.8721 (1.8829)   Prec@1 48.000 (47.881)   Prec@5 76.000 (80.368)   [2018-05-02 19:26:54]
  Epoch: [009][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 1.8427 (1.8704)   Prec@1 45.000 (48.379)   Prec@5 82.000 (80.446)   [2018-05-02 19:27:05]
  **Train** Prec@1 48.500 Prec@5 80.504 Error@1 51.500
  **Test** Prec@1 49.660 Prec@5 80.560 Error@1 50.340

==>>[2018-05-02 19:27:13] [Epoch=010/540] [Need: 04:39:35] [learning_rate=0.100000] [Best : Accuracy=49.66, Error=50.34]
  Epoch: [010][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 1.8601 (1.8601)   Prec@1 43.000 (43.000)   Prec@5 84.000 (84.000)   [2018-05-02 19:27:13]
  Epoch: [010][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 2.0474 (1.7866)   Prec@1 48.000 (50.557)   Prec@5 73.000 (81.741)   [2018-05-02 19:27:24]
  Epoch: [010][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 2.1041 (1.7877)   Prec@1 37.000 (50.514)   Prec@5 77.000 (81.800)   [2018-05-02 19:27:35]
  **Train** Prec@1 50.488 Prec@5 81.858 Error@1 49.512
  **Test** Prec@1 52.810 Prec@5 82.580 Error@1 47.190

==>>[2018-05-02 19:27:43] [Epoch=011/540] [Need: 04:37:48] [learning_rate=0.100000] [Best : Accuracy=52.81, Error=47.19]
  Epoch: [011][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 1.7966 (1.7966)   Prec@1 48.000 (48.000)   Prec@5 82.000 (82.000)   [2018-05-02 19:27:43]
  Epoch: [011][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.7177 (1.7124)   Prec@1 54.000 (52.259)   Prec@5 82.000 (83.010)   [2018-05-02 19:27:54]
  Epoch: [011][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.9101 (1.7190)   Prec@1 50.000 (52.020)   Prec@5 81.000 (83.015)   [2018-05-02 19:28:05]
  **Train** Prec@1 52.038 Prec@5 82.984 Error@1 47.962
  **Test** Prec@1 52.630 Prec@5 83.430 Error@1 47.370

==>>[2018-05-02 19:28:13] [Epoch=012/540] [Need: 04:36:14] [learning_rate=0.100000] [Best : Accuracy=52.81, Error=47.19]
  Epoch: [012][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 1.6459 (1.6459)   Prec@1 56.000 (56.000)   Prec@5 85.000 (85.000)   [2018-05-02 19:28:13]
  Epoch: [012][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.9542 (1.6460)   Prec@1 45.000 (54.055)   Prec@5 81.000 (84.323)   [2018-05-02 19:28:24]
  Epoch: [012][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.7988 (1.6543)   Prec@1 49.000 (53.875)   Prec@5 83.000 (84.117)   [2018-05-02 19:28:35]
  **Train** Prec@1 53.928 Prec@5 84.150 Error@1 46.072
  **Test** Prec@1 52.900 Prec@5 82.080 Error@1 47.100

==>>[2018-05-02 19:28:43] [Epoch=013/540] [Need: 04:34:53] [learning_rate=0.100000] [Best : Accuracy=52.90, Error=47.10]
  Epoch: [013][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 1.4440 (1.4440)   Prec@1 58.000 (58.000)   Prec@5 86.000 (86.000)   [2018-05-02 19:28:43]
  Epoch: [013][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.4403 (1.5726)   Prec@1 55.000 (55.960)   Prec@5 86.000 (85.219)   [2018-05-02 19:28:54]
  Epoch: [013][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.3575 (1.5869)   Prec@1 61.000 (55.377)   Prec@5 90.000 (85.239)   [2018-05-02 19:29:05]
  **Train** Prec@1 55.352 Prec@5 85.122 Error@1 44.648
  **Test** Prec@1 53.820 Prec@5 83.570 Error@1 46.180

==>>[2018-05-02 19:29:13] [Epoch=014/540] [Need: 04:33:37] [learning_rate=0.100000] [Best : Accuracy=53.82, Error=46.18]
  Epoch: [014][000/500]   Time 0.093 (0.093)   Data 0.067 (0.067)   Loss 1.6112 (1.6112)   Prec@1 58.000 (58.000)   Prec@5 88.000 (88.000)   [2018-05-02 19:29:13]
  Epoch: [014][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.6138 (1.5182)   Prec@1 54.000 (57.219)   Prec@5 88.000 (86.224)   [2018-05-02 19:29:24]
  Epoch: [014][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.4700 (1.5367)   Prec@1 54.000 (56.653)   Prec@5 88.000 (85.918)   [2018-05-02 19:29:35]
  **Train** Prec@1 56.658 Prec@5 85.758 Error@1 43.342
  **Test** Prec@1 55.930 Prec@5 84.980 Error@1 44.070

==>>[2018-05-02 19:29:43] [Epoch=015/540] [Need: 04:32:25] [learning_rate=0.100000] [Best : Accuracy=55.93, Error=44.07]
  Epoch: [015][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 1.5252 (1.5252)   Prec@1 57.000 (57.000)   Prec@5 89.000 (89.000)   [2018-05-02 19:29:43]
  Epoch: [015][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.5786 (1.4884)   Prec@1 51.000 (58.045)   Prec@5 86.000 (86.726)   [2018-05-02 19:29:54]
  Epoch: [015][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.4237 (1.5007)   Prec@1 60.000 (57.768)   Prec@5 88.000 (86.469)   [2018-05-02 19:30:05]
  **Train** Prec@1 57.600 Prec@5 86.500 Error@1 42.400
  **Test** Prec@1 57.490 Prec@5 86.240 Error@1 42.510

==>>[2018-05-02 19:30:13] [Epoch=016/540] [Need: 04:31:19] [learning_rate=0.100000] [Best : Accuracy=57.49, Error=42.51]
  Epoch: [016][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 1.2271 (1.2271)   Prec@1 66.000 (66.000)   Prec@5 93.000 (93.000)   [2018-05-02 19:30:13]
  Epoch: [016][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 1.4519 (1.4320)   Prec@1 58.000 (59.791)   Prec@5 85.000 (87.701)   [2018-05-02 19:30:24]
  Epoch: [016][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.6193 (1.4493)   Prec@1 56.000 (59.247)   Prec@5 82.000 (87.342)   [2018-05-02 19:30:35]
  **Train** Prec@1 59.126 Prec@5 87.164 Error@1 40.874
  **Test** Prec@1 56.760 Prec@5 85.240 Error@1 43.240

==>>[2018-05-02 19:30:43] [Epoch=017/540] [Need: 04:30:18] [learning_rate=0.100000] [Best : Accuracy=57.49, Error=42.51]
  Epoch: [017][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 1.5177 (1.5177)   Prec@1 51.000 (51.000)   Prec@5 88.000 (88.000)   [2018-05-02 19:30:43]
  Epoch: [017][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.4059 (1.3945)   Prec@1 61.000 (60.831)   Prec@5 91.000 (88.020)   [2018-05-02 19:30:54]
  Epoch: [017][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.2739 (1.4059)   Prec@1 57.000 (60.272)   Prec@5 94.000 (87.810)   [2018-05-02 19:31:05]
  **Train** Prec@1 60.076 Prec@5 87.732 Error@1 39.924
  **Test** Prec@1 56.960 Prec@5 85.430 Error@1 43.040

==>>[2018-05-02 19:31:13] [Epoch=018/540] [Need: 04:29:20] [learning_rate=0.100000] [Best : Accuracy=57.49, Error=42.51]
  Epoch: [018][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 1.2728 (1.2728)   Prec@1 60.000 (60.000)   Prec@5 91.000 (91.000)   [2018-05-02 19:31:13]
  Epoch: [018][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 1.2808 (1.3532)   Prec@1 61.000 (61.169)   Prec@5 89.000 (88.587)   [2018-05-02 19:31:24]
  Epoch: [018][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 1.7370 (1.3841)   Prec@1 55.000 (60.454)   Prec@5 83.000 (88.197)   [2018-05-02 19:31:36]
  **Train** Prec@1 60.420 Prec@5 88.052 Error@1 39.580
  **Test** Prec@1 57.960 Prec@5 86.100 Error@1 42.040

==>>[2018-05-02 19:31:44] [Epoch=019/540] [Need: 04:28:50] [learning_rate=0.100000] [Best : Accuracy=57.96, Error=42.04]
  Epoch: [019][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 1.4700 (1.4700)   Prec@1 61.000 (61.000)   Prec@5 85.000 (85.000)   [2018-05-02 19:31:45]
  Epoch: [019][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.3312 (1.3403)   Prec@1 63.000 (61.900)   Prec@5 88.000 (88.871)   [2018-05-02 19:31:56]
  Epoch: [019][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.3116 (1.3504)   Prec@1 65.000 (61.576)   Prec@5 88.000 (88.771)   [2018-05-02 19:32:08]
  **Train** Prec@1 61.592 Prec@5 88.710 Error@1 38.408
  **Test** Prec@1 56.960 Prec@5 85.190 Error@1 43.040

==>>[2018-05-02 19:32:16] [Epoch=020/540] [Need: 04:28:47] [learning_rate=0.100000] [Best : Accuracy=57.96, Error=42.04]
  Epoch: [020][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 1.3403 (1.3403)   Prec@1 59.000 (59.000)   Prec@5 89.000 (89.000)   [2018-05-02 19:32:17]
  Epoch: [020][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 1.5169 (1.3016)   Prec@1 55.000 (62.861)   Prec@5 88.000 (89.398)   [2018-05-02 19:32:28]
  Epoch: [020][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 1.3140 (1.3132)   Prec@1 62.000 (62.494)   Prec@5 89.000 (89.392)   [2018-05-02 19:32:40]
  **Train** Prec@1 62.296 Prec@5 89.262 Error@1 37.704
  **Test** Prec@1 60.460 Prec@5 86.980 Error@1 39.540

==>>[2018-05-02 19:32:49] [Epoch=021/540] [Need: 04:28:42] [learning_rate=0.100000] [Best : Accuracy=60.46, Error=39.54]
  Epoch: [021][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 1.2015 (1.2015)   Prec@1 66.000 (66.000)   Prec@5 94.000 (94.000)   [2018-05-02 19:32:49]
  Epoch: [021][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 1.1730 (1.2718)   Prec@1 64.000 (63.866)   Prec@5 94.000 (89.945)   [2018-05-02 19:33:00]
  Epoch: [021][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.4992 (1.2946)   Prec@1 62.000 (63.249)   Prec@5 86.000 (89.471)   [2018-05-02 19:33:12]
  **Train** Prec@1 63.204 Prec@5 89.476 Error@1 36.796
  **Test** Prec@1 58.220 Prec@5 85.230 Error@1 41.780

==>>[2018-05-02 19:33:21] [Epoch=022/540] [Need: 04:28:34] [learning_rate=0.100000] [Best : Accuracy=60.46, Error=39.54]
  Epoch: [022][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 1.4945 (1.4945)   Prec@1 51.000 (51.000)   Prec@5 85.000 (85.000)   [2018-05-02 19:33:21]
  Epoch: [022][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.1850 (1.2397)   Prec@1 68.000 (64.682)   Prec@5 89.000 (89.950)   [2018-05-02 19:33:32]
  Epoch: [022][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 1.0992 (1.2569)   Prec@1 63.000 (64.157)   Prec@5 94.000 (89.706)   [2018-05-02 19:33:44]
  **Train** Prec@1 63.884 Prec@5 89.620 Error@1 36.116
  **Test** Prec@1 59.900 Prec@5 87.080 Error@1 40.100

==>>[2018-05-02 19:33:53] [Epoch=023/540] [Need: 04:28:22] [learning_rate=0.100000] [Best : Accuracy=60.46, Error=39.54]
  Epoch: [023][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 1.2387 (1.2387)   Prec@1 63.000 (63.000)   Prec@5 90.000 (90.000)   [2018-05-02 19:33:53]
  Epoch: [023][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.4303 (1.2291)   Prec@1 58.000 (64.682)   Prec@5 87.000 (90.542)   [2018-05-02 19:34:04]
  Epoch: [023][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 1.5079 (1.2403)   Prec@1 55.000 (64.416)   Prec@5 87.000 (90.279)   [2018-05-02 19:34:16]
  **Train** Prec@1 64.274 Prec@5 90.096 Error@1 35.726
  **Test** Prec@1 59.340 Prec@5 86.170 Error@1 40.660

==>>[2018-05-02 19:34:25] [Epoch=024/540] [Need: 04:28:09] [learning_rate=0.100000] [Best : Accuracy=60.46, Error=39.54]
  Epoch: [024][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 1.0559 (1.0559)   Prec@1 71.000 (71.000)   Prec@5 94.000 (94.000)   [2018-05-02 19:34:25]
  Epoch: [024][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.0814 (1.1889)   Prec@1 69.000 (66.010)   Prec@5 93.000 (90.741)   [2018-05-02 19:34:36]
  Epoch: [024][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.0702 (1.2133)   Prec@1 70.000 (65.234)   Prec@5 91.000 (90.551)   [2018-05-02 19:34:48]
  **Train** Prec@1 65.084 Prec@5 90.508 Error@1 34.916
  **Test** Prec@1 58.320 Prec@5 86.230 Error@1 41.680

==>>[2018-05-02 19:34:57] [Epoch=025/540] [Need: 04:27:58] [learning_rate=0.100000] [Best : Accuracy=60.46, Error=39.54]
  Epoch: [025][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 1.2245 (1.2245)   Prec@1 66.000 (66.000)   Prec@5 91.000 (91.000)   [2018-05-02 19:34:57]
  Epoch: [025][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.0650 (1.1685)   Prec@1 68.000 (66.179)   Prec@5 93.000 (91.184)   [2018-05-02 19:35:08]
  Epoch: [025][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 1.3624 (1.1936)   Prec@1 61.000 (65.758)   Prec@5 92.000 (90.810)   [2018-05-02 19:35:20]
  **Train** Prec@1 65.634 Prec@5 90.680 Error@1 34.366
  **Test** Prec@1 62.570 Prec@5 88.390 Error@1 37.430

==>>[2018-05-02 19:35:29] [Epoch=026/540] [Need: 04:27:43] [learning_rate=0.100000] [Best : Accuracy=62.57, Error=37.43]
  Epoch: [026][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 1.1164 (1.1164)   Prec@1 68.000 (68.000)   Prec@5 91.000 (91.000)   [2018-05-02 19:35:29]
  Epoch: [026][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.2027 (1.1612)   Prec@1 65.000 (66.806)   Prec@5 92.000 (91.264)   [2018-05-02 19:35:40]
  Epoch: [026][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.0865 (1.1840)   Prec@1 66.000 (65.998)   Prec@5 90.000 (91.077)   [2018-05-02 19:35:52]
  **Train** Prec@1 65.866 Prec@5 91.016 Error@1 34.134
  **Test** Prec@1 62.290 Prec@5 88.690 Error@1 37.710

==>>[2018-05-02 19:36:01] [Epoch=027/540] [Need: 04:27:27] [learning_rate=0.100000] [Best : Accuracy=62.57, Error=37.43]
  Epoch: [027][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 0.9986 (0.9986)   Prec@1 71.000 (71.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:36:01]
  Epoch: [027][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.0123 (1.1316)   Prec@1 68.000 (67.522)   Prec@5 93.000 (91.721)   [2018-05-02 19:36:13]
  Epoch: [027][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.2523 (1.1642)   Prec@1 66.000 (66.741)   Prec@5 89.000 (91.242)   [2018-05-02 19:36:24]
  **Train** Prec@1 66.744 Prec@5 91.174 Error@1 33.256
  **Test** Prec@1 58.360 Prec@5 86.510 Error@1 41.640

==>>[2018-05-02 19:36:33] [Epoch=028/540] [Need: 04:27:09] [learning_rate=0.100000] [Best : Accuracy=62.57, Error=37.43]
  Epoch: [028][000/500]   Time 0.089 (0.089)   Data 0.060 (0.060)   Loss 1.2295 (1.2295)   Prec@1 64.000 (64.000)   Prec@5 87.000 (87.000)   [2018-05-02 19:36:33]
  Epoch: [028][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.2309 (1.1180)   Prec@1 63.000 (67.711)   Prec@5 92.000 (91.871)   [2018-05-02 19:36:45]
  Epoch: [028][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.3331 (1.1357)   Prec@1 63.000 (67.232)   Prec@5 92.000 (91.566)   [2018-05-02 19:36:56]
  **Train** Prec@1 67.164 Prec@5 91.596 Error@1 32.836
  **Test** Prec@1 62.270 Prec@5 88.470 Error@1 37.730

==>>[2018-05-02 19:37:05] [Epoch=029/540] [Need: 04:26:52] [learning_rate=0.100000] [Best : Accuracy=62.57, Error=37.43]
  Epoch: [029][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 1.2331 (1.2331)   Prec@1 66.000 (66.000)   Prec@5 88.000 (88.000)   [2018-05-02 19:37:05]
  Epoch: [029][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 1.0214 (1.1057)   Prec@1 70.000 (68.164)   Prec@5 93.000 (91.955)   [2018-05-02 19:37:17]
  Epoch: [029][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.2026 (1.1325)   Prec@1 63.000 (67.374)   Prec@5 93.000 (91.651)   [2018-05-02 19:37:28]
  **Train** Prec@1 67.170 Prec@5 91.586 Error@1 32.830
  **Test** Prec@1 61.410 Prec@5 87.210 Error@1 38.590

==>>[2018-05-02 19:37:37] [Epoch=030/540] [Need: 04:26:32] [learning_rate=0.100000] [Best : Accuracy=62.57, Error=37.43]
  Epoch: [030][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 1.0155 (1.0155)   Prec@1 71.000 (71.000)   Prec@5 94.000 (94.000)   [2018-05-02 19:37:37]
  Epoch: [030][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.2695 (1.0986)   Prec@1 65.000 (68.209)   Prec@5 89.000 (92.065)   [2018-05-02 19:37:49]
  Epoch: [030][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.8960 (1.1136)   Prec@1 72.000 (67.860)   Prec@5 96.000 (91.883)   [2018-05-02 19:38:00]
  **Train** Prec@1 67.718 Prec@5 91.778 Error@1 32.282
  **Test** Prec@1 60.650 Prec@5 86.880 Error@1 39.350

==>>[2018-05-02 19:38:09] [Epoch=031/540] [Need: 04:26:11] [learning_rate=0.100000] [Best : Accuracy=62.57, Error=37.43]
  Epoch: [031][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 0.8128 (0.8128)   Prec@1 73.000 (73.000)   Prec@5 97.000 (97.000)   [2018-05-02 19:38:09]
  Epoch: [031][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.0082 (1.0748)   Prec@1 74.000 (69.080)   Prec@5 96.000 (92.537)   [2018-05-02 19:38:21]
  Epoch: [031][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.0235 (1.0986)   Prec@1 74.000 (68.511)   Prec@5 91.000 (92.167)   [2018-05-02 19:38:32]
  **Train** Prec@1 68.542 Prec@5 91.980 Error@1 31.458
  **Test** Prec@1 62.340 Prec@5 88.530 Error@1 37.660

==>>[2018-05-02 19:38:41] [Epoch=032/540] [Need: 04:25:49] [learning_rate=0.100000] [Best : Accuracy=62.57, Error=37.43]
  Epoch: [032][000/500]   Time 0.088 (0.088)   Data 0.061 (0.061)   Loss 1.1580 (1.1580)   Prec@1 69.000 (69.000)   Prec@5 88.000 (88.000)   [2018-05-02 19:38:41]
  Epoch: [032][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.9366 (1.0553)   Prec@1 74.000 (69.667)   Prec@5 95.000 (92.736)   [2018-05-02 19:38:53]
  Epoch: [032][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.4251 (1.0835)   Prec@1 60.000 (68.890)   Prec@5 89.000 (92.272)   [2018-05-02 19:39:04]
  **Train** Prec@1 68.780 Prec@5 92.148 Error@1 31.220
  **Test** Prec@1 63.470 Prec@5 88.900 Error@1 36.530

==>>[2018-05-02 19:39:13] [Epoch=033/540] [Need: 04:25:28] [learning_rate=0.100000] [Best : Accuracy=63.47, Error=36.53]
  Epoch: [033][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.8726 (0.8726)   Prec@1 77.000 (77.000)   Prec@5 94.000 (94.000)   [2018-05-02 19:39:13]
  Epoch: [033][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 1.3402 (1.0394)   Prec@1 66.000 (70.204)   Prec@5 89.000 (92.876)   [2018-05-02 19:39:25]
  Epoch: [033][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.1694 (1.0568)   Prec@1 68.000 (69.726)   Prec@5 92.000 (92.633)   [2018-05-02 19:39:36]
  **Train** Prec@1 69.312 Prec@5 92.464 Error@1 30.688
  **Test** Prec@1 62.360 Prec@5 87.780 Error@1 37.640

==>>[2018-05-02 19:39:45] [Epoch=034/540] [Need: 04:25:06] [learning_rate=0.100000] [Best : Accuracy=63.47, Error=36.53]
  Epoch: [034][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 1.0948 (1.0948)   Prec@1 65.000 (65.000)   Prec@5 91.000 (91.000)   [2018-05-02 19:39:45]
  Epoch: [034][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.9160 (1.0526)   Prec@1 73.000 (69.930)   Prec@5 94.000 (92.483)   [2018-05-02 19:39:57]
  Epoch: [034][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.3018 (1.0578)   Prec@1 64.000 (69.584)   Prec@5 91.000 (92.389)   [2018-05-02 19:40:08]
  **Train** Prec@1 69.438 Prec@5 92.442 Error@1 30.562
  **Test** Prec@1 61.530 Prec@5 86.770 Error@1 38.470

==>>[2018-05-02 19:40:17] [Epoch=035/540] [Need: 04:24:44] [learning_rate=0.100000] [Best : Accuracy=63.47, Error=36.53]
  Epoch: [035][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 1.0093 (1.0093)   Prec@1 72.000 (72.000)   Prec@5 91.000 (91.000)   [2018-05-02 19:40:17]
  Epoch: [035][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.0414 (1.0237)   Prec@1 68.000 (70.368)   Prec@5 96.000 (93.030)   [2018-05-02 19:40:29]
  Epoch: [035][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 1.0342 (1.0392)   Prec@1 70.000 (69.968)   Prec@5 92.000 (92.850)   [2018-05-02 19:40:41]
  **Train** Prec@1 69.726 Prec@5 92.720 Error@1 30.274
  **Test** Prec@1 60.580 Prec@5 86.570 Error@1 39.420

==>>[2018-05-02 19:40:49] [Epoch=036/540] [Need: 04:24:20] [learning_rate=0.100000] [Best : Accuracy=63.47, Error=36.53]
  Epoch: [036][000/500]   Time 0.088 (0.088)   Data 0.061 (0.061)   Loss 1.1552 (1.1552)   Prec@1 64.000 (64.000)   Prec@5 94.000 (94.000)   [2018-05-02 19:40:49]
  Epoch: [036][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.1160 (1.0282)   Prec@1 63.000 (70.488)   Prec@5 94.000 (92.905)   [2018-05-02 19:41:01]
  Epoch: [036][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.0538 (1.0474)   Prec@1 69.000 (70.035)   Prec@5 92.000 (92.638)   [2018-05-02 19:41:13]
  **Train** Prec@1 70.234 Prec@5 92.702 Error@1 29.766
  **Test** Prec@1 64.640 Prec@5 89.620 Error@1 35.360

==>>[2018-05-02 19:41:21] [Epoch=037/540] [Need: 04:23:57] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [037][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.8378 (0.8378)   Prec@1 72.000 (72.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:41:21]
  Epoch: [037][200/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 1.1576 (0.9996)   Prec@1 67.000 (70.955)   Prec@5 93.000 (93.398)   [2018-05-02 19:41:33]
  Epoch: [037][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 1.0316 (1.0198)   Prec@1 70.000 (70.421)   Prec@5 93.000 (93.042)   [2018-05-02 19:41:45]
  **Train** Prec@1 70.210 Prec@5 92.904 Error@1 29.790
  **Test** Prec@1 59.470 Prec@5 86.690 Error@1 40.530

==>>[2018-05-02 19:41:53] [Epoch=038/540] [Need: 04:23:34] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [038][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 1.0821 (1.0821)   Prec@1 65.000 (65.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:41:53]
  Epoch: [038][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 1.2089 (1.0001)   Prec@1 69.000 (71.010)   Prec@5 89.000 (93.677)   [2018-05-02 19:42:05]
  Epoch: [038][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 1.0200 (1.0094)   Prec@1 70.000 (70.613)   Prec@5 92.000 (93.379)   [2018-05-02 19:42:17]
  **Train** Prec@1 70.422 Prec@5 93.190 Error@1 29.578
  **Test** Prec@1 64.340 Prec@5 88.830 Error@1 35.660

==>>[2018-05-02 19:42:25] [Epoch=039/540] [Need: 04:23:09] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [039][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.9437 (0.9437)   Prec@1 72.000 (72.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:42:25]
  Epoch: [039][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.9828 (0.9734)   Prec@1 72.000 (71.781)   Prec@5 94.000 (93.726)   [2018-05-02 19:42:37]
  Epoch: [039][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.8970 (1.0015)   Prec@1 75.000 (71.067)   Prec@5 97.000 (93.317)   [2018-05-02 19:42:49]
  **Train** Prec@1 70.756 Prec@5 93.162 Error@1 29.244
  **Test** Prec@1 62.060 Prec@5 87.310 Error@1 37.940

==>>[2018-05-02 19:42:57] [Epoch=040/540] [Need: 04:22:44] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [040][000/500]   Time 0.088 (0.088)   Data 0.061 (0.061)   Loss 0.7750 (0.7750)   Prec@1 74.000 (74.000)   Prec@5 98.000 (98.000)   [2018-05-02 19:42:57]
  Epoch: [040][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.9666 (0.9672)   Prec@1 69.000 (71.940)   Prec@5 95.000 (93.965)   [2018-05-02 19:43:09]
  Epoch: [040][400/500]   Time 0.063 (0.058)   Data 0.000 (0.000)   Loss 1.0142 (0.9918)   Prec@1 69.000 (71.369)   Prec@5 95.000 (93.426)   [2018-05-02 19:43:21]
  **Train** Prec@1 71.110 Prec@5 93.222 Error@1 28.890
  **Test** Prec@1 61.910 Prec@5 87.340 Error@1 38.090

==>>[2018-05-02 19:43:29] [Epoch=041/540] [Need: 04:22:19] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [041][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.9293 (0.9293)   Prec@1 73.000 (73.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:43:30]
  Epoch: [041][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 1.2404 (0.9551)   Prec@1 67.000 (72.199)   Prec@5 90.000 (93.935)   [2018-05-02 19:43:41]
  Epoch: [041][400/500]   Time 0.062 (0.058)   Data 0.000 (0.000)   Loss 0.9718 (0.9816)   Prec@1 74.000 (71.571)   Prec@5 93.000 (93.531)   [2018-05-02 19:43:53]
  **Train** Prec@1 71.374 Prec@5 93.448 Error@1 28.626
  **Test** Prec@1 63.620 Prec@5 88.730 Error@1 36.380

==>>[2018-05-02 19:44:01] [Epoch=042/540] [Need: 04:21:54] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [042][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.7936 (0.7936)   Prec@1 76.000 (76.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:44:02]
  Epoch: [042][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 1.0795 (0.9485)   Prec@1 66.000 (72.642)   Prec@5 92.000 (93.831)   [2018-05-02 19:44:13]
  Epoch: [042][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.9776 (0.9816)   Prec@1 73.000 (71.781)   Prec@5 95.000 (93.551)   [2018-05-02 19:44:25]
  **Train** Prec@1 71.640 Prec@5 93.420 Error@1 28.360
  **Test** Prec@1 62.560 Prec@5 88.050 Error@1 37.440

==>>[2018-05-02 19:44:34] [Epoch=043/540] [Need: 04:21:28] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [043][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.8926 (0.8926)   Prec@1 74.000 (74.000)   Prec@5 97.000 (97.000)   [2018-05-02 19:44:34]
  Epoch: [043][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.7904 (0.9437)   Prec@1 80.000 (73.085)   Prec@5 95.000 (93.746)   [2018-05-02 19:44:45]
  Epoch: [043][400/500]   Time 0.062 (0.058)   Data 0.000 (0.000)   Loss 1.1608 (0.9738)   Prec@1 68.000 (72.207)   Prec@5 88.000 (93.596)   [2018-05-02 19:44:57]
  **Train** Prec@1 71.742 Prec@5 93.534 Error@1 28.258
  **Test** Prec@1 62.820 Prec@5 88.080 Error@1 37.180

==>>[2018-05-02 19:45:06] [Epoch=044/540] [Need: 04:21:01] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [044][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.8919 (0.8919)   Prec@1 75.000 (75.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:45:06]
  Epoch: [044][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.9187 (0.9220)   Prec@1 76.000 (73.219)   Prec@5 97.000 (94.393)   [2018-05-02 19:45:17]
  Epoch: [044][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 1.0660 (0.9502)   Prec@1 69.000 (72.526)   Prec@5 88.000 (93.988)   [2018-05-02 19:45:29]
  **Train** Prec@1 72.038 Prec@5 93.710 Error@1 27.962
  **Test** Prec@1 64.570 Prec@5 88.380 Error@1 35.430

==>>[2018-05-02 19:45:38] [Epoch=045/540] [Need: 04:20:34] [learning_rate=0.100000] [Best : Accuracy=64.64, Error=35.36]
  Epoch: [045][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.7944 (0.7944)   Prec@1 78.000 (78.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:45:38]
  Epoch: [045][200/500]   Time 0.060 (0.059)   Data 0.000 (0.001)   Loss 0.8833 (0.9288)   Prec@1 76.000 (72.945)   Prec@5 94.000 (94.313)   [2018-05-02 19:45:49]
  Epoch: [045][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.1026 (0.9479)   Prec@1 62.000 (72.474)   Prec@5 94.000 (93.973)   [2018-05-02 19:46:01]
  **Train** Prec@1 72.328 Prec@5 93.842 Error@1 27.672
  **Test** Prec@1 64.750 Prec@5 89.490 Error@1 35.250

==>>[2018-05-02 19:46:10] [Epoch=046/540] [Need: 04:20:08] [learning_rate=0.100000] [Best : Accuracy=64.75, Error=35.25]
  Epoch: [046][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.9328 (0.9328)   Prec@1 75.000 (75.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:46:10]
  Epoch: [046][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 1.1498 (0.9294)   Prec@1 66.000 (73.224)   Prec@5 92.000 (94.149)   [2018-05-02 19:46:21]
  Epoch: [046][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.9571 (0.9423)   Prec@1 75.000 (72.783)   Prec@5 96.000 (93.975)   [2018-05-02 19:46:33]
  **Train** Prec@1 72.464 Prec@5 93.780 Error@1 27.536
  **Test** Prec@1 62.960 Prec@5 88.100 Error@1 37.040

==>>[2018-05-02 19:46:42] [Epoch=047/540] [Need: 04:19:41] [learning_rate=0.100000] [Best : Accuracy=64.75, Error=35.25]
  Epoch: [047][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 1.1741 (1.1741)   Prec@1 67.000 (67.000)   Prec@5 91.000 (91.000)   [2018-05-02 19:46:42]
  Epoch: [047][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.8558 (0.9125)   Prec@1 80.000 (73.234)   Prec@5 94.000 (94.597)   [2018-05-02 19:46:53]
  Epoch: [047][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.9934 (0.9390)   Prec@1 75.000 (72.703)   Prec@5 92.000 (94.097)   [2018-05-02 19:47:05]
  **Train** Prec@1 72.494 Prec@5 93.914 Error@1 27.506
  **Test** Prec@1 63.930 Prec@5 88.480 Error@1 36.070

==>>[2018-05-02 19:47:14] [Epoch=048/540] [Need: 04:19:13] [learning_rate=0.100000] [Best : Accuracy=64.75, Error=35.25]
  Epoch: [048][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.6443 (0.6443)   Prec@1 81.000 (81.000)   Prec@5 97.000 (97.000)   [2018-05-02 19:47:14]
  Epoch: [048][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.9584 (0.9160)   Prec@1 72.000 (73.463)   Prec@5 93.000 (94.333)   [2018-05-02 19:47:25]
  Epoch: [048][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 1.0112 (0.9398)   Prec@1 71.000 (72.701)   Prec@5 91.000 (94.075)   [2018-05-02 19:47:37]
  **Train** Prec@1 72.598 Prec@5 94.054 Error@1 27.402
  **Test** Prec@1 64.360 Prec@5 88.920 Error@1 35.640

==>>[2018-05-02 19:47:45] [Epoch=049/540] [Need: 04:18:43] [learning_rate=0.100000] [Best : Accuracy=64.75, Error=35.25]
  Epoch: [049][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 0.7216 (0.7216)   Prec@1 75.000 (75.000)   Prec@5 98.000 (98.000)   [2018-05-02 19:47:46]
  Epoch: [049][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.9058 (0.8856)   Prec@1 70.000 (74.040)   Prec@5 92.000 (94.597)   [2018-05-02 19:47:57]
  Epoch: [049][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.7298 (0.9212)   Prec@1 78.000 (73.122)   Prec@5 96.000 (94.147)   [2018-05-02 19:48:08]
  **Train** Prec@1 72.838 Prec@5 94.008 Error@1 27.162
  **Test** Prec@1 64.120 Prec@5 88.970 Error@1 35.880

==>>[2018-05-02 19:48:16] [Epoch=050/540] [Need: 04:18:03] [learning_rate=0.100000] [Best : Accuracy=64.75, Error=35.25]
  Epoch: [050][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.7326 (0.7326)   Prec@1 80.000 (80.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:48:16]
  Epoch: [050][200/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 1.1351 (0.9099)   Prec@1 68.000 (73.328)   Prec@5 94.000 (94.398)   [2018-05-02 19:48:27]
  Epoch: [050][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.9439 (0.9266)   Prec@1 74.000 (72.903)   Prec@5 95.000 (94.239)   [2018-05-02 19:48:39]
  **Train** Prec@1 72.868 Prec@5 94.156 Error@1 27.132
  **Test** Prec@1 61.990 Prec@5 87.550 Error@1 38.010

==>>[2018-05-02 19:48:48] [Epoch=051/540] [Need: 04:17:30] [learning_rate=0.100000] [Best : Accuracy=64.75, Error=35.25]
  Epoch: [051][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.6801 (0.6801)   Prec@1 81.000 (81.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:48:48]
  Epoch: [051][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.8123 (0.8986)   Prec@1 76.000 (73.682)   Prec@5 96.000 (94.423)   [2018-05-02 19:48:59]
  Epoch: [051][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.7112 (0.9128)   Prec@1 77.000 (73.454)   Prec@5 94.000 (94.294)   [2018-05-02 19:49:11]
  **Train** Prec@1 73.176 Prec@5 94.200 Error@1 26.824
  **Test** Prec@1 65.110 Prec@5 88.700 Error@1 34.890

==>>[2018-05-02 19:49:19] [Epoch=052/540] [Need: 04:16:58] [learning_rate=0.100000] [Best : Accuracy=65.11, Error=34.89]
  Epoch: [052][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.6341 (0.6341)   Prec@1 81.000 (81.000)   Prec@5 97.000 (97.000)   [2018-05-02 19:49:19]
  Epoch: [052][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.8228 (0.8740)   Prec@1 78.000 (74.299)   Prec@5 94.000 (94.925)   [2018-05-02 19:49:31]
  Epoch: [052][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.9828 (0.9070)   Prec@1 74.000 (73.444)   Prec@5 94.000 (94.322)   [2018-05-02 19:49:42]
  **Train** Prec@1 73.166 Prec@5 94.152 Error@1 26.834
  **Test** Prec@1 62.990 Prec@5 88.030 Error@1 37.010

==>>[2018-05-02 19:49:51] [Epoch=053/540] [Need: 04:16:25] [learning_rate=0.100000] [Best : Accuracy=65.11, Error=34.89]
  Epoch: [053][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.6913 (0.6913)   Prec@1 79.000 (79.000)   Prec@5 99.000 (99.000)   [2018-05-02 19:49:51]
  Epoch: [053][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.7855 (0.8756)   Prec@1 80.000 (74.577)   Prec@5 96.000 (94.806)   [2018-05-02 19:50:02]
  Epoch: [053][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 1.2728 (0.9070)   Prec@1 61.000 (73.751)   Prec@5 92.000 (94.392)   [2018-05-02 19:50:13]
  **Train** Prec@1 73.440 Prec@5 94.394 Error@1 26.560
  **Test** Prec@1 64.780 Prec@5 88.340 Error@1 35.220

==>>[2018-05-02 19:50:21] [Epoch=054/540] [Need: 04:15:42] [learning_rate=0.100000] [Best : Accuracy=65.11, Error=34.89]
  Epoch: [054][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.9473 (0.9473)   Prec@1 73.000 (73.000)   Prec@5 94.000 (94.000)   [2018-05-02 19:50:21]
  Epoch: [054][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.7689 (0.8829)   Prec@1 78.000 (74.572)   Prec@5 96.000 (94.572)   [2018-05-02 19:50:32]
  Epoch: [054][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8787 (0.8984)   Prec@1 73.000 (73.933)   Prec@5 94.000 (94.404)   [2018-05-02 19:50:43]
  **Train** Prec@1 73.734 Prec@5 94.376 Error@1 26.266
  **Test** Prec@1 66.020 Prec@5 89.800 Error@1 33.980

==>>[2018-05-02 19:50:51] [Epoch=055/540] [Need: 04:14:59] [learning_rate=0.100000] [Best : Accuracy=66.02, Error=33.98]
  Epoch: [055][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.8730 (0.8730)   Prec@1 71.000 (71.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:50:51]
  Epoch: [055][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.6473 (0.8872)   Prec@1 79.000 (74.184)   Prec@5 97.000 (94.692)   [2018-05-02 19:51:02]
  Epoch: [055][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8255 (0.9067)   Prec@1 80.000 (73.661)   Prec@5 95.000 (94.466)   [2018-05-02 19:51:13]
  **Train** Prec@1 73.580 Prec@5 94.358 Error@1 26.420
  **Test** Prec@1 62.590 Prec@5 87.210 Error@1 37.410

==>>[2018-05-02 19:51:22] [Epoch=056/540] [Need: 04:14:17] [learning_rate=0.100000] [Best : Accuracy=66.02, Error=33.98]
  Epoch: [056][000/500]   Time 0.097 (0.097)   Data 0.070 (0.070)   Loss 0.6802 (0.6802)   Prec@1 79.000 (79.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:51:22]
  Epoch: [056][200/500]   Time 0.060 (0.055)   Data 0.000 (0.000)   Loss 1.0285 (0.8806)   Prec@1 69.000 (74.468)   Prec@5 92.000 (94.876)   [2018-05-02 19:51:33]
  Epoch: [056][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8229 (0.8971)   Prec@1 74.000 (74.042)   Prec@5 94.000 (94.673)   [2018-05-02 19:51:44]
  **Train** Prec@1 73.896 Prec@5 94.536 Error@1 26.104
  **Test** Prec@1 65.040 Prec@5 89.200 Error@1 34.960

==>>[2018-05-02 19:51:52] [Epoch=057/540] [Need: 04:13:36] [learning_rate=0.100000] [Best : Accuracy=66.02, Error=33.98]
  Epoch: [057][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.9566 (0.9566)   Prec@1 69.000 (69.000)   Prec@5 93.000 (93.000)   [2018-05-02 19:51:52]
  Epoch: [057][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.8057 (0.8545)   Prec@1 76.000 (75.045)   Prec@5 96.000 (94.871)   [2018-05-02 19:52:03]
  Epoch: [057][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.7177 (0.8769)   Prec@1 78.000 (74.591)   Prec@5 97.000 (94.763)   [2018-05-02 19:52:15]
  **Train** Prec@1 74.456 Prec@5 94.592 Error@1 25.544
  **Test** Prec@1 65.310 Prec@5 89.340 Error@1 34.690

==>>[2018-05-02 19:52:23] [Epoch=058/540] [Need: 04:13:01] [learning_rate=0.100000] [Best : Accuracy=66.02, Error=33.98]
  Epoch: [058][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.5859 (0.5859)   Prec@1 85.000 (85.000)   Prec@5 99.000 (99.000)   [2018-05-02 19:52:23]
  Epoch: [058][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.0134 (0.8450)   Prec@1 68.000 (75.418)   Prec@5 94.000 (95.055)   [2018-05-02 19:52:34]
  Epoch: [058][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9221 (0.8666)   Prec@1 77.000 (74.751)   Prec@5 93.000 (94.848)   [2018-05-02 19:52:45]
  **Train** Prec@1 74.442 Prec@5 94.682 Error@1 25.558
  **Test** Prec@1 65.070 Prec@5 89.340 Error@1 34.930

==>>[2018-05-02 19:52:54] [Epoch=059/540] [Need: 04:12:23] [learning_rate=0.100000] [Best : Accuracy=66.02, Error=33.98]
  Epoch: [059][000/500]   Time 0.096 (0.096)   Data 0.069 (0.069)   Loss 0.7156 (0.7156)   Prec@1 83.000 (83.000)   Prec@5 97.000 (97.000)   [2018-05-02 19:52:54]
  Epoch: [059][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.8377 (0.8573)   Prec@1 77.000 (75.050)   Prec@5 97.000 (95.114)   [2018-05-02 19:53:05]
  Epoch: [059][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.7935 (0.8812)   Prec@1 76.000 (74.337)   Prec@5 97.000 (94.728)   [2018-05-02 19:53:16]
  **Train** Prec@1 74.130 Prec@5 94.642 Error@1 25.870
  **Test** Prec@1 66.110 Prec@5 89.990 Error@1 33.890

==>>[2018-05-02 19:53:24] [Epoch=060/540] [Need: 04:11:45] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [060][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.8590 (0.8590)   Prec@1 76.000 (76.000)   Prec@5 94.000 (94.000)   [2018-05-02 19:53:25]
  Epoch: [060][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 1.0348 (0.8506)   Prec@1 68.000 (75.114)   Prec@5 92.000 (94.900)   [2018-05-02 19:53:36]
  Epoch: [060][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 1.0861 (0.8775)   Prec@1 66.000 (74.494)   Prec@5 92.000 (94.668)   [2018-05-02 19:53:47]
  **Train** Prec@1 74.292 Prec@5 94.556 Error@1 25.708
  **Test** Prec@1 63.090 Prec@5 88.080 Error@1 36.910

==>>[2018-05-02 19:53:55] [Epoch=061/540] [Need: 04:11:09] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [061][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.9036 (0.9036)   Prec@1 72.000 (72.000)   Prec@5 97.000 (97.000)   [2018-05-02 19:53:55]
  Epoch: [061][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.9286 (0.8607)   Prec@1 72.000 (75.000)   Prec@5 96.000 (94.771)   [2018-05-02 19:54:06]
  Epoch: [061][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.3350 (0.8744)   Prec@1 65.000 (74.753)   Prec@5 88.000 (94.728)   [2018-05-02 19:54:17]
  **Train** Prec@1 74.538 Prec@5 94.710 Error@1 25.462
  **Test** Prec@1 63.010 Prec@5 88.250 Error@1 36.990

==>>[2018-05-02 19:54:25] [Epoch=062/540] [Need: 04:10:28] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [062][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.5997 (0.5997)   Prec@1 81.000 (81.000)   Prec@5 99.000 (99.000)   [2018-05-02 19:54:26]
  Epoch: [062][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.9084 (0.8377)   Prec@1 78.000 (75.622)   Prec@5 92.000 (95.264)   [2018-05-02 19:54:37]
  Epoch: [062][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.9805 (0.8627)   Prec@1 65.000 (75.012)   Prec@5 96.000 (94.953)   [2018-05-02 19:54:47]
  **Train** Prec@1 74.832 Prec@5 94.828 Error@1 25.168
  **Test** Prec@1 64.300 Prec@5 87.690 Error@1 35.700

==>>[2018-05-02 19:54:56] [Epoch=063/540] [Need: 04:09:46] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [063][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.7967 (0.7967)   Prec@1 75.000 (75.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:54:56]
  Epoch: [063][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8929 (0.8379)   Prec@1 75.000 (75.468)   Prec@5 97.000 (95.323)   [2018-05-02 19:55:07]
  Epoch: [063][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.0070 (0.8617)   Prec@1 69.000 (74.825)   Prec@5 95.000 (94.983)   [2018-05-02 19:55:17]
  **Train** Prec@1 74.648 Prec@5 94.834 Error@1 25.352
  **Test** Prec@1 65.650 Prec@5 89.540 Error@1 34.350

==>>[2018-05-02 19:55:26] [Epoch=064/540] [Need: 04:09:04] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [064][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.6951 (0.6951)   Prec@1 79.000 (79.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:55:26]
  Epoch: [064][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7729 (0.8355)   Prec@1 78.000 (75.453)   Prec@5 95.000 (95.438)   [2018-05-02 19:55:37]
  Epoch: [064][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8635 (0.8621)   Prec@1 74.000 (74.830)   Prec@5 97.000 (95.035)   [2018-05-02 19:55:48]
  **Train** Prec@1 74.546 Prec@5 94.816 Error@1 25.454
  **Test** Prec@1 63.510 Prec@5 87.850 Error@1 36.490

==>>[2018-05-02 19:55:56] [Epoch=065/540] [Need: 04:08:23] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [065][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.8533 (0.8533)   Prec@1 74.000 (74.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:55:56]
  Epoch: [065][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8313 (0.8426)   Prec@1 77.000 (75.363)   Prec@5 94.000 (95.289)   [2018-05-02 19:56:07]
  Epoch: [065][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7257 (0.8607)   Prec@1 75.000 (74.943)   Prec@5 96.000 (95.055)   [2018-05-02 19:56:18]
  **Train** Prec@1 74.728 Prec@5 94.920 Error@1 25.272
  **Test** Prec@1 64.950 Prec@5 88.990 Error@1 35.050

==>>[2018-05-02 19:56:26] [Epoch=066/540] [Need: 04:07:43] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [066][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.7616 (0.7616)   Prec@1 78.000 (78.000)   Prec@5 97.000 (97.000)   [2018-05-02 19:56:26]
  Epoch: [066][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.0361 (0.8139)   Prec@1 69.000 (76.323)   Prec@5 95.000 (95.348)   [2018-05-02 19:56:37]
  Epoch: [066][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8935 (0.8511)   Prec@1 74.000 (75.167)   Prec@5 93.000 (95.025)   [2018-05-02 19:56:48]
  **Train** Prec@1 74.998 Prec@5 94.956 Error@1 25.002
  **Test** Prec@1 64.450 Prec@5 88.770 Error@1 35.550

==>>[2018-05-02 19:56:56] [Epoch=067/540] [Need: 04:07:02] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [067][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.7672 (0.7672)   Prec@1 79.000 (79.000)   Prec@5 93.000 (93.000)   [2018-05-02 19:56:56]
  Epoch: [067][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8160 (0.8169)   Prec@1 79.000 (76.488)   Prec@5 94.000 (95.254)   [2018-05-02 19:57:07]
  Epoch: [067][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8648 (0.8410)   Prec@1 74.000 (75.738)   Prec@5 93.000 (95.112)   [2018-05-02 19:57:18]
  **Train** Prec@1 75.400 Prec@5 94.958 Error@1 24.600
  **Test** Prec@1 65.490 Prec@5 88.850 Error@1 34.510

==>>[2018-05-02 19:57:26] [Epoch=068/540] [Need: 04:06:22] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [068][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.6418 (0.6418)   Prec@1 81.000 (81.000)   Prec@5 96.000 (96.000)   [2018-05-02 19:57:26]
  Epoch: [068][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8797 (0.8255)   Prec@1 76.000 (76.060)   Prec@5 93.000 (95.194)   [2018-05-02 19:57:37]
  Epoch: [068][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9054 (0.8429)   Prec@1 74.000 (75.399)   Prec@5 94.000 (95.130)   [2018-05-02 19:57:48]
  **Train** Prec@1 75.220 Prec@5 95.010 Error@1 24.780
  **Test** Prec@1 64.450 Prec@5 89.060 Error@1 35.550

==>>[2018-05-02 19:57:56] [Epoch=069/540] [Need: 04:05:42] [learning_rate=0.100000] [Best : Accuracy=66.11, Error=33.89]
  Epoch: [069][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.7506 (0.7506)   Prec@1 80.000 (80.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:57:56]
  Epoch: [069][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7691 (0.8162)   Prec@1 80.000 (76.303)   Prec@5 98.000 (95.458)   [2018-05-02 19:58:07]
  Epoch: [069][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9639 (0.8419)   Prec@1 75.000 (75.611)   Prec@5 92.000 (95.100)   [2018-05-02 19:58:18]
  **Train** Prec@1 75.212 Prec@5 94.974 Error@1 24.788
  **Test** Prec@1 67.540 Prec@5 90.310 Error@1 32.460

==>>[2018-05-02 19:58:26] [Epoch=070/540] [Need: 04:05:03] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [070][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.5383 (0.5383)   Prec@1 85.000 (85.000)   Prec@5 98.000 (98.000)   [2018-05-02 19:58:26]
  Epoch: [070][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9101 (0.8038)   Prec@1 75.000 (76.572)   Prec@5 92.000 (95.617)   [2018-05-02 19:58:37]
  Epoch: [070][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8087 (0.8330)   Prec@1 73.000 (75.915)   Prec@5 96.000 (95.150)   [2018-05-02 19:58:48]
  **Train** Prec@1 75.476 Prec@5 95.056 Error@1 24.524
  **Test** Prec@1 64.750 Prec@5 89.190 Error@1 35.250

==>>[2018-05-02 19:58:56] [Epoch=071/540] [Need: 04:04:24] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [071][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.6935 (0.6935)   Prec@1 81.000 (81.000)   Prec@5 95.000 (95.000)   [2018-05-02 19:58:56]
  Epoch: [071][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.8209 (0.8308)   Prec@1 71.000 (76.070)   Prec@5 97.000 (95.189)   [2018-05-02 19:59:07]
  Epoch: [071][400/500]   Time 0.061 (0.056)   Data 0.000 (0.000)   Loss 0.7996 (0.8390)   Prec@1 80.000 (75.838)   Prec@5 94.000 (95.047)   [2018-05-02 19:59:19]
  **Train** Prec@1 75.634 Prec@5 94.950 Error@1 24.366
  **Test** Prec@1 66.110 Prec@5 89.850 Error@1 33.890

==>>[2018-05-02 19:59:27] [Epoch=072/540] [Need: 04:03:48] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [072][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.5536 (0.5536)   Prec@1 84.000 (84.000)   Prec@5 99.000 (99.000)   [2018-05-02 19:59:27]
  Epoch: [072][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7544 (0.8063)   Prec@1 76.000 (76.483)   Prec@5 98.000 (95.721)   [2018-05-02 19:59:38]
  Epoch: [072][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8548 (0.8345)   Prec@1 77.000 (75.771)   Prec@5 94.000 (95.307)   [2018-05-02 19:59:49]
  **Train** Prec@1 75.350 Prec@5 95.114 Error@1 24.650
  **Test** Prec@1 64.720 Prec@5 89.090 Error@1 35.280

==>>[2018-05-02 19:59:57] [Epoch=073/540] [Need: 04:03:10] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [073][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.7112 (0.7112)   Prec@1 77.000 (77.000)   Prec@5 99.000 (99.000)   [2018-05-02 19:59:57]
  Epoch: [073][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9645 (0.8173)   Prec@1 74.000 (76.159)   Prec@5 94.000 (95.383)   [2018-05-02 20:00:08]
  Epoch: [073][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.9062 (0.8316)   Prec@1 71.000 (75.648)   Prec@5 93.000 (95.272)   [2018-05-02 20:00:19]
  **Train** Prec@1 75.452 Prec@5 95.190 Error@1 24.548
  **Test** Prec@1 63.520 Prec@5 88.410 Error@1 36.480

==>>[2018-05-02 20:00:27] [Epoch=074/540] [Need: 04:02:31] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [074][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.8422 (0.8422)   Prec@1 73.000 (73.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:00:27]
  Epoch: [074][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8902 (0.8023)   Prec@1 76.000 (76.711)   Prec@5 94.000 (95.468)   [2018-05-02 20:00:38]
  Epoch: [074][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7872 (0.8240)   Prec@1 75.000 (76.219)   Prec@5 99.000 (95.202)   [2018-05-02 20:00:49]
  **Train** Prec@1 75.940 Prec@5 95.128 Error@1 24.060
  **Test** Prec@1 64.690 Prec@5 89.150 Error@1 35.310

==>>[2018-05-02 20:00:57] [Epoch=075/540] [Need: 04:01:53] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [075][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.7180 (0.7180)   Prec@1 81.000 (81.000)   Prec@5 97.000 (97.000)   [2018-05-02 20:00:57]
  Epoch: [075][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8919 (0.7979)   Prec@1 71.000 (76.806)   Prec@5 95.000 (95.592)   [2018-05-02 20:01:08]
  Epoch: [075][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 1.0196 (0.8242)   Prec@1 72.000 (75.893)   Prec@5 93.000 (95.317)   [2018-05-02 20:01:19]
  **Train** Prec@1 75.632 Prec@5 95.182 Error@1 24.368
  **Test** Prec@1 66.710 Prec@5 90.030 Error@1 33.290

==>>[2018-05-02 20:01:27] [Epoch=076/540] [Need: 04:01:15] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [076][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.6333 (0.6333)   Prec@1 82.000 (82.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:01:27]
  Epoch: [076][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7924 (0.8046)   Prec@1 77.000 (76.313)   Prec@5 98.000 (95.612)   [2018-05-02 20:01:38]
  Epoch: [076][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8901 (0.8227)   Prec@1 75.000 (75.930)   Prec@5 94.000 (95.374)   [2018-05-02 20:01:49]
  **Train** Prec@1 75.796 Prec@5 95.278 Error@1 24.204
  **Test** Prec@1 66.600 Prec@5 89.720 Error@1 33.400

==>>[2018-05-02 20:01:57] [Epoch=077/540] [Need: 04:00:37] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [077][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.6706 (0.6706)   Prec@1 83.000 (83.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:01:57]
  Epoch: [077][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8647 (0.7964)   Prec@1 73.000 (76.791)   Prec@5 94.000 (95.736)   [2018-05-02 20:02:08]
  Epoch: [077][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8616 (0.8202)   Prec@1 76.000 (75.935)   Prec@5 95.000 (95.526)   [2018-05-02 20:02:19]
  **Train** Prec@1 75.688 Prec@5 95.368 Error@1 24.312
  **Test** Prec@1 62.650 Prec@5 87.250 Error@1 37.350

==>>[2018-05-02 20:02:27] [Epoch=078/540] [Need: 04:00:00] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [078][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.8767 (0.8767)   Prec@1 77.000 (77.000)   Prec@5 89.000 (89.000)   [2018-05-02 20:02:27]
  Epoch: [078][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9979 (0.7821)   Prec@1 72.000 (77.498)   Prec@5 93.000 (95.811)   [2018-05-02 20:02:38]
  Epoch: [078][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.6303 (0.8137)   Prec@1 84.000 (76.511)   Prec@5 99.000 (95.474)   [2018-05-02 20:02:49]
  **Train** Prec@1 76.230 Prec@5 95.310 Error@1 23.770
  **Test** Prec@1 65.270 Prec@5 88.600 Error@1 34.730

==>>[2018-05-02 20:02:57] [Epoch=079/540] [Need: 03:59:22] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [079][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.7332 (0.7332)   Prec@1 80.000 (80.000)   Prec@5 97.000 (97.000)   [2018-05-02 20:02:57]
  Epoch: [079][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9012 (0.7882)   Prec@1 74.000 (77.159)   Prec@5 96.000 (95.706)   [2018-05-02 20:03:08]
  Epoch: [079][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 1.1239 (0.8157)   Prec@1 73.000 (76.304)   Prec@5 90.000 (95.416)   [2018-05-02 20:03:19]
  **Train** Prec@1 75.942 Prec@5 95.288 Error@1 24.058
  **Test** Prec@1 65.920 Prec@5 89.370 Error@1 34.080

==>>[2018-05-02 20:03:27] [Epoch=080/540] [Need: 03:58:44] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [080][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.6558 (0.6558)   Prec@1 82.000 (82.000)   Prec@5 97.000 (97.000)   [2018-05-02 20:03:28]
  Epoch: [080][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 1.0378 (0.7752)   Prec@1 73.000 (77.791)   Prec@5 95.000 (95.697)   [2018-05-02 20:03:38]
  Epoch: [080][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 1.0360 (0.8057)   Prec@1 66.000 (76.850)   Prec@5 92.000 (95.434)   [2018-05-02 20:03:49]
  **Train** Prec@1 76.502 Prec@5 95.276 Error@1 23.498
  **Test** Prec@1 67.260 Prec@5 90.190 Error@1 32.740

==>>[2018-05-02 20:03:58] [Epoch=081/540] [Need: 03:58:07] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [081][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.6955 (0.6955)   Prec@1 80.000 (80.000)   Prec@5 95.000 (95.000)   [2018-05-02 20:03:58]
  Epoch: [081][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8651 (0.7952)   Prec@1 75.000 (76.796)   Prec@5 95.000 (95.602)   [2018-05-02 20:04:09]
  Epoch: [081][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.7075 (0.8179)   Prec@1 82.000 (76.125)   Prec@5 96.000 (95.272)   [2018-05-02 20:04:20]
  **Train** Prec@1 76.028 Prec@5 95.202 Error@1 23.972
  **Test** Prec@1 66.050 Prec@5 89.530 Error@1 33.950

==>>[2018-05-02 20:04:28] [Epoch=082/540] [Need: 03:57:31] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [082][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.6684 (0.6684)   Prec@1 78.000 (78.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:04:28]
  Epoch: [082][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7916 (0.7917)   Prec@1 78.000 (76.721)   Prec@5 94.000 (95.751)   [2018-05-02 20:04:39]
  Epoch: [082][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.9128 (0.8100)   Prec@1 76.000 (76.401)   Prec@5 94.000 (95.456)   [2018-05-02 20:04:50]
  **Train** Prec@1 76.264 Prec@5 95.366 Error@1 23.736
  **Test** Prec@1 65.480 Prec@5 89.320 Error@1 34.520

==>>[2018-05-02 20:04:58] [Epoch=083/540] [Need: 03:56:54] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [083][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 1.0163 (1.0163)   Prec@1 69.000 (69.000)   Prec@5 96.000 (96.000)   [2018-05-02 20:04:58]
  Epoch: [083][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8151 (0.7885)   Prec@1 79.000 (76.617)   Prec@5 97.000 (95.781)   [2018-05-02 20:05:09]
  Epoch: [083][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8795 (0.8131)   Prec@1 76.000 (76.072)   Prec@5 94.000 (95.504)   [2018-05-02 20:05:20]
  **Train** Prec@1 75.860 Prec@5 95.442 Error@1 24.140
  **Test** Prec@1 65.570 Prec@5 89.510 Error@1 34.430

==>>[2018-05-02 20:05:28] [Epoch=084/540] [Need: 03:56:17] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [084][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.9729 (0.9729)   Prec@1 70.000 (70.000)   Prec@5 95.000 (95.000)   [2018-05-02 20:05:28]
  Epoch: [084][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8593 (0.7781)   Prec@1 72.000 (77.433)   Prec@5 97.000 (95.682)   [2018-05-02 20:05:39]
  Epoch: [084][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7817 (0.8072)   Prec@1 74.000 (76.641)   Prec@5 96.000 (95.496)   [2018-05-02 20:05:50]
  **Train** Prec@1 76.420 Prec@5 95.356 Error@1 23.580
  **Test** Prec@1 65.740 Prec@5 89.610 Error@1 34.260

==>>[2018-05-02 20:05:58] [Epoch=085/540] [Need: 03:55:41] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [085][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.6775 (0.6775)   Prec@1 81.000 (81.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:05:58]
  Epoch: [085][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.7811 (0.7845)   Prec@1 75.000 (76.776)   Prec@5 96.000 (95.731)   [2018-05-02 20:06:09]
  Epoch: [085][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8740 (0.8052)   Prec@1 73.000 (76.372)   Prec@5 95.000 (95.556)   [2018-05-02 20:06:20]
  **Train** Prec@1 76.222 Prec@5 95.460 Error@1 23.778
  **Test** Prec@1 65.980 Prec@5 89.680 Error@1 34.020

==>>[2018-05-02 20:06:28] [Epoch=086/540] [Need: 03:55:05] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [086][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.6206 (0.6206)   Prec@1 83.000 (83.000)   Prec@5 97.000 (97.000)   [2018-05-02 20:06:28]
  Epoch: [086][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9928 (0.7677)   Prec@1 73.000 (77.692)   Prec@5 95.000 (95.881)   [2018-05-02 20:06:39]
  Epoch: [086][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8280 (0.8026)   Prec@1 76.000 (76.778)   Prec@5 95.000 (95.549)   [2018-05-02 20:06:50]
  **Train** Prec@1 76.526 Prec@5 95.420 Error@1 23.474
  **Test** Prec@1 64.870 Prec@5 88.760 Error@1 35.130

==>>[2018-05-02 20:06:58] [Epoch=087/540] [Need: 03:54:28] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [087][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.9192 (0.9192)   Prec@1 76.000 (76.000)   Prec@5 93.000 (93.000)   [2018-05-02 20:06:58]
  Epoch: [087][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8470 (0.7792)   Prec@1 80.000 (77.124)   Prec@5 92.000 (95.811)   [2018-05-02 20:07:09]
  Epoch: [087][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7120 (0.7954)   Prec@1 76.000 (76.863)   Prec@5 96.000 (95.603)   [2018-05-02 20:07:20]
  **Train** Prec@1 76.520 Prec@5 95.510 Error@1 23.480
  **Test** Prec@1 65.230 Prec@5 89.380 Error@1 34.770

==>>[2018-05-02 20:07:28] [Epoch=088/540] [Need: 03:53:52] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [088][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.5586 (0.5586)   Prec@1 84.000 (84.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:07:28]
  Epoch: [088][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7485 (0.7699)   Prec@1 75.000 (77.378)   Prec@5 97.000 (96.005)   [2018-05-02 20:07:39]
  Epoch: [088][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.8714 (0.7881)   Prec@1 74.000 (76.898)   Prec@5 93.000 (95.761)   [2018-05-02 20:07:50]
  **Train** Prec@1 76.592 Prec@5 95.630 Error@1 23.408
  **Test** Prec@1 64.820 Prec@5 89.080 Error@1 35.180

==>>[2018-05-02 20:07:58] [Epoch=089/540] [Need: 03:53:17] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [089][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.7139 (0.7139)   Prec@1 77.000 (77.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:07:58]
  Epoch: [089][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7488 (0.7673)   Prec@1 74.000 (77.766)   Prec@5 98.000 (95.856)   [2018-05-02 20:08:09]
  Epoch: [089][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 1.1250 (0.7982)   Prec@1 68.000 (76.833)   Prec@5 92.000 (95.584)   [2018-05-02 20:08:20]
  **Train** Prec@1 76.836 Prec@5 95.524 Error@1 23.164
  **Test** Prec@1 64.950 Prec@5 88.490 Error@1 35.050

==>>[2018-05-02 20:08:28] [Epoch=090/540] [Need: 03:52:41] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [090][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.6895 (0.6895)   Prec@1 77.000 (77.000)   Prec@5 94.000 (94.000)   [2018-05-02 20:08:29]
  Epoch: [090][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.6615 (0.7867)   Prec@1 80.000 (76.791)   Prec@5 98.000 (95.896)   [2018-05-02 20:08:40]
  Epoch: [090][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9210 (0.8003)   Prec@1 70.000 (76.594)   Prec@5 99.000 (95.703)   [2018-05-02 20:08:50]
  **Train** Prec@1 76.612 Prec@5 95.640 Error@1 23.388
  **Test** Prec@1 66.790 Prec@5 90.310 Error@1 33.210

==>>[2018-05-02 20:08:59] [Epoch=091/540] [Need: 03:52:05] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [091][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.6096 (0.6096)   Prec@1 79.000 (79.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:08:59]
  Epoch: [091][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8288 (0.7579)   Prec@1 81.000 (77.831)   Prec@5 97.000 (95.816)   [2018-05-02 20:09:10]
  Epoch: [091][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9221 (0.7890)   Prec@1 75.000 (77.000)   Prec@5 94.000 (95.529)   [2018-05-02 20:09:21]
  **Train** Prec@1 76.596 Prec@5 95.382 Error@1 23.404
  **Test** Prec@1 66.240 Prec@5 89.450 Error@1 33.760

==>>[2018-05-02 20:09:29] [Epoch=092/540] [Need: 03:51:30] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [092][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.7011 (0.7011)   Prec@1 78.000 (78.000)   Prec@5 96.000 (96.000)   [2018-05-02 20:09:29]
  Epoch: [092][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8817 (0.7558)   Prec@1 74.000 (78.030)   Prec@5 94.000 (95.975)   [2018-05-02 20:09:40]
  Epoch: [092][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7500 (0.7880)   Prec@1 79.000 (76.955)   Prec@5 96.000 (95.701)   [2018-05-02 20:09:51]
  **Train** Prec@1 76.786 Prec@5 95.634 Error@1 23.214
  **Test** Prec@1 63.170 Prec@5 87.890 Error@1 36.830

==>>[2018-05-02 20:09:59] [Epoch=093/540] [Need: 03:50:55] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [093][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.7447 (0.7447)   Prec@1 78.000 (78.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:09:59]
  Epoch: [093][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.8645 (0.7522)   Prec@1 74.000 (78.174)   Prec@5 95.000 (95.920)   [2018-05-02 20:10:10]
  Epoch: [093][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7742 (0.7799)   Prec@1 77.000 (77.269)   Prec@5 97.000 (95.701)   [2018-05-02 20:10:21]
  **Train** Prec@1 76.998 Prec@5 95.640 Error@1 23.002
  **Test** Prec@1 66.070 Prec@5 89.130 Error@1 33.930

==>>[2018-05-02 20:10:29] [Epoch=094/540] [Need: 03:50:19] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [094][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.7968 (0.7968)   Prec@1 77.000 (77.000)   Prec@5 96.000 (96.000)   [2018-05-02 20:10:29]
  Epoch: [094][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 1.0560 (0.7636)   Prec@1 70.000 (77.368)   Prec@5 92.000 (96.035)   [2018-05-02 20:10:40]
  Epoch: [094][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.4962 (0.7934)   Prec@1 87.000 (76.768)   Prec@5 98.000 (95.606)   [2018-05-02 20:10:51]
  **Train** Prec@1 76.524 Prec@5 95.502 Error@1 23.476
  **Test** Prec@1 65.920 Prec@5 89.530 Error@1 34.080

==>>[2018-05-02 20:10:59] [Epoch=095/540] [Need: 03:49:44] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [095][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.8206 (0.8206)   Prec@1 80.000 (80.000)   Prec@5 95.000 (95.000)   [2018-05-02 20:10:59]
  Epoch: [095][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.7610 (0.7604)   Prec@1 79.000 (77.786)   Prec@5 95.000 (95.920)   [2018-05-02 20:11:10]
  Epoch: [095][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8381 (0.7869)   Prec@1 77.000 (77.052)   Prec@5 97.000 (95.586)   [2018-05-02 20:11:21]
  **Train** Prec@1 76.782 Prec@5 95.504 Error@1 23.218
  **Test** Prec@1 64.620 Prec@5 88.520 Error@1 35.380

==>>[2018-05-02 20:11:29] [Epoch=096/540] [Need: 03:49:09] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [096][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.5694 (0.5694)   Prec@1 83.000 (83.000)   Prec@5 96.000 (96.000)   [2018-05-02 20:11:29]
  Epoch: [096][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.6756 (0.7604)   Prec@1 80.000 (77.607)   Prec@5 96.000 (96.149)   [2018-05-02 20:11:40]
  Epoch: [096][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9645 (0.7862)   Prec@1 76.000 (77.000)   Prec@5 95.000 (95.890)   [2018-05-02 20:11:51]
  **Train** Prec@1 76.742 Prec@5 95.718 Error@1 23.258
  **Test** Prec@1 64.240 Prec@5 88.600 Error@1 35.760

==>>[2018-05-02 20:11:59] [Epoch=097/540] [Need: 03:48:34] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [097][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.7466 (0.7466)   Prec@1 78.000 (78.000)   Prec@5 96.000 (96.000)   [2018-05-02 20:11:59]
  Epoch: [097][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8633 (0.7638)   Prec@1 77.000 (77.612)   Prec@5 93.000 (96.000)   [2018-05-02 20:12:10]
  Epoch: [097][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.7545 (0.7853)   Prec@1 80.000 (77.217)   Prec@5 97.000 (95.833)   [2018-05-02 20:12:21]
  **Train** Prec@1 76.936 Prec@5 95.754 Error@1 23.064
  **Test** Prec@1 66.200 Prec@5 89.230 Error@1 33.800

==>>[2018-05-02 20:12:29] [Epoch=098/540] [Need: 03:48:00] [learning_rate=0.100000] [Best : Accuracy=67.54, Error=32.46]
  Epoch: [098][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.7998 (0.7998)   Prec@1 79.000 (79.000)   Prec@5 94.000 (94.000)   [2018-05-02 20:12:29]
  Epoch: [098][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.5670 (0.7469)   Prec@1 83.000 (78.413)   Prec@5 99.000 (96.020)   [2018-05-02 20:12:40]
  Epoch: [098][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.7380 (0.7742)   Prec@1 77.000 (77.524)   Prec@5 96.000 (95.723)   [2018-05-02 20:12:51]
  **Train** Prec@1 77.054 Prec@5 95.616 Error@1 22.946
  **Test** Prec@1 67.610 Prec@5 89.850 Error@1 32.390

==>>[2018-05-02 20:12:59] [Epoch=099/540] [Need: 03:47:25] [learning_rate=0.100000] [Best : Accuracy=67.61, Error=32.39]
  Epoch: [099][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.8949 (0.8949)   Prec@1 74.000 (74.000)   Prec@5 93.000 (93.000)   [2018-05-02 20:12:59]
  Epoch: [099][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.6075 (0.7571)   Prec@1 86.000 (78.050)   Prec@5 98.000 (96.010)   [2018-05-02 20:13:10]
  Epoch: [099][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.5808 (0.7763)   Prec@1 84.000 (77.367)   Prec@5 98.000 (95.858)   [2018-05-02 20:13:21]
  **Train** Prec@1 77.144 Prec@5 95.678 Error@1 22.856
  **Test** Prec@1 66.290 Prec@5 89.330 Error@1 33.710

==>>[2018-05-02 20:13:29] [Epoch=100/540] [Need: 03:46:50] [learning_rate=0.100000] [Best : Accuracy=67.61, Error=32.39]
  Epoch: [100][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.7113 (0.7113)   Prec@1 74.000 (74.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:13:30]
  Epoch: [100][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3979 (0.5920)   Prec@1 92.000 (82.866)   Prec@5 100.000 (97.433)   [2018-05-02 20:13:40]
  Epoch: [100][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.4580 (0.5639)   Prec@1 86.000 (83.566)   Prec@5 97.000 (97.631)   [2018-05-02 20:13:51]
  **Train** Prec@1 83.948 Prec@5 97.714 Error@1 16.052
  **Test** Prec@1 74.930 Prec@5 93.660 Error@1 25.070

==>>[2018-05-02 20:14:00] [Epoch=101/540] [Need: 03:46:15] [learning_rate=0.010000] [Best : Accuracy=74.93, Error=25.07]
  Epoch: [101][000/500]   Time 0.092 (0.092)   Data 0.065 (0.065)   Loss 0.5402 (0.5402)   Prec@1 83.000 (83.000)   Prec@5 96.000 (96.000)   [2018-05-02 20:14:00]
  Epoch: [101][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.4590 (0.4750)   Prec@1 87.000 (86.259)   Prec@5 98.000 (98.109)   [2018-05-02 20:14:11]
  Epoch: [101][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3816 (0.4639)   Prec@1 91.000 (86.574)   Prec@5 99.000 (98.292)   [2018-05-02 20:14:22]
  **Train** Prec@1 86.506 Prec@5 98.282 Error@1 13.494
  **Test** Prec@1 75.170 Prec@5 94.030 Error@1 24.830

==>>[2018-05-02 20:14:30] [Epoch=102/540] [Need: 03:45:41] [learning_rate=0.010000] [Best : Accuracy=75.17, Error=24.83]
  Epoch: [102][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.2954 (0.2954)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:14:30]
  Epoch: [102][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4418 (0.4326)   Prec@1 89.000 (87.652)   Prec@5 98.000 (98.587)   [2018-05-02 20:14:41]
  Epoch: [102][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3080 (0.4281)   Prec@1 93.000 (87.723)   Prec@5 100.000 (98.566)   [2018-05-02 20:14:52]
  **Train** Prec@1 87.778 Prec@5 98.594 Error@1 12.222
  **Test** Prec@1 75.650 Prec@5 94.110 Error@1 24.350

==>>[2018-05-02 20:15:00] [Epoch=103/540] [Need: 03:45:06] [learning_rate=0.010000] [Best : Accuracy=75.65, Error=24.35]
  Epoch: [103][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.4200 (0.4200)   Prec@1 88.000 (88.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:15:00]
  Epoch: [103][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4425 (0.3953)   Prec@1 90.000 (88.657)   Prec@5 98.000 (98.721)   [2018-05-02 20:15:11]
  Epoch: [103][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3883 (0.3988)   Prec@1 89.000 (88.511)   Prec@5 99.000 (98.741)   [2018-05-02 20:15:22]
  **Train** Prec@1 88.462 Prec@5 98.732 Error@1 11.538
  **Test** Prec@1 75.710 Prec@5 93.880 Error@1 24.290

==>>[2018-05-02 20:15:30] [Epoch=104/540] [Need: 03:44:32] [learning_rate=0.010000] [Best : Accuracy=75.71, Error=24.29]
  Epoch: [104][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.4316 (0.4316)   Prec@1 89.000 (89.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:15:30]
  Epoch: [104][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3863 (0.3916)   Prec@1 90.000 (88.617)   Prec@5 98.000 (98.791)   [2018-05-02 20:15:41]
  Epoch: [104][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3952 (0.3825)   Prec@1 89.000 (88.975)   Prec@5 98.000 (98.853)   [2018-05-02 20:15:52]
  **Train** Prec@1 89.008 Prec@5 98.852 Error@1 10.992
  **Test** Prec@1 75.480 Prec@5 94.050 Error@1 24.520

==>>[2018-05-02 20:16:00] [Epoch=105/540] [Need: 03:43:58] [learning_rate=0.010000] [Best : Accuracy=75.71, Error=24.29]
  Epoch: [105][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.3704 (0.3704)   Prec@1 91.000 (91.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:16:00]
  Epoch: [105][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4657 (0.3681)   Prec@1 85.000 (89.239)   Prec@5 99.000 (98.965)   [2018-05-02 20:16:11]
  Epoch: [105][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2628 (0.3685)   Prec@1 93.000 (89.317)   Prec@5 100.000 (98.920)   [2018-05-02 20:16:22]
  **Train** Prec@1 89.312 Prec@5 98.924 Error@1 10.688
  **Test** Prec@1 75.940 Prec@5 94.170 Error@1 24.060

==>>[2018-05-02 20:16:30] [Epoch=106/540] [Need: 03:43:24] [learning_rate=0.010000] [Best : Accuracy=75.94, Error=24.06]
  Epoch: [106][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.4664 (0.4664)   Prec@1 82.000 (82.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:16:30]
  Epoch: [106][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3958 (0.3558)   Prec@1 87.000 (89.751)   Prec@5 99.000 (99.045)   [2018-05-02 20:16:41]
  Epoch: [106][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4404 (0.3536)   Prec@1 85.000 (89.810)   Prec@5 99.000 (99.055)   [2018-05-02 20:16:52]
  **Train** Prec@1 89.756 Prec@5 99.026 Error@1 10.244
  **Test** Prec@1 75.470 Prec@5 94.080 Error@1 24.530

==>>[2018-05-02 20:17:00] [Epoch=107/540] [Need: 03:42:50] [learning_rate=0.010000] [Best : Accuracy=75.94, Error=24.06]
  Epoch: [107][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.3408 (0.3408)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:17:00]
  Epoch: [107][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3962 (0.3363)   Prec@1 90.000 (90.299)   Prec@5 98.000 (99.149)   [2018-05-02 20:17:11]
  Epoch: [107][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.4293 (0.3426)   Prec@1 90.000 (90.032)   Prec@5 98.000 (99.100)   [2018-05-02 20:17:22]
  **Train** Prec@1 90.120 Prec@5 99.116 Error@1 9.880
  **Test** Prec@1 75.550 Prec@5 94.100 Error@1 24.450

==>>[2018-05-02 20:17:30] [Epoch=108/540] [Need: 03:42:15] [learning_rate=0.010000] [Best : Accuracy=75.94, Error=24.06]
  Epoch: [108][000/500]   Time 0.086 (0.086)   Data 0.061 (0.061)   Loss 0.3805 (0.3805)   Prec@1 88.000 (88.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:17:30]
  Epoch: [108][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2851 (0.3284)   Prec@1 92.000 (90.522)   Prec@5 99.000 (99.184)   [2018-05-02 20:17:41]
  Epoch: [108][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1878 (0.3331)   Prec@1 93.000 (90.374)   Prec@5 100.000 (99.127)   [2018-05-02 20:17:52]
  **Train** Prec@1 90.376 Prec@5 99.112 Error@1 9.624
  **Test** Prec@1 76.270 Prec@5 94.340 Error@1 23.730

==>>[2018-05-02 20:18:00] [Epoch=109/540] [Need: 03:41:42] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [109][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.4518 (0.4518)   Prec@1 87.000 (87.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:18:00]
  Epoch: [109][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3140 (0.3206)   Prec@1 92.000 (90.891)   Prec@5 98.000 (99.194)   [2018-05-02 20:18:11]
  Epoch: [109][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.2667 (0.3200)   Prec@1 93.000 (90.761)   Prec@5 99.000 (99.222)   [2018-05-02 20:18:22]
  **Train** Prec@1 90.704 Prec@5 99.232 Error@1 9.296
  **Test** Prec@1 75.970 Prec@5 94.140 Error@1 24.030

==>>[2018-05-02 20:18:30] [Epoch=110/540] [Need: 03:41:08] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [110][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.2821 (0.2821)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:18:30]
  Epoch: [110][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2456 (0.3124)   Prec@1 93.000 (91.095)   Prec@5 99.000 (99.249)   [2018-05-02 20:18:41]
  Epoch: [110][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.3908 (0.3107)   Prec@1 88.000 (91.162)   Prec@5 99.000 (99.197)   [2018-05-02 20:18:52]
  **Train** Prec@1 91.078 Prec@5 99.200 Error@1 8.922
  **Test** Prec@1 76.050 Prec@5 94.200 Error@1 23.950

==>>[2018-05-02 20:19:00] [Epoch=111/540] [Need: 03:40:34] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [111][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.3397 (0.3397)   Prec@1 92.000 (92.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:19:01]
  Epoch: [111][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1773 (0.2930)   Prec@1 96.000 (91.403)   Prec@5 100.000 (99.333)   [2018-05-02 20:19:11]
  Epoch: [111][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3502 (0.2990)   Prec@1 91.000 (91.377)   Prec@5 98.000 (99.289)   [2018-05-02 20:19:22]
  **Train** Prec@1 91.360 Prec@5 99.286 Error@1 8.640
  **Test** Prec@1 75.890 Prec@5 94.240 Error@1 24.110

==>>[2018-05-02 20:19:31] [Epoch=112/540] [Need: 03:40:00] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [112][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.2736 (0.2736)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:19:31]
  Epoch: [112][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2188 (0.2857)   Prec@1 94.000 (91.776)   Prec@5 100.000 (99.333)   [2018-05-02 20:19:42]
  Epoch: [112][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.2643 (0.2894)   Prec@1 91.000 (91.636)   Prec@5 100.000 (99.342)   [2018-05-02 20:19:52]
  **Train** Prec@1 91.636 Prec@5 99.346 Error@1 8.364
  **Test** Prec@1 75.900 Prec@5 94.260 Error@1 24.100

==>>[2018-05-02 20:20:01] [Epoch=113/540] [Need: 03:39:26] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [113][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.2210 (0.2210)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:20:01]
  Epoch: [113][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.2313 (0.2857)   Prec@1 96.000 (91.672)   Prec@5 99.000 (99.428)   [2018-05-02 20:20:12]
  Epoch: [113][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4269 (0.2948)   Prec@1 86.000 (91.299)   Prec@5 99.000 (99.379)   [2018-05-02 20:20:23]
  **Train** Prec@1 91.308 Prec@5 99.372 Error@1 8.692
  **Test** Prec@1 75.920 Prec@5 94.120 Error@1 24.080

==>>[2018-05-02 20:20:31] [Epoch=114/540] [Need: 03:38:53] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [114][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.2631 (0.2631)   Prec@1 95.000 (95.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:20:31]
  Epoch: [114][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2315 (0.2798)   Prec@1 91.000 (91.925)   Prec@5 100.000 (99.443)   [2018-05-02 20:20:42]
  Epoch: [114][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3606 (0.2740)   Prec@1 92.000 (92.120)   Prec@5 99.000 (99.491)   [2018-05-02 20:20:53]
  **Train** Prec@1 92.074 Prec@5 99.464 Error@1 7.926
  **Test** Prec@1 76.090 Prec@5 94.210 Error@1 23.910

==>>[2018-05-02 20:21:01] [Epoch=115/540] [Need: 03:38:19] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [115][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.2569 (0.2569)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:21:01]
  Epoch: [115][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2689 (0.2694)   Prec@1 91.000 (92.259)   Prec@5 100.000 (99.413)   [2018-05-02 20:21:12]
  Epoch: [115][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2746 (0.2700)   Prec@1 94.000 (92.259)   Prec@5 100.000 (99.426)   [2018-05-02 20:21:23]
  **Train** Prec@1 92.234 Prec@5 99.436 Error@1 7.766
  **Test** Prec@1 76.250 Prec@5 94.190 Error@1 23.750

==>>[2018-05-02 20:21:31] [Epoch=116/540] [Need: 03:37:46] [learning_rate=0.010000] [Best : Accuracy=76.27, Error=23.73]
  Epoch: [116][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.2690 (0.2690)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:21:31]
  Epoch: [116][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2060 (0.2624)   Prec@1 94.000 (92.557)   Prec@5 100.000 (99.532)   [2018-05-02 20:21:42]
  Epoch: [116][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2827 (0.2645)   Prec@1 92.000 (92.426)   Prec@5 100.000 (99.521)   [2018-05-02 20:21:53]
  **Train** Prec@1 92.438 Prec@5 99.512 Error@1 7.562
  **Test** Prec@1 76.370 Prec@5 94.180 Error@1 23.630

==>>[2018-05-02 20:22:01] [Epoch=117/540] [Need: 03:37:12] [learning_rate=0.010000] [Best : Accuracy=76.37, Error=23.63]
  Epoch: [117][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.2157 (0.2157)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:22:01]
  Epoch: [117][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1754 (0.2558)   Prec@1 96.000 (92.761)   Prec@5 100.000 (99.478)   [2018-05-02 20:22:12]
  Epoch: [117][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2356 (0.2614)   Prec@1 91.000 (92.526)   Prec@5 100.000 (99.481)   [2018-05-02 20:22:23]
  **Train** Prec@1 92.524 Prec@5 99.486 Error@1 7.476
  **Test** Prec@1 76.150 Prec@5 93.950 Error@1 23.850

==>>[2018-05-02 20:22:31] [Epoch=118/540] [Need: 03:36:39] [learning_rate=0.010000] [Best : Accuracy=76.37, Error=23.63]
  Epoch: [118][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.2379 (0.2379)   Prec@1 95.000 (95.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:22:31]
  Epoch: [118][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2881 (0.2500)   Prec@1 93.000 (92.821)   Prec@5 100.000 (99.572)   [2018-05-02 20:22:42]
  Epoch: [118][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2768 (0.2535)   Prec@1 90.000 (92.743)   Prec@5 99.000 (99.546)   [2018-05-02 20:22:53]
  **Train** Prec@1 92.798 Prec@5 99.554 Error@1 7.202
  **Test** Prec@1 76.570 Prec@5 94.250 Error@1 23.430

==>>[2018-05-02 20:23:01] [Epoch=119/540] [Need: 03:36:06] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [119][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.2946 (0.2946)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:23:01]
  Epoch: [119][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2515 (0.2524)   Prec@1 93.000 (92.776)   Prec@5 100.000 (99.602)   [2018-05-02 20:23:12]
  Epoch: [119][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2744 (0.2510)   Prec@1 94.000 (92.825)   Prec@5 98.000 (99.569)   [2018-05-02 20:23:23]
  **Train** Prec@1 92.840 Prec@5 99.574 Error@1 7.160
  **Test** Prec@1 76.350 Prec@5 94.210 Error@1 23.650

==>>[2018-05-02 20:23:31] [Epoch=120/540] [Need: 03:35:32] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [120][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.2147 (0.2147)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:23:31]
  Epoch: [120][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2539 (0.2474)   Prec@1 93.000 (92.935)   Prec@5 100.000 (99.622)   [2018-05-02 20:23:42]
  Epoch: [120][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2346 (0.2440)   Prec@1 92.000 (93.115)   Prec@5 99.000 (99.589)   [2018-05-02 20:23:53]
  **Train** Prec@1 93.198 Prec@5 99.594 Error@1 6.802
  **Test** Prec@1 76.120 Prec@5 94.080 Error@1 23.880

==>>[2018-05-02 20:24:01] [Epoch=121/540] [Need: 03:34:59] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [121][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.3580 (0.3580)   Prec@1 92.000 (92.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:24:02]
  Epoch: [121][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2644 (0.2315)   Prec@1 90.000 (93.448)   Prec@5 100.000 (99.692)   [2018-05-02 20:24:12]
  Epoch: [121][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3516 (0.2348)   Prec@1 91.000 (93.279)   Prec@5 98.000 (99.631)   [2018-05-02 20:24:23]
  **Train** Prec@1 93.170 Prec@5 99.620 Error@1 6.830
  **Test** Prec@1 76.200 Prec@5 94.170 Error@1 23.800

==>>[2018-05-02 20:24:32] [Epoch=122/540] [Need: 03:34:26] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [122][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.2738 (0.2738)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:24:32]
  Epoch: [122][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2615 (0.2279)   Prec@1 90.000 (93.488)   Prec@5 100.000 (99.622)   [2018-05-02 20:24:43]
  Epoch: [122][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2247 (0.2330)   Prec@1 94.000 (93.364)   Prec@5 100.000 (99.646)   [2018-05-02 20:24:53]
  **Train** Prec@1 93.380 Prec@5 99.634 Error@1 6.620
  **Test** Prec@1 76.160 Prec@5 93.950 Error@1 23.840

==>>[2018-05-02 20:25:02] [Epoch=123/540] [Need: 03:33:53] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [123][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.2407 (0.2407)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:25:02]
  Epoch: [123][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2557 (0.2237)   Prec@1 91.000 (93.766)   Prec@5 100.000 (99.627)   [2018-05-02 20:25:13]
  Epoch: [123][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2001 (0.2265)   Prec@1 92.000 (93.708)   Prec@5 100.000 (99.663)   [2018-05-02 20:25:24]
  **Train** Prec@1 93.630 Prec@5 99.650 Error@1 6.370
  **Test** Prec@1 76.200 Prec@5 94.230 Error@1 23.800

==>>[2018-05-02 20:25:32] [Epoch=124/540] [Need: 03:33:20] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [124][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.1673 (0.1673)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:25:32]
  Epoch: [124][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3612 (0.2233)   Prec@1 90.000 (93.736)   Prec@5 98.000 (99.607)   [2018-05-02 20:25:43]
  Epoch: [124][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1916 (0.2253)   Prec@1 95.000 (93.579)   Prec@5 99.000 (99.621)   [2018-05-02 20:25:54]
  **Train** Prec@1 93.588 Prec@5 99.642 Error@1 6.412
  **Test** Prec@1 76.410 Prec@5 93.950 Error@1 23.590

==>>[2018-05-02 20:26:02] [Epoch=125/540] [Need: 03:32:47] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [125][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1477 (0.1477)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:26:02]
  Epoch: [125][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3296 (0.2148)   Prec@1 91.000 (94.005)   Prec@5 100.000 (99.672)   [2018-05-02 20:26:13]
  Epoch: [125][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1132 (0.2170)   Prec@1 98.000 (93.880)   Prec@5 100.000 (99.718)   [2018-05-02 20:26:24]
  **Train** Prec@1 93.822 Prec@5 99.700 Error@1 6.178
  **Test** Prec@1 76.250 Prec@5 94.080 Error@1 23.750

==>>[2018-05-02 20:26:32] [Epoch=126/540] [Need: 03:32:14] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [126][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.2330 (0.2330)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:26:32]
  Epoch: [126][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2736 (0.2163)   Prec@1 94.000 (94.005)   Prec@5 99.000 (99.652)   [2018-05-02 20:26:43]
  Epoch: [126][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1322 (0.2174)   Prec@1 97.000 (93.928)   Prec@5 100.000 (99.626)   [2018-05-02 20:26:54]
  **Train** Prec@1 93.920 Prec@5 99.614 Error@1 6.080
  **Test** Prec@1 76.300 Prec@5 94.050 Error@1 23.700

==>>[2018-05-02 20:27:02] [Epoch=127/540] [Need: 03:31:41] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [127][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1657 (0.1657)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:27:02]
  Epoch: [127][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2285 (0.2070)   Prec@1 94.000 (94.239)   Prec@5 99.000 (99.721)   [2018-05-02 20:27:13]
  Epoch: [127][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2455 (0.2127)   Prec@1 93.000 (94.012)   Prec@5 99.000 (99.713)   [2018-05-02 20:27:24]
  **Train** Prec@1 93.952 Prec@5 99.704 Error@1 6.048
  **Test** Prec@1 76.560 Prec@5 94.010 Error@1 23.440

==>>[2018-05-02 20:27:32] [Epoch=128/540] [Need: 03:31:08] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [128][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.3638 (0.3638)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:27:32]
  Epoch: [128][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2386 (0.2106)   Prec@1 94.000 (94.020)   Prec@5 100.000 (99.697)   [2018-05-02 20:27:43]
  Epoch: [128][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1976 (0.2124)   Prec@1 96.000 (93.978)   Prec@5 99.000 (99.711)   [2018-05-02 20:27:54]
  **Train** Prec@1 93.950 Prec@5 99.690 Error@1 6.050
  **Test** Prec@1 76.340 Prec@5 94.110 Error@1 23.660

==>>[2018-05-02 20:28:02] [Epoch=129/540] [Need: 03:30:35] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [129][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1791 (0.1791)   Prec@1 99.000 (99.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:28:02]
  Epoch: [129][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1292 (0.1999)   Prec@1 95.000 (94.483)   Prec@5 100.000 (99.677)   [2018-05-02 20:28:13]
  Epoch: [129][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1350 (0.2024)   Prec@1 99.000 (94.441)   Prec@5 100.000 (99.673)   [2018-05-02 20:28:24]
  **Train** Prec@1 94.402 Prec@5 99.684 Error@1 5.598
  **Test** Prec@1 75.750 Prec@5 93.890 Error@1 24.250

==>>[2018-05-02 20:28:32] [Epoch=130/540] [Need: 03:30:02] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [130][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.2342 (0.2342)   Prec@1 94.000 (94.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:28:32]
  Epoch: [130][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2565 (0.1990)   Prec@1 95.000 (94.373)   Prec@5 98.000 (99.746)   [2018-05-02 20:28:43]
  Epoch: [130][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2118 (0.2036)   Prec@1 95.000 (94.289)   Prec@5 100.000 (99.723)   [2018-05-02 20:28:54]
  **Train** Prec@1 94.324 Prec@5 99.720 Error@1 5.676
  **Test** Prec@1 76.040 Prec@5 94.050 Error@1 23.960

==>>[2018-05-02 20:29:02] [Epoch=131/540] [Need: 03:29:29] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [131][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.2902 (0.2902)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:29:02]
  Epoch: [131][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1910 (0.1955)   Prec@1 94.000 (94.458)   Prec@5 100.000 (99.796)   [2018-05-02 20:29:13]
  Epoch: [131][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2071 (0.1964)   Prec@1 91.000 (94.519)   Prec@5 100.000 (99.781)   [2018-05-02 20:29:24]
  **Train** Prec@1 94.568 Prec@5 99.772 Error@1 5.432
  **Test** Prec@1 76.270 Prec@5 93.900 Error@1 23.730

==>>[2018-05-02 20:29:32] [Epoch=132/540] [Need: 03:28:57] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [132][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.3120 (0.3120)   Prec@1 91.000 (91.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:29:32]
  Epoch: [132][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2011 (0.1931)   Prec@1 94.000 (94.607)   Prec@5 100.000 (99.751)   [2018-05-02 20:29:43]
  Epoch: [132][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1903 (0.1939)   Prec@1 95.000 (94.556)   Prec@5 100.000 (99.761)   [2018-05-02 20:29:54]
  **Train** Prec@1 94.528 Prec@5 99.754 Error@1 5.472
  **Test** Prec@1 76.320 Prec@5 93.910 Error@1 23.680

==>>[2018-05-02 20:30:02] [Epoch=133/540] [Need: 03:28:24] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [133][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1598 (0.1598)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:30:03]
  Epoch: [133][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2687 (0.1916)   Prec@1 94.000 (94.622)   Prec@5 98.000 (99.766)   [2018-05-02 20:30:13]
  Epoch: [133][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1353 (0.1941)   Prec@1 97.000 (94.496)   Prec@5 100.000 (99.773)   [2018-05-02 20:30:24]
  **Train** Prec@1 94.466 Prec@5 99.776 Error@1 5.534
  **Test** Prec@1 76.090 Prec@5 94.190 Error@1 23.910

==>>[2018-05-02 20:30:33] [Epoch=134/540] [Need: 03:27:51] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [134][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.1323 (0.1323)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:30:33]
  Epoch: [134][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1686 (0.1840)   Prec@1 97.000 (94.881)   Prec@5 100.000 (99.846)   [2018-05-02 20:30:44]
  Epoch: [134][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1688 (0.1872)   Prec@1 95.000 (94.791)   Prec@5 100.000 (99.803)   [2018-05-02 20:30:54]
  **Train** Prec@1 94.802 Prec@5 99.790 Error@1 5.198
  **Test** Prec@1 76.440 Prec@5 93.930 Error@1 23.560

==>>[2018-05-02 20:31:03] [Epoch=135/540] [Need: 03:27:19] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [135][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.2049 (0.2049)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:31:03]
  Epoch: [135][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2369 (0.1808)   Prec@1 93.000 (94.950)   Prec@5 100.000 (99.801)   [2018-05-02 20:31:14]
  Epoch: [135][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1462 (0.1866)   Prec@1 95.000 (94.776)   Prec@5 99.000 (99.778)   [2018-05-02 20:31:25]
  **Train** Prec@1 94.772 Prec@5 99.768 Error@1 5.228
  **Test** Prec@1 76.150 Prec@5 93.860 Error@1 23.850

==>>[2018-05-02 20:31:33] [Epoch=136/540] [Need: 03:26:46] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [136][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1882 (0.1882)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:31:33]
  Epoch: [136][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3042 (0.1823)   Prec@1 91.000 (94.866)   Prec@5 100.000 (99.786)   [2018-05-02 20:31:44]
  Epoch: [136][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1842 (0.1818)   Prec@1 97.000 (94.993)   Prec@5 99.000 (99.793)   [2018-05-02 20:31:55]
  **Train** Prec@1 94.892 Prec@5 99.786 Error@1 5.108
  **Test** Prec@1 76.310 Prec@5 93.740 Error@1 23.690

==>>[2018-05-02 20:32:03] [Epoch=137/540] [Need: 03:26:13] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [137][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.1566 (0.1566)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:32:03]
  Epoch: [137][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1499 (0.1790)   Prec@1 96.000 (95.119)   Prec@5 100.000 (99.811)   [2018-05-02 20:32:14]
  Epoch: [137][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1474 (0.1812)   Prec@1 95.000 (95.080)   Prec@5 100.000 (99.813)   [2018-05-02 20:32:25]
  **Train** Prec@1 95.096 Prec@5 99.802 Error@1 4.904
  **Test** Prec@1 76.090 Prec@5 94.040 Error@1 23.910

==>>[2018-05-02 20:32:33] [Epoch=138/540] [Need: 03:25:41] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [138][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1671 (0.1671)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:32:33]
  Epoch: [138][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1134 (0.1755)   Prec@1 97.000 (95.294)   Prec@5 100.000 (99.786)   [2018-05-02 20:32:44]
  Epoch: [138][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1857 (0.1778)   Prec@1 97.000 (95.212)   Prec@5 99.000 (99.771)   [2018-05-02 20:32:55]
  **Train** Prec@1 95.122 Prec@5 99.788 Error@1 4.878
  **Test** Prec@1 76.380 Prec@5 93.560 Error@1 23.620

==>>[2018-05-02 20:33:03] [Epoch=139/540] [Need: 03:25:08] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [139][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.2067 (0.2067)   Prec@1 94.000 (94.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:33:03]
  Epoch: [139][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1536 (0.1723)   Prec@1 94.000 (95.179)   Prec@5 100.000 (99.841)   [2018-05-02 20:33:14]
  Epoch: [139][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2616 (0.1783)   Prec@1 93.000 (95.067)   Prec@5 100.000 (99.830)   [2018-05-02 20:33:25]
  **Train** Prec@1 95.038 Prec@5 99.820 Error@1 4.962
  **Test** Prec@1 76.180 Prec@5 93.750 Error@1 23.820

==>>[2018-05-02 20:33:33] [Epoch=140/540] [Need: 03:24:36] [learning_rate=0.010000] [Best : Accuracy=76.57, Error=23.43]
  Epoch: [140][000/500]   Time 0.088 (0.088)   Data 0.062 (0.062)   Loss 0.1813 (0.1813)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:33:33]
  Epoch: [140][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2330 (0.1773)   Prec@1 94.000 (95.020)   Prec@5 99.000 (99.826)   [2018-05-02 20:33:44]
  Epoch: [140][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1815 (0.1780)   Prec@1 95.000 (95.070)   Prec@5 100.000 (99.820)   [2018-05-02 20:33:55]
  **Train** Prec@1 95.172 Prec@5 99.824 Error@1 4.828
  **Test** Prec@1 76.750 Prec@5 94.000 Error@1 23.250

==>>[2018-05-02 20:34:03] [Epoch=141/540] [Need: 03:24:04] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [141][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.1590 (0.1590)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:34:03]
  Epoch: [141][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1087 (0.1708)   Prec@1 98.000 (95.413)   Prec@5 100.000 (99.796)   [2018-05-02 20:34:14]
  Epoch: [141][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.2028 (0.1698)   Prec@1 95.000 (95.429)   Prec@5 100.000 (99.800)   [2018-05-02 20:34:25]
  **Train** Prec@1 95.380 Prec@5 99.808 Error@1 4.620
  **Test** Prec@1 76.390 Prec@5 93.860 Error@1 23.610

==>>[2018-05-02 20:34:33] [Epoch=142/540] [Need: 03:23:32] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [142][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1825 (0.1825)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:34:34]
  Epoch: [142][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2504 (0.1735)   Prec@1 94.000 (95.229)   Prec@5 99.000 (99.806)   [2018-05-02 20:34:44]
  Epoch: [142][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0650 (0.1747)   Prec@1 99.000 (95.204)   Prec@5 100.000 (99.778)   [2018-05-02 20:34:55]
  **Train** Prec@1 95.184 Prec@5 99.792 Error@1 4.816
  **Test** Prec@1 76.340 Prec@5 93.950 Error@1 23.660

==>>[2018-05-02 20:35:03] [Epoch=143/540] [Need: 03:23:00] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [143][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.1276 (0.1276)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:35:04]
  Epoch: [143][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1572 (0.1681)   Prec@1 97.000 (95.458)   Prec@5 100.000 (99.766)   [2018-05-02 20:35:15]
  Epoch: [143][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2509 (0.1667)   Prec@1 93.000 (95.399)   Prec@5 100.000 (99.815)   [2018-05-02 20:35:25]
  **Train** Prec@1 95.396 Prec@5 99.814 Error@1 4.604
  **Test** Prec@1 76.390 Prec@5 94.080 Error@1 23.610

==>>[2018-05-02 20:35:34] [Epoch=144/540] [Need: 03:22:27] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [144][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.1487 (0.1487)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:35:34]
  Epoch: [144][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2308 (0.1548)   Prec@1 91.000 (95.920)   Prec@5 99.000 (99.886)   [2018-05-02 20:35:45]
  Epoch: [144][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1354 (0.1609)   Prec@1 96.000 (95.623)   Prec@5 100.000 (99.853)   [2018-05-02 20:35:56]
  **Train** Prec@1 95.524 Prec@5 99.848 Error@1 4.476
  **Test** Prec@1 76.020 Prec@5 93.980 Error@1 23.980

==>>[2018-05-02 20:36:04] [Epoch=145/540] [Need: 03:21:55] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [145][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.1929 (0.1929)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:36:04]
  Epoch: [145][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1987 (0.1660)   Prec@1 93.000 (95.338)   Prec@5 100.000 (99.886)   [2018-05-02 20:36:15]
  Epoch: [145][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1342 (0.1691)   Prec@1 97.000 (95.219)   Prec@5 100.000 (99.863)   [2018-05-02 20:36:26]
  **Train** Prec@1 95.256 Prec@5 99.844 Error@1 4.744
  **Test** Prec@1 76.390 Prec@5 93.960 Error@1 23.610

==>>[2018-05-02 20:36:34] [Epoch=146/540] [Need: 03:21:23] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [146][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1174 (0.1174)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:36:34]
  Epoch: [146][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1161 (0.1545)   Prec@1 100.000 (95.876)   Prec@5 100.000 (99.861)   [2018-05-02 20:36:45]
  Epoch: [146][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0510 (0.1573)   Prec@1 99.000 (95.813)   Prec@5 100.000 (99.848)   [2018-05-02 20:36:56]
  **Train** Prec@1 95.728 Prec@5 99.856 Error@1 4.272
  **Test** Prec@1 75.990 Prec@5 93.820 Error@1 24.010

==>>[2018-05-02 20:37:04] [Epoch=147/540] [Need: 03:20:51] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [147][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1752 (0.1752)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:37:04]
  Epoch: [147][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1406 (0.1559)   Prec@1 96.000 (95.766)   Prec@5 100.000 (99.905)   [2018-05-02 20:37:15]
  Epoch: [147][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1577 (0.1594)   Prec@1 95.000 (95.706)   Prec@5 100.000 (99.873)   [2018-05-02 20:37:26]
  **Train** Prec@1 95.664 Prec@5 99.860 Error@1 4.336
  **Test** Prec@1 76.000 Prec@5 93.910 Error@1 24.000

==>>[2018-05-02 20:37:34] [Epoch=148/540] [Need: 03:20:18] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [148][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1101 (0.1101)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:37:34]
  Epoch: [148][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0968 (0.1451)   Prec@1 96.000 (96.080)   Prec@5 100.000 (99.856)   [2018-05-02 20:37:45]
  Epoch: [148][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0880 (0.1525)   Prec@1 99.000 (95.860)   Prec@5 100.000 (99.850)   [2018-05-02 20:37:56]
  **Train** Prec@1 95.848 Prec@5 99.844 Error@1 4.152
  **Test** Prec@1 76.640 Prec@5 94.070 Error@1 23.360

==>>[2018-05-02 20:38:04] [Epoch=149/540] [Need: 03:19:46] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [149][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1781 (0.1781)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:38:04]
  Epoch: [149][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0908 (0.1501)   Prec@1 99.000 (95.995)   Prec@5 100.000 (99.866)   [2018-05-02 20:38:15]
  Epoch: [149][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1406 (0.1530)   Prec@1 97.000 (95.923)   Prec@5 100.000 (99.850)   [2018-05-02 20:38:26]
  **Train** Prec@1 95.836 Prec@5 99.858 Error@1 4.164
  **Test** Prec@1 76.140 Prec@5 93.640 Error@1 23.860

==>>[2018-05-02 20:38:34] [Epoch=150/540] [Need: 03:19:14] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [150][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.1483 (0.1483)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:38:34]
  Epoch: [150][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1659 (0.1543)   Prec@1 97.000 (95.731)   Prec@5 100.000 (99.910)   [2018-05-02 20:38:45]
  Epoch: [150][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1318 (0.1531)   Prec@1 94.000 (95.863)   Prec@5 100.000 (99.853)   [2018-05-02 20:38:56]
  **Train** Prec@1 95.802 Prec@5 99.860 Error@1 4.198
  **Test** Prec@1 76.310 Prec@5 93.840 Error@1 23.690

==>>[2018-05-02 20:39:04] [Epoch=151/540] [Need: 03:18:42] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [151][000/500]   Time 0.100 (0.100)   Data 0.075 (0.075)   Loss 0.1318 (0.1318)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:39:04]
  Epoch: [151][200/500]   Time 0.055 (0.055)   Data 0.000 (0.001)   Loss 0.1828 (0.1429)   Prec@1 92.000 (96.284)   Prec@5 100.000 (99.925)   [2018-05-02 20:39:15]
  Epoch: [151][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.1220 (0.1492)   Prec@1 98.000 (96.000)   Prec@5 100.000 (99.885)   [2018-05-02 20:39:26]
  **Train** Prec@1 95.976 Prec@5 99.896 Error@1 4.024
  **Test** Prec@1 76.230 Prec@5 93.790 Error@1 23.770

==>>[2018-05-02 20:39:34] [Epoch=152/540] [Need: 03:18:10] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [152][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1595 (0.1595)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:39:34]
  Epoch: [152][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1040 (0.1524)   Prec@1 97.000 (95.896)   Prec@5 100.000 (99.846)   [2018-05-02 20:39:45]
  Epoch: [152][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1499 (0.1521)   Prec@1 98.000 (95.853)   Prec@5 100.000 (99.858)   [2018-05-02 20:39:56]
  **Train** Prec@1 95.890 Prec@5 99.862 Error@1 4.110
  **Test** Prec@1 76.320 Prec@5 93.780 Error@1 23.680

==>>[2018-05-02 20:40:05] [Epoch=153/540] [Need: 03:17:38] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [153][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.1866 (0.1866)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:40:05]
  Epoch: [153][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1336 (0.1480)   Prec@1 98.000 (95.851)   Prec@5 100.000 (99.896)   [2018-05-02 20:40:16]
  Epoch: [153][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1430 (0.1523)   Prec@1 97.000 (95.840)   Prec@5 100.000 (99.893)   [2018-05-02 20:40:27]
  **Train** Prec@1 95.818 Prec@5 99.890 Error@1 4.182
  **Test** Prec@1 76.280 Prec@5 93.880 Error@1 23.720

==>>[2018-05-02 20:40:35] [Epoch=154/540] [Need: 03:17:06] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [154][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.1906 (0.1906)   Prec@1 97.000 (97.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:40:35]
  Epoch: [154][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0950 (0.1443)   Prec@1 97.000 (96.174)   Prec@5 100.000 (99.881)   [2018-05-02 20:40:46]
  Epoch: [154][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1361 (0.1465)   Prec@1 97.000 (96.200)   Prec@5 99.000 (99.848)   [2018-05-02 20:40:57]
  **Train** Prec@1 96.128 Prec@5 99.854 Error@1 3.872
  **Test** Prec@1 76.650 Prec@5 94.010 Error@1 23.350

==>>[2018-05-02 20:41:05] [Epoch=155/540] [Need: 03:16:34] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [155][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0813 (0.0813)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:41:05]
  Epoch: [155][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0972 (0.1450)   Prec@1 99.000 (96.045)   Prec@5 100.000 (99.871)   [2018-05-02 20:41:16]
  Epoch: [155][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1261 (0.1484)   Prec@1 97.000 (95.908)   Prec@5 100.000 (99.873)   [2018-05-02 20:41:27]
  **Train** Prec@1 95.916 Prec@5 99.876 Error@1 4.084
  **Test** Prec@1 76.270 Prec@5 93.840 Error@1 23.730

==>>[2018-05-02 20:41:35] [Epoch=156/540] [Need: 03:16:02] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [156][000/500]   Time 0.088 (0.088)   Data 0.062 (0.062)   Loss 0.1183 (0.1183)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:41:35]
  Epoch: [156][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1831 (0.1421)   Prec@1 96.000 (96.318)   Prec@5 100.000 (99.856)   [2018-05-02 20:41:46]
  Epoch: [156][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1319 (0.1439)   Prec@1 97.000 (96.182)   Prec@5 100.000 (99.883)   [2018-05-02 20:41:57]
  **Train** Prec@1 96.120 Prec@5 99.892 Error@1 3.880
  **Test** Prec@1 75.840 Prec@5 93.720 Error@1 24.160

==>>[2018-05-02 20:42:05] [Epoch=157/540] [Need: 03:15:30] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [157][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.1238 (0.1238)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:42:05]
  Epoch: [157][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1680 (0.1471)   Prec@1 94.000 (96.109)   Prec@5 100.000 (99.841)   [2018-05-02 20:42:16]
  Epoch: [157][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1259 (0.1495)   Prec@1 97.000 (96.035)   Prec@5 100.000 (99.838)   [2018-05-02 20:42:27]
  **Train** Prec@1 95.984 Prec@5 99.844 Error@1 4.016
  **Test** Prec@1 76.220 Prec@5 93.740 Error@1 23.780

==>>[2018-05-02 20:42:35] [Epoch=158/540] [Need: 03:14:58] [learning_rate=0.010000] [Best : Accuracy=76.75, Error=23.25]
  Epoch: [158][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0765 (0.0765)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:42:35]
  Epoch: [158][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1912 (0.1371)   Prec@1 97.000 (96.303)   Prec@5 99.000 (99.866)   [2018-05-02 20:42:46]
  Epoch: [158][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1183 (0.1396)   Prec@1 97.000 (96.229)   Prec@5 100.000 (99.883)   [2018-05-02 20:42:57]
  **Train** Prec@1 96.212 Prec@5 99.880 Error@1 3.788
  **Test** Prec@1 76.890 Prec@5 93.910 Error@1 23.110

==>>[2018-05-02 20:43:05] [Epoch=159/540] [Need: 03:14:26] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [159][000/500]   Time 0.087 (0.087)   Data 0.062 (0.062)   Loss 0.1773 (0.1773)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:43:05]
  Epoch: [159][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1435 (0.1422)   Prec@1 96.000 (96.289)   Prec@5 100.000 (99.920)   [2018-05-02 20:43:16]
  Epoch: [159][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1708 (0.1425)   Prec@1 96.000 (96.219)   Prec@5 99.000 (99.893)   [2018-05-02 20:43:27]
  **Train** Prec@1 96.172 Prec@5 99.900 Error@1 3.828
  **Test** Prec@1 76.260 Prec@5 93.810 Error@1 23.740

==>>[2018-05-02 20:43:35] [Epoch=160/540] [Need: 03:13:54] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [160][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.0793 (0.0793)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:43:35]
  Epoch: [160][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1754 (0.1406)   Prec@1 94.000 (96.050)   Prec@5 99.000 (99.896)   [2018-05-02 20:43:46]
  Epoch: [160][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1853 (0.1415)   Prec@1 95.000 (96.167)   Prec@5 100.000 (99.890)   [2018-05-02 20:43:57]
  **Train** Prec@1 96.164 Prec@5 99.894 Error@1 3.836
  **Test** Prec@1 76.220 Prec@5 93.770 Error@1 23.780

==>>[2018-05-02 20:44:05] [Epoch=161/540] [Need: 03:13:23] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [161][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.1036 (0.1036)   Prec@1 98.000 (98.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:44:05]
  Epoch: [161][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1696 (0.1387)   Prec@1 95.000 (96.338)   Prec@5 100.000 (99.900)   [2018-05-02 20:44:16]
  Epoch: [161][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1390 (0.1407)   Prec@1 94.000 (96.224)   Prec@5 100.000 (99.893)   [2018-05-02 20:44:27]
  **Train** Prec@1 96.238 Prec@5 99.898 Error@1 3.762
  **Test** Prec@1 76.140 Prec@5 93.930 Error@1 23.860

==>>[2018-05-02 20:44:35] [Epoch=162/540] [Need: 03:12:51] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [162][000/500]   Time 0.093 (0.093)   Data 0.067 (0.067)   Loss 0.1691 (0.1691)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:44:35]
  Epoch: [162][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1763 (0.1317)   Prec@1 95.000 (96.657)   Prec@5 99.000 (99.910)   [2018-05-02 20:44:46]
  Epoch: [162][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1584 (0.1340)   Prec@1 95.000 (96.534)   Prec@5 100.000 (99.898)   [2018-05-02 20:44:57]
  **Train** Prec@1 96.518 Prec@5 99.908 Error@1 3.482
  **Test** Prec@1 76.150 Prec@5 93.800 Error@1 23.850

==>>[2018-05-02 20:45:05] [Epoch=163/540] [Need: 03:12:19] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [163][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1194 (0.1194)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:45:05]
  Epoch: [163][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1638 (0.1393)   Prec@1 95.000 (96.308)   Prec@5 100.000 (99.920)   [2018-05-02 20:45:16]
  Epoch: [163][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0841 (0.1391)   Prec@1 99.000 (96.332)   Prec@5 100.000 (99.910)   [2018-05-02 20:45:27]
  **Train** Prec@1 96.220 Prec@5 99.896 Error@1 3.780
  **Test** Prec@1 75.950 Prec@5 93.460 Error@1 24.050

==>>[2018-05-02 20:45:35] [Epoch=164/540] [Need: 03:11:47] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [164][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.1154 (0.1154)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:45:35]
  Epoch: [164][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0598 (0.1313)   Prec@1 100.000 (96.592)   Prec@5 100.000 (99.881)   [2018-05-02 20:45:46]
  Epoch: [164][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1439 (0.1357)   Prec@1 94.000 (96.374)   Prec@5 100.000 (99.853)   [2018-05-02 20:45:57]
  **Train** Prec@1 96.328 Prec@5 99.862 Error@1 3.672
  **Test** Prec@1 75.950 Prec@5 93.620 Error@1 24.050

==>>[2018-05-02 20:46:06] [Epoch=165/540] [Need: 03:11:15] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [165][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0989 (0.0989)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:46:06]
  Epoch: [165][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1443 (0.1389)   Prec@1 97.000 (96.438)   Prec@5 100.000 (99.910)   [2018-05-02 20:46:17]
  Epoch: [165][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1452 (0.1360)   Prec@1 97.000 (96.494)   Prec@5 100.000 (99.913)   [2018-05-02 20:46:28]
  **Train** Prec@1 96.458 Prec@5 99.912 Error@1 3.542
  **Test** Prec@1 76.140 Prec@5 93.450 Error@1 23.860

==>>[2018-05-02 20:46:36] [Epoch=166/540] [Need: 03:10:44] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [166][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1037 (0.1037)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:46:36]
  Epoch: [166][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1521 (0.1268)   Prec@1 95.000 (96.587)   Prec@5 100.000 (99.871)   [2018-05-02 20:46:47]
  Epoch: [166][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0905 (0.1312)   Prec@1 98.000 (96.531)   Prec@5 100.000 (99.898)   [2018-05-02 20:46:58]
  **Train** Prec@1 96.526 Prec@5 99.900 Error@1 3.474
  **Test** Prec@1 76.050 Prec@5 93.580 Error@1 23.950

==>>[2018-05-02 20:47:06] [Epoch=167/540] [Need: 03:10:12] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [167][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.1471 (0.1471)   Prec@1 97.000 (97.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:47:06]
  Epoch: [167][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1251 (0.1301)   Prec@1 96.000 (96.731)   Prec@5 100.000 (99.891)   [2018-05-02 20:47:17]
  Epoch: [167][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0890 (0.1352)   Prec@1 98.000 (96.426)   Prec@5 100.000 (99.898)   [2018-05-02 20:47:28]
  **Train** Prec@1 96.364 Prec@5 99.904 Error@1 3.636
  **Test** Prec@1 76.140 Prec@5 93.630 Error@1 23.860

==>>[2018-05-02 20:47:36] [Epoch=168/540] [Need: 03:09:40] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [168][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.1757 (0.1757)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:47:36]
  Epoch: [168][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1965 (0.1335)   Prec@1 95.000 (96.478)   Prec@5 100.000 (99.886)   [2018-05-02 20:47:47]
  Epoch: [168][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2082 (0.1379)   Prec@1 94.000 (96.317)   Prec@5 100.000 (99.878)   [2018-05-02 20:47:58]
  **Train** Prec@1 96.372 Prec@5 99.890 Error@1 3.628
  **Test** Prec@1 76.250 Prec@5 93.650 Error@1 23.750

==>>[2018-05-02 20:48:06] [Epoch=169/540] [Need: 03:09:08] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [169][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.1371 (0.1371)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:48:06]
  Epoch: [169][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1049 (0.1223)   Prec@1 97.000 (96.990)   Prec@5 100.000 (99.876)   [2018-05-02 20:48:17]
  Epoch: [169][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1290 (0.1262)   Prec@1 98.000 (96.870)   Prec@5 99.000 (99.888)   [2018-05-02 20:48:28]
  **Train** Prec@1 96.710 Prec@5 99.878 Error@1 3.290
  **Test** Prec@1 76.210 Prec@5 93.690 Error@1 23.790

==>>[2018-05-02 20:48:36] [Epoch=170/540] [Need: 03:08:37] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [170][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.2339 (0.2339)   Prec@1 93.000 (93.000)   Prec@5 98.000 (98.000)   [2018-05-02 20:48:36]
  Epoch: [170][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0742 (0.1267)   Prec@1 99.000 (96.687)   Prec@5 100.000 (99.905)   [2018-05-02 20:48:47]
  Epoch: [170][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1304 (0.1329)   Prec@1 96.000 (96.526)   Prec@5 100.000 (99.885)   [2018-05-02 20:48:58]
  **Train** Prec@1 96.464 Prec@5 99.886 Error@1 3.536
  **Test** Prec@1 76.140 Prec@5 93.810 Error@1 23.860

==>>[2018-05-02 20:49:06] [Epoch=171/540] [Need: 03:08:05] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [171][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.1078 (0.1078)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:49:06]
  Epoch: [171][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1179 (0.1285)   Prec@1 97.000 (96.711)   Prec@5 100.000 (99.935)   [2018-05-02 20:49:17]
  Epoch: [171][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1745 (0.1322)   Prec@1 96.000 (96.594)   Prec@5 100.000 (99.908)   [2018-05-02 20:49:28]
  **Train** Prec@1 96.568 Prec@5 99.914 Error@1 3.432
  **Test** Prec@1 75.770 Prec@5 93.760 Error@1 24.230

==>>[2018-05-02 20:49:36] [Epoch=172/540] [Need: 03:07:33] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [172][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1679 (0.1679)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:49:36]
  Epoch: [172][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0704 (0.1317)   Prec@1 100.000 (96.478)   Prec@5 100.000 (99.896)   [2018-05-02 20:49:47]
  Epoch: [172][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1296 (0.1360)   Prec@1 95.000 (96.332)   Prec@5 100.000 (99.888)   [2018-05-02 20:49:58]
  **Train** Prec@1 96.282 Prec@5 99.888 Error@1 3.718
  **Test** Prec@1 76.390 Prec@5 93.580 Error@1 23.610

==>>[2018-05-02 20:50:06] [Epoch=173/540] [Need: 03:07:02] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [173][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.2065 (0.2065)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:50:06]
  Epoch: [173][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1073 (0.1303)   Prec@1 95.000 (96.493)   Prec@5 100.000 (99.945)   [2018-05-02 20:50:17]
  Epoch: [173][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1429 (0.1324)   Prec@1 96.000 (96.476)   Prec@5 100.000 (99.928)   [2018-05-02 20:50:28]
  **Train** Prec@1 96.538 Prec@5 99.920 Error@1 3.462
  **Test** Prec@1 76.210 Prec@5 93.680 Error@1 23.790

==>>[2018-05-02 20:50:36] [Epoch=174/540] [Need: 03:06:30] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [174][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0792 (0.0792)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:50:36]
  Epoch: [174][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1000 (0.1280)   Prec@1 97.000 (96.672)   Prec@5 100.000 (99.910)   [2018-05-02 20:50:47]
  Epoch: [174][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1045 (0.1295)   Prec@1 98.000 (96.641)   Prec@5 100.000 (99.910)   [2018-05-02 20:50:58]
  **Train** Prec@1 96.618 Prec@5 99.904 Error@1 3.382
  **Test** Prec@1 76.080 Prec@5 93.570 Error@1 23.920

==>>[2018-05-02 20:51:06] [Epoch=175/540] [Need: 03:05:59] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [175][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.1426 (0.1426)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:51:06]
  Epoch: [175][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1074 (0.1259)   Prec@1 95.000 (96.547)   Prec@5 100.000 (99.891)   [2018-05-02 20:51:17]
  Epoch: [175][400/500]   Time 0.060 (0.055)   Data 0.000 (0.000)   Loss 0.1980 (0.1263)   Prec@1 96.000 (96.643)   Prec@5 99.000 (99.900)   [2018-05-02 20:51:28]
  **Train** Prec@1 96.622 Prec@5 99.892 Error@1 3.378
  **Test** Prec@1 76.340 Prec@5 93.860 Error@1 23.660

==>>[2018-05-02 20:51:36] [Epoch=176/540] [Need: 03:05:27] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [176][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.1534 (0.1534)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:51:37]
  Epoch: [176][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1576 (0.1239)   Prec@1 97.000 (96.836)   Prec@5 100.000 (99.876)   [2018-05-02 20:51:47]
  Epoch: [176][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1967 (0.1262)   Prec@1 94.000 (96.778)   Prec@5 100.000 (99.905)   [2018-05-02 20:51:58]
  **Train** Prec@1 96.734 Prec@5 99.904 Error@1 3.266
  **Test** Prec@1 76.100 Prec@5 93.340 Error@1 23.900

==>>[2018-05-02 20:52:07] [Epoch=177/540] [Need: 03:04:55] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [177][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.1514 (0.1514)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:52:07]
  Epoch: [177][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1690 (0.1260)   Prec@1 93.000 (96.751)   Prec@5 100.000 (99.920)   [2018-05-02 20:52:18]
  Epoch: [177][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0505 (0.1283)   Prec@1 99.000 (96.606)   Prec@5 100.000 (99.935)   [2018-05-02 20:52:29]
  **Train** Prec@1 96.562 Prec@5 99.926 Error@1 3.438
  **Test** Prec@1 76.300 Prec@5 93.420 Error@1 23.700

==>>[2018-05-02 20:52:37] [Epoch=178/540] [Need: 03:04:24] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [178][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0947 (0.0947)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:52:37]
  Epoch: [178][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1618 (0.1277)   Prec@1 97.000 (96.632)   Prec@5 99.000 (99.900)   [2018-05-02 20:52:48]
  Epoch: [178][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1378 (0.1277)   Prec@1 97.000 (96.681)   Prec@5 100.000 (99.895)   [2018-05-02 20:52:59]
  **Train** Prec@1 96.650 Prec@5 99.900 Error@1 3.350
  **Test** Prec@1 76.230 Prec@5 93.480 Error@1 23.770

==>>[2018-05-02 20:53:07] [Epoch=179/540] [Need: 03:03:52] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [179][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.1373 (0.1373)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:53:07]
  Epoch: [179][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1288 (0.1276)   Prec@1 94.000 (96.662)   Prec@5 100.000 (99.896)   [2018-05-02 20:53:18]
  Epoch: [179][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1853 (0.1299)   Prec@1 97.000 (96.569)   Prec@5 100.000 (99.903)   [2018-05-02 20:53:29]
  **Train** Prec@1 96.566 Prec@5 99.900 Error@1 3.434
  **Test** Prec@1 75.870 Prec@5 93.440 Error@1 24.130

==>>[2018-05-02 20:53:37] [Epoch=180/540] [Need: 03:03:21] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [180][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1154 (0.1154)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:53:37]
  Epoch: [180][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1315 (0.1270)   Prec@1 97.000 (96.791)   Prec@5 100.000 (99.910)   [2018-05-02 20:53:48]
  Epoch: [180][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2002 (0.1264)   Prec@1 94.000 (96.786)   Prec@5 100.000 (99.915)   [2018-05-02 20:53:59]
  **Train** Prec@1 96.774 Prec@5 99.912 Error@1 3.226
  **Test** Prec@1 76.210 Prec@5 93.520 Error@1 23.790

==>>[2018-05-02 20:54:07] [Epoch=181/540] [Need: 03:02:49] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [181][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0819 (0.0819)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:54:07]
  Epoch: [181][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1000 (0.1220)   Prec@1 97.000 (96.995)   Prec@5 100.000 (99.920)   [2018-05-02 20:54:18]
  Epoch: [181][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0834 (0.1273)   Prec@1 98.000 (96.706)   Prec@5 100.000 (99.895)   [2018-05-02 20:54:29]
  **Train** Prec@1 96.618 Prec@5 99.896 Error@1 3.382
  **Test** Prec@1 76.120 Prec@5 93.680 Error@1 23.880

==>>[2018-05-02 20:54:37] [Epoch=182/540] [Need: 03:02:18] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [182][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0936 (0.0936)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:54:37]
  Epoch: [182][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1060 (0.1270)   Prec@1 98.000 (96.721)   Prec@5 100.000 (99.881)   [2018-05-02 20:54:48]
  Epoch: [182][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0804 (0.1260)   Prec@1 98.000 (96.701)   Prec@5 100.000 (99.903)   [2018-05-02 20:54:59]
  **Train** Prec@1 96.656 Prec@5 99.908 Error@1 3.344
  **Test** Prec@1 75.960 Prec@5 93.590 Error@1 24.040

==>>[2018-05-02 20:55:07] [Epoch=183/540] [Need: 03:01:47] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [183][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.1661 (0.1661)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:55:07]
  Epoch: [183][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0700 (0.1328)   Prec@1 99.000 (96.522)   Prec@5 100.000 (99.891)   [2018-05-02 20:55:18]
  Epoch: [183][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1577 (0.1307)   Prec@1 95.000 (96.591)   Prec@5 100.000 (99.883)   [2018-05-02 20:55:29]
  **Train** Prec@1 96.618 Prec@5 99.878 Error@1 3.382
  **Test** Prec@1 75.780 Prec@5 93.410 Error@1 24.220

==>>[2018-05-02 20:55:37] [Epoch=184/540] [Need: 03:01:15] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [184][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0808 (0.0808)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:55:37]
  Epoch: [184][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1041 (0.1269)   Prec@1 97.000 (96.741)   Prec@5 100.000 (99.896)   [2018-05-02 20:55:48]
  Epoch: [184][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1100 (0.1278)   Prec@1 97.000 (96.746)   Prec@5 100.000 (99.888)   [2018-05-02 20:55:59]
  **Train** Prec@1 96.694 Prec@5 99.892 Error@1 3.306
  **Test** Prec@1 75.670 Prec@5 93.180 Error@1 24.330

==>>[2018-05-02 20:56:07] [Epoch=185/540] [Need: 03:00:44] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [185][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.1258 (0.1258)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:56:07]
  Epoch: [185][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1015 (0.1228)   Prec@1 97.000 (96.876)   Prec@5 100.000 (99.886)   [2018-05-02 20:56:18]
  Epoch: [185][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1438 (0.1283)   Prec@1 96.000 (96.661)   Prec@5 100.000 (99.890)   [2018-05-02 20:56:29]
  **Train** Prec@1 96.686 Prec@5 99.880 Error@1 3.314
  **Test** Prec@1 75.930 Prec@5 93.390 Error@1 24.070

==>>[2018-05-02 20:56:37] [Epoch=186/540] [Need: 03:00:12] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [186][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1497 (0.1497)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:56:38]
  Epoch: [186][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1748 (0.1204)   Prec@1 94.000 (96.920)   Prec@5 100.000 (99.905)   [2018-05-02 20:56:49]
  Epoch: [186][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0961 (0.1261)   Prec@1 99.000 (96.698)   Prec@5 100.000 (99.913)   [2018-05-02 20:56:59]
  **Train** Prec@1 96.640 Prec@5 99.908 Error@1 3.360
  **Test** Prec@1 75.780 Prec@5 93.510 Error@1 24.220

==>>[2018-05-02 20:57:08] [Epoch=187/540] [Need: 02:59:41] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [187][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.1063 (0.1063)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:57:08]
  Epoch: [187][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1018 (0.1204)   Prec@1 99.000 (96.806)   Prec@5 100.000 (99.920)   [2018-05-02 20:57:19]
  Epoch: [187][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1673 (0.1224)   Prec@1 96.000 (96.810)   Prec@5 100.000 (99.908)   [2018-05-02 20:57:30]
  **Train** Prec@1 96.720 Prec@5 99.912 Error@1 3.280
  **Test** Prec@1 75.980 Prec@5 93.670 Error@1 24.020

==>>[2018-05-02 20:57:38] [Epoch=188/540] [Need: 02:59:09] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [188][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.1814 (0.1814)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:57:38]
  Epoch: [188][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1401 (0.1245)   Prec@1 97.000 (96.861)   Prec@5 100.000 (99.886)   [2018-05-02 20:57:49]
  Epoch: [188][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0815 (0.1268)   Prec@1 98.000 (96.758)   Prec@5 100.000 (99.888)   [2018-05-02 20:58:00]
  **Train** Prec@1 96.796 Prec@5 99.900 Error@1 3.204
  **Test** Prec@1 76.390 Prec@5 93.420 Error@1 23.610

==>>[2018-05-02 20:58:08] [Epoch=189/540] [Need: 02:58:38] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [189][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.1419 (0.1419)   Prec@1 98.000 (98.000)   Prec@5 99.000 (99.000)   [2018-05-02 20:58:08]
  Epoch: [189][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1304 (0.1237)   Prec@1 97.000 (96.801)   Prec@5 100.000 (99.910)   [2018-05-02 20:58:19]
  Epoch: [189][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0966 (0.1276)   Prec@1 99.000 (96.651)   Prec@5 100.000 (99.925)   [2018-05-02 20:58:30]
  **Train** Prec@1 96.710 Prec@5 99.922 Error@1 3.290
  **Test** Prec@1 75.910 Prec@5 93.570 Error@1 24.090

==>>[2018-05-02 20:58:38] [Epoch=190/540] [Need: 02:58:07] [learning_rate=0.010000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [190][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.2134 (0.2134)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:58:38]
  Epoch: [190][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1109 (0.1121)   Prec@1 99.000 (97.219)   Prec@5 100.000 (99.925)   [2018-05-02 20:58:49]
  Epoch: [190][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0717 (0.1086)   Prec@1 100.000 (97.364)   Prec@5 100.000 (99.925)   [2018-05-02 20:59:00]
  **Train** Prec@1 97.400 Prec@5 99.932 Error@1 2.600
  **Test** Prec@1 76.830 Prec@5 93.670 Error@1 23.170

==>>[2018-05-02 20:59:08] [Epoch=191/540] [Need: 02:57:35] [learning_rate=0.001000] [Best : Accuracy=76.89, Error=23.11]
  Epoch: [191][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0744 (0.0744)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:59:08]
  Epoch: [191][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0888 (0.0996)   Prec@1 97.000 (97.572)   Prec@5 100.000 (99.965)   [2018-05-02 20:59:19]
  Epoch: [191][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0892 (0.0985)   Prec@1 98.000 (97.594)   Prec@5 100.000 (99.950)   [2018-05-02 20:59:30]
  **Train** Prec@1 97.586 Prec@5 99.946 Error@1 2.414
  **Test** Prec@1 76.920 Prec@5 93.870 Error@1 23.080

==>>[2018-05-02 20:59:38] [Epoch=192/540] [Need: 02:57:04] [learning_rate=0.001000] [Best : Accuracy=76.92, Error=23.08]
  Epoch: [192][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0580 (0.0580)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 20:59:38]
  Epoch: [192][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1033 (0.0929)   Prec@1 95.000 (97.746)   Prec@5 100.000 (99.945)   [2018-05-02 20:59:49]
  Epoch: [192][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1315 (0.0932)   Prec@1 96.000 (97.721)   Prec@5 100.000 (99.953)   [2018-05-02 21:00:00]
  **Train** Prec@1 97.720 Prec@5 99.950 Error@1 2.280
  **Test** Prec@1 77.150 Prec@5 93.960 Error@1 22.850

==>>[2018-05-02 21:00:08] [Epoch=193/540] [Need: 02:56:33] [learning_rate=0.001000] [Best : Accuracy=77.15, Error=22.85]
  Epoch: [193][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.1135 (0.1135)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:00:08]
  Epoch: [193][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1407 (0.0934)   Prec@1 98.000 (97.771)   Prec@5 100.000 (99.960)   [2018-05-02 21:00:19]
  Epoch: [193][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1004 (0.0910)   Prec@1 98.000 (97.848)   Prec@5 100.000 (99.970)   [2018-05-02 21:00:30]
  **Train** Prec@1 97.844 Prec@5 99.970 Error@1 2.156
  **Test** Prec@1 77.080 Prec@5 94.050 Error@1 22.920

==>>[2018-05-02 21:00:38] [Epoch=194/540] [Need: 02:56:02] [learning_rate=0.001000] [Best : Accuracy=77.15, Error=22.85]
  Epoch: [194][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1450 (0.1450)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:00:38]
  Epoch: [194][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1159 (0.0877)   Prec@1 97.000 (97.975)   Prec@5 100.000 (99.965)   [2018-05-02 21:00:49]
  Epoch: [194][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0655 (0.0887)   Prec@1 99.000 (97.923)   Prec@5 100.000 (99.965)   [2018-05-02 21:01:00]
  **Train** Prec@1 97.954 Prec@5 99.956 Error@1 2.046
  **Test** Prec@1 77.000 Prec@5 93.830 Error@1 23.000

==>>[2018-05-02 21:01:08] [Epoch=195/540] [Need: 02:55:30] [learning_rate=0.001000] [Best : Accuracy=77.15, Error=22.85]
  Epoch: [195][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0438 (0.0438)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:01:08]
  Epoch: [195][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0835 (0.0930)   Prec@1 97.000 (97.697)   Prec@5 100.000 (99.935)   [2018-05-02 21:01:19]
  Epoch: [195][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1191 (0.0899)   Prec@1 95.000 (97.810)   Prec@5 100.000 (99.950)   [2018-05-02 21:01:30]
  **Train** Prec@1 97.794 Prec@5 99.952 Error@1 2.206
  **Test** Prec@1 77.010 Prec@5 93.990 Error@1 22.990

==>>[2018-05-02 21:01:38] [Epoch=196/540] [Need: 02:54:59] [learning_rate=0.001000] [Best : Accuracy=77.15, Error=22.85]
  Epoch: [196][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.1583 (0.1583)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:01:38]
  Epoch: [196][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0596 (0.0905)   Prec@1 99.000 (97.896)   Prec@5 100.000 (99.935)   [2018-05-02 21:01:49]
  Epoch: [196][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0540 (0.0864)   Prec@1 99.000 (98.040)   Prec@5 100.000 (99.958)   [2018-05-02 21:02:00]
  **Train** Prec@1 98.050 Prec@5 99.964 Error@1 1.950
  **Test** Prec@1 77.370 Prec@5 93.930 Error@1 22.630

==>>[2018-05-02 21:02:09] [Epoch=197/540] [Need: 02:54:28] [learning_rate=0.001000] [Best : Accuracy=77.37, Error=22.63]
  Epoch: [197][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0988 (0.0988)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:02:09]
  Epoch: [197][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0774 (0.0843)   Prec@1 99.000 (98.070)   Prec@5 100.000 (99.970)   [2018-05-02 21:02:20]
  Epoch: [197][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0735 (0.0859)   Prec@1 98.000 (97.973)   Prec@5 100.000 (99.963)   [2018-05-02 21:02:30]
  **Train** Prec@1 98.036 Prec@5 99.964 Error@1 1.964
  **Test** Prec@1 77.350 Prec@5 93.860 Error@1 22.650

==>>[2018-05-02 21:02:39] [Epoch=198/540] [Need: 02:53:56] [learning_rate=0.001000] [Best : Accuracy=77.37, Error=22.63]
  Epoch: [198][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0519 (0.0519)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:02:39]
  Epoch: [198][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0913 (0.0863)   Prec@1 98.000 (97.980)   Prec@5 100.000 (99.945)   [2018-05-02 21:02:50]
  Epoch: [198][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1087 (0.0845)   Prec@1 97.000 (98.025)   Prec@5 100.000 (99.955)   [2018-05-02 21:03:01]
  **Train** Prec@1 98.046 Prec@5 99.956 Error@1 1.954
  **Test** Prec@1 77.130 Prec@5 93.810 Error@1 22.870

==>>[2018-05-02 21:03:09] [Epoch=199/540] [Need: 02:53:25] [learning_rate=0.001000] [Best : Accuracy=77.37, Error=22.63]
  Epoch: [199][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0713 (0.0713)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:03:09]
  Epoch: [199][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0532 (0.0815)   Prec@1 100.000 (98.174)   Prec@5 100.000 (99.945)   [2018-05-02 21:03:20]
  Epoch: [199][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0776 (0.0826)   Prec@1 99.000 (98.095)   Prec@5 100.000 (99.958)   [2018-05-02 21:03:31]
  **Train** Prec@1 98.092 Prec@5 99.950 Error@1 1.908
  **Test** Prec@1 77.320 Prec@5 93.770 Error@1 22.680

==>>[2018-05-02 21:03:39] [Epoch=200/540] [Need: 02:52:54] [learning_rate=0.001000] [Best : Accuracy=77.37, Error=22.63]
  Epoch: [200][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0704 (0.0704)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:03:39]
  Epoch: [200][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0523 (0.0812)   Prec@1 100.000 (98.219)   Prec@5 100.000 (99.965)   [2018-05-02 21:03:50]
  Epoch: [200][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1090 (0.0815)   Prec@1 96.000 (98.145)   Prec@5 100.000 (99.958)   [2018-05-02 21:04:01]
  **Train** Prec@1 98.126 Prec@5 99.948 Error@1 1.874
  **Test** Prec@1 77.240 Prec@5 93.970 Error@1 22.760

==>>[2018-05-02 21:04:09] [Epoch=201/540] [Need: 02:52:23] [learning_rate=0.001000] [Best : Accuracy=77.37, Error=22.63]
  Epoch: [201][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.1101 (0.1101)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:04:09]
  Epoch: [201][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1702 (0.0794)   Prec@1 95.000 (98.204)   Prec@5 100.000 (99.950)   [2018-05-02 21:04:20]
  Epoch: [201][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1171 (0.0807)   Prec@1 99.000 (98.209)   Prec@5 100.000 (99.950)   [2018-05-02 21:04:31]
  **Train** Prec@1 98.240 Prec@5 99.954 Error@1 1.760
  **Test** Prec@1 77.220 Prec@5 93.980 Error@1 22.780

==>>[2018-05-02 21:04:39] [Epoch=202/540] [Need: 02:51:51] [learning_rate=0.001000] [Best : Accuracy=77.37, Error=22.63]
  Epoch: [202][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0554 (0.0554)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:04:39]
  Epoch: [202][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0739 (0.0785)   Prec@1 99.000 (98.308)   Prec@5 100.000 (99.960)   [2018-05-02 21:04:50]
  Epoch: [202][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0596 (0.0780)   Prec@1 98.000 (98.294)   Prec@5 100.000 (99.965)   [2018-05-02 21:05:01]
  **Train** Prec@1 98.264 Prec@5 99.956 Error@1 1.736
  **Test** Prec@1 77.490 Prec@5 94.030 Error@1 22.510

==>>[2018-05-02 21:05:09] [Epoch=203/540] [Need: 02:51:20] [learning_rate=0.001000] [Best : Accuracy=77.49, Error=22.51]
  Epoch: [203][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1190 (0.1190)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:05:09]
  Epoch: [203][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1426 (0.0768)   Prec@1 95.000 (98.383)   Prec@5 100.000 (99.960)   [2018-05-02 21:05:20]
  Epoch: [203][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1192 (0.0776)   Prec@1 96.000 (98.327)   Prec@5 100.000 (99.968)   [2018-05-02 21:05:31]
  **Train** Prec@1 98.316 Prec@5 99.970 Error@1 1.684
  **Test** Prec@1 77.250 Prec@5 93.940 Error@1 22.750

==>>[2018-05-02 21:05:39] [Epoch=204/540] [Need: 02:50:49] [learning_rate=0.001000] [Best : Accuracy=77.49, Error=22.51]
  Epoch: [204][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1137 (0.1137)   Prec@1 97.000 (97.000)   Prec@5 99.000 (99.000)   [2018-05-02 21:05:39]
  Epoch: [204][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0637 (0.0808)   Prec@1 100.000 (98.104)   Prec@5 100.000 (99.940)   [2018-05-02 21:05:50]
  Epoch: [204][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0616 (0.0780)   Prec@1 98.000 (98.249)   Prec@5 100.000 (99.948)   [2018-05-02 21:06:01]
  **Train** Prec@1 98.286 Prec@5 99.954 Error@1 1.714
  **Test** Prec@1 77.470 Prec@5 93.810 Error@1 22.530

==>>[2018-05-02 21:06:09] [Epoch=205/540] [Need: 02:50:18] [learning_rate=0.001000] [Best : Accuracy=77.49, Error=22.51]
  Epoch: [205][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0745 (0.0745)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:06:09]
  Epoch: [205][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0664 (0.0726)   Prec@1 98.000 (98.398)   Prec@5 100.000 (99.955)   [2018-05-02 21:06:20]
  Epoch: [205][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0750 (0.0739)   Prec@1 99.000 (98.384)   Prec@5 100.000 (99.970)   [2018-05-02 21:06:31]
  **Train** Prec@1 98.358 Prec@5 99.970 Error@1 1.642
  **Test** Prec@1 77.430 Prec@5 93.860 Error@1 22.570

==>>[2018-05-02 21:06:39] [Epoch=206/540] [Need: 02:49:47] [learning_rate=0.001000] [Best : Accuracy=77.49, Error=22.51]
  Epoch: [206][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0690 (0.0690)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:06:39]
  Epoch: [206][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0699 (0.0730)   Prec@1 97.000 (98.338)   Prec@5 100.000 (99.980)   [2018-05-02 21:06:50]
  Epoch: [206][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0544 (0.0749)   Prec@1 98.000 (98.314)   Prec@5 100.000 (99.983)   [2018-05-02 21:07:01]
  **Train** Prec@1 98.294 Prec@5 99.984 Error@1 1.706
  **Test** Prec@1 77.140 Prec@5 93.960 Error@1 22.860

==>>[2018-05-02 21:07:09] [Epoch=207/540] [Need: 02:49:15] [learning_rate=0.001000] [Best : Accuracy=77.49, Error=22.51]
  Epoch: [207][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0559 (0.0559)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:07:09]
  Epoch: [207][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0634 (0.0726)   Prec@1 99.000 (98.562)   Prec@5 100.000 (99.975)   [2018-05-02 21:07:20]
  Epoch: [207][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0623 (0.0724)   Prec@1 100.000 (98.529)   Prec@5 100.000 (99.980)   [2018-05-02 21:07:31]
  **Train** Prec@1 98.474 Prec@5 99.976 Error@1 1.526
  **Test** Prec@1 77.270 Prec@5 93.820 Error@1 22.730

==>>[2018-05-02 21:07:39] [Epoch=208/540] [Need: 02:48:44] [learning_rate=0.001000] [Best : Accuracy=77.49, Error=22.51]
  Epoch: [208][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.1393 (0.1393)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:07:40]
  Epoch: [208][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0275 (0.0744)   Prec@1 100.000 (98.378)   Prec@5 100.000 (99.985)   [2018-05-02 21:07:50]
  Epoch: [208][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0786 (0.0734)   Prec@1 99.000 (98.347)   Prec@5 100.000 (99.988)   [2018-05-02 21:08:01]
  **Train** Prec@1 98.354 Prec@5 99.984 Error@1 1.646
  **Test** Prec@1 77.110 Prec@5 93.960 Error@1 22.890

==>>[2018-05-02 21:08:10] [Epoch=209/540] [Need: 02:48:13] [learning_rate=0.001000] [Best : Accuracy=77.49, Error=22.51]
  Epoch: [209][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.0576 (0.0576)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:08:10]
  Epoch: [209][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0533 (0.0757)   Prec@1 99.000 (98.249)   Prec@5 100.000 (99.965)   [2018-05-02 21:08:21]
  Epoch: [209][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1363 (0.0771)   Prec@1 96.000 (98.219)   Prec@5 100.000 (99.970)   [2018-05-02 21:08:32]
  **Train** Prec@1 98.228 Prec@5 99.972 Error@1 1.772
  **Test** Prec@1 77.530 Prec@5 93.910 Error@1 22.470

==>>[2018-05-02 21:08:40] [Epoch=210/540] [Need: 02:47:42] [learning_rate=0.001000] [Best : Accuracy=77.53, Error=22.47]
  Epoch: [210][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0321 (0.0321)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:08:40]
  Epoch: [210][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0693 (0.0776)   Prec@1 98.000 (98.284)   Prec@5 100.000 (99.970)   [2018-05-02 21:08:51]
  Epoch: [210][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0891 (0.0759)   Prec@1 98.000 (98.344)   Prec@5 100.000 (99.960)   [2018-05-02 21:09:02]
  **Train** Prec@1 98.342 Prec@5 99.958 Error@1 1.658
  **Test** Prec@1 77.460 Prec@5 94.010 Error@1 22.540

==>>[2018-05-02 21:09:10] [Epoch=211/540] [Need: 02:47:11] [learning_rate=0.001000] [Best : Accuracy=77.53, Error=22.47]
  Epoch: [211][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0407 (0.0407)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:09:10]
  Epoch: [211][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0654 (0.0759)   Prec@1 98.000 (98.194)   Prec@5 100.000 (99.975)   [2018-05-02 21:09:21]
  Epoch: [211][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0927 (0.0742)   Prec@1 97.000 (98.267)   Prec@5 100.000 (99.975)   [2018-05-02 21:09:32]
  **Train** Prec@1 98.296 Prec@5 99.970 Error@1 1.704
  **Test** Prec@1 77.560 Prec@5 93.900 Error@1 22.440

==>>[2018-05-02 21:09:40] [Epoch=212/540] [Need: 02:46:40] [learning_rate=0.001000] [Best : Accuracy=77.56, Error=22.44]
  Epoch: [212][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0472 (0.0472)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:09:40]
  Epoch: [212][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0398 (0.0718)   Prec@1 99.000 (98.393)   Prec@5 100.000 (99.980)   [2018-05-02 21:09:51]
  Epoch: [212][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1243 (0.0714)   Prec@1 96.000 (98.471)   Prec@5 100.000 (99.978)   [2018-05-02 21:10:02]
  **Train** Prec@1 98.440 Prec@5 99.980 Error@1 1.560
  **Test** Prec@1 77.660 Prec@5 93.880 Error@1 22.340

==>>[2018-05-02 21:10:10] [Epoch=213/540] [Need: 02:46:09] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [213][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1068 (0.1068)   Prec@1 97.000 (97.000)   Prec@5 99.000 (99.000)   [2018-05-02 21:10:10]
  Epoch: [213][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0544 (0.0710)   Prec@1 98.000 (98.483)   Prec@5 100.000 (99.965)   [2018-05-02 21:10:21]
  Epoch: [213][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0685 (0.0714)   Prec@1 99.000 (98.469)   Prec@5 100.000 (99.970)   [2018-05-02 21:10:32]
  **Train** Prec@1 98.458 Prec@5 99.974 Error@1 1.542
  **Test** Prec@1 77.520 Prec@5 93.840 Error@1 22.480

==>>[2018-05-02 21:10:40] [Epoch=214/540] [Need: 02:45:38] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [214][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0323 (0.0323)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:10:40]
  Epoch: [214][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0331 (0.0716)   Prec@1 100.000 (98.403)   Prec@5 100.000 (99.980)   [2018-05-02 21:10:51]
  Epoch: [214][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0570 (0.0726)   Prec@1 99.000 (98.354)   Prec@5 100.000 (99.983)   [2018-05-02 21:11:02]
  **Train** Prec@1 98.360 Prec@5 99.976 Error@1 1.640
  **Test** Prec@1 77.610 Prec@5 93.980 Error@1 22.390

==>>[2018-05-02 21:11:10] [Epoch=215/540] [Need: 02:45:07] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [215][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0747 (0.0747)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:11:10]
  Epoch: [215][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0737 (0.0754)   Prec@1 98.000 (98.289)   Prec@5 100.000 (99.975)   [2018-05-02 21:11:21]
  Epoch: [215][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0425 (0.0747)   Prec@1 99.000 (98.334)   Prec@5 100.000 (99.973)   [2018-05-02 21:11:32]
  **Train** Prec@1 98.398 Prec@5 99.974 Error@1 1.602
  **Test** Prec@1 77.580 Prec@5 94.000 Error@1 22.420

==>>[2018-05-02 21:11:40] [Epoch=216/540] [Need: 02:44:35] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [216][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0615 (0.0615)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:11:40]
  Epoch: [216][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0410 (0.0732)   Prec@1 100.000 (98.443)   Prec@5 100.000 (99.990)   [2018-05-02 21:11:51]
  Epoch: [216][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0897 (0.0726)   Prec@1 98.000 (98.399)   Prec@5 99.000 (99.980)   [2018-05-02 21:12:02]
  **Train** Prec@1 98.384 Prec@5 99.980 Error@1 1.616
  **Test** Prec@1 77.400 Prec@5 93.690 Error@1 22.600

==>>[2018-05-02 21:12:10] [Epoch=217/540] [Need: 02:44:04] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [217][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0372 (0.0372)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:12:10]
  Epoch: [217][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0617 (0.0727)   Prec@1 99.000 (98.498)   Prec@5 100.000 (99.980)   [2018-05-02 21:12:21]
  Epoch: [217][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1002 (0.0713)   Prec@1 97.000 (98.534)   Prec@5 100.000 (99.973)   [2018-05-02 21:12:32]
  **Train** Prec@1 98.530 Prec@5 99.970 Error@1 1.470
  **Test** Prec@1 77.520 Prec@5 93.870 Error@1 22.480

==>>[2018-05-02 21:12:40] [Epoch=218/540] [Need: 02:43:33] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [218][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0491 (0.0491)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:12:40]
  Epoch: [218][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0464 (0.0715)   Prec@1 100.000 (98.418)   Prec@5 100.000 (99.985)   [2018-05-02 21:12:51]
  Epoch: [218][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0814 (0.0703)   Prec@1 98.000 (98.456)   Prec@5 100.000 (99.990)   [2018-05-02 21:13:02]
  **Train** Prec@1 98.442 Prec@5 99.986 Error@1 1.558
  **Test** Prec@1 77.430 Prec@5 93.950 Error@1 22.570

==>>[2018-05-02 21:13:10] [Epoch=219/540] [Need: 02:43:02] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [219][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.0840 (0.0840)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:13:11]
  Epoch: [219][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1242 (0.0730)   Prec@1 95.000 (98.378)   Prec@5 100.000 (99.955)   [2018-05-02 21:13:21]
  Epoch: [219][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0947 (0.0716)   Prec@1 97.000 (98.419)   Prec@5 100.000 (99.965)   [2018-05-02 21:13:32]
  **Train** Prec@1 98.408 Prec@5 99.962 Error@1 1.592
  **Test** Prec@1 77.410 Prec@5 93.950 Error@1 22.590

==>>[2018-05-02 21:13:40] [Epoch=220/540] [Need: 02:42:31] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [220][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0957 (0.0957)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:13:41]
  Epoch: [220][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0900 (0.0704)   Prec@1 98.000 (98.473)   Prec@5 100.000 (99.970)   [2018-05-02 21:13:52]
  Epoch: [220][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0314 (0.0695)   Prec@1 100.000 (98.539)   Prec@5 100.000 (99.978)   [2018-05-02 21:14:02]
  **Train** Prec@1 98.532 Prec@5 99.978 Error@1 1.468
  **Test** Prec@1 77.570 Prec@5 93.980 Error@1 22.430

==>>[2018-05-02 21:14:11] [Epoch=221/540] [Need: 02:42:00] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [221][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0441 (0.0441)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:14:11]
  Epoch: [221][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0312 (0.0692)   Prec@1 100.000 (98.572)   Prec@5 100.000 (99.960)   [2018-05-02 21:14:22]
  Epoch: [221][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0689 (0.0684)   Prec@1 99.000 (98.571)   Prec@5 100.000 (99.963)   [2018-05-02 21:14:33]
  **Train** Prec@1 98.526 Prec@5 99.964 Error@1 1.474
  **Test** Prec@1 77.370 Prec@5 94.070 Error@1 22.630

==>>[2018-05-02 21:14:41] [Epoch=222/540] [Need: 02:41:29] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [222][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.0514 (0.0514)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:14:41]
  Epoch: [222][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0475 (0.0723)   Prec@1 99.000 (98.408)   Prec@5 100.000 (99.945)   [2018-05-02 21:14:52]
  Epoch: [222][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0782 (0.0712)   Prec@1 98.000 (98.429)   Prec@5 100.000 (99.963)   [2018-05-02 21:15:03]
  **Train** Prec@1 98.444 Prec@5 99.962 Error@1 1.556
  **Test** Prec@1 77.620 Prec@5 94.080 Error@1 22.380

==>>[2018-05-02 21:15:11] [Epoch=223/540] [Need: 02:40:58] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [223][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0719 (0.0719)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:15:11]
  Epoch: [223][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0661 (0.0660)   Prec@1 98.000 (98.557)   Prec@5 100.000 (99.985)   [2018-05-02 21:15:22]
  Epoch: [223][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0996 (0.0670)   Prec@1 98.000 (98.561)   Prec@5 100.000 (99.980)   [2018-05-02 21:15:33]
  **Train** Prec@1 98.630 Prec@5 99.982 Error@1 1.370
  **Test** Prec@1 77.610 Prec@5 93.990 Error@1 22.390

==>>[2018-05-02 21:15:41] [Epoch=224/540] [Need: 02:40:27] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [224][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0800 (0.0800)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:15:41]
  Epoch: [224][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0861 (0.0704)   Prec@1 97.000 (98.318)   Prec@5 100.000 (99.975)   [2018-05-02 21:15:52]
  Epoch: [224][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0393 (0.0688)   Prec@1 100.000 (98.464)   Prec@5 100.000 (99.975)   [2018-05-02 21:16:03]
  **Train** Prec@1 98.510 Prec@5 99.974 Error@1 1.490
  **Test** Prec@1 77.410 Prec@5 93.800 Error@1 22.590

==>>[2018-05-02 21:16:11] [Epoch=225/540] [Need: 02:39:56] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [225][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0587 (0.0587)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:16:11]
  Epoch: [225][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0460 (0.0657)   Prec@1 100.000 (98.701)   Prec@5 100.000 (99.975)   [2018-05-02 21:16:22]
  Epoch: [225][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0888 (0.0680)   Prec@1 98.000 (98.589)   Prec@5 100.000 (99.983)   [2018-05-02 21:16:33]
  **Train** Prec@1 98.612 Prec@5 99.980 Error@1 1.388
  **Test** Prec@1 77.450 Prec@5 93.950 Error@1 22.550

==>>[2018-05-02 21:16:41] [Epoch=226/540] [Need: 02:39:25] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [226][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0490 (0.0490)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:16:41]
  Epoch: [226][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1056 (0.0672)   Prec@1 97.000 (98.607)   Prec@5 99.000 (99.970)   [2018-05-02 21:16:52]
  Epoch: [226][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0769 (0.0708)   Prec@1 97.000 (98.451)   Prec@5 100.000 (99.963)   [2018-05-02 21:17:03]
  **Train** Prec@1 98.452 Prec@5 99.962 Error@1 1.548
  **Test** Prec@1 77.600 Prec@5 94.020 Error@1 22.400

==>>[2018-05-02 21:17:11] [Epoch=227/540] [Need: 02:38:54] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [227][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.0384 (0.0384)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:17:11]
  Epoch: [227][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0645 (0.0714)   Prec@1 99.000 (98.423)   Prec@5 100.000 (99.970)   [2018-05-02 21:17:22]
  Epoch: [227][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0511 (0.0695)   Prec@1 99.000 (98.471)   Prec@5 100.000 (99.985)   [2018-05-02 21:17:33]
  **Train** Prec@1 98.500 Prec@5 99.982 Error@1 1.500
  **Test** Prec@1 77.620 Prec@5 93.800 Error@1 22.380

==>>[2018-05-02 21:17:41] [Epoch=228/540] [Need: 02:38:23] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [228][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0903 (0.0903)   Prec@1 97.000 (97.000)   Prec@5 99.000 (99.000)   [2018-05-02 21:17:41]
  Epoch: [228][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1040 (0.0687)   Prec@1 98.000 (98.542)   Prec@5 100.000 (99.970)   [2018-05-02 21:17:52]
  Epoch: [228][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0828 (0.0695)   Prec@1 97.000 (98.506)   Prec@5 100.000 (99.965)   [2018-05-02 21:18:03]
  **Train** Prec@1 98.550 Prec@5 99.968 Error@1 1.450
  **Test** Prec@1 77.330 Prec@5 93.960 Error@1 22.670

==>>[2018-05-02 21:18:11] [Epoch=229/540] [Need: 02:37:52] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [229][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0762 (0.0762)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:18:11]
  Epoch: [229][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0455 (0.0678)   Prec@1 100.000 (98.557)   Prec@5 100.000 (99.975)   [2018-05-02 21:18:22]
  Epoch: [229][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0476 (0.0676)   Prec@1 99.000 (98.539)   Prec@5 100.000 (99.980)   [2018-05-02 21:18:33]
  **Train** Prec@1 98.572 Prec@5 99.984 Error@1 1.428
  **Test** Prec@1 77.420 Prec@5 93.980 Error@1 22.580

==>>[2018-05-02 21:18:41] [Epoch=230/540] [Need: 02:37:21] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [230][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0443 (0.0443)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:18:42]
  Epoch: [230][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0617 (0.0676)   Prec@1 99.000 (98.622)   Prec@5 100.000 (99.970)   [2018-05-02 21:18:52]
  Epoch: [230][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0266 (0.0679)   Prec@1 100.000 (98.581)   Prec@5 100.000 (99.968)   [2018-05-02 21:19:03]
  **Train** Prec@1 98.604 Prec@5 99.972 Error@1 1.396
  **Test** Prec@1 77.430 Prec@5 94.120 Error@1 22.570

==>>[2018-05-02 21:19:12] [Epoch=231/540] [Need: 02:36:50] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [231][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0626 (0.0626)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:19:12]
  Epoch: [231][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0291 (0.0653)   Prec@1 100.000 (98.607)   Prec@5 100.000 (99.975)   [2018-05-02 21:19:23]
  Epoch: [231][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0606 (0.0678)   Prec@1 99.000 (98.536)   Prec@5 100.000 (99.975)   [2018-05-02 21:19:33]
  **Train** Prec@1 98.528 Prec@5 99.976 Error@1 1.472
  **Test** Prec@1 77.160 Prec@5 94.050 Error@1 22.840

==>>[2018-05-02 21:19:42] [Epoch=232/540] [Need: 02:36:19] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [232][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0219 (0.0219)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:19:42]
  Epoch: [232][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0395 (0.0661)   Prec@1 99.000 (98.642)   Prec@5 100.000 (99.980)   [2018-05-02 21:19:53]
  Epoch: [232][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0905 (0.0675)   Prec@1 97.000 (98.536)   Prec@5 100.000 (99.975)   [2018-05-02 21:20:04]
  **Train** Prec@1 98.552 Prec@5 99.978 Error@1 1.448
  **Test** Prec@1 77.560 Prec@5 93.940 Error@1 22.440

==>>[2018-05-02 21:20:12] [Epoch=233/540] [Need: 02:35:49] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [233][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0522 (0.0522)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:20:12]
  Epoch: [233][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0571 (0.0644)   Prec@1 98.000 (98.632)   Prec@5 100.000 (99.965)   [2018-05-02 21:20:23]
  Epoch: [233][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0383 (0.0662)   Prec@1 99.000 (98.569)   Prec@5 100.000 (99.970)   [2018-05-02 21:20:34]
  **Train** Prec@1 98.568 Prec@5 99.974 Error@1 1.432
  **Test** Prec@1 77.340 Prec@5 94.170 Error@1 22.660

==>>[2018-05-02 21:20:42] [Epoch=234/540] [Need: 02:35:18] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [234][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.1275 (0.1275)   Prec@1 99.000 (99.000)   Prec@5 99.000 (99.000)   [2018-05-02 21:20:42]
  Epoch: [234][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0497 (0.0650)   Prec@1 99.000 (98.642)   Prec@5 100.000 (99.980)   [2018-05-02 21:20:53]
  Epoch: [234][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0394 (0.0653)   Prec@1 100.000 (98.656)   Prec@5 100.000 (99.990)   [2018-05-02 21:21:04]
  **Train** Prec@1 98.630 Prec@5 99.984 Error@1 1.370
  **Test** Prec@1 77.350 Prec@5 94.040 Error@1 22.650

==>>[2018-05-02 21:21:12] [Epoch=235/540] [Need: 02:34:47] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [235][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0476 (0.0476)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:21:12]
  Epoch: [235][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1241 (0.0685)   Prec@1 98.000 (98.463)   Prec@5 100.000 (99.965)   [2018-05-02 21:21:23]
  Epoch: [235][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0359 (0.0657)   Prec@1 100.000 (98.561)   Prec@5 100.000 (99.968)   [2018-05-02 21:21:34]
  **Train** Prec@1 98.552 Prec@5 99.970 Error@1 1.448
  **Test** Prec@1 77.440 Prec@5 93.940 Error@1 22.560

==>>[2018-05-02 21:21:42] [Epoch=236/540] [Need: 02:34:16] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [236][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0921 (0.0921)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:21:42]
  Epoch: [236][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0375 (0.0642)   Prec@1 100.000 (98.687)   Prec@5 100.000 (99.975)   [2018-05-02 21:21:53]
  Epoch: [236][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0811 (0.0668)   Prec@1 98.000 (98.561)   Prec@5 100.000 (99.980)   [2018-05-02 21:22:04]
  **Train** Prec@1 98.562 Prec@5 99.978 Error@1 1.438
  **Test** Prec@1 77.450 Prec@5 93.900 Error@1 22.550

==>>[2018-05-02 21:22:12] [Epoch=237/540] [Need: 02:33:45] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [237][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0420 (0.0420)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:22:12]
  Epoch: [237][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0699 (0.0616)   Prec@1 98.000 (98.881)   Prec@5 100.000 (99.980)   [2018-05-02 21:22:23]
  Epoch: [237][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0843 (0.0633)   Prec@1 98.000 (98.736)   Prec@5 100.000 (99.980)   [2018-05-02 21:22:34]
  **Train** Prec@1 98.740 Prec@5 99.984 Error@1 1.260
  **Test** Prec@1 77.520 Prec@5 93.850 Error@1 22.480

==>>[2018-05-02 21:22:42] [Epoch=238/540] [Need: 02:33:14] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [238][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0366 (0.0366)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:22:42]
  Epoch: [238][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0510 (0.0637)   Prec@1 99.000 (98.652)   Prec@5 100.000 (99.985)   [2018-05-02 21:22:53]
  Epoch: [238][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0519 (0.0638)   Prec@1 99.000 (98.653)   Prec@5 100.000 (99.985)   [2018-05-02 21:23:04]
  **Train** Prec@1 98.640 Prec@5 99.984 Error@1 1.360
  **Test** Prec@1 77.440 Prec@5 93.950 Error@1 22.560

==>>[2018-05-02 21:23:12] [Epoch=239/540] [Need: 02:32:43] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [239][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.0634 (0.0634)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:23:12]
  Epoch: [239][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0251 (0.0658)   Prec@1 100.000 (98.682)   Prec@5 100.000 (99.990)   [2018-05-02 21:23:23]
  Epoch: [239][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0590 (0.0665)   Prec@1 100.000 (98.633)   Prec@5 100.000 (99.975)   [2018-05-02 21:23:34]
  **Train** Prec@1 98.650 Prec@5 99.974 Error@1 1.350
  **Test** Prec@1 77.360 Prec@5 93.890 Error@1 22.640

==>>[2018-05-02 21:23:42] [Epoch=240/540] [Need: 02:32:12] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [240][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.0262 (0.0262)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:23:42]
  Epoch: [240][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0654 (0.0660)   Prec@1 99.000 (98.622)   Prec@5 100.000 (99.985)   [2018-05-02 21:23:53]
  Epoch: [240][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0293 (0.0658)   Prec@1 100.000 (98.596)   Prec@5 100.000 (99.985)   [2018-05-02 21:24:04]
  **Train** Prec@1 98.618 Prec@5 99.984 Error@1 1.382
  **Test** Prec@1 77.420 Prec@5 93.890 Error@1 22.580

==>>[2018-05-02 21:24:12] [Epoch=241/540] [Need: 02:31:41] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [241][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0534 (0.0534)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:24:12]
  Epoch: [241][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0257 (0.0639)   Prec@1 100.000 (98.557)   Prec@5 100.000 (99.985)   [2018-05-02 21:24:23]
  Epoch: [241][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0637 (0.0654)   Prec@1 98.000 (98.536)   Prec@5 100.000 (99.988)   [2018-05-02 21:24:34]
  **Train** Prec@1 98.554 Prec@5 99.986 Error@1 1.446
  **Test** Prec@1 77.480 Prec@5 93.950 Error@1 22.520

==>>[2018-05-02 21:24:42] [Epoch=242/540] [Need: 02:31:10] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [242][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0521 (0.0521)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:24:42]
  Epoch: [242][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0382 (0.0640)   Prec@1 100.000 (98.682)   Prec@5 100.000 (99.980)   [2018-05-02 21:24:53]
  Epoch: [242][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0306 (0.0653)   Prec@1 100.000 (98.626)   Prec@5 100.000 (99.973)   [2018-05-02 21:25:04]
  **Train** Prec@1 98.610 Prec@5 99.974 Error@1 1.390
  **Test** Prec@1 77.390 Prec@5 93.850 Error@1 22.610

==>>[2018-05-02 21:25:12] [Epoch=243/540] [Need: 02:30:39] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [243][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0940 (0.0940)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:25:13]
  Epoch: [243][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0485 (0.0654)   Prec@1 99.000 (98.597)   Prec@5 100.000 (99.990)   [2018-05-02 21:25:23]
  Epoch: [243][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0810 (0.0643)   Prec@1 98.000 (98.648)   Prec@5 100.000 (99.985)   [2018-05-02 21:25:34]
  **Train** Prec@1 98.632 Prec@5 99.982 Error@1 1.368
  **Test** Prec@1 77.410 Prec@5 93.850 Error@1 22.590

==>>[2018-05-02 21:25:42] [Epoch=244/540] [Need: 02:30:08] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [244][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0385 (0.0385)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:25:43]
  Epoch: [244][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0619 (0.0645)   Prec@1 100.000 (98.741)   Prec@5 100.000 (99.980)   [2018-05-02 21:25:54]
  Epoch: [244][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0726 (0.0634)   Prec@1 99.000 (98.751)   Prec@5 100.000 (99.980)   [2018-05-02 21:26:04]
  **Train** Prec@1 98.758 Prec@5 99.982 Error@1 1.242
  **Test** Prec@1 77.290 Prec@5 94.020 Error@1 22.710

==>>[2018-05-02 21:26:13] [Epoch=245/540] [Need: 02:29:38] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [245][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.1061 (0.1061)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:26:13]
  Epoch: [245][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0268 (0.0646)   Prec@1 100.000 (98.577)   Prec@5 100.000 (99.970)   [2018-05-02 21:26:24]
  Epoch: [245][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0495 (0.0648)   Prec@1 100.000 (98.606)   Prec@5 100.000 (99.970)   [2018-05-02 21:26:35]
  **Train** Prec@1 98.644 Prec@5 99.968 Error@1 1.356
  **Test** Prec@1 77.500 Prec@5 93.820 Error@1 22.500

==>>[2018-05-02 21:26:43] [Epoch=246/540] [Need: 02:29:07] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [246][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0444 (0.0444)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:26:43]
  Epoch: [246][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0524 (0.0626)   Prec@1 99.000 (98.721)   Prec@5 100.000 (99.970)   [2018-05-02 21:26:54]
  Epoch: [246][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0386 (0.0626)   Prec@1 100.000 (98.736)   Prec@5 100.000 (99.970)   [2018-05-02 21:27:05]
  **Train** Prec@1 98.696 Prec@5 99.972 Error@1 1.304
  **Test** Prec@1 77.530 Prec@5 94.010 Error@1 22.470

==>>[2018-05-02 21:27:13] [Epoch=247/540] [Need: 02:28:36] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [247][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.0889 (0.0889)   Prec@1 98.000 (98.000)   Prec@5 99.000 (99.000)   [2018-05-02 21:27:13]
  Epoch: [247][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0406 (0.0646)   Prec@1 99.000 (98.632)   Prec@5 100.000 (99.980)   [2018-05-02 21:27:24]
  Epoch: [247][400/500]   Time 0.064 (0.055)   Data 0.000 (0.000)   Loss 0.0875 (0.0635)   Prec@1 98.000 (98.666)   Prec@5 99.000 (99.978)   [2018-05-02 21:27:35]
  **Train** Prec@1 98.664 Prec@5 99.978 Error@1 1.336
  **Test** Prec@1 77.480 Prec@5 93.860 Error@1 22.520

==>>[2018-05-02 21:27:43] [Epoch=248/540] [Need: 02:28:05] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [248][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1036 (0.1036)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:27:43]
  Epoch: [248][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0515 (0.0657)   Prec@1 99.000 (98.577)   Prec@5 100.000 (99.985)   [2018-05-02 21:27:54]
  Epoch: [248][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0421 (0.0652)   Prec@1 99.000 (98.603)   Prec@5 100.000 (99.980)   [2018-05-02 21:28:05]
  **Train** Prec@1 98.652 Prec@5 99.982 Error@1 1.348
  **Test** Prec@1 77.490 Prec@5 93.990 Error@1 22.510

==>>[2018-05-02 21:28:13] [Epoch=249/540] [Need: 02:27:34] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [249][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0349 (0.0349)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:28:13]
  Epoch: [249][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0593 (0.0614)   Prec@1 100.000 (98.786)   Prec@5 100.000 (99.980)   [2018-05-02 21:28:24]
  Epoch: [249][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0567 (0.0644)   Prec@1 99.000 (98.631)   Prec@5 100.000 (99.978)   [2018-05-02 21:28:35]
  **Train** Prec@1 98.570 Prec@5 99.980 Error@1 1.430
  **Test** Prec@1 77.310 Prec@5 93.770 Error@1 22.690

==>>[2018-05-02 21:28:43] [Epoch=250/540] [Need: 02:27:04] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [250][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0719 (0.0719)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:28:43]
  Epoch: [250][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1148 (0.0601)   Prec@1 97.000 (98.836)   Prec@5 100.000 (99.990)   [2018-05-02 21:28:54]
  Epoch: [250][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0608 (0.0613)   Prec@1 99.000 (98.771)   Prec@5 100.000 (99.988)   [2018-05-02 21:29:05]
  **Train** Prec@1 98.796 Prec@5 99.988 Error@1 1.204
  **Test** Prec@1 77.350 Prec@5 93.820 Error@1 22.650

==>>[2018-05-02 21:29:13] [Epoch=251/540] [Need: 02:26:33] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [251][000/500]   Time 0.094 (0.094)   Data 0.068 (0.068)   Loss 0.0709 (0.0709)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:29:13]
  Epoch: [251][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0551 (0.0640)   Prec@1 98.000 (98.607)   Prec@5 100.000 (99.980)   [2018-05-02 21:29:24]
  Epoch: [251][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0634 (0.0636)   Prec@1 98.000 (98.641)   Prec@5 100.000 (99.975)   [2018-05-02 21:29:35]
  **Train** Prec@1 98.676 Prec@5 99.978 Error@1 1.324
  **Test** Prec@1 77.630 Prec@5 93.940 Error@1 22.370

==>>[2018-05-02 21:29:43] [Epoch=252/540] [Need: 02:26:02] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [252][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0783 (0.0783)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:29:43]
  Epoch: [252][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0863 (0.0587)   Prec@1 97.000 (98.831)   Prec@5 100.000 (99.975)   [2018-05-02 21:29:54]
  Epoch: [252][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0710 (0.0622)   Prec@1 97.000 (98.738)   Prec@5 100.000 (99.978)   [2018-05-02 21:30:05]
  **Train** Prec@1 98.724 Prec@5 99.978 Error@1 1.276
  **Test** Prec@1 77.270 Prec@5 93.840 Error@1 22.730

==>>[2018-05-02 21:30:13] [Epoch=253/540] [Need: 02:25:31] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [253][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0329 (0.0329)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:30:14]
  Epoch: [253][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0241 (0.0619)   Prec@1 100.000 (98.746)   Prec@5 100.000 (99.995)   [2018-05-02 21:30:24]
  Epoch: [253][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0337 (0.0622)   Prec@1 100.000 (98.718)   Prec@5 100.000 (99.985)   [2018-05-02 21:30:35]
  **Train** Prec@1 98.700 Prec@5 99.986 Error@1 1.300
  **Test** Prec@1 77.340 Prec@5 93.780 Error@1 22.660

==>>[2018-05-02 21:30:43] [Epoch=254/540] [Need: 02:25:00] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [254][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0707 (0.0707)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:30:44]
  Epoch: [254][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0642 (0.0612)   Prec@1 99.000 (98.697)   Prec@5 100.000 (99.990)   [2018-05-02 21:30:55]
  Epoch: [254][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0471 (0.0613)   Prec@1 99.000 (98.681)   Prec@5 100.000 (99.990)   [2018-05-02 21:31:05]
  **Train** Prec@1 98.706 Prec@5 99.990 Error@1 1.294
  **Test** Prec@1 77.400 Prec@5 93.930 Error@1 22.600

==>>[2018-05-02 21:31:14] [Epoch=255/540] [Need: 02:24:30] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [255][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0753 (0.0753)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:31:14]
  Epoch: [255][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0516 (0.0659)   Prec@1 98.000 (98.657)   Prec@5 100.000 (99.955)   [2018-05-02 21:31:25]
  Epoch: [255][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0374 (0.0629)   Prec@1 99.000 (98.741)   Prec@5 100.000 (99.973)   [2018-05-02 21:31:36]
  **Train** Prec@1 98.764 Prec@5 99.974 Error@1 1.236
  **Test** Prec@1 77.360 Prec@5 93.970 Error@1 22.640

==>>[2018-05-02 21:31:44] [Epoch=256/540] [Need: 02:23:59] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [256][000/500]   Time 0.088 (0.088)   Data 0.061 (0.061)   Loss 0.0951 (0.0951)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:31:44]
  Epoch: [256][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1411 (0.0616)   Prec@1 96.000 (98.716)   Prec@5 100.000 (99.975)   [2018-05-02 21:31:55]
  Epoch: [256][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0496 (0.0597)   Prec@1 99.000 (98.783)   Prec@5 100.000 (99.978)   [2018-05-02 21:32:06]
  **Train** Prec@1 98.762 Prec@5 99.976 Error@1 1.238
  **Test** Prec@1 77.240 Prec@5 93.990 Error@1 22.760

==>>[2018-05-02 21:32:14] [Epoch=257/540] [Need: 02:23:28] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [257][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.0989 (0.0989)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:32:14]
  Epoch: [257][200/500]   Time 0.053 (0.055)   Data 0.000 (0.000)   Loss 0.0745 (0.0612)   Prec@1 98.000 (98.672)   Prec@5 100.000 (99.985)   [2018-05-02 21:32:25]
  Epoch: [257][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0405 (0.0619)   Prec@1 100.000 (98.633)   Prec@5 100.000 (99.980)   [2018-05-02 21:32:36]
  **Train** Prec@1 98.624 Prec@5 99.980 Error@1 1.376
  **Test** Prec@1 77.330 Prec@5 93.880 Error@1 22.670

==>>[2018-05-02 21:32:44] [Epoch=258/540] [Need: 02:22:57] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [258][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1412 (0.1412)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:32:44]
  Epoch: [258][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0754 (0.0598)   Prec@1 99.000 (98.801)   Prec@5 100.000 (99.960)   [2018-05-02 21:32:55]
  Epoch: [258][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0474 (0.0616)   Prec@1 100.000 (98.741)   Prec@5 100.000 (99.960)   [2018-05-02 21:33:06]
  **Train** Prec@1 98.748 Prec@5 99.966 Error@1 1.252
  **Test** Prec@1 77.290 Prec@5 93.860 Error@1 22.710

==>>[2018-05-02 21:33:14] [Epoch=259/540] [Need: 02:22:26] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [259][000/500]   Time 0.086 (0.086)   Data 0.061 (0.061)   Loss 0.0712 (0.0712)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:33:14]
  Epoch: [259][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0736 (0.0586)   Prec@1 98.000 (98.746)   Prec@5 100.000 (100.000)   [2018-05-02 21:33:25]
  Epoch: [259][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0491 (0.0604)   Prec@1 99.000 (98.796)   Prec@5 100.000 (99.988)   [2018-05-02 21:33:36]
  **Train** Prec@1 98.784 Prec@5 99.990 Error@1 1.216
  **Test** Prec@1 77.490 Prec@5 93.930 Error@1 22.510

==>>[2018-05-02 21:33:44] [Epoch=260/540] [Need: 02:21:56] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [260][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0638 (0.0638)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:33:44]
  Epoch: [260][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0749 (0.0633)   Prec@1 99.000 (98.716)   Prec@5 100.000 (99.975)   [2018-05-02 21:33:55]
  Epoch: [260][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0481 (0.0613)   Prec@1 99.000 (98.813)   Prec@5 100.000 (99.980)   [2018-05-02 21:34:06]
  **Train** Prec@1 98.824 Prec@5 99.980 Error@1 1.176
  **Test** Prec@1 77.230 Prec@5 93.900 Error@1 22.770

==>>[2018-05-02 21:34:14] [Epoch=261/540] [Need: 02:21:25] [learning_rate=0.001000] [Best : Accuracy=77.66, Error=22.34]
  Epoch: [261][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0437 (0.0437)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:34:14]
  Epoch: [261][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0445 (0.0597)   Prec@1 99.000 (98.786)   Prec@5 100.000 (99.975)   [2018-05-02 21:34:25]
  Epoch: [261][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1067 (0.0604)   Prec@1 97.000 (98.723)   Prec@5 100.000 (99.975)   [2018-05-02 21:34:36]
  **Train** Prec@1 98.722 Prec@5 99.980 Error@1 1.278
  **Test** Prec@1 77.770 Prec@5 93.770 Error@1 22.230

==>>[2018-05-02 21:34:44] [Epoch=262/540] [Need: 02:20:54] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [262][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0323 (0.0323)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:34:44]
  Epoch: [262][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0596 (0.0620)   Prec@1 100.000 (98.731)   Prec@5 100.000 (99.975)   [2018-05-02 21:34:55]
  Epoch: [262][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0509 (0.0612)   Prec@1 98.000 (98.738)   Prec@5 100.000 (99.975)   [2018-05-02 21:35:06]
  **Train** Prec@1 98.724 Prec@5 99.974 Error@1 1.276
  **Test** Prec@1 77.360 Prec@5 93.730 Error@1 22.640

==>>[2018-05-02 21:35:14] [Epoch=263/540] [Need: 02:20:23] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [263][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0479 (0.0479)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:35:14]
  Epoch: [263][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0678 (0.0604)   Prec@1 99.000 (98.806)   Prec@5 100.000 (99.980)   [2018-05-02 21:35:25]
  Epoch: [263][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0461 (0.0613)   Prec@1 100.000 (98.796)   Prec@5 100.000 (99.975)   [2018-05-02 21:35:36]
  **Train** Prec@1 98.786 Prec@5 99.978 Error@1 1.214
  **Test** Prec@1 77.610 Prec@5 94.020 Error@1 22.390

==>>[2018-05-02 21:35:44] [Epoch=264/540] [Need: 02:19:53] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [264][000/500]   Time 0.090 (0.090)   Data 0.064 (0.064)   Loss 0.0810 (0.0810)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:35:44]
  Epoch: [264][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0749 (0.0552)   Prec@1 97.000 (98.915)   Prec@5 100.000 (99.995)   [2018-05-02 21:35:55]
  Epoch: [264][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0505 (0.0584)   Prec@1 99.000 (98.805)   Prec@5 100.000 (99.985)   [2018-05-02 21:36:06]
  **Train** Prec@1 98.796 Prec@5 99.984 Error@1 1.204
  **Test** Prec@1 77.440 Prec@5 93.820 Error@1 22.560

==>>[2018-05-02 21:36:14] [Epoch=265/540] [Need: 02:19:22] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [265][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0605 (0.0605)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:36:15]
  Epoch: [265][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0850 (0.0594)   Prec@1 98.000 (98.791)   Prec@5 100.000 (99.985)   [2018-05-02 21:36:26]
  Epoch: [265][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0740 (0.0610)   Prec@1 97.000 (98.726)   Prec@5 100.000 (99.980)   [2018-05-02 21:36:36]
  **Train** Prec@1 98.750 Prec@5 99.982 Error@1 1.250
  **Test** Prec@1 77.450 Prec@5 94.030 Error@1 22.550

==>>[2018-05-02 21:36:45] [Epoch=266/540] [Need: 02:18:51] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [266][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0684 (0.0684)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:36:45]
  Epoch: [266][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0862 (0.0589)   Prec@1 98.000 (98.776)   Prec@5 100.000 (99.980)   [2018-05-02 21:36:56]
  Epoch: [266][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0480 (0.0595)   Prec@1 100.000 (98.800)   Prec@5 100.000 (99.985)   [2018-05-02 21:37:06]
  **Train** Prec@1 98.798 Prec@5 99.982 Error@1 1.202
  **Test** Prec@1 77.320 Prec@5 94.020 Error@1 22.680

==>>[2018-05-02 21:37:15] [Epoch=267/540] [Need: 02:18:20] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [267][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0538 (0.0538)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:37:15]
  Epoch: [267][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0695 (0.0607)   Prec@1 99.000 (98.741)   Prec@5 100.000 (99.995)   [2018-05-02 21:37:26]
  Epoch: [267][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0305 (0.0609)   Prec@1 100.000 (98.718)   Prec@5 100.000 (99.988)   [2018-05-02 21:37:37]
  **Train** Prec@1 98.702 Prec@5 99.984 Error@1 1.298
  **Test** Prec@1 77.430 Prec@5 93.910 Error@1 22.570

==>>[2018-05-02 21:37:45] [Epoch=268/540] [Need: 02:17:50] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [268][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1209 (0.1209)   Prec@1 96.000 (96.000)   Prec@5 99.000 (99.000)   [2018-05-02 21:37:45]
  Epoch: [268][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0388 (0.0621)   Prec@1 100.000 (98.657)   Prec@5 100.000 (99.990)   [2018-05-02 21:37:56]
  Epoch: [268][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0564 (0.0614)   Prec@1 99.000 (98.703)   Prec@5 100.000 (99.983)   [2018-05-02 21:38:07]
  **Train** Prec@1 98.692 Prec@5 99.982 Error@1 1.308
  **Test** Prec@1 77.610 Prec@5 93.950 Error@1 22.390

==>>[2018-05-02 21:38:15] [Epoch=269/540] [Need: 02:17:19] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [269][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0535 (0.0535)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:38:15]
  Epoch: [269][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0595 (0.0582)   Prec@1 99.000 (98.786)   Prec@5 100.000 (99.995)   [2018-05-02 21:38:26]
  Epoch: [269][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0324 (0.0577)   Prec@1 100.000 (98.786)   Prec@5 100.000 (99.990)   [2018-05-02 21:38:37]
  **Train** Prec@1 98.764 Prec@5 99.990 Error@1 1.236
  **Test** Prec@1 77.680 Prec@5 93.960 Error@1 22.320

==>>[2018-05-02 21:38:45] [Epoch=270/540] [Need: 02:16:48] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [270][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0719 (0.0719)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:38:45]
  Epoch: [270][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0961 (0.0606)   Prec@1 98.000 (98.786)   Prec@5 100.000 (99.980)   [2018-05-02 21:38:56]
  Epoch: [270][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0337 (0.0606)   Prec@1 100.000 (98.820)   Prec@5 100.000 (99.983)   [2018-05-02 21:39:07]
  **Train** Prec@1 98.796 Prec@5 99.982 Error@1 1.204
  **Test** Prec@1 77.530 Prec@5 93.910 Error@1 22.470

==>>[2018-05-02 21:39:15] [Epoch=271/540] [Need: 02:16:17] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [271][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0502 (0.0502)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:39:15]
  Epoch: [271][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1409 (0.0604)   Prec@1 98.000 (98.796)   Prec@5 100.000 (99.990)   [2018-05-02 21:39:26]
  Epoch: [271][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1020 (0.0600)   Prec@1 97.000 (98.793)   Prec@5 100.000 (99.988)   [2018-05-02 21:39:37]
  **Train** Prec@1 98.766 Prec@5 99.990 Error@1 1.234
  **Test** Prec@1 77.140 Prec@5 93.800 Error@1 22.860

==>>[2018-05-02 21:39:45] [Epoch=272/540] [Need: 02:15:47] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [272][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.1001 (0.1001)   Prec@1 98.000 (98.000)   Prec@5 99.000 (99.000)   [2018-05-02 21:39:45]
  Epoch: [272][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0657 (0.0596)   Prec@1 98.000 (98.756)   Prec@5 100.000 (99.980)   [2018-05-02 21:39:56]
  Epoch: [272][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0561 (0.0587)   Prec@1 98.000 (98.815)   Prec@5 100.000 (99.975)   [2018-05-02 21:40:07]
  **Train** Prec@1 98.826 Prec@5 99.978 Error@1 1.174
  **Test** Prec@1 77.260 Prec@5 93.940 Error@1 22.740

==>>[2018-05-02 21:40:15] [Epoch=273/540] [Need: 02:15:16] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [273][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0458 (0.0458)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:40:15]
  Epoch: [273][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0538 (0.0593)   Prec@1 98.000 (98.766)   Prec@5 100.000 (99.975)   [2018-05-02 21:40:26]
  Epoch: [273][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0694 (0.0595)   Prec@1 99.000 (98.791)   Prec@5 100.000 (99.983)   [2018-05-02 21:40:37]
  **Train** Prec@1 98.776 Prec@5 99.978 Error@1 1.224
  **Test** Prec@1 77.400 Prec@5 93.870 Error@1 22.600

==>>[2018-05-02 21:40:45] [Epoch=274/540] [Need: 02:14:45] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [274][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0488 (0.0488)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:40:45]
  Epoch: [274][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0422 (0.0580)   Prec@1 99.000 (98.851)   Prec@5 100.000 (99.995)   [2018-05-02 21:40:56]
  Epoch: [274][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0729 (0.0588)   Prec@1 98.000 (98.843)   Prec@5 100.000 (99.990)   [2018-05-02 21:41:07]
  **Train** Prec@1 98.836 Prec@5 99.986 Error@1 1.164
  **Test** Prec@1 77.360 Prec@5 93.950 Error@1 22.640

==>>[2018-05-02 21:41:15] [Epoch=275/540] [Need: 02:14:15] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [275][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0848 (0.0848)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:41:15]
  Epoch: [275][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1257 (0.0601)   Prec@1 96.000 (98.731)   Prec@5 100.000 (99.990)   [2018-05-02 21:41:26]
  Epoch: [275][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0478 (0.0583)   Prec@1 98.000 (98.835)   Prec@5 100.000 (99.975)   [2018-05-02 21:41:37]
  **Train** Prec@1 98.854 Prec@5 99.978 Error@1 1.146
  **Test** Prec@1 77.460 Prec@5 93.870 Error@1 22.540

==>>[2018-05-02 21:41:45] [Epoch=276/540] [Need: 02:13:44] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [276][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0575 (0.0575)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:41:45]
  Epoch: [276][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0898 (0.0582)   Prec@1 97.000 (98.935)   Prec@5 100.000 (99.990)   [2018-05-02 21:41:56]
  Epoch: [276][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0697 (0.0573)   Prec@1 98.000 (98.915)   Prec@5 100.000 (99.978)   [2018-05-02 21:42:07]
  **Train** Prec@1 98.904 Prec@5 99.980 Error@1 1.096
  **Test** Prec@1 77.460 Prec@5 94.020 Error@1 22.540

==>>[2018-05-02 21:42:16] [Epoch=277/540] [Need: 02:13:13] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [277][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.0538 (0.0538)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:42:16]
  Epoch: [277][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0793 (0.0589)   Prec@1 98.000 (98.881)   Prec@5 100.000 (99.975)   [2018-05-02 21:42:27]
  Epoch: [277][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0304 (0.0579)   Prec@1 100.000 (98.858)   Prec@5 100.000 (99.983)   [2018-05-02 21:42:37]
  **Train** Prec@1 98.864 Prec@5 99.986 Error@1 1.136
  **Test** Prec@1 77.310 Prec@5 93.870 Error@1 22.690

==>>[2018-05-02 21:42:46] [Epoch=278/540] [Need: 02:12:43] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [278][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0352 (0.0352)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:42:46]
  Epoch: [278][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0539 (0.0588)   Prec@1 100.000 (98.796)   Prec@5 100.000 (99.990)   [2018-05-02 21:42:57]
  Epoch: [278][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0561 (0.0587)   Prec@1 99.000 (98.805)   Prec@5 100.000 (99.990)   [2018-05-02 21:43:08]
  **Train** Prec@1 98.840 Prec@5 99.988 Error@1 1.160
  **Test** Prec@1 77.390 Prec@5 93.980 Error@1 22.610

==>>[2018-05-02 21:43:16] [Epoch=279/540] [Need: 02:12:12] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [279][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1035 (0.1035)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:43:16]
  Epoch: [279][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0354 (0.0568)   Prec@1 100.000 (98.811)   Prec@5 100.000 (99.980)   [2018-05-02 21:43:27]
  Epoch: [279][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0690 (0.0568)   Prec@1 99.000 (98.860)   Prec@5 100.000 (99.978)   [2018-05-02 21:43:38]
  **Train** Prec@1 98.822 Prec@5 99.972 Error@1 1.178
  **Test** Prec@1 77.420 Prec@5 93.860 Error@1 22.580

==>>[2018-05-02 21:43:46] [Epoch=280/540] [Need: 02:11:41] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [280][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0653 (0.0653)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:43:46]
  Epoch: [280][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0682 (0.0605)   Prec@1 98.000 (98.657)   Prec@5 100.000 (99.980)   [2018-05-02 21:43:57]
  Epoch: [280][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0691 (0.0586)   Prec@1 99.000 (98.758)   Prec@5 100.000 (99.983)   [2018-05-02 21:44:08]
  **Train** Prec@1 98.784 Prec@5 99.986 Error@1 1.216
  **Test** Prec@1 77.440 Prec@5 93.860 Error@1 22.560

==>>[2018-05-02 21:44:16] [Epoch=281/540] [Need: 02:11:11] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [281][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.0942 (0.0942)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:44:16]
  Epoch: [281][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0684 (0.0576)   Prec@1 99.000 (98.891)   Prec@5 100.000 (99.980)   [2018-05-02 21:44:27]
  Epoch: [281][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0589 (0.0583)   Prec@1 99.000 (98.825)   Prec@5 100.000 (99.980)   [2018-05-02 21:44:38]
  **Train** Prec@1 98.830 Prec@5 99.984 Error@1 1.170
  **Test** Prec@1 77.310 Prec@5 93.900 Error@1 22.690

==>>[2018-05-02 21:44:46] [Epoch=282/540] [Need: 02:10:40] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [282][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0389 (0.0389)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:44:46]
  Epoch: [282][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0533 (0.0580)   Prec@1 99.000 (98.930)   Prec@5 100.000 (99.985)   [2018-05-02 21:44:57]
  Epoch: [282][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0899 (0.0581)   Prec@1 98.000 (98.845)   Prec@5 100.000 (99.985)   [2018-05-02 21:45:08]
  **Train** Prec@1 98.838 Prec@5 99.984 Error@1 1.162
  **Test** Prec@1 77.360 Prec@5 93.890 Error@1 22.640

==>>[2018-05-02 21:45:16] [Epoch=283/540] [Need: 02:10:09] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [283][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0465 (0.0465)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:45:16]
  Epoch: [283][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0340 (0.0568)   Prec@1 100.000 (98.945)   Prec@5 100.000 (100.000)   [2018-05-02 21:45:27]
  Epoch: [283][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0753 (0.0575)   Prec@1 97.000 (98.928)   Prec@5 100.000 (99.990)   [2018-05-02 21:45:38]
  **Train** Prec@1 98.926 Prec@5 99.988 Error@1 1.074
  **Test** Prec@1 77.670 Prec@5 93.810 Error@1 22.330

==>>[2018-05-02 21:45:46] [Epoch=284/540] [Need: 02:09:39] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [284][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1226 (0.1226)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:45:46]
  Epoch: [284][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0303 (0.0571)   Prec@1 100.000 (98.886)   Prec@5 100.000 (99.995)   [2018-05-02 21:45:57]
  Epoch: [284][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0463 (0.0570)   Prec@1 99.000 (98.860)   Prec@5 100.000 (99.995)   [2018-05-02 21:46:08]
  **Train** Prec@1 98.892 Prec@5 99.994 Error@1 1.108
  **Test** Prec@1 77.510 Prec@5 93.840 Error@1 22.490

==>>[2018-05-02 21:46:16] [Epoch=285/540] [Need: 02:09:08] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [285][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0452 (0.0452)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:46:16]
  Epoch: [285][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0511 (0.0566)   Prec@1 99.000 (98.940)   Prec@5 100.000 (100.000)   [2018-05-02 21:46:27]
  Epoch: [285][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0680 (0.0574)   Prec@1 99.000 (98.898)   Prec@5 100.000 (99.995)   [2018-05-02 21:46:38]
  **Train** Prec@1 98.852 Prec@5 99.994 Error@1 1.148
  **Test** Prec@1 77.220 Prec@5 93.700 Error@1 22.780

==>>[2018-05-02 21:46:46] [Epoch=286/540] [Need: 02:08:37] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [286][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0613 (0.0613)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:46:46]
  Epoch: [286][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0311 (0.0582)   Prec@1 99.000 (98.816)   Prec@5 100.000 (99.990)   [2018-05-02 21:46:57]
  Epoch: [286][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0606 (0.0590)   Prec@1 98.000 (98.763)   Prec@5 100.000 (99.985)   [2018-05-02 21:47:08]
  **Train** Prec@1 98.784 Prec@5 99.976 Error@1 1.216
  **Test** Prec@1 77.390 Prec@5 94.050 Error@1 22.610

==>>[2018-05-02 21:47:16] [Epoch=287/540] [Need: 02:08:07] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [287][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0427 (0.0427)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:47:16]
  Epoch: [287][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0694 (0.0590)   Prec@1 97.000 (98.811)   Prec@5 100.000 (99.985)   [2018-05-02 21:47:27]
  Epoch: [287][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0684 (0.0575)   Prec@1 99.000 (98.858)   Prec@5 100.000 (99.988)   [2018-05-02 21:47:38]
  **Train** Prec@1 98.858 Prec@5 99.986 Error@1 1.142
  **Test** Prec@1 77.290 Prec@5 94.010 Error@1 22.710

==>>[2018-05-02 21:47:46] [Epoch=288/540] [Need: 02:07:36] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [288][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0506 (0.0506)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:47:47]
  Epoch: [288][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0321 (0.0553)   Prec@1 100.000 (98.990)   Prec@5 100.000 (99.990)   [2018-05-02 21:47:57]
  Epoch: [288][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0468 (0.0568)   Prec@1 100.000 (98.908)   Prec@5 100.000 (99.993)   [2018-05-02 21:48:08]
  **Train** Prec@1 98.868 Prec@5 99.992 Error@1 1.132
  **Test** Prec@1 77.380 Prec@5 93.940 Error@1 22.620

==>>[2018-05-02 21:48:17] [Epoch=289/540] [Need: 02:07:05] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [289][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0830 (0.0830)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:48:17]
  Epoch: [289][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1632 (0.0605)   Prec@1 96.000 (98.766)   Prec@5 100.000 (99.965)   [2018-05-02 21:48:28]
  Epoch: [289][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0835 (0.0588)   Prec@1 98.000 (98.840)   Prec@5 100.000 (99.983)   [2018-05-02 21:48:39]
  **Train** Prec@1 98.844 Prec@5 99.982 Error@1 1.156
  **Test** Prec@1 77.540 Prec@5 93.880 Error@1 22.460

==>>[2018-05-02 21:48:47] [Epoch=290/540] [Need: 02:06:35] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [290][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0474 (0.0474)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:48:47]
  Epoch: [290][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0352 (0.0603)   Prec@1 100.000 (98.761)   Prec@5 100.000 (99.985)   [2018-05-02 21:48:58]
  Epoch: [290][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0524 (0.0588)   Prec@1 100.000 (98.835)   Prec@5 100.000 (99.980)   [2018-05-02 21:49:09]
  **Train** Prec@1 98.874 Prec@5 99.984 Error@1 1.126
  **Test** Prec@1 77.510 Prec@5 94.060 Error@1 22.490

==>>[2018-05-02 21:49:17] [Epoch=291/540] [Need: 02:06:04] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [291][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0425 (0.0425)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:49:17]
  Epoch: [291][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0490 (0.0544)   Prec@1 100.000 (98.925)   Prec@5 100.000 (99.985)   [2018-05-02 21:49:28]
  Epoch: [291][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0520 (0.0549)   Prec@1 99.000 (98.993)   Prec@5 100.000 (99.990)   [2018-05-02 21:49:39]
  **Train** Prec@1 98.970 Prec@5 99.990 Error@1 1.030
  **Test** Prec@1 77.310 Prec@5 93.870 Error@1 22.690

==>>[2018-05-02 21:49:47] [Epoch=292/540] [Need: 02:05:33] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [292][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0254 (0.0254)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:49:47]
  Epoch: [292][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0298 (0.0552)   Prec@1 100.000 (98.990)   Prec@5 100.000 (99.975)   [2018-05-02 21:49:58]
  Epoch: [292][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0394 (0.0574)   Prec@1 99.000 (98.883)   Prec@5 100.000 (99.980)   [2018-05-02 21:50:09]
  **Train** Prec@1 98.834 Prec@5 99.982 Error@1 1.166
  **Test** Prec@1 77.410 Prec@5 93.970 Error@1 22.590

==>>[2018-05-02 21:50:17] [Epoch=293/540] [Need: 02:05:03] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [293][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0317 (0.0317)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:50:17]
  Epoch: [293][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0657 (0.0549)   Prec@1 99.000 (98.891)   Prec@5 100.000 (99.970)   [2018-05-02 21:50:28]
  Epoch: [293][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0684 (0.0539)   Prec@1 98.000 (98.960)   Prec@5 100.000 (99.973)   [2018-05-02 21:50:39]
  **Train** Prec@1 98.940 Prec@5 99.978 Error@1 1.060
  **Test** Prec@1 77.510 Prec@5 93.960 Error@1 22.490

==>>[2018-05-02 21:50:47] [Epoch=294/540] [Need: 02:04:32] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [294][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0444 (0.0444)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:50:47]
  Epoch: [294][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0422 (0.0567)   Prec@1 100.000 (98.866)   Prec@5 100.000 (99.995)   [2018-05-02 21:50:58]
  Epoch: [294][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0612 (0.0566)   Prec@1 100.000 (98.860)   Prec@5 100.000 (99.988)   [2018-05-02 21:51:09]
  **Train** Prec@1 98.868 Prec@5 99.986 Error@1 1.132
  **Test** Prec@1 77.570 Prec@5 93.930 Error@1 22.430

==>>[2018-05-02 21:51:17] [Epoch=295/540] [Need: 02:04:02] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [295][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.1037 (0.1037)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:51:17]
  Epoch: [295][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0641 (0.0582)   Prec@1 98.000 (98.796)   Prec@5 100.000 (99.995)   [2018-05-02 21:51:28]
  Epoch: [295][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0270 (0.0573)   Prec@1 100.000 (98.853)   Prec@5 100.000 (99.990)   [2018-05-02 21:51:39]
  **Train** Prec@1 98.858 Prec@5 99.986 Error@1 1.142
  **Test** Prec@1 77.600 Prec@5 93.870 Error@1 22.400

==>>[2018-05-02 21:51:47] [Epoch=296/540] [Need: 02:03:31] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [296][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0478 (0.0478)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:51:47]
  Epoch: [296][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0875 (0.0540)   Prec@1 98.000 (98.965)   Prec@5 100.000 (100.000)   [2018-05-02 21:51:58]
  Epoch: [296][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0385 (0.0550)   Prec@1 100.000 (98.930)   Prec@5 100.000 (99.983)   [2018-05-02 21:52:09]
  **Train** Prec@1 98.942 Prec@5 99.984 Error@1 1.058
  **Test** Prec@1 77.560 Prec@5 93.910 Error@1 22.440

==>>[2018-05-02 21:52:17] [Epoch=297/540] [Need: 02:03:00] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [297][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0687 (0.0687)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:52:17]
  Epoch: [297][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0411 (0.0565)   Prec@1 99.000 (98.896)   Prec@5 100.000 (99.990)   [2018-05-02 21:52:28]
  Epoch: [297][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0619 (0.0566)   Prec@1 99.000 (98.903)   Prec@5 100.000 (99.988)   [2018-05-02 21:52:39]
  **Train** Prec@1 98.860 Prec@5 99.986 Error@1 1.140
  **Test** Prec@1 77.620 Prec@5 94.100 Error@1 22.380

==>>[2018-05-02 21:52:47] [Epoch=298/540] [Need: 02:02:30] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [298][000/500]   Time 0.095 (0.095)   Data 0.069 (0.069)   Loss 0.0559 (0.0559)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:52:47]
  Epoch: [298][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0782 (0.0557)   Prec@1 97.000 (98.940)   Prec@5 100.000 (99.990)   [2018-05-02 21:52:58]
  Epoch: [298][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0579 (0.0567)   Prec@1 98.000 (98.903)   Prec@5 100.000 (99.990)   [2018-05-02 21:53:09]
  **Train** Prec@1 98.904 Prec@5 99.986 Error@1 1.096
  **Test** Prec@1 77.580 Prec@5 93.920 Error@1 22.420

==>>[2018-05-02 21:53:17] [Epoch=299/540] [Need: 02:01:59] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [299][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0509 (0.0509)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:53:17]
  Epoch: [299][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0686 (0.0547)   Prec@1 98.000 (98.905)   Prec@5 100.000 (99.985)   [2018-05-02 21:53:28]
  Epoch: [299][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0499 (0.0551)   Prec@1 99.000 (98.915)   Prec@5 100.000 (99.990)   [2018-05-02 21:53:39]
  **Train** Prec@1 98.942 Prec@5 99.990 Error@1 1.058
  **Test** Prec@1 77.510 Prec@5 93.950 Error@1 22.490

==>>[2018-05-02 21:53:47] [Epoch=300/540] [Need: 02:01:29] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [300][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1169 (0.1169)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:53:48]
  Epoch: [300][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0827 (0.0569)   Prec@1 100.000 (98.871)   Prec@5 100.000 (99.980)   [2018-05-02 21:53:58]
  Epoch: [300][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0567 (0.0558)   Prec@1 99.000 (98.890)   Prec@5 100.000 (99.985)   [2018-05-02 21:54:09]
  **Train** Prec@1 98.906 Prec@5 99.988 Error@1 1.094
  **Test** Prec@1 77.600 Prec@5 93.980 Error@1 22.400

==>>[2018-05-02 21:54:18] [Epoch=301/540] [Need: 02:00:58] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [301][000/500]   Time 0.104 (0.104)   Data 0.077 (0.077)   Loss 0.0507 (0.0507)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:54:18]
  Epoch: [301][200/500]   Time 0.054 (0.055)   Data 0.000 (0.001)   Loss 0.0445 (0.0538)   Prec@1 100.000 (99.005)   Prec@5 100.000 (99.970)   [2018-05-02 21:54:29]
  Epoch: [301][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0548 (0.0563)   Prec@1 100.000 (98.920)   Prec@5 100.000 (99.978)   [2018-05-02 21:54:40]
  **Train** Prec@1 98.924 Prec@5 99.982 Error@1 1.076
  **Test** Prec@1 77.210 Prec@5 93.830 Error@1 22.790

==>>[2018-05-02 21:54:48] [Epoch=302/540] [Need: 02:00:27] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [302][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0723 (0.0723)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:54:48]
  Epoch: [302][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1085 (0.0555)   Prec@1 95.000 (98.940)   Prec@5 100.000 (99.985)   [2018-05-02 21:54:59]
  Epoch: [302][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0358 (0.0542)   Prec@1 99.000 (98.988)   Prec@5 100.000 (99.990)   [2018-05-02 21:55:10]
  **Train** Prec@1 98.948 Prec@5 99.990 Error@1 1.052
  **Test** Prec@1 77.420 Prec@5 93.840 Error@1 22.580

==>>[2018-05-02 21:55:18] [Epoch=303/540] [Need: 01:59:57] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [303][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0381 (0.0381)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:55:18]
  Epoch: [303][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0251 (0.0546)   Prec@1 100.000 (98.950)   Prec@5 100.000 (99.985)   [2018-05-02 21:55:29]
  Epoch: [303][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0634 (0.0555)   Prec@1 97.000 (98.940)   Prec@5 100.000 (99.983)   [2018-05-02 21:55:40]
  **Train** Prec@1 98.970 Prec@5 99.984 Error@1 1.030
  **Test** Prec@1 77.590 Prec@5 93.820 Error@1 22.410

==>>[2018-05-02 21:55:48] [Epoch=304/540] [Need: 01:59:26] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [304][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0197 (0.0197)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:55:48]
  Epoch: [304][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0636 (0.0544)   Prec@1 99.000 (98.945)   Prec@5 100.000 (99.995)   [2018-05-02 21:55:59]
  Epoch: [304][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0418 (0.0541)   Prec@1 100.000 (98.958)   Prec@5 100.000 (99.988)   [2018-05-02 21:56:10]
  **Train** Prec@1 98.930 Prec@5 99.988 Error@1 1.070
  **Test** Prec@1 77.500 Prec@5 93.850 Error@1 22.500

==>>[2018-05-02 21:56:18] [Epoch=305/540] [Need: 01:58:56] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [305][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0336 (0.0336)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:56:18]
  Epoch: [305][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0468 (0.0543)   Prec@1 100.000 (98.980)   Prec@5 100.000 (99.990)   [2018-05-02 21:56:29]
  Epoch: [305][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1017 (0.0551)   Prec@1 97.000 (98.940)   Prec@5 99.000 (99.990)   [2018-05-02 21:56:40]
  **Train** Prec@1 98.954 Prec@5 99.988 Error@1 1.046
  **Test** Prec@1 77.470 Prec@5 93.880 Error@1 22.530

==>>[2018-05-02 21:56:48] [Epoch=306/540] [Need: 01:58:25] [learning_rate=0.001000] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [306][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0445 (0.0445)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:56:48]
  Epoch: [306][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0765 (0.0543)   Prec@1 97.000 (98.965)   Prec@5 100.000 (99.990)   [2018-05-02 21:56:59]
  Epoch: [306][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0306 (0.0548)   Prec@1 100.000 (98.925)   Prec@5 100.000 (99.988)   [2018-05-02 21:57:10]
  **Train** Prec@1 98.960 Prec@5 99.986 Error@1 1.040
  **Test** Prec@1 77.580 Prec@5 93.940 Error@1 22.420

==>>[2018-05-02 21:57:18] [Epoch=307/540] [Need: 01:57:54] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [307][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0677 (0.0677)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:57:18]
  Epoch: [307][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0397 (0.0526)   Prec@1 99.000 (99.025)   Prec@5 100.000 (99.990)   [2018-05-02 21:57:29]
  Epoch: [307][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0342 (0.0550)   Prec@1 100.000 (98.920)   Prec@5 100.000 (99.980)   [2018-05-02 21:57:40]
  **Train** Prec@1 98.916 Prec@5 99.980 Error@1 1.084
  **Test** Prec@1 77.400 Prec@5 94.020 Error@1 22.600

==>>[2018-05-02 21:57:48] [Epoch=308/540] [Need: 01:57:24] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [308][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0502 (0.0502)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:57:48]
  Epoch: [308][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0730 (0.0531)   Prec@1 99.000 (99.045)   Prec@5 100.000 (99.985)   [2018-05-02 21:57:59]
  Epoch: [308][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1270 (0.0538)   Prec@1 97.000 (98.973)   Prec@5 100.000 (99.983)   [2018-05-02 21:58:10]
  **Train** Prec@1 98.978 Prec@5 99.982 Error@1 1.022
  **Test** Prec@1 77.280 Prec@5 93.850 Error@1 22.720

==>>[2018-05-02 21:58:18] [Epoch=309/540] [Need: 01:56:53] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [309][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0858 (0.0858)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:58:18]
  Epoch: [309][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0336 (0.0526)   Prec@1 99.000 (98.995)   Prec@5 100.000 (99.995)   [2018-05-02 21:58:29]
  Epoch: [309][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0766 (0.0527)   Prec@1 98.000 (99.012)   Prec@5 100.000 (99.993)   [2018-05-02 21:58:40]
  **Train** Prec@1 99.038 Prec@5 99.994 Error@1 0.962
  **Test** Prec@1 77.650 Prec@5 94.110 Error@1 22.350

==>>[2018-05-02 21:58:48] [Epoch=310/540] [Need: 01:56:23] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [310][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0779 (0.0779)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:58:49]
  Epoch: [310][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0450 (0.0533)   Prec@1 100.000 (98.960)   Prec@5 100.000 (99.980)   [2018-05-02 21:58:59]
  Epoch: [310][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0289 (0.0548)   Prec@1 99.000 (98.935)   Prec@5 100.000 (99.980)   [2018-05-02 21:59:10]
  **Train** Prec@1 98.986 Prec@5 99.982 Error@1 1.014
  **Test** Prec@1 77.410 Prec@5 93.960 Error@1 22.590

==>>[2018-05-02 21:59:18] [Epoch=311/540] [Need: 01:55:52] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [311][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0461 (0.0461)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:59:19]
  Epoch: [311][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0406 (0.0590)   Prec@1 100.000 (98.786)   Prec@5 100.000 (99.960)   [2018-05-02 21:59:30]
  Epoch: [311][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0423 (0.0560)   Prec@1 98.000 (98.868)   Prec@5 100.000 (99.973)   [2018-05-02 21:59:40]
  **Train** Prec@1 98.896 Prec@5 99.968 Error@1 1.104
  **Test** Prec@1 77.430 Prec@5 93.980 Error@1 22.570

==>>[2018-05-02 21:59:49] [Epoch=312/540] [Need: 01:55:22] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [312][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0680 (0.0680)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 21:59:49]
  Epoch: [312][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0511 (0.0574)   Prec@1 98.000 (98.781)   Prec@5 100.000 (99.975)   [2018-05-02 22:00:00]
  Epoch: [312][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0350 (0.0557)   Prec@1 99.000 (98.858)   Prec@5 100.000 (99.980)   [2018-05-02 22:00:11]
  **Train** Prec@1 98.876 Prec@5 99.982 Error@1 1.124
  **Test** Prec@1 77.670 Prec@5 94.090 Error@1 22.330

==>>[2018-05-02 22:00:19] [Epoch=313/540] [Need: 01:54:51] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [313][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0629 (0.0629)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:00:19]
  Epoch: [313][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0678 (0.0534)   Prec@1 98.000 (98.965)   Prec@5 100.000 (100.000)   [2018-05-02 22:00:30]
  Epoch: [313][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0370 (0.0540)   Prec@1 99.000 (98.978)   Prec@5 100.000 (99.993)   [2018-05-02 22:00:41]
  **Train** Prec@1 98.976 Prec@5 99.994 Error@1 1.024
  **Test** Prec@1 77.480 Prec@5 94.060 Error@1 22.520

==>>[2018-05-02 22:00:49] [Epoch=314/540] [Need: 01:54:21] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [314][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1063 (0.1063)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:00:49]
  Epoch: [314][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0408 (0.0564)   Prec@1 100.000 (98.925)   Prec@5 100.000 (99.975)   [2018-05-02 22:01:00]
  Epoch: [314][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0274 (0.0548)   Prec@1 100.000 (98.968)   Prec@5 100.000 (99.983)   [2018-05-02 22:01:11]
  **Train** Prec@1 98.960 Prec@5 99.984 Error@1 1.040
  **Test** Prec@1 77.380 Prec@5 93.970 Error@1 22.620

==>>[2018-05-02 22:01:19] [Epoch=315/540] [Need: 01:53:50] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [315][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0517 (0.0517)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:01:19]
  Epoch: [315][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0413 (0.0569)   Prec@1 98.000 (98.841)   Prec@5 100.000 (99.975)   [2018-05-02 22:01:30]
  Epoch: [315][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0571 (0.0555)   Prec@1 99.000 (98.923)   Prec@5 100.000 (99.975)   [2018-05-02 22:01:41]
  **Train** Prec@1 98.892 Prec@5 99.978 Error@1 1.108
  **Test** Prec@1 77.420 Prec@5 93.910 Error@1 22.580

==>>[2018-05-02 22:01:49] [Epoch=316/540] [Need: 01:53:19] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [316][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0243 (0.0243)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:01:49]
  Epoch: [316][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0504 (0.0513)   Prec@1 99.000 (99.035)   Prec@5 100.000 (100.000)   [2018-05-02 22:02:00]
  Epoch: [316][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0647 (0.0547)   Prec@1 97.000 (98.935)   Prec@5 100.000 (99.990)   [2018-05-02 22:02:11]
  **Train** Prec@1 98.910 Prec@5 99.992 Error@1 1.090
  **Test** Prec@1 77.610 Prec@5 94.120 Error@1 22.390

==>>[2018-05-02 22:02:19] [Epoch=317/540] [Need: 01:52:49] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [317][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0515 (0.0515)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:02:19]
  Epoch: [317][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0592 (0.0534)   Prec@1 98.000 (98.985)   Prec@5 100.000 (99.995)   [2018-05-02 22:02:30]
  Epoch: [317][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0479 (0.0534)   Prec@1 99.000 (98.968)   Prec@5 100.000 (99.990)   [2018-05-02 22:02:41]
  **Train** Prec@1 98.970 Prec@5 99.990 Error@1 1.030
  **Test** Prec@1 77.360 Prec@5 93.960 Error@1 22.640

==>>[2018-05-02 22:02:49] [Epoch=318/540] [Need: 01:52:18] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [318][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.1106 (0.1106)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:02:49]
  Epoch: [318][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0426 (0.0512)   Prec@1 99.000 (99.055)   Prec@5 100.000 (100.000)   [2018-05-02 22:03:00]
  Epoch: [318][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0583 (0.0513)   Prec@1 99.000 (99.052)   Prec@5 100.000 (99.993)   [2018-05-02 22:03:11]
  **Train** Prec@1 99.014 Prec@5 99.990 Error@1 0.986
  **Test** Prec@1 77.490 Prec@5 93.930 Error@1 22.510

==>>[2018-05-02 22:03:19] [Epoch=319/540] [Need: 01:51:48] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [319][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0860 (0.0860)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:03:19]
  Epoch: [319][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0344 (0.0549)   Prec@1 99.000 (98.920)   Prec@5 100.000 (99.975)   [2018-05-02 22:03:30]
  Epoch: [319][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1084 (0.0546)   Prec@1 97.000 (98.938)   Prec@5 100.000 (99.988)   [2018-05-02 22:03:41]
  **Train** Prec@1 98.940 Prec@5 99.988 Error@1 1.060
  **Test** Prec@1 77.480 Prec@5 93.930 Error@1 22.520

==>>[2018-05-02 22:03:49] [Epoch=320/540] [Need: 01:51:17] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [320][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0324 (0.0324)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:03:49]
  Epoch: [320][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0358 (0.0529)   Prec@1 100.000 (99.015)   Prec@5 100.000 (99.980)   [2018-05-02 22:04:00]
  Epoch: [320][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0397 (0.0536)   Prec@1 100.000 (98.995)   Prec@5 100.000 (99.988)   [2018-05-02 22:04:11]
  **Train** Prec@1 98.976 Prec@5 99.990 Error@1 1.024
  **Test** Prec@1 77.420 Prec@5 94.080 Error@1 22.580

==>>[2018-05-02 22:04:19] [Epoch=321/540] [Need: 01:50:47] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [321][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0457 (0.0457)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:04:20]
  Epoch: [321][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0580 (0.0549)   Prec@1 98.000 (98.910)   Prec@5 100.000 (99.995)   [2018-05-02 22:04:30]
  Epoch: [321][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0386 (0.0533)   Prec@1 100.000 (98.998)   Prec@5 100.000 (99.985)   [2018-05-02 22:04:41]
  **Train** Prec@1 98.990 Prec@5 99.986 Error@1 1.010
  **Test** Prec@1 77.550 Prec@5 93.980 Error@1 22.450

==>>[2018-05-02 22:04:49] [Epoch=322/540] [Need: 01:50:16] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [322][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0701 (0.0701)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:04:50]
  Epoch: [322][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0387 (0.0530)   Prec@1 99.000 (98.960)   Prec@5 100.000 (99.970)   [2018-05-02 22:05:00]
  Epoch: [322][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0588 (0.0531)   Prec@1 99.000 (98.968)   Prec@5 100.000 (99.978)   [2018-05-02 22:05:11]
  **Train** Prec@1 98.960 Prec@5 99.982 Error@1 1.040
  **Test** Prec@1 77.410 Prec@5 93.920 Error@1 22.590

==>>[2018-05-02 22:05:20] [Epoch=323/540] [Need: 01:49:46] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [323][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0350 (0.0350)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:05:20]
  Epoch: [323][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0717 (0.0528)   Prec@1 98.000 (99.020)   Prec@5 100.000 (99.990)   [2018-05-02 22:05:31]
  Epoch: [323][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0539 (0.0538)   Prec@1 99.000 (98.975)   Prec@5 100.000 (99.990)   [2018-05-02 22:05:41]
  **Train** Prec@1 98.968 Prec@5 99.992 Error@1 1.032
  **Test** Prec@1 77.500 Prec@5 94.000 Error@1 22.500

==>>[2018-05-02 22:05:50] [Epoch=324/540] [Need: 01:49:15] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [324][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0947 (0.0947)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:05:50]
  Epoch: [324][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0215 (0.0532)   Prec@1 100.000 (99.015)   Prec@5 100.000 (99.990)   [2018-05-02 22:06:01]
  Epoch: [324][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0533 (0.0532)   Prec@1 100.000 (99.007)   Prec@5 100.000 (99.993)   [2018-05-02 22:06:12]
  **Train** Prec@1 99.002 Prec@5 99.986 Error@1 0.998
  **Test** Prec@1 77.400 Prec@5 94.010 Error@1 22.600

==>>[2018-05-02 22:06:20] [Epoch=325/540] [Need: 01:48:45] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [325][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0299 (0.0299)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:06:20]
  Epoch: [325][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0669 (0.0550)   Prec@1 98.000 (98.925)   Prec@5 100.000 (99.975)   [2018-05-02 22:06:31]
  Epoch: [325][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0294 (0.0543)   Prec@1 100.000 (98.975)   Prec@5 100.000 (99.975)   [2018-05-02 22:06:42]
  **Train** Prec@1 98.972 Prec@5 99.976 Error@1 1.028
  **Test** Prec@1 77.620 Prec@5 93.940 Error@1 22.380

==>>[2018-05-02 22:06:50] [Epoch=326/540] [Need: 01:48:14] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [326][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0437 (0.0437)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:06:50]
  Epoch: [326][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0490 (0.0542)   Prec@1 100.000 (99.075)   Prec@5 100.000 (99.980)   [2018-05-02 22:07:01]
  Epoch: [326][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0910 (0.0533)   Prec@1 99.000 (99.040)   Prec@5 99.000 (99.985)   [2018-05-02 22:07:12]
  **Train** Prec@1 99.008 Prec@5 99.986 Error@1 0.992
  **Test** Prec@1 77.580 Prec@5 94.030 Error@1 22.420

==>>[2018-05-02 22:07:20] [Epoch=327/540] [Need: 01:47:44] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [327][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0311 (0.0311)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:07:20]
  Epoch: [327][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0557 (0.0519)   Prec@1 99.000 (99.070)   Prec@5 100.000 (99.995)   [2018-05-02 22:07:31]
  Epoch: [327][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0303 (0.0545)   Prec@1 100.000 (98.968)   Prec@5 100.000 (99.990)   [2018-05-02 22:07:42]
  **Train** Prec@1 98.962 Prec@5 99.988 Error@1 1.038
  **Test** Prec@1 77.350 Prec@5 93.950 Error@1 22.650

==>>[2018-05-02 22:07:50] [Epoch=328/540] [Need: 01:47:13] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [328][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0299 (0.0299)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:07:50]
  Epoch: [328][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0887 (0.0531)   Prec@1 97.000 (98.990)   Prec@5 100.000 (99.985)   [2018-05-02 22:08:01]
  Epoch: [328][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1083 (0.0535)   Prec@1 97.000 (98.938)   Prec@5 100.000 (99.985)   [2018-05-02 22:08:12]
  **Train** Prec@1 98.930 Prec@5 99.986 Error@1 1.070
  **Test** Prec@1 77.530 Prec@5 93.960 Error@1 22.470

==>>[2018-05-02 22:08:20] [Epoch=329/540] [Need: 01:46:43] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [329][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0311 (0.0311)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:08:20]
  Epoch: [329][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0410 (0.0543)   Prec@1 99.000 (98.905)   Prec@5 100.000 (99.985)   [2018-05-02 22:08:31]
  Epoch: [329][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0286 (0.0530)   Prec@1 100.000 (98.948)   Prec@5 100.000 (99.985)   [2018-05-02 22:08:42]
  **Train** Prec@1 98.932 Prec@5 99.986 Error@1 1.068
  **Test** Prec@1 77.560 Prec@5 93.990 Error@1 22.440

==>>[2018-05-02 22:08:50] [Epoch=330/540] [Need: 01:46:12] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [330][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0314 (0.0314)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:08:50]
  Epoch: [330][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0328 (0.0529)   Prec@1 99.000 (98.910)   Prec@5 100.000 (99.975)   [2018-05-02 22:09:01]
  Epoch: [330][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0704 (0.0526)   Prec@1 97.000 (98.958)   Prec@5 100.000 (99.980)   [2018-05-02 22:09:12]
  **Train** Prec@1 98.958 Prec@5 99.980 Error@1 1.042
  **Test** Prec@1 77.560 Prec@5 93.900 Error@1 22.440

==>>[2018-05-02 22:09:20] [Epoch=331/540] [Need: 01:45:41] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [331][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0635 (0.0635)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:09:20]
  Epoch: [331][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0837 (0.0536)   Prec@1 99.000 (98.980)   Prec@5 100.000 (99.995)   [2018-05-02 22:09:31]
  Epoch: [331][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0430 (0.0538)   Prec@1 100.000 (98.955)   Prec@5 100.000 (99.990)   [2018-05-02 22:09:42]
  **Train** Prec@1 98.990 Prec@5 99.992 Error@1 1.010
  **Test** Prec@1 77.350 Prec@5 93.910 Error@1 22.650

==>>[2018-05-02 22:09:50] [Epoch=332/540] [Need: 01:45:11] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [332][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.0362 (0.0362)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:09:50]
  Epoch: [332][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0760 (0.0534)   Prec@1 97.000 (98.985)   Prec@5 100.000 (99.980)   [2018-05-02 22:10:01]
  Epoch: [332][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0586 (0.0537)   Prec@1 99.000 (98.940)   Prec@5 100.000 (99.980)   [2018-05-02 22:10:12]
  **Train** Prec@1 98.962 Prec@5 99.982 Error@1 1.038
  **Test** Prec@1 77.660 Prec@5 94.020 Error@1 22.340

==>>[2018-05-02 22:10:20] [Epoch=333/540] [Need: 01:44:40] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [333][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0826 (0.0826)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:10:21]
  Epoch: [333][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0432 (0.0535)   Prec@1 99.000 (98.940)   Prec@5 100.000 (99.985)   [2018-05-02 22:10:31]
  Epoch: [333][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0498 (0.0539)   Prec@1 99.000 (98.920)   Prec@5 100.000 (99.978)   [2018-05-02 22:10:42]
  **Train** Prec@1 98.918 Prec@5 99.980 Error@1 1.082
  **Test** Prec@1 77.630 Prec@5 93.950 Error@1 22.370

==>>[2018-05-02 22:10:50] [Epoch=334/540] [Need: 01:44:10] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [334][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0481 (0.0481)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:10:51]
  Epoch: [334][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1249 (0.0523)   Prec@1 98.000 (99.020)   Prec@5 100.000 (99.980)   [2018-05-02 22:11:02]
  Epoch: [334][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0949 (0.0530)   Prec@1 98.000 (99.030)   Prec@5 100.000 (99.983)   [2018-05-02 22:11:12]
  **Train** Prec@1 99.024 Prec@5 99.986 Error@1 0.976
  **Test** Prec@1 77.470 Prec@5 94.040 Error@1 22.530

==>>[2018-05-02 22:11:21] [Epoch=335/540] [Need: 01:43:39] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [335][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0653 (0.0653)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:11:21]
  Epoch: [335][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0314 (0.0509)   Prec@1 100.000 (99.060)   Prec@5 100.000 (99.995)   [2018-05-02 22:11:32]
  Epoch: [335][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0360 (0.0516)   Prec@1 100.000 (99.040)   Prec@5 100.000 (99.998)   [2018-05-02 22:11:42]
  **Train** Prec@1 99.022 Prec@5 99.994 Error@1 0.978
  **Test** Prec@1 77.600 Prec@5 93.980 Error@1 22.400

==>>[2018-05-02 22:11:51] [Epoch=336/540] [Need: 01:43:09] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [336][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0579 (0.0579)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:11:51]
  Epoch: [336][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0541 (0.0536)   Prec@1 99.000 (98.995)   Prec@5 100.000 (99.995)   [2018-05-02 22:12:02]
  Epoch: [336][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0420 (0.0538)   Prec@1 99.000 (98.943)   Prec@5 100.000 (99.990)   [2018-05-02 22:12:13]
  **Train** Prec@1 98.964 Prec@5 99.990 Error@1 1.036
  **Test** Prec@1 77.320 Prec@5 93.920 Error@1 22.680

==>>[2018-05-02 22:12:21] [Epoch=337/540] [Need: 01:42:38] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [337][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0527 (0.0527)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:12:21]
  Epoch: [337][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0757 (0.0532)   Prec@1 98.000 (99.020)   Prec@5 100.000 (99.990)   [2018-05-02 22:12:32]
  Epoch: [337][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0480 (0.0543)   Prec@1 99.000 (98.930)   Prec@5 100.000 (99.985)   [2018-05-02 22:12:43]
  **Train** Prec@1 98.952 Prec@5 99.988 Error@1 1.048
  **Test** Prec@1 77.420 Prec@5 93.930 Error@1 22.580

==>>[2018-05-02 22:12:51] [Epoch=338/540] [Need: 01:42:08] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [338][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0867 (0.0867)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:12:51]
  Epoch: [338][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0351 (0.0552)   Prec@1 100.000 (98.896)   Prec@5 100.000 (99.990)   [2018-05-02 22:13:02]
  Epoch: [338][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0414 (0.0538)   Prec@1 100.000 (98.980)   Prec@5 100.000 (99.993)   [2018-05-02 22:13:13]
  **Train** Prec@1 98.972 Prec@5 99.994 Error@1 1.028
  **Test** Prec@1 77.480 Prec@5 93.810 Error@1 22.520

==>>[2018-05-02 22:13:21] [Epoch=339/540] [Need: 01:41:38] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [339][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0482 (0.0482)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:13:21]
  Epoch: [339][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0351 (0.0537)   Prec@1 100.000 (98.970)   Prec@5 100.000 (99.990)   [2018-05-02 22:13:32]
  Epoch: [339][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0488 (0.0535)   Prec@1 99.000 (99.005)   Prec@5 100.000 (99.993)   [2018-05-02 22:13:43]
  **Train** Prec@1 99.006 Prec@5 99.992 Error@1 0.994
  **Test** Prec@1 77.450 Prec@5 93.960 Error@1 22.550

==>>[2018-05-02 22:13:51] [Epoch=340/540] [Need: 01:41:07] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [340][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0232 (0.0232)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:13:51]
  Epoch: [340][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0320 (0.0492)   Prec@1 100.000 (99.164)   Prec@5 100.000 (99.985)   [2018-05-02 22:14:02]
  Epoch: [340][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1141 (0.0510)   Prec@1 97.000 (99.065)   Prec@5 100.000 (99.990)   [2018-05-02 22:14:13]
  **Train** Prec@1 99.058 Prec@5 99.990 Error@1 0.942
  **Test** Prec@1 77.350 Prec@5 93.980 Error@1 22.650

==>>[2018-05-02 22:14:21] [Epoch=341/540] [Need: 01:40:37] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [341][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0595 (0.0595)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:14:21]
  Epoch: [341][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0276 (0.0535)   Prec@1 100.000 (98.985)   Prec@5 100.000 (99.985)   [2018-05-02 22:14:32]
  Epoch: [341][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0352 (0.0529)   Prec@1 100.000 (98.975)   Prec@5 100.000 (99.990)   [2018-05-02 22:14:43]
  **Train** Prec@1 98.958 Prec@5 99.988 Error@1 1.042
  **Test** Prec@1 77.460 Prec@5 93.910 Error@1 22.540

==>>[2018-05-02 22:14:51] [Epoch=342/540] [Need: 01:40:06] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [342][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0811 (0.0811)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:14:51]
  Epoch: [342][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0625 (0.0534)   Prec@1 99.000 (98.955)   Prec@5 100.000 (99.980)   [2018-05-02 22:15:02]
  Epoch: [342][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1096 (0.0535)   Prec@1 98.000 (98.950)   Prec@5 100.000 (99.985)   [2018-05-02 22:15:13]
  **Train** Prec@1 98.988 Prec@5 99.986 Error@1 1.012
  **Test** Prec@1 77.650 Prec@5 93.950 Error@1 22.350

==>>[2018-05-02 22:15:21] [Epoch=343/540] [Need: 01:39:36] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [343][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0690 (0.0690)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:15:21]
  Epoch: [343][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0521 (0.0520)   Prec@1 99.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 22:15:32]
  Epoch: [343][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0315 (0.0520)   Prec@1 100.000 (99.032)   Prec@5 100.000 (99.990)   [2018-05-02 22:15:43]
  **Train** Prec@1 99.032 Prec@5 99.990 Error@1 0.968
  **Test** Prec@1 77.550 Prec@5 94.020 Error@1 22.450

==>>[2018-05-02 22:15:51] [Epoch=344/540] [Need: 01:39:05] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [344][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0220 (0.0220)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:15:51]
  Epoch: [344][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0623 (0.0527)   Prec@1 98.000 (99.020)   Prec@5 100.000 (99.985)   [2018-05-02 22:16:02]
  Epoch: [344][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0486 (0.0518)   Prec@1 99.000 (99.002)   Prec@5 100.000 (99.983)   [2018-05-02 22:16:13]
  **Train** Prec@1 98.998 Prec@5 99.984 Error@1 1.002
  **Test** Prec@1 77.710 Prec@5 93.890 Error@1 22.290

==>>[2018-05-02 22:16:22] [Epoch=345/540] [Need: 01:38:35] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [345][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0321 (0.0321)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:16:22]
  Epoch: [345][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1316 (0.0507)   Prec@1 97.000 (99.100)   Prec@5 100.000 (99.985)   [2018-05-02 22:16:33]
  Epoch: [345][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0188 (0.0523)   Prec@1 100.000 (99.005)   Prec@5 100.000 (99.988)   [2018-05-02 22:16:44]
  **Train** Prec@1 98.984 Prec@5 99.988 Error@1 1.016
  **Test** Prec@1 77.470 Prec@5 93.770 Error@1 22.530

==>>[2018-05-02 22:16:52] [Epoch=346/540] [Need: 01:38:04] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [346][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0600 (0.0600)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:16:52]
  Epoch: [346][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0559 (0.0551)   Prec@1 99.000 (98.935)   Prec@5 100.000 (99.995)   [2018-05-02 22:17:03]
  Epoch: [346][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0523 (0.0547)   Prec@1 99.000 (98.915)   Prec@5 100.000 (99.985)   [2018-05-02 22:17:14]
  **Train** Prec@1 98.936 Prec@5 99.988 Error@1 1.064
  **Test** Prec@1 77.370 Prec@5 94.100 Error@1 22.630

==>>[2018-05-02 22:17:22] [Epoch=347/540] [Need: 01:37:34] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [347][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0614 (0.0614)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:17:22]
  Epoch: [347][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0339 (0.0529)   Prec@1 100.000 (99.035)   Prec@5 100.000 (99.985)   [2018-05-02 22:17:33]
  Epoch: [347][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0731 (0.0546)   Prec@1 98.000 (98.963)   Prec@5 100.000 (99.990)   [2018-05-02 22:17:44]
  **Train** Prec@1 98.958 Prec@5 99.986 Error@1 1.042
  **Test** Prec@1 77.730 Prec@5 93.990 Error@1 22.270

==>>[2018-05-02 22:17:52] [Epoch=348/540] [Need: 01:37:03] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [348][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0215 (0.0215)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:17:52]
  Epoch: [348][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0686 (0.0545)   Prec@1 99.000 (98.915)   Prec@5 100.000 (99.995)   [2018-05-02 22:18:03]
  Epoch: [348][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0443 (0.0530)   Prec@1 100.000 (98.965)   Prec@5 100.000 (99.990)   [2018-05-02 22:18:14]
  **Train** Prec@1 98.956 Prec@5 99.992 Error@1 1.044
  **Test** Prec@1 77.380 Prec@5 93.940 Error@1 22.620

==>>[2018-05-02 22:18:22] [Epoch=349/540] [Need: 01:36:33] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [349][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0320 (0.0320)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:18:22]
  Epoch: [349][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0552 (0.0533)   Prec@1 98.000 (98.886)   Prec@5 100.000 (99.990)   [2018-05-02 22:18:33]
  Epoch: [349][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0339 (0.0535)   Prec@1 100.000 (98.925)   Prec@5 100.000 (99.980)   [2018-05-02 22:18:44]
  **Train** Prec@1 98.960 Prec@5 99.982 Error@1 1.040
  **Test** Prec@1 77.300 Prec@5 93.950 Error@1 22.700

==>>[2018-05-02 22:18:52] [Epoch=350/540] [Need: 01:36:02] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [350][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0367 (0.0367)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:18:52]
  Epoch: [350][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0442 (0.0553)   Prec@1 99.000 (98.891)   Prec@5 100.000 (99.990)   [2018-05-02 22:19:03]
  Epoch: [350][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0573 (0.0534)   Prec@1 99.000 (98.978)   Prec@5 100.000 (99.990)   [2018-05-02 22:19:14]
  **Train** Prec@1 99.010 Prec@5 99.988 Error@1 0.990
  **Test** Prec@1 77.510 Prec@5 94.000 Error@1 22.490

==>>[2018-05-02 22:19:22] [Epoch=351/540] [Need: 01:35:32] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [351][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0428 (0.0428)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:19:22]
  Epoch: [351][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0961 (0.0534)   Prec@1 98.000 (98.896)   Prec@5 100.000 (99.965)   [2018-05-02 22:19:33]
  Epoch: [351][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0466 (0.0514)   Prec@1 99.000 (98.990)   Prec@5 100.000 (99.980)   [2018-05-02 22:19:44]
  **Train** Prec@1 98.994 Prec@5 99.982 Error@1 1.006
  **Test** Prec@1 77.460 Prec@5 94.010 Error@1 22.540

==>>[2018-05-02 22:19:52] [Epoch=352/540] [Need: 01:35:01] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [352][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0409 (0.0409)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:19:52]
  Epoch: [352][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0774 (0.0537)   Prec@1 98.000 (98.940)   Prec@5 100.000 (99.995)   [2018-05-02 22:20:03]
  Epoch: [352][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0600 (0.0517)   Prec@1 99.000 (99.007)   Prec@5 100.000 (99.993)   [2018-05-02 22:20:14]
  **Train** Prec@1 98.974 Prec@5 99.994 Error@1 1.026
  **Test** Prec@1 77.460 Prec@5 93.970 Error@1 22.540

==>>[2018-05-02 22:20:22] [Epoch=353/540] [Need: 01:34:31] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [353][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0502 (0.0502)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:20:22]
  Epoch: [353][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0820 (0.0537)   Prec@1 98.000 (98.876)   Prec@5 100.000 (99.995)   [2018-05-02 22:20:33]
  Epoch: [353][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0557 (0.0526)   Prec@1 97.000 (98.988)   Prec@5 100.000 (99.995)   [2018-05-02 22:20:44]
  **Train** Prec@1 98.982 Prec@5 99.996 Error@1 1.018
  **Test** Prec@1 77.600 Prec@5 94.030 Error@1 22.400

==>>[2018-05-02 22:20:52] [Epoch=354/540] [Need: 01:34:00] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [354][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0251 (0.0251)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:20:52]
  Epoch: [354][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1006 (0.0537)   Prec@1 97.000 (98.995)   Prec@5 100.000 (99.980)   [2018-05-02 22:21:03]
  Epoch: [354][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0402 (0.0526)   Prec@1 100.000 (98.985)   Prec@5 100.000 (99.985)   [2018-05-02 22:21:14]
  **Train** Prec@1 99.010 Prec@5 99.982 Error@1 0.990
  **Test** Prec@1 77.410 Prec@5 93.870 Error@1 22.590

==>>[2018-05-02 22:21:22] [Epoch=355/540] [Need: 01:33:30] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [355][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0692 (0.0692)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:21:22]
  Epoch: [355][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0518 (0.0546)   Prec@1 99.000 (98.915)   Prec@5 100.000 (99.995)   [2018-05-02 22:21:33]
  Epoch: [355][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0278 (0.0536)   Prec@1 100.000 (98.955)   Prec@5 100.000 (99.998)   [2018-05-02 22:21:44]
  **Train** Prec@1 98.956 Prec@5 99.996 Error@1 1.044
  **Test** Prec@1 77.610 Prec@5 93.900 Error@1 22.390

==>>[2018-05-02 22:21:52] [Epoch=356/540] [Need: 01:33:00] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [356][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0394 (0.0394)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:21:53]
  Epoch: [356][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0452 (0.0522)   Prec@1 99.000 (98.970)   Prec@5 100.000 (99.980)   [2018-05-02 22:22:03]
  Epoch: [356][400/500]   Time 0.062 (0.055)   Data 0.000 (0.000)   Loss 0.0418 (0.0513)   Prec@1 100.000 (99.002)   Prec@5 100.000 (99.985)   [2018-05-02 22:22:14]
  **Train** Prec@1 98.976 Prec@5 99.988 Error@1 1.024
  **Test** Prec@1 77.620 Prec@5 93.940 Error@1 22.380

==>>[2018-05-02 22:22:23] [Epoch=357/540] [Need: 01:32:29] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [357][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0644 (0.0644)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:22:23]
  Epoch: [357][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0729 (0.0553)   Prec@1 99.000 (98.900)   Prec@5 100.000 (99.995)   [2018-05-02 22:22:34]
  Epoch: [357][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0322 (0.0548)   Prec@1 100.000 (98.915)   Prec@5 100.000 (99.988)   [2018-05-02 22:22:45]
  **Train** Prec@1 98.920 Prec@5 99.988 Error@1 1.080
  **Test** Prec@1 77.330 Prec@5 93.870 Error@1 22.670

==>>[2018-05-02 22:22:53] [Epoch=358/540] [Need: 01:31:59] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [358][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0484 (0.0484)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:22:53]
  Epoch: [358][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0512 (0.0512)   Prec@1 98.000 (99.045)   Prec@5 100.000 (100.000)   [2018-05-02 22:23:04]
  Epoch: [358][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0798 (0.0522)   Prec@1 99.000 (99.040)   Prec@5 100.000 (99.995)   [2018-05-02 22:23:15]
  **Train** Prec@1 98.998 Prec@5 99.992 Error@1 1.002
  **Test** Prec@1 77.290 Prec@5 93.970 Error@1 22.710

==>>[2018-05-02 22:23:23] [Epoch=359/540] [Need: 01:31:28] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [359][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0234 (0.0234)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:23:23]
  Epoch: [359][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0801 (0.0532)   Prec@1 98.000 (98.965)   Prec@5 100.000 (99.990)   [2018-05-02 22:23:34]
  Epoch: [359][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0429 (0.0545)   Prec@1 99.000 (98.913)   Prec@5 100.000 (99.988)   [2018-05-02 22:23:45]
  **Train** Prec@1 98.922 Prec@5 99.980 Error@1 1.078
  **Test** Prec@1 77.510 Prec@5 93.970 Error@1 22.490

==>>[2018-05-02 22:23:53] [Epoch=360/540] [Need: 01:30:58] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [360][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0781 (0.0781)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:23:53]
  Epoch: [360][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0604 (0.0543)   Prec@1 99.000 (98.955)   Prec@5 100.000 (99.985)   [2018-05-02 22:24:04]
  Epoch: [360][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0618 (0.0529)   Prec@1 99.000 (99.022)   Prec@5 100.000 (99.988)   [2018-05-02 22:24:15]
  **Train** Prec@1 99.006 Prec@5 99.982 Error@1 0.994
  **Test** Prec@1 77.520 Prec@5 93.980 Error@1 22.480

==>>[2018-05-02 22:24:23] [Epoch=361/540] [Need: 01:30:27] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [361][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0443 (0.0443)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:24:23]
  Epoch: [361][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0695 (0.0516)   Prec@1 99.000 (99.095)   Prec@5 100.000 (99.985)   [2018-05-02 22:24:34]
  Epoch: [361][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1071 (0.0506)   Prec@1 97.000 (99.102)   Prec@5 100.000 (99.988)   [2018-05-02 22:24:45]
  **Train** Prec@1 99.118 Prec@5 99.990 Error@1 0.882
  **Test** Prec@1 77.340 Prec@5 94.040 Error@1 22.660

==>>[2018-05-02 22:24:53] [Epoch=362/540] [Need: 01:29:57] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [362][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0419 (0.0419)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:24:53]
  Epoch: [362][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0892 (0.0511)   Prec@1 98.000 (99.020)   Prec@5 99.000 (99.995)   [2018-05-02 22:25:04]
  Epoch: [362][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0649 (0.0509)   Prec@1 98.000 (99.037)   Prec@5 100.000 (99.995)   [2018-05-02 22:25:15]
  **Train** Prec@1 99.018 Prec@5 99.994 Error@1 0.982
  **Test** Prec@1 77.410 Prec@5 94.020 Error@1 22.590

==>>[2018-05-02 22:25:23] [Epoch=363/540] [Need: 01:29:26] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [363][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0333 (0.0333)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:25:23]
  Epoch: [363][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0288 (0.0537)   Prec@1 100.000 (98.965)   Prec@5 100.000 (99.980)   [2018-05-02 22:25:34]
  Epoch: [363][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0414 (0.0527)   Prec@1 100.000 (98.993)   Prec@5 100.000 (99.985)   [2018-05-02 22:25:45]
  **Train** Prec@1 99.006 Prec@5 99.988 Error@1 0.994
  **Test** Prec@1 77.610 Prec@5 93.800 Error@1 22.390

==>>[2018-05-02 22:25:53] [Epoch=364/540] [Need: 01:28:56] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [364][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0538 (0.0538)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:25:53]
  Epoch: [364][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1251 (0.0534)   Prec@1 96.000 (98.995)   Prec@5 100.000 (99.990)   [2018-05-02 22:26:04]
  Epoch: [364][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0956 (0.0530)   Prec@1 97.000 (98.958)   Prec@5 100.000 (99.988)   [2018-05-02 22:26:15]
  **Train** Prec@1 98.994 Prec@5 99.988 Error@1 1.006
  **Test** Prec@1 77.550 Prec@5 93.900 Error@1 22.450

==>>[2018-05-02 22:26:23] [Epoch=365/540] [Need: 01:28:26] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [365][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0788 (0.0788)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:26:23]
  Epoch: [365][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0453 (0.0510)   Prec@1 100.000 (99.070)   Prec@5 100.000 (99.985)   [2018-05-02 22:26:34]
  Epoch: [365][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0451 (0.0518)   Prec@1 100.000 (99.047)   Prec@5 100.000 (99.983)   [2018-05-02 22:26:45]
  **Train** Prec@1 99.062 Prec@5 99.984 Error@1 0.938
  **Test** Prec@1 77.580 Prec@5 93.960 Error@1 22.420

==>>[2018-05-02 22:26:53] [Epoch=366/540] [Need: 01:27:55] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [366][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0861 (0.0861)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:26:54]
  Epoch: [366][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0871 (0.0543)   Prec@1 98.000 (98.965)   Prec@5 100.000 (99.980)   [2018-05-02 22:27:04]
  Epoch: [366][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0563 (0.0539)   Prec@1 99.000 (98.960)   Prec@5 100.000 (99.988)   [2018-05-02 22:27:15]
  **Train** Prec@1 98.988 Prec@5 99.988 Error@1 1.012
  **Test** Prec@1 77.620 Prec@5 93.980 Error@1 22.380

==>>[2018-05-02 22:27:24] [Epoch=367/540] [Need: 01:27:25] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [367][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0731 (0.0731)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:27:24]
  Epoch: [367][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1139 (0.0512)   Prec@1 97.000 (98.950)   Prec@5 100.000 (99.990)   [2018-05-02 22:27:35]
  Epoch: [367][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0279 (0.0515)   Prec@1 100.000 (98.998)   Prec@5 100.000 (99.993)   [2018-05-02 22:27:46]
  **Train** Prec@1 99.002 Prec@5 99.992 Error@1 0.998
  **Test** Prec@1 77.450 Prec@5 93.780 Error@1 22.550

==>>[2018-05-02 22:27:54] [Epoch=368/540] [Need: 01:26:54] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [368][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0364 (0.0364)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:27:54]
  Epoch: [368][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0467 (0.0534)   Prec@1 99.000 (99.005)   Prec@5 100.000 (99.965)   [2018-05-02 22:28:05]
  Epoch: [368][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0333 (0.0529)   Prec@1 100.000 (98.978)   Prec@5 100.000 (99.983)   [2018-05-02 22:28:16]
  **Train** Prec@1 98.960 Prec@5 99.984 Error@1 1.040
  **Test** Prec@1 77.530 Prec@5 93.860 Error@1 22.470

==>>[2018-05-02 22:28:24] [Epoch=369/540] [Need: 01:26:24] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [369][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0485 (0.0485)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:28:24]
  Epoch: [369][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0577 (0.0521)   Prec@1 99.000 (98.980)   Prec@5 100.000 (99.990)   [2018-05-02 22:28:35]
  Epoch: [369][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0599 (0.0523)   Prec@1 99.000 (98.983)   Prec@5 100.000 (99.993)   [2018-05-02 22:28:46]
  **Train** Prec@1 98.976 Prec@5 99.994 Error@1 1.024
  **Test** Prec@1 77.470 Prec@5 94.010 Error@1 22.530

==>>[2018-05-02 22:28:54] [Epoch=370/540] [Need: 01:25:54] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [370][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0654 (0.0654)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:28:54]
  Epoch: [370][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0764 (0.0516)   Prec@1 97.000 (98.995)   Prec@5 100.000 (99.995)   [2018-05-02 22:29:05]
  Epoch: [370][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0572 (0.0519)   Prec@1 98.000 (98.998)   Prec@5 100.000 (99.993)   [2018-05-02 22:29:16]
  **Train** Prec@1 99.018 Prec@5 99.992 Error@1 0.982
  **Test** Prec@1 77.350 Prec@5 93.950 Error@1 22.650

==>>[2018-05-02 22:29:24] [Epoch=371/540] [Need: 01:25:23] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [371][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0574 (0.0574)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:29:24]
  Epoch: [371][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0333 (0.0499)   Prec@1 100.000 (99.139)   Prec@5 100.000 (99.985)   [2018-05-02 22:29:35]
  Epoch: [371][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0909 (0.0522)   Prec@1 99.000 (99.037)   Prec@5 99.000 (99.983)   [2018-05-02 22:29:46]
  **Train** Prec@1 99.026 Prec@5 99.984 Error@1 0.974
  **Test** Prec@1 77.540 Prec@5 93.940 Error@1 22.460

==>>[2018-05-02 22:29:54] [Epoch=372/540] [Need: 01:24:53] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [372][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0266 (0.0266)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:29:54]
  Epoch: [372][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0414 (0.0525)   Prec@1 99.000 (99.065)   Prec@5 100.000 (99.995)   [2018-05-02 22:30:05]
  Epoch: [372][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0388 (0.0505)   Prec@1 100.000 (99.105)   Prec@5 100.000 (99.995)   [2018-05-02 22:30:16]
  **Train** Prec@1 99.076 Prec@5 99.992 Error@1 0.924
  **Test** Prec@1 77.630 Prec@5 93.920 Error@1 22.370

==>>[2018-05-02 22:30:24] [Epoch=373/540] [Need: 01:24:22] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [373][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0332 (0.0332)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:30:24]
  Epoch: [373][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0387 (0.0535)   Prec@1 99.000 (98.980)   Prec@5 100.000 (99.980)   [2018-05-02 22:30:35]
  Epoch: [373][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0591 (0.0532)   Prec@1 99.000 (98.968)   Prec@5 100.000 (99.983)   [2018-05-02 22:30:46]
  **Train** Prec@1 98.980 Prec@5 99.982 Error@1 1.020
  **Test** Prec@1 77.340 Prec@5 93.920 Error@1 22.660

==>>[2018-05-02 22:30:54] [Epoch=374/540] [Need: 01:23:52] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [374][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0368 (0.0368)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:30:54]
  Epoch: [374][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0703 (0.0520)   Prec@1 98.000 (99.025)   Prec@5 100.000 (99.985)   [2018-05-02 22:31:05]
  Epoch: [374][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0680 (0.0531)   Prec@1 98.000 (99.002)   Prec@5 100.000 (99.988)   [2018-05-02 22:31:16]
  **Train** Prec@1 98.994 Prec@5 99.986 Error@1 1.006
  **Test** Prec@1 77.440 Prec@5 94.040 Error@1 22.560

==>>[2018-05-02 22:31:24] [Epoch=375/540] [Need: 01:23:21] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [375][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0270 (0.0270)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:31:24]
  Epoch: [375][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0497 (0.0493)   Prec@1 99.000 (99.109)   Prec@5 100.000 (100.000)   [2018-05-02 22:31:35]
  Epoch: [375][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0997 (0.0509)   Prec@1 97.000 (99.060)   Prec@5 99.000 (99.978)   [2018-05-02 22:31:46]
  **Train** Prec@1 99.044 Prec@5 99.980 Error@1 0.956
  **Test** Prec@1 77.530 Prec@5 94.060 Error@1 22.470

==>>[2018-05-02 22:31:54] [Epoch=376/540] [Need: 01:22:51] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [376][000/500]   Time 0.096 (0.096)   Data 0.070 (0.070)   Loss 0.0468 (0.0468)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:31:54]
  Epoch: [376][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0755 (0.0526)   Prec@1 98.000 (99.040)   Prec@5 100.000 (99.995)   [2018-05-02 22:32:05]
  Epoch: [376][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0382 (0.0527)   Prec@1 100.000 (99.042)   Prec@5 100.000 (99.993)   [2018-05-02 22:32:16]
  **Train** Prec@1 99.044 Prec@5 99.988 Error@1 0.956
  **Test** Prec@1 77.740 Prec@5 94.010 Error@1 22.260

==>>[2018-05-02 22:32:25] [Epoch=377/540] [Need: 01:22:21] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [377][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0428 (0.0428)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:32:25]
  Epoch: [377][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0738 (0.0532)   Prec@1 99.000 (98.930)   Prec@5 100.000 (99.995)   [2018-05-02 22:32:36]
  Epoch: [377][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0432 (0.0509)   Prec@1 100.000 (99.022)   Prec@5 100.000 (99.995)   [2018-05-02 22:32:46]
  **Train** Prec@1 99.036 Prec@5 99.994 Error@1 0.964
  **Test** Prec@1 77.550 Prec@5 93.850 Error@1 22.450

==>>[2018-05-02 22:32:55] [Epoch=378/540] [Need: 01:21:50] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [378][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0330 (0.0330)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:32:55]
  Epoch: [378][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0359 (0.0537)   Prec@1 100.000 (99.055)   Prec@5 100.000 (99.970)   [2018-05-02 22:33:06]
  Epoch: [378][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0459 (0.0525)   Prec@1 99.000 (99.035)   Prec@5 100.000 (99.983)   [2018-05-02 22:33:17]
  **Train** Prec@1 99.012 Prec@5 99.980 Error@1 0.988
  **Test** Prec@1 77.600 Prec@5 93.860 Error@1 22.400

==>>[2018-05-02 22:33:25] [Epoch=379/540] [Need: 01:21:20] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [379][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0901 (0.0901)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:33:25]
  Epoch: [379][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0724 (0.0523)   Prec@1 98.000 (98.980)   Prec@5 100.000 (99.990)   [2018-05-02 22:33:36]
  Epoch: [379][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0657 (0.0522)   Prec@1 98.000 (99.002)   Prec@5 100.000 (99.983)   [2018-05-02 22:33:47]
  **Train** Prec@1 99.016 Prec@5 99.982 Error@1 0.984
  **Test** Prec@1 77.480 Prec@5 93.970 Error@1 22.520

==>>[2018-05-02 22:33:55] [Epoch=380/540] [Need: 01:20:49] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [380][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0766 (0.0766)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:33:55]
  Epoch: [380][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0520 (0.0524)   Prec@1 99.000 (98.945)   Prec@5 100.000 (99.995)   [2018-05-02 22:34:06]
  Epoch: [380][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0189 (0.0513)   Prec@1 100.000 (99.055)   Prec@5 100.000 (99.995)   [2018-05-02 22:34:17]
  **Train** Prec@1 99.024 Prec@5 99.994 Error@1 0.976
  **Test** Prec@1 77.590 Prec@5 94.000 Error@1 22.410

==>>[2018-05-02 22:34:25] [Epoch=381/540] [Need: 01:20:19] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [381][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0990 (0.0990)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:34:25]
  Epoch: [381][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0800 (0.0517)   Prec@1 98.000 (99.045)   Prec@5 100.000 (99.990)   [2018-05-02 22:34:36]
  Epoch: [381][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0952 (0.0504)   Prec@1 97.000 (99.080)   Prec@5 100.000 (99.995)   [2018-05-02 22:34:47]
  **Train** Prec@1 99.046 Prec@5 99.994 Error@1 0.954
  **Test** Prec@1 77.460 Prec@5 93.900 Error@1 22.540

==>>[2018-05-02 22:34:55] [Epoch=382/540] [Need: 01:19:49] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [382][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0514 (0.0514)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:34:55]
  Epoch: [382][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0371 (0.0511)   Prec@1 100.000 (99.025)   Prec@5 100.000 (99.990)   [2018-05-02 22:35:06]
  Epoch: [382][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0264 (0.0506)   Prec@1 100.000 (99.097)   Prec@5 100.000 (99.993)   [2018-05-02 22:35:17]
  **Train** Prec@1 99.106 Prec@5 99.984 Error@1 0.894
  **Test** Prec@1 77.610 Prec@5 93.980 Error@1 22.390

==>>[2018-05-02 22:35:25] [Epoch=383/540] [Need: 01:19:18] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [383][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0540 (0.0540)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:35:25]
  Epoch: [383][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0461 (0.0529)   Prec@1 99.000 (99.035)   Prec@5 100.000 (99.995)   [2018-05-02 22:35:36]
  Epoch: [383][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0719 (0.0509)   Prec@1 97.000 (99.072)   Prec@5 100.000 (99.990)   [2018-05-02 22:35:47]
  **Train** Prec@1 99.068 Prec@5 99.992 Error@1 0.932
  **Test** Prec@1 77.700 Prec@5 93.980 Error@1 22.300

==>>[2018-05-02 22:35:55] [Epoch=384/540] [Need: 01:18:48] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [384][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.0539 (0.0539)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:35:55]
  Epoch: [384][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0206 (0.0512)   Prec@1 100.000 (99.119)   Prec@5 100.000 (99.995)   [2018-05-02 22:36:06]
  Epoch: [384][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0339 (0.0524)   Prec@1 99.000 (99.022)   Prec@5 100.000 (99.985)   [2018-05-02 22:36:17]
  **Train** Prec@1 99.042 Prec@5 99.986 Error@1 0.958
  **Test** Prec@1 77.570 Prec@5 93.980 Error@1 22.430

==>>[2018-05-02 22:36:25] [Epoch=385/540] [Need: 01:18:17] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [385][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0367 (0.0367)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:36:25]
  Epoch: [385][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0849 (0.0552)   Prec@1 99.000 (98.826)   Prec@5 100.000 (99.990)   [2018-05-02 22:36:36]
  Epoch: [385][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0483 (0.0521)   Prec@1 99.000 (98.980)   Prec@5 100.000 (99.990)   [2018-05-02 22:36:47]
  **Train** Prec@1 98.998 Prec@5 99.986 Error@1 1.002
  **Test** Prec@1 77.520 Prec@5 93.920 Error@1 22.480

==>>[2018-05-02 22:36:55] [Epoch=386/540] [Need: 01:17:47] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [386][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0278 (0.0278)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:36:55]
  Epoch: [386][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0545 (0.0498)   Prec@1 100.000 (99.119)   Prec@5 100.000 (99.990)   [2018-05-02 22:37:06]
  Epoch: [386][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0822 (0.0498)   Prec@1 98.000 (99.112)   Prec@5 100.000 (99.990)   [2018-05-02 22:37:17]
  **Train** Prec@1 99.080 Prec@5 99.990 Error@1 0.920
  **Test** Prec@1 77.530 Prec@5 93.950 Error@1 22.470

==>>[2018-05-02 22:37:25] [Epoch=387/540] [Need: 01:17:17] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [387][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0584 (0.0584)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:37:25]
  Epoch: [387][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0256 (0.0498)   Prec@1 100.000 (99.144)   Prec@5 100.000 (99.990)   [2018-05-02 22:37:36]
  Epoch: [387][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0874 (0.0507)   Prec@1 99.000 (99.072)   Prec@5 100.000 (99.990)   [2018-05-02 22:37:47]
  **Train** Prec@1 99.068 Prec@5 99.992 Error@1 0.932
  **Test** Prec@1 77.630 Prec@5 93.920 Error@1 22.370

==>>[2018-05-02 22:37:55] [Epoch=388/540] [Need: 01:16:46] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [388][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.0587 (0.0587)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:37:56]
  Epoch: [388][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0444 (0.0547)   Prec@1 99.000 (98.920)   Prec@5 100.000 (99.990)   [2018-05-02 22:38:07]
  Epoch: [388][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0422 (0.0527)   Prec@1 100.000 (98.990)   Prec@5 100.000 (99.988)   [2018-05-02 22:38:17]
  **Train** Prec@1 99.006 Prec@5 99.990 Error@1 0.994
  **Test** Prec@1 77.750 Prec@5 93.950 Error@1 22.250

==>>[2018-05-02 22:38:26] [Epoch=389/540] [Need: 01:16:16] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [389][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0527 (0.0527)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:38:26]
  Epoch: [389][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0487 (0.0526)   Prec@1 99.000 (98.975)   Prec@5 100.000 (99.975)   [2018-05-02 22:38:37]
  Epoch: [389][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0347 (0.0534)   Prec@1 100.000 (98.953)   Prec@5 100.000 (99.980)   [2018-05-02 22:38:48]
  **Train** Prec@1 98.988 Prec@5 99.978 Error@1 1.012
  **Test** Prec@1 77.570 Prec@5 93.980 Error@1 22.430

==>>[2018-05-02 22:38:56] [Epoch=390/540] [Need: 01:15:45] [learning_rate=0.000100] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [390][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0518 (0.0518)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:38:56]
  Epoch: [390][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0452 (0.0528)   Prec@1 99.000 (99.065)   Prec@5 100.000 (99.985)   [2018-05-02 22:39:07]
  Epoch: [390][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0874 (0.0543)   Prec@1 98.000 (98.935)   Prec@5 100.000 (99.988)   [2018-05-02 22:39:18]
  **Train** Prec@1 98.948 Prec@5 99.986 Error@1 1.052
  **Test** Prec@1 77.470 Prec@5 94.010 Error@1 22.530

==>>[2018-05-02 22:39:26] [Epoch=391/540] [Need: 01:15:15] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [391][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0230 (0.0230)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:39:26]
  Epoch: [391][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0515 (0.0515)   Prec@1 98.000 (99.070)   Prec@5 100.000 (99.990)   [2018-05-02 22:39:37]
  Epoch: [391][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0282 (0.0513)   Prec@1 99.000 (99.035)   Prec@5 100.000 (99.993)   [2018-05-02 22:39:48]
  **Train** Prec@1 99.030 Prec@5 99.990 Error@1 0.970
  **Test** Prec@1 77.580 Prec@5 93.890 Error@1 22.420

==>>[2018-05-02 22:39:56] [Epoch=392/540] [Need: 01:14:45] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [392][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.0459 (0.0459)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:39:56]
  Epoch: [392][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0512 (0.0537)   Prec@1 99.000 (98.965)   Prec@5 100.000 (99.985)   [2018-05-02 22:40:07]
  Epoch: [392][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0718 (0.0532)   Prec@1 97.000 (98.978)   Prec@5 100.000 (99.985)   [2018-05-02 22:40:18]
  **Train** Prec@1 98.980 Prec@5 99.982 Error@1 1.020
  **Test** Prec@1 77.500 Prec@5 93.900 Error@1 22.500

==>>[2018-05-02 22:40:26] [Epoch=393/540] [Need: 01:14:14] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [393][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0804 (0.0804)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:40:26]
  Epoch: [393][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0331 (0.0507)   Prec@1 100.000 (99.070)   Prec@5 100.000 (99.975)   [2018-05-02 22:40:37]
  Epoch: [393][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0344 (0.0521)   Prec@1 100.000 (99.032)   Prec@5 100.000 (99.983)   [2018-05-02 22:40:48]
  **Train** Prec@1 99.040 Prec@5 99.982 Error@1 0.960
  **Test** Prec@1 77.340 Prec@5 93.940 Error@1 22.660

==>>[2018-05-02 22:40:56] [Epoch=394/540] [Need: 01:13:44] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [394][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0922 (0.0922)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:40:56]
  Epoch: [394][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0841 (0.0525)   Prec@1 97.000 (98.990)   Prec@5 100.000 (99.995)   [2018-05-02 22:41:07]
  Epoch: [394][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0491 (0.0528)   Prec@1 99.000 (98.990)   Prec@5 100.000 (99.988)   [2018-05-02 22:41:18]
  **Train** Prec@1 98.938 Prec@5 99.990 Error@1 1.062
  **Test** Prec@1 77.670 Prec@5 93.940 Error@1 22.330

==>>[2018-05-02 22:41:26] [Epoch=395/540] [Need: 01:13:14] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [395][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0778 (0.0778)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:41:26]
  Epoch: [395][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0364 (0.0509)   Prec@1 100.000 (99.090)   Prec@5 100.000 (99.995)   [2018-05-02 22:41:37]
  Epoch: [395][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0375 (0.0502)   Prec@1 100.000 (99.092)   Prec@5 100.000 (99.998)   [2018-05-02 22:41:48]
  **Train** Prec@1 99.076 Prec@5 99.996 Error@1 0.924
  **Test** Prec@1 77.620 Prec@5 93.960 Error@1 22.380

==>>[2018-05-02 22:41:56] [Epoch=396/540] [Need: 01:12:43] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [396][000/500]   Time 0.088 (0.088)   Data 0.062 (0.062)   Loss 0.0236 (0.0236)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:41:56]
  Epoch: [396][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0538 (0.0508)   Prec@1 99.000 (99.025)   Prec@5 100.000 (99.985)   [2018-05-02 22:42:07]
  Epoch: [396][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0415 (0.0516)   Prec@1 100.000 (99.020)   Prec@5 100.000 (99.988)   [2018-05-02 22:42:18]
  **Train** Prec@1 99.002 Prec@5 99.988 Error@1 0.998
  **Test** Prec@1 77.520 Prec@5 93.880 Error@1 22.480

==>>[2018-05-02 22:42:26] [Epoch=397/540] [Need: 01:12:13] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [397][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0475 (0.0475)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:42:26]
  Epoch: [397][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0763 (0.0523)   Prec@1 98.000 (98.995)   Prec@5 100.000 (99.990)   [2018-05-02 22:42:37]
  Epoch: [397][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0243 (0.0514)   Prec@1 100.000 (99.022)   Prec@5 100.000 (99.990)   [2018-05-02 22:42:48]
  **Train** Prec@1 99.038 Prec@5 99.990 Error@1 0.962
  **Test** Prec@1 77.680 Prec@5 94.030 Error@1 22.320

==>>[2018-05-02 22:42:56] [Epoch=398/540] [Need: 01:11:42] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [398][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.1047 (0.1047)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:42:56]
  Epoch: [398][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0448 (0.0507)   Prec@1 100.000 (99.104)   Prec@5 100.000 (99.985)   [2018-05-02 22:43:07]
  Epoch: [398][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0418 (0.0516)   Prec@1 99.000 (99.072)   Prec@5 100.000 (99.988)   [2018-05-02 22:43:18]
  **Train** Prec@1 99.090 Prec@5 99.990 Error@1 0.910
  **Test** Prec@1 77.510 Prec@5 93.860 Error@1 22.490

==>>[2018-05-02 22:43:26] [Epoch=399/540] [Need: 01:11:12] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [399][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.0655 (0.0655)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:43:27]
  Epoch: [399][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0684 (0.0531)   Prec@1 99.000 (98.910)   Prec@5 100.000 (99.980)   [2018-05-02 22:43:37]
  Epoch: [399][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0838 (0.0512)   Prec@1 98.000 (99.020)   Prec@5 100.000 (99.985)   [2018-05-02 22:43:48]
  **Train** Prec@1 98.994 Prec@5 99.984 Error@1 1.006
  **Test** Prec@1 77.590 Prec@5 93.940 Error@1 22.410

==>>[2018-05-02 22:43:56] [Epoch=400/540] [Need: 01:10:42] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [400][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0772 (0.0772)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:43:57]
  Epoch: [400][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0541 (0.0507)   Prec@1 99.000 (99.080)   Prec@5 100.000 (99.985)   [2018-05-02 22:44:08]
  Epoch: [400][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0423 (0.0526)   Prec@1 99.000 (99.015)   Prec@5 100.000 (99.990)   [2018-05-02 22:44:18]
  **Train** Prec@1 99.032 Prec@5 99.992 Error@1 0.968
  **Test** Prec@1 77.470 Prec@5 94.000 Error@1 22.530

==>>[2018-05-02 22:44:27] [Epoch=401/540] [Need: 01:10:11] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [401][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0327 (0.0327)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:44:27]
  Epoch: [401][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0625 (0.0534)   Prec@1 100.000 (98.940)   Prec@5 100.000 (99.990)   [2018-05-02 22:44:38]
  Epoch: [401][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0219 (0.0533)   Prec@1 100.000 (98.963)   Prec@5 100.000 (99.995)   [2018-05-02 22:44:49]
  **Train** Prec@1 99.002 Prec@5 99.996 Error@1 0.998
  **Test** Prec@1 77.640 Prec@5 94.060 Error@1 22.360

==>>[2018-05-02 22:44:57] [Epoch=402/540] [Need: 01:09:41] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [402][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0466 (0.0466)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:44:57]
  Epoch: [402][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0460 (0.0557)   Prec@1 99.000 (98.896)   Prec@5 100.000 (99.980)   [2018-05-02 22:45:08]
  Epoch: [402][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0258 (0.0536)   Prec@1 100.000 (98.985)   Prec@5 100.000 (99.983)   [2018-05-02 22:45:19]
  **Train** Prec@1 98.978 Prec@5 99.982 Error@1 1.022
  **Test** Prec@1 77.600 Prec@5 94.010 Error@1 22.400

==>>[2018-05-02 22:45:27] [Epoch=403/540] [Need: 01:09:10] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [403][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.0638 (0.0638)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:45:27]
  Epoch: [403][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0369 (0.0514)   Prec@1 100.000 (98.980)   Prec@5 100.000 (99.995)   [2018-05-02 22:45:38]
  Epoch: [403][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0261 (0.0518)   Prec@1 100.000 (99.015)   Prec@5 100.000 (99.998)   [2018-05-02 22:45:49]
  **Train** Prec@1 99.012 Prec@5 99.998 Error@1 0.988
  **Test** Prec@1 77.400 Prec@5 94.010 Error@1 22.600

==>>[2018-05-02 22:45:57] [Epoch=404/540] [Need: 01:08:40] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [404][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0744 (0.0744)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:45:57]
  Epoch: [404][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0622 (0.0524)   Prec@1 98.000 (98.980)   Prec@5 100.000 (99.995)   [2018-05-02 22:46:08]
  Epoch: [404][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0337 (0.0514)   Prec@1 100.000 (99.070)   Prec@5 100.000 (99.998)   [2018-05-02 22:46:19]
  **Train** Prec@1 99.042 Prec@5 99.994 Error@1 0.958
  **Test** Prec@1 77.540 Prec@5 93.960 Error@1 22.460

==>>[2018-05-02 22:46:27] [Epoch=405/540] [Need: 01:08:10] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [405][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0669 (0.0669)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:46:27]
  Epoch: [405][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0551 (0.0510)   Prec@1 98.000 (99.085)   Prec@5 100.000 (99.995)   [2018-05-02 22:46:38]
  Epoch: [405][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0310 (0.0523)   Prec@1 99.000 (99.000)   Prec@5 100.000 (99.995)   [2018-05-02 22:46:49]
  **Train** Prec@1 99.006 Prec@5 99.996 Error@1 0.994
  **Test** Prec@1 77.710 Prec@5 93.880 Error@1 22.290

==>>[2018-05-02 22:46:57] [Epoch=406/540] [Need: 01:07:39] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [406][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0522 (0.0522)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:46:57]
  Epoch: [406][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0389 (0.0528)   Prec@1 99.000 (98.980)   Prec@5 100.000 (99.985)   [2018-05-02 22:47:08]
  Epoch: [406][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0804 (0.0538)   Prec@1 98.000 (98.995)   Prec@5 100.000 (99.990)   [2018-05-02 22:47:19]
  **Train** Prec@1 99.032 Prec@5 99.992 Error@1 0.968
  **Test** Prec@1 77.620 Prec@5 94.000 Error@1 22.380

==>>[2018-05-02 22:47:27] [Epoch=407/540] [Need: 01:07:09] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [407][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0607 (0.0607)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:47:27]
  Epoch: [407][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0215 (0.0512)   Prec@1 100.000 (99.060)   Prec@5 100.000 (99.985)   [2018-05-02 22:47:38]
  Epoch: [407][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0280 (0.0509)   Prec@1 100.000 (99.047)   Prec@5 100.000 (99.983)   [2018-05-02 22:47:49]
  **Train** Prec@1 99.058 Prec@5 99.982 Error@1 0.942
  **Test** Prec@1 77.440 Prec@5 93.720 Error@1 22.560

==>>[2018-05-02 22:47:57] [Epoch=408/540] [Need: 01:06:39] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [408][000/500]   Time 0.086 (0.086)   Data 0.061 (0.061)   Loss 0.0483 (0.0483)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:47:57]
  Epoch: [408][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0286 (0.0519)   Prec@1 100.000 (99.020)   Prec@5 100.000 (99.980)   [2018-05-02 22:48:08]
  Epoch: [408][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0345 (0.0512)   Prec@1 100.000 (99.040)   Prec@5 100.000 (99.985)   [2018-05-02 22:48:19]
  **Train** Prec@1 99.016 Prec@5 99.984 Error@1 0.984
  **Test** Prec@1 77.610 Prec@5 94.090 Error@1 22.390

==>>[2018-05-02 22:48:27] [Epoch=409/540] [Need: 01:06:08] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [409][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0415 (0.0415)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:48:27]
  Epoch: [409][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0405 (0.0540)   Prec@1 99.000 (98.935)   Prec@5 100.000 (99.970)   [2018-05-02 22:48:38]
  Epoch: [409][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0717 (0.0524)   Prec@1 98.000 (99.015)   Prec@5 100.000 (99.983)   [2018-05-02 22:48:49]
  **Train** Prec@1 99.016 Prec@5 99.982 Error@1 0.984
  **Test** Prec@1 77.660 Prec@5 94.030 Error@1 22.340

==>>[2018-05-02 22:48:57] [Epoch=410/540] [Need: 01:05:38] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [410][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0693 (0.0693)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:48:58]
  Epoch: [410][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0262 (0.0523)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 22:49:08]
  Epoch: [410][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0417 (0.0515)   Prec@1 100.000 (99.035)   Prec@5 100.000 (99.993)   [2018-05-02 22:49:19]
  **Train** Prec@1 99.026 Prec@5 99.994 Error@1 0.974
  **Test** Prec@1 77.700 Prec@5 93.870 Error@1 22.300

==>>[2018-05-02 22:49:28] [Epoch=411/540] [Need: 01:05:08] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [411][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0811 (0.0811)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:49:28]
  Epoch: [411][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0747 (0.0500)   Prec@1 99.000 (99.070)   Prec@5 100.000 (99.995)   [2018-05-02 22:49:39]
  Epoch: [411][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0555 (0.0514)   Prec@1 99.000 (99.002)   Prec@5 100.000 (99.988)   [2018-05-02 22:49:49]
  **Train** Prec@1 99.036 Prec@5 99.990 Error@1 0.964
  **Test** Prec@1 77.620 Prec@5 94.010 Error@1 22.380

==>>[2018-05-02 22:49:58] [Epoch=412/540] [Need: 01:04:37] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [412][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0354 (0.0354)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:49:58]
  Epoch: [412][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0230 (0.0511)   Prec@1 100.000 (99.065)   Prec@5 100.000 (99.990)   [2018-05-02 22:50:09]
  Epoch: [412][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0331 (0.0515)   Prec@1 99.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 22:50:20]
  **Train** Prec@1 99.028 Prec@5 99.988 Error@1 0.972
  **Test** Prec@1 77.360 Prec@5 93.980 Error@1 22.640

==>>[2018-05-02 22:50:28] [Epoch=413/540] [Need: 01:04:07] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [413][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0530 (0.0530)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:50:28]
  Epoch: [413][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0680 (0.0525)   Prec@1 97.000 (99.040)   Prec@5 100.000 (99.990)   [2018-05-02 22:50:39]
  Epoch: [413][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1310 (0.0515)   Prec@1 97.000 (99.050)   Prec@5 100.000 (99.990)   [2018-05-02 22:50:50]
  **Train** Prec@1 99.042 Prec@5 99.992 Error@1 0.958
  **Test** Prec@1 77.550 Prec@5 94.070 Error@1 22.450

==>>[2018-05-02 22:50:58] [Epoch=414/540] [Need: 01:03:37] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [414][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0269 (0.0269)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:50:58]
  Epoch: [414][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0365 (0.0534)   Prec@1 99.000 (98.985)   Prec@5 100.000 (99.975)   [2018-05-02 22:51:09]
  Epoch: [414][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0806 (0.0526)   Prec@1 99.000 (99.010)   Prec@5 100.000 (99.980)   [2018-05-02 22:51:20]
  **Train** Prec@1 99.036 Prec@5 99.982 Error@1 0.964
  **Test** Prec@1 77.490 Prec@5 94.050 Error@1 22.510

==>>[2018-05-02 22:51:28] [Epoch=415/540] [Need: 01:03:06] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [415][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0333 (0.0333)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:51:28]
  Epoch: [415][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0525 (0.0531)   Prec@1 98.000 (98.881)   Prec@5 100.000 (99.970)   [2018-05-02 22:51:39]
  Epoch: [415][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0621 (0.0530)   Prec@1 99.000 (98.913)   Prec@5 100.000 (99.975)   [2018-05-02 22:51:50]
  **Train** Prec@1 98.948 Prec@5 99.976 Error@1 1.052
  **Test** Prec@1 77.440 Prec@5 93.870 Error@1 22.560

==>>[2018-05-02 22:51:58] [Epoch=416/540] [Need: 01:02:36] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [416][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0283 (0.0283)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:51:58]
  Epoch: [416][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0346 (0.0547)   Prec@1 100.000 (98.945)   Prec@5 100.000 (99.985)   [2018-05-02 22:52:09]
  Epoch: [416][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0276 (0.0528)   Prec@1 100.000 (99.000)   Prec@5 100.000 (99.993)   [2018-05-02 22:52:20]
  **Train** Prec@1 99.008 Prec@5 99.994 Error@1 0.992
  **Test** Prec@1 77.490 Prec@5 94.080 Error@1 22.510

==>>[2018-05-02 22:52:28] [Epoch=417/540] [Need: 01:02:05] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [417][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0334 (0.0334)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:52:28]
  Epoch: [417][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0344 (0.0498)   Prec@1 100.000 (99.114)   Prec@5 100.000 (99.975)   [2018-05-02 22:52:39]
  Epoch: [417][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0703 (0.0512)   Prec@1 97.000 (99.017)   Prec@5 100.000 (99.985)   [2018-05-02 22:52:50]
  **Train** Prec@1 99.008 Prec@5 99.986 Error@1 0.992
  **Test** Prec@1 77.420 Prec@5 94.050 Error@1 22.580

==>>[2018-05-02 22:52:58] [Epoch=418/540] [Need: 01:01:35] [learning_rate=0.000010] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [418][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0229 (0.0229)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:52:58]
  Epoch: [418][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0268 (0.0515)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 22:53:09]
  Epoch: [418][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0729 (0.0525)   Prec@1 99.000 (98.995)   Prec@5 100.000 (99.995)   [2018-05-02 22:53:20]
  **Train** Prec@1 98.980 Prec@5 99.992 Error@1 1.020
  **Test** Prec@1 77.810 Prec@5 94.040 Error@1 22.190

==>>[2018-05-02 22:53:28] [Epoch=419/540] [Need: 01:01:05] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [419][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0761 (0.0761)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:53:28]
  Epoch: [419][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0299 (0.0544)   Prec@1 100.000 (98.960)   Prec@5 100.000 (99.975)   [2018-05-02 22:53:39]
  Epoch: [419][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0455 (0.0533)   Prec@1 99.000 (98.935)   Prec@5 100.000 (99.985)   [2018-05-02 22:53:50]
  **Train** Prec@1 98.970 Prec@5 99.988 Error@1 1.030
  **Test** Prec@1 77.590 Prec@5 93.810 Error@1 22.410

==>>[2018-05-02 22:53:58] [Epoch=420/540] [Need: 01:00:34] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [420][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0751 (0.0751)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:53:58]
  Epoch: [420][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0413 (0.0512)   Prec@1 99.000 (99.035)   Prec@5 100.000 (99.990)   [2018-05-02 22:54:09]
  Epoch: [420][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0565 (0.0514)   Prec@1 98.000 (99.032)   Prec@5 100.000 (99.988)   [2018-05-02 22:54:20]
  **Train** Prec@1 99.002 Prec@5 99.988 Error@1 0.998
  **Test** Prec@1 77.740 Prec@5 94.100 Error@1 22.260

==>>[2018-05-02 22:54:28] [Epoch=421/540] [Need: 01:00:04] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [421][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0279 (0.0279)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:54:29]
  Epoch: [421][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0385 (0.0499)   Prec@1 99.000 (99.040)   Prec@5 100.000 (100.000)   [2018-05-02 22:54:39]
  Epoch: [421][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0388 (0.0504)   Prec@1 99.000 (99.055)   Prec@5 100.000 (99.998)   [2018-05-02 22:54:50]
  **Train** Prec@1 99.038 Prec@5 99.996 Error@1 0.962
  **Test** Prec@1 77.440 Prec@5 93.930 Error@1 22.560

==>>[2018-05-02 22:54:59] [Epoch=422/540] [Need: 00:59:34] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [422][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0477 (0.0477)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:54:59]
  Epoch: [422][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0818 (0.0521)   Prec@1 97.000 (99.129)   Prec@5 100.000 (99.980)   [2018-05-02 22:55:10]
  Epoch: [422][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0278 (0.0525)   Prec@1 100.000 (99.057)   Prec@5 100.000 (99.985)   [2018-05-02 22:55:20]
  **Train** Prec@1 99.064 Prec@5 99.986 Error@1 0.936
  **Test** Prec@1 77.700 Prec@5 93.990 Error@1 22.300

==>>[2018-05-02 22:55:29] [Epoch=423/540] [Need: 00:59:03] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [423][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.0908 (0.0908)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:55:29]
  Epoch: [423][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0477 (0.0521)   Prec@1 99.000 (99.075)   Prec@5 100.000 (99.995)   [2018-05-02 22:55:40]
  Epoch: [423][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0347 (0.0513)   Prec@1 99.000 (99.107)   Prec@5 100.000 (99.995)   [2018-05-02 22:55:51]
  **Train** Prec@1 99.098 Prec@5 99.994 Error@1 0.902
  **Test** Prec@1 77.620 Prec@5 93.950 Error@1 22.380

==>>[2018-05-02 22:55:59] [Epoch=424/540] [Need: 00:58:33] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [424][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0823 (0.0823)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:55:59]
  Epoch: [424][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0695 (0.0540)   Prec@1 98.000 (98.900)   Prec@5 100.000 (99.975)   [2018-05-02 22:56:10]
  Epoch: [424][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0578 (0.0535)   Prec@1 99.000 (98.953)   Prec@5 100.000 (99.985)   [2018-05-02 22:56:21]
  **Train** Prec@1 98.958 Prec@5 99.988 Error@1 1.042
  **Test** Prec@1 77.670 Prec@5 93.840 Error@1 22.330

==>>[2018-05-02 22:56:29] [Epoch=425/540] [Need: 00:58:03] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [425][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0692 (0.0692)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:56:29]
  Epoch: [425][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0732 (0.0523)   Prec@1 98.000 (99.035)   Prec@5 100.000 (99.975)   [2018-05-02 22:56:40]
  Epoch: [425][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0397 (0.0528)   Prec@1 100.000 (98.983)   Prec@5 100.000 (99.983)   [2018-05-02 22:56:51]
  **Train** Prec@1 98.986 Prec@5 99.976 Error@1 1.014
  **Test** Prec@1 77.510 Prec@5 93.970 Error@1 22.490

==>>[2018-05-02 22:56:59] [Epoch=426/540] [Need: 00:57:32] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [426][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0223 (0.0223)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:56:59]
  Epoch: [426][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0874 (0.0532)   Prec@1 98.000 (98.975)   Prec@5 100.000 (99.995)   [2018-05-02 22:57:10]
  Epoch: [426][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0596 (0.0517)   Prec@1 99.000 (99.057)   Prec@5 100.000 (99.995)   [2018-05-02 22:57:21]
  **Train** Prec@1 99.026 Prec@5 99.990 Error@1 0.974
  **Test** Prec@1 77.610 Prec@5 93.960 Error@1 22.390

==>>[2018-05-02 22:57:29] [Epoch=427/540] [Need: 00:57:02] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [427][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0277 (0.0277)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:57:29]
  Epoch: [427][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0259 (0.0500)   Prec@1 100.000 (99.075)   Prec@5 100.000 (99.990)   [2018-05-02 22:57:40]
  Epoch: [427][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0219 (0.0494)   Prec@1 100.000 (99.072)   Prec@5 100.000 (99.990)   [2018-05-02 22:57:51]
  **Train** Prec@1 99.044 Prec@5 99.992 Error@1 0.956
  **Test** Prec@1 77.640 Prec@5 94.040 Error@1 22.360

==>>[2018-05-02 22:57:59] [Epoch=428/540] [Need: 00:56:32] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [428][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0574 (0.0574)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:57:59]
  Epoch: [428][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0418 (0.0522)   Prec@1 100.000 (99.000)   Prec@5 100.000 (99.995)   [2018-05-02 22:58:10]
  Epoch: [428][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0499 (0.0530)   Prec@1 98.000 (98.970)   Prec@5 100.000 (99.988)   [2018-05-02 22:58:21]
  **Train** Prec@1 98.972 Prec@5 99.986 Error@1 1.028
  **Test** Prec@1 77.380 Prec@5 93.850 Error@1 22.620

==>>[2018-05-02 22:58:29] [Epoch=429/540] [Need: 00:56:01] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [429][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0331 (0.0331)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:58:29]
  Epoch: [429][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0505 (0.0538)   Prec@1 99.000 (98.905)   Prec@5 100.000 (99.990)   [2018-05-02 22:58:40]
  Epoch: [429][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1234 (0.0524)   Prec@1 96.000 (98.988)   Prec@5 100.000 (99.990)   [2018-05-02 22:58:51]
  **Train** Prec@1 98.976 Prec@5 99.990 Error@1 1.024
  **Test** Prec@1 77.380 Prec@5 93.930 Error@1 22.620

==>>[2018-05-02 22:58:59] [Epoch=430/540] [Need: 00:55:31] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [430][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0704 (0.0704)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:58:59]
  Epoch: [430][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1353 (0.0512)   Prec@1 97.000 (99.119)   Prec@5 99.000 (99.985)   [2018-05-02 22:59:10]
  Epoch: [430][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0381 (0.0524)   Prec@1 99.000 (99.047)   Prec@5 100.000 (99.980)   [2018-05-02 22:59:21]
  **Train** Prec@1 99.042 Prec@5 99.978 Error@1 0.958
  **Test** Prec@1 77.690 Prec@5 93.970 Error@1 22.310

==>>[2018-05-02 22:59:29] [Epoch=431/540] [Need: 00:55:01] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [431][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0340 (0.0340)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:59:29]
  Epoch: [431][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0477 (0.0519)   Prec@1 99.000 (99.040)   Prec@5 100.000 (99.985)   [2018-05-02 22:59:40]
  Epoch: [431][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0945 (0.0514)   Prec@1 97.000 (99.062)   Prec@5 100.000 (99.990)   [2018-05-02 22:59:51]
  **Train** Prec@1 99.058 Prec@5 99.992 Error@1 0.942
  **Test** Prec@1 77.410 Prec@5 94.020 Error@1 22.590

==>>[2018-05-02 22:59:59] [Epoch=432/540] [Need: 00:54:30] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [432][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0292 (0.0292)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 22:59:59]
  Epoch: [432][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0434 (0.0511)   Prec@1 99.000 (99.040)   Prec@5 100.000 (100.000)   [2018-05-02 23:00:10]
  Epoch: [432][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0639 (0.0535)   Prec@1 99.000 (98.975)   Prec@5 100.000 (99.993)   [2018-05-02 23:00:21]
  **Train** Prec@1 99.000 Prec@5 99.992 Error@1 1.000
  **Test** Prec@1 77.600 Prec@5 93.990 Error@1 22.400

==>>[2018-05-02 23:00:29] [Epoch=433/540] [Need: 00:54:00] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [433][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.1334 (0.1334)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:00:30]
  Epoch: [433][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0428 (0.0509)   Prec@1 99.000 (99.005)   Prec@5 100.000 (99.980)   [2018-05-02 23:00:40]
  Epoch: [433][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0387 (0.0522)   Prec@1 100.000 (98.978)   Prec@5 100.000 (99.988)   [2018-05-02 23:00:51]
  **Train** Prec@1 99.026 Prec@5 99.990 Error@1 0.974
  **Test** Prec@1 77.570 Prec@5 93.900 Error@1 22.430

==>>[2018-05-02 23:01:00] [Epoch=434/540] [Need: 00:53:30] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [434][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0512 (0.0512)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:01:00]
  Epoch: [434][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0399 (0.0510)   Prec@1 99.000 (99.080)   Prec@5 100.000 (99.985)   [2018-05-02 23:01:11]
  Epoch: [434][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0357 (0.0500)   Prec@1 99.000 (99.107)   Prec@5 100.000 (99.990)   [2018-05-02 23:01:21]
  **Train** Prec@1 99.098 Prec@5 99.986 Error@1 0.902
  **Test** Prec@1 77.610 Prec@5 93.910 Error@1 22.390

==>>[2018-05-02 23:01:30] [Epoch=435/540] [Need: 00:52:59] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [435][000/500]   Time 0.086 (0.086)   Data 0.057 (0.057)   Loss 0.0539 (0.0539)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:01:30]
  Epoch: [435][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0798 (0.0533)   Prec@1 99.000 (99.030)   Prec@5 100.000 (99.990)   [2018-05-02 23:01:41]
  Epoch: [435][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0861 (0.0516)   Prec@1 97.000 (99.027)   Prec@5 100.000 (99.990)   [2018-05-02 23:01:52]
  **Train** Prec@1 99.042 Prec@5 99.990 Error@1 0.958
  **Test** Prec@1 77.540 Prec@5 94.060 Error@1 22.460

==>>[2018-05-02 23:02:00] [Epoch=436/540] [Need: 00:52:29] [learning_rate=0.000010] [Best : Accuracy=77.81, Error=22.19]
  Epoch: [436][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0375 (0.0375)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:02:00]
  Epoch: [436][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0979 (0.0539)   Prec@1 98.000 (98.935)   Prec@5 100.000 (99.995)   [2018-05-02 23:02:11]
  Epoch: [436][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0758 (0.0515)   Prec@1 97.000 (99.012)   Prec@5 100.000 (99.993)   [2018-05-02 23:02:22]
  **Train** Prec@1 99.022 Prec@5 99.990 Error@1 0.978
  **Test** Prec@1 77.820 Prec@5 93.890 Error@1 22.180

==>>[2018-05-02 23:02:30] [Epoch=437/540] [Need: 00:51:59] [learning_rate=0.000010] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [437][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0834 (0.0834)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:02:30]
  Epoch: [437][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0625 (0.0528)   Prec@1 98.000 (98.965)   Prec@5 100.000 (99.980)   [2018-05-02 23:02:41]
  Epoch: [437][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0882 (0.0513)   Prec@1 98.000 (99.010)   Prec@5 100.000 (99.985)   [2018-05-02 23:02:52]
  **Train** Prec@1 99.006 Prec@5 99.986 Error@1 0.994
  **Test** Prec@1 77.660 Prec@5 93.910 Error@1 22.340

==>>[2018-05-02 23:03:00] [Epoch=438/540] [Need: 00:51:28] [learning_rate=0.000010] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [438][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0793 (0.0793)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:03:00]
  Epoch: [438][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0744 (0.0513)   Prec@1 99.000 (99.100)   Prec@5 100.000 (100.000)   [2018-05-02 23:03:11]
  Epoch: [438][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0659 (0.0533)   Prec@1 98.000 (99.005)   Prec@5 100.000 (99.993)   [2018-05-02 23:03:22]
  **Train** Prec@1 98.994 Prec@5 99.988 Error@1 1.006
  **Test** Prec@1 77.700 Prec@5 94.030 Error@1 22.300

==>>[2018-05-02 23:03:30] [Epoch=439/540] [Need: 00:50:58] [learning_rate=0.000010] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [439][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0384 (0.0384)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:03:30]
  Epoch: [439][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0570 (0.0530)   Prec@1 98.000 (98.940)   Prec@5 100.000 (99.990)   [2018-05-02 23:03:41]
  Epoch: [439][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0312 (0.0526)   Prec@1 100.000 (98.975)   Prec@5 100.000 (99.978)   [2018-05-02 23:03:52]
  **Train** Prec@1 98.978 Prec@5 99.978 Error@1 1.022
  **Test** Prec@1 77.540 Prec@5 93.800 Error@1 22.460

==>>[2018-05-02 23:04:00] [Epoch=440/540] [Need: 00:50:28] [learning_rate=0.000010] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [440][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0886 (0.0886)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:04:00]
  Epoch: [440][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0798 (0.0547)   Prec@1 98.000 (98.920)   Prec@5 100.000 (99.975)   [2018-05-02 23:04:11]
  Epoch: [440][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0467 (0.0528)   Prec@1 99.000 (98.993)   Prec@5 100.000 (99.980)   [2018-05-02 23:04:22]
  **Train** Prec@1 98.994 Prec@5 99.984 Error@1 1.006
  **Test** Prec@1 77.490 Prec@5 93.910 Error@1 22.510

==>>[2018-05-02 23:04:30] [Epoch=441/540] [Need: 00:49:57] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [441][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0789 (0.0789)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:04:30]
  Epoch: [441][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0750 (0.0531)   Prec@1 98.000 (98.970)   Prec@5 100.000 (99.990)   [2018-05-02 23:04:41]
  Epoch: [441][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0594 (0.0539)   Prec@1 100.000 (98.923)   Prec@5 100.000 (99.983)   [2018-05-02 23:04:52]
  **Train** Prec@1 98.922 Prec@5 99.982 Error@1 1.078
  **Test** Prec@1 77.570 Prec@5 93.970 Error@1 22.430

==>>[2018-05-02 23:05:00] [Epoch=442/540] [Need: 00:49:27] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [442][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0394 (0.0394)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:05:00]
  Epoch: [442][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0533 (0.0542)   Prec@1 100.000 (98.970)   Prec@5 100.000 (99.980)   [2018-05-02 23:05:11]
  Epoch: [442][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0463 (0.0528)   Prec@1 100.000 (99.000)   Prec@5 100.000 (99.980)   [2018-05-02 23:05:22]
  **Train** Prec@1 98.974 Prec@5 99.978 Error@1 1.026
  **Test** Prec@1 77.600 Prec@5 93.960 Error@1 22.400

==>>[2018-05-02 23:05:30] [Epoch=443/540] [Need: 00:48:57] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [443][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0369 (0.0369)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:05:30]
  Epoch: [443][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0405 (0.0519)   Prec@1 100.000 (99.060)   Prec@5 100.000 (99.970)   [2018-05-02 23:05:41]
  Epoch: [443][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0483 (0.0526)   Prec@1 99.000 (98.990)   Prec@5 100.000 (99.980)   [2018-05-02 23:05:52]
  **Train** Prec@1 99.012 Prec@5 99.984 Error@1 0.988
  **Test** Prec@1 77.380 Prec@5 93.830 Error@1 22.620

==>>[2018-05-02 23:06:01] [Epoch=444/540] [Need: 00:48:26] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [444][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0305 (0.0305)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:06:01]
  Epoch: [444][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0366 (0.0488)   Prec@1 99.000 (99.055)   Prec@5 100.000 (99.995)   [2018-05-02 23:06:12]
  Epoch: [444][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0986 (0.0503)   Prec@1 97.000 (99.080)   Prec@5 100.000 (99.993)   [2018-05-02 23:06:23]
  **Train** Prec@1 99.058 Prec@5 99.988 Error@1 0.942
  **Test** Prec@1 77.410 Prec@5 93.960 Error@1 22.590

==>>[2018-05-02 23:06:31] [Epoch=445/540] [Need: 00:47:56] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [445][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0621 (0.0621)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:06:31]
  Epoch: [445][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0456 (0.0546)   Prec@1 100.000 (98.910)   Prec@5 100.000 (99.990)   [2018-05-02 23:06:42]
  Epoch: [445][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0250 (0.0500)   Prec@1 100.000 (99.117)   Prec@5 100.000 (99.995)   [2018-05-02 23:06:53]
  **Train** Prec@1 99.082 Prec@5 99.990 Error@1 0.918
  **Test** Prec@1 77.580 Prec@5 93.940 Error@1 22.420

==>>[2018-05-02 23:07:01] [Epoch=446/540] [Need: 00:47:26] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [446][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0547 (0.0547)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:07:01]
  Epoch: [446][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0555 (0.0531)   Prec@1 99.000 (98.950)   Prec@5 100.000 (99.975)   [2018-05-02 23:07:12]
  Epoch: [446][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0452 (0.0524)   Prec@1 99.000 (98.960)   Prec@5 100.000 (99.980)   [2018-05-02 23:07:23]
  **Train** Prec@1 98.986 Prec@5 99.984 Error@1 1.014
  **Test** Prec@1 77.480 Prec@5 93.790 Error@1 22.520

==>>[2018-05-02 23:07:31] [Epoch=447/540] [Need: 00:46:55] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [447][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0982 (0.0982)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:07:31]
  Epoch: [447][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0499 (0.0526)   Prec@1 100.000 (99.085)   Prec@5 100.000 (99.990)   [2018-05-02 23:07:42]
  Epoch: [447][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0464 (0.0519)   Prec@1 99.000 (99.040)   Prec@5 100.000 (99.990)   [2018-05-02 23:07:53]
  **Train** Prec@1 99.004 Prec@5 99.986 Error@1 0.996
  **Test** Prec@1 77.590 Prec@5 93.810 Error@1 22.410

==>>[2018-05-02 23:08:01] [Epoch=448/540] [Need: 00:46:25] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [448][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 0.0255 (0.0255)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:08:01]
  Epoch: [448][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0256 (0.0499)   Prec@1 100.000 (99.085)   Prec@5 100.000 (99.990)   [2018-05-02 23:08:12]
  Epoch: [448][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1384 (0.0525)   Prec@1 97.000 (98.993)   Prec@5 100.000 (99.990)   [2018-05-02 23:08:23]
  **Train** Prec@1 99.006 Prec@5 99.990 Error@1 0.994
  **Test** Prec@1 77.490 Prec@5 94.120 Error@1 22.510

==>>[2018-05-02 23:08:31] [Epoch=449/540] [Need: 00:45:55] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [449][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0483 (0.0483)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:08:31]
  Epoch: [449][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0638 (0.0543)   Prec@1 98.000 (98.881)   Prec@5 100.000 (99.975)   [2018-05-02 23:08:42]
  Epoch: [449][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0274 (0.0536)   Prec@1 100.000 (98.940)   Prec@5 100.000 (99.983)   [2018-05-02 23:08:53]
  **Train** Prec@1 98.932 Prec@5 99.982 Error@1 1.068
  **Test** Prec@1 77.650 Prec@5 93.970 Error@1 22.350

==>>[2018-05-02 23:09:01] [Epoch=450/540] [Need: 00:45:25] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [450][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0372 (0.0372)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:09:01]
  Epoch: [450][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0845 (0.0529)   Prec@1 99.000 (99.040)   Prec@5 100.000 (99.995)   [2018-05-02 23:09:12]
  Epoch: [450][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0467 (0.0513)   Prec@1 99.000 (99.045)   Prec@5 100.000 (99.985)   [2018-05-02 23:09:23]
  **Train** Prec@1 99.066 Prec@5 99.984 Error@1 0.934
  **Test** Prec@1 77.720 Prec@5 93.840 Error@1 22.280

==>>[2018-05-02 23:09:31] [Epoch=451/540] [Need: 00:44:54] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [451][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0954 (0.0954)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:09:32]
  Epoch: [451][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0470 (0.0528)   Prec@1 99.000 (98.930)   Prec@5 100.000 (99.980)   [2018-05-02 23:09:43]
  Epoch: [451][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1303 (0.0507)   Prec@1 96.000 (99.045)   Prec@5 100.000 (99.985)   [2018-05-02 23:09:53]
  **Train** Prec@1 99.064 Prec@5 99.988 Error@1 0.936
  **Test** Prec@1 77.590 Prec@5 94.010 Error@1 22.410

==>>[2018-05-02 23:10:02] [Epoch=452/540] [Need: 00:44:24] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [452][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0149 (0.0149)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:10:02]
  Epoch: [452][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0495 (0.0516)   Prec@1 98.000 (99.090)   Prec@5 100.000 (100.000)   [2018-05-02 23:10:13]
  Epoch: [452][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0298 (0.0507)   Prec@1 100.000 (99.112)   Prec@5 100.000 (99.993)   [2018-05-02 23:10:24]
  **Train** Prec@1 99.118 Prec@5 99.992 Error@1 0.882
  **Test** Prec@1 77.580 Prec@5 93.820 Error@1 22.420

==>>[2018-05-02 23:10:32] [Epoch=453/540] [Need: 00:43:54] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [453][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0248 (0.0248)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:10:32]
  Epoch: [453][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0404 (0.0540)   Prec@1 99.000 (98.900)   Prec@5 100.000 (99.970)   [2018-05-02 23:10:43]
  Epoch: [453][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0530 (0.0520)   Prec@1 99.000 (98.988)   Prec@5 100.000 (99.980)   [2018-05-02 23:10:54]
  **Train** Prec@1 99.004 Prec@5 99.978 Error@1 0.996
  **Test** Prec@1 77.700 Prec@5 93.850 Error@1 22.300

==>>[2018-05-02 23:11:02] [Epoch=454/540] [Need: 00:43:23] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [454][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0376 (0.0376)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:11:02]
  Epoch: [454][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0307 (0.0518)   Prec@1 100.000 (99.065)   Prec@5 100.000 (99.985)   [2018-05-02 23:11:13]
  Epoch: [454][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0514 (0.0513)   Prec@1 98.000 (99.050)   Prec@5 100.000 (99.990)   [2018-05-02 23:11:24]
  **Train** Prec@1 99.040 Prec@5 99.990 Error@1 0.960
  **Test** Prec@1 77.490 Prec@5 93.930 Error@1 22.510

==>>[2018-05-02 23:11:32] [Epoch=455/540] [Need: 00:42:53] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [455][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0401 (0.0401)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:11:32]
  Epoch: [455][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0321 (0.0511)   Prec@1 100.000 (99.119)   Prec@5 100.000 (99.995)   [2018-05-02 23:11:43]
  Epoch: [455][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0514 (0.0523)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.983)   [2018-05-02 23:11:54]
  **Train** Prec@1 99.036 Prec@5 99.984 Error@1 0.964
  **Test** Prec@1 77.510 Prec@5 93.930 Error@1 22.490

==>>[2018-05-02 23:12:02] [Epoch=456/540] [Need: 00:42:23] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [456][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0711 (0.0711)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:12:02]
  Epoch: [456][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0497 (0.0511)   Prec@1 99.000 (99.045)   Prec@5 100.000 (99.985)   [2018-05-02 23:12:13]
  Epoch: [456][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0275 (0.0519)   Prec@1 100.000 (99.037)   Prec@5 100.000 (99.993)   [2018-05-02 23:12:24]
  **Train** Prec@1 99.038 Prec@5 99.990 Error@1 0.962
  **Test** Prec@1 77.530 Prec@5 93.980 Error@1 22.470

==>>[2018-05-02 23:12:32] [Epoch=457/540] [Need: 00:41:52] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [457][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0610 (0.0610)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:12:32]
  Epoch: [457][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0559 (0.0526)   Prec@1 99.000 (99.035)   Prec@5 100.000 (100.000)   [2018-05-02 23:12:43]
  Epoch: [457][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0948 (0.0529)   Prec@1 97.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 23:12:54]
  **Train** Prec@1 99.000 Prec@5 99.990 Error@1 1.000
  **Test** Prec@1 77.820 Prec@5 93.970 Error@1 22.180

==>>[2018-05-02 23:13:02] [Epoch=458/540] [Need: 00:41:22] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [458][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0226 (0.0226)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:13:02]
  Epoch: [458][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0414 (0.0510)   Prec@1 99.000 (99.045)   Prec@5 100.000 (99.980)   [2018-05-02 23:13:13]
  Epoch: [458][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0865 (0.0522)   Prec@1 98.000 (98.980)   Prec@5 100.000 (99.975)   [2018-05-02 23:13:24]
  **Train** Prec@1 99.004 Prec@5 99.980 Error@1 0.996
  **Test** Prec@1 77.670 Prec@5 93.960 Error@1 22.330

==>>[2018-05-02 23:13:32] [Epoch=459/540] [Need: 00:40:52] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [459][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0364 (0.0364)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:13:32]
  Epoch: [459][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0692 (0.0520)   Prec@1 99.000 (99.080)   Prec@5 100.000 (99.990)   [2018-05-02 23:13:43]
  Epoch: [459][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0603 (0.0530)   Prec@1 99.000 (99.002)   Prec@5 100.000 (99.993)   [2018-05-02 23:13:54]
  **Train** Prec@1 98.978 Prec@5 99.994 Error@1 1.022
  **Test** Prec@1 77.520 Prec@5 94.060 Error@1 22.480

==>>[2018-05-02 23:14:02] [Epoch=460/540] [Need: 00:40:21] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [460][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0494 (0.0494)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:14:02]
  Epoch: [460][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0679 (0.0534)   Prec@1 98.000 (99.065)   Prec@5 100.000 (99.985)   [2018-05-02 23:14:13]
  Epoch: [460][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0550 (0.0528)   Prec@1 99.000 (99.032)   Prec@5 100.000 (99.985)   [2018-05-02 23:14:24]
  **Train** Prec@1 99.042 Prec@5 99.988 Error@1 0.958
  **Test** Prec@1 77.470 Prec@5 93.910 Error@1 22.530

==>>[2018-05-02 23:14:32] [Epoch=461/540] [Need: 00:39:51] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [461][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0303 (0.0303)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:14:33]
  Epoch: [461][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0431 (0.0525)   Prec@1 100.000 (98.975)   Prec@5 100.000 (99.985)   [2018-05-02 23:14:43]
  Epoch: [461][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0605 (0.0519)   Prec@1 98.000 (98.988)   Prec@5 100.000 (99.990)   [2018-05-02 23:14:54]
  **Train** Prec@1 99.010 Prec@5 99.990 Error@1 0.990
  **Test** Prec@1 77.380 Prec@5 93.980 Error@1 22.620

==>>[2018-05-02 23:15:03] [Epoch=462/540] [Need: 00:39:21] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [462][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.0360 (0.0360)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:15:03]
  Epoch: [462][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0312 (0.0521)   Prec@1 100.000 (99.000)   Prec@5 100.000 (99.985)   [2018-05-02 23:15:14]
  Epoch: [462][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0333 (0.0500)   Prec@1 99.000 (99.085)   Prec@5 100.000 (99.990)   [2018-05-02 23:15:24]
  **Train** Prec@1 99.106 Prec@5 99.992 Error@1 0.894
  **Test** Prec@1 77.340 Prec@5 94.000 Error@1 22.660

==>>[2018-05-02 23:15:33] [Epoch=463/540] [Need: 00:38:51] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [463][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0584 (0.0584)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:15:33]
  Epoch: [463][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0514 (0.0502)   Prec@1 99.000 (99.050)   Prec@5 100.000 (100.000)   [2018-05-02 23:15:44]
  Epoch: [463][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0485 (0.0513)   Prec@1 99.000 (99.047)   Prec@5 100.000 (99.990)   [2018-05-02 23:15:55]
  **Train** Prec@1 99.060 Prec@5 99.990 Error@1 0.940
  **Test** Prec@1 77.610 Prec@5 93.880 Error@1 22.390

==>>[2018-05-02 23:16:03] [Epoch=464/540] [Need: 00:38:20] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [464][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0383 (0.0383)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:16:03]
  Epoch: [464][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0306 (0.0498)   Prec@1 100.000 (99.075)   Prec@5 100.000 (99.990)   [2018-05-02 23:16:14]
  Epoch: [464][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0544 (0.0508)   Prec@1 99.000 (99.062)   Prec@5 100.000 (99.985)   [2018-05-02 23:16:25]
  **Train** Prec@1 99.036 Prec@5 99.982 Error@1 0.964
  **Test** Prec@1 77.760 Prec@5 93.900 Error@1 22.240

==>>[2018-05-02 23:16:33] [Epoch=465/540] [Need: 00:37:50] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [465][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0666 (0.0666)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:16:33]
  Epoch: [465][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0383 (0.0539)   Prec@1 99.000 (98.960)   Prec@5 100.000 (99.990)   [2018-05-02 23:16:44]
  Epoch: [465][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0351 (0.0526)   Prec@1 99.000 (99.012)   Prec@5 100.000 (99.990)   [2018-05-02 23:16:55]
  **Train** Prec@1 98.988 Prec@5 99.986 Error@1 1.012
  **Test** Prec@1 77.420 Prec@5 93.860 Error@1 22.580

==>>[2018-05-02 23:17:03] [Epoch=466/540] [Need: 00:37:20] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [466][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.0592 (0.0592)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:17:03]
  Epoch: [466][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0695 (0.0523)   Prec@1 98.000 (99.040)   Prec@5 100.000 (99.995)   [2018-05-02 23:17:14]
  Epoch: [466][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0431 (0.0513)   Prec@1 99.000 (99.075)   Prec@5 100.000 (99.995)   [2018-05-02 23:17:25]
  **Train** Prec@1 99.084 Prec@5 99.992 Error@1 0.916
  **Test** Prec@1 77.740 Prec@5 93.860 Error@1 22.260

==>>[2018-05-02 23:17:33] [Epoch=467/540] [Need: 00:36:49] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [467][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.0283 (0.0283)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:17:33]
  Epoch: [467][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0506 (0.0522)   Prec@1 100.000 (99.025)   Prec@5 100.000 (99.985)   [2018-05-02 23:17:44]
  Epoch: [467][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0770 (0.0533)   Prec@1 99.000 (98.933)   Prec@5 100.000 (99.993)   [2018-05-02 23:17:55]
  **Train** Prec@1 98.928 Prec@5 99.988 Error@1 1.072
  **Test** Prec@1 77.500 Prec@5 93.860 Error@1 22.500

==>>[2018-05-02 23:18:03] [Epoch=468/540] [Need: 00:36:19] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [468][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0618 (0.0618)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:18:03]
  Epoch: [468][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0391 (0.0531)   Prec@1 100.000 (98.955)   Prec@5 100.000 (99.985)   [2018-05-02 23:18:14]
  Epoch: [468][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0532 (0.0546)   Prec@1 99.000 (98.883)   Prec@5 100.000 (99.985)   [2018-05-02 23:18:25]
  **Train** Prec@1 98.904 Prec@5 99.986 Error@1 1.096
  **Test** Prec@1 77.400 Prec@5 94.000 Error@1 22.600

==>>[2018-05-02 23:18:33] [Epoch=469/540] [Need: 00:35:49] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [469][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0437 (0.0437)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:18:33]
  Epoch: [469][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0329 (0.0519)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 23:18:44]
  Epoch: [469][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0505 (0.0531)   Prec@1 100.000 (99.000)   Prec@5 100.000 (99.988)   [2018-05-02 23:18:55]
  **Train** Prec@1 98.972 Prec@5 99.986 Error@1 1.028
  **Test** Prec@1 77.650 Prec@5 93.980 Error@1 22.350

==>>[2018-05-02 23:19:03] [Epoch=470/540] [Need: 00:35:18] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [470][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0263 (0.0263)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:19:03]
  Epoch: [470][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0639 (0.0490)   Prec@1 99.000 (99.209)   Prec@5 100.000 (100.000)   [2018-05-02 23:19:14]
  Epoch: [470][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0684 (0.0501)   Prec@1 99.000 (99.127)   Prec@5 100.000 (99.995)   [2018-05-02 23:19:25]
  **Train** Prec@1 99.136 Prec@5 99.994 Error@1 0.864
  **Test** Prec@1 77.520 Prec@5 93.940 Error@1 22.480

==>>[2018-05-02 23:19:33] [Epoch=471/540] [Need: 00:34:48] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [471][000/500]   Time 0.095 (0.095)   Data 0.069 (0.069)   Loss 0.0638 (0.0638)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:19:33]
  Epoch: [471][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0771 (0.0508)   Prec@1 98.000 (99.035)   Prec@5 100.000 (99.985)   [2018-05-02 23:19:44]
  Epoch: [471][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0423 (0.0511)   Prec@1 99.000 (99.037)   Prec@5 100.000 (99.983)   [2018-05-02 23:19:55]
  **Train** Prec@1 99.030 Prec@5 99.986 Error@1 0.970
  **Test** Prec@1 77.600 Prec@5 94.020 Error@1 22.400

==>>[2018-05-02 23:20:03] [Epoch=472/540] [Need: 00:34:18] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [472][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0371 (0.0371)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:20:03]
  Epoch: [472][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0631 (0.0488)   Prec@1 98.000 (99.184)   Prec@5 100.000 (99.995)   [2018-05-02 23:20:14]
  Epoch: [472][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0367 (0.0506)   Prec@1 99.000 (99.072)   Prec@5 100.000 (99.980)   [2018-05-02 23:20:25]
  **Train** Prec@1 99.082 Prec@5 99.982 Error@1 0.918
  **Test** Prec@1 77.750 Prec@5 93.980 Error@1 22.250

==>>[2018-05-02 23:20:34] [Epoch=473/540] [Need: 00:33:48] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [473][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0319 (0.0319)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:20:34]
  Epoch: [473][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0361 (0.0511)   Prec@1 100.000 (99.035)   Prec@5 100.000 (99.990)   [2018-05-02 23:20:45]
  Epoch: [473][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0359 (0.0523)   Prec@1 100.000 (98.968)   Prec@5 100.000 (99.990)   [2018-05-02 23:20:56]
  **Train** Prec@1 98.972 Prec@5 99.990 Error@1 1.028
  **Test** Prec@1 77.480 Prec@5 93.910 Error@1 22.520

==>>[2018-05-02 23:21:04] [Epoch=474/540] [Need: 00:33:17] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [474][000/500]   Time 0.084 (0.084)   Data 0.059 (0.059)   Loss 0.0271 (0.0271)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:21:04]
  Epoch: [474][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0518 (0.0530)   Prec@1 100.000 (99.025)   Prec@5 100.000 (99.985)   [2018-05-02 23:21:15]
  Epoch: [474][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0276 (0.0513)   Prec@1 100.000 (99.077)   Prec@5 100.000 (99.990)   [2018-05-02 23:21:26]
  **Train** Prec@1 99.048 Prec@5 99.990 Error@1 0.952
  **Test** Prec@1 77.550 Prec@5 94.090 Error@1 22.450

==>>[2018-05-02 23:21:34] [Epoch=475/540] [Need: 00:32:47] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [475][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0302 (0.0302)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:21:34]
  Epoch: [475][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0364 (0.0516)   Prec@1 99.000 (99.055)   Prec@5 100.000 (99.980)   [2018-05-02 23:21:45]
  Epoch: [475][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0292 (0.0520)   Prec@1 100.000 (99.040)   Prec@5 100.000 (99.983)   [2018-05-02 23:21:56]
  **Train** Prec@1 99.026 Prec@5 99.984 Error@1 0.974
  **Test** Prec@1 77.510 Prec@5 93.850 Error@1 22.490

==>>[2018-05-02 23:22:04] [Epoch=476/540] [Need: 00:32:17] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [476][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0472 (0.0472)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:22:04]
  Epoch: [476][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1025 (0.0526)   Prec@1 96.000 (99.055)   Prec@5 100.000 (99.990)   [2018-05-02 23:22:15]
  Epoch: [476][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0824 (0.0528)   Prec@1 97.000 (99.002)   Prec@5 100.000 (99.993)   [2018-05-02 23:22:26]
  **Train** Prec@1 99.000 Prec@5 99.992 Error@1 1.000
  **Test** Prec@1 77.620 Prec@5 93.940 Error@1 22.380

==>>[2018-05-02 23:22:34] [Epoch=477/540] [Need: 00:31:46] [learning_rate=0.000001] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [477][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0424 (0.0424)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:22:34]
  Epoch: [477][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0413 (0.0519)   Prec@1 99.000 (98.965)   Prec@5 100.000 (99.990)   [2018-05-02 23:22:45]
  Epoch: [477][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0385 (0.0511)   Prec@1 99.000 (99.035)   Prec@5 100.000 (99.990)   [2018-05-02 23:22:56]
  **Train** Prec@1 98.994 Prec@5 99.988 Error@1 1.006
  **Test** Prec@1 77.830 Prec@5 93.990 Error@1 22.170

==>>[2018-05-02 23:23:04] [Epoch=478/540] [Need: 00:31:16] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [478][000/500]   Time 0.083 (0.083)   Data 0.058 (0.058)   Loss 0.0836 (0.0836)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:23:04]
  Epoch: [478][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0405 (0.0545)   Prec@1 99.000 (98.871)   Prec@5 100.000 (99.985)   [2018-05-02 23:23:15]
  Epoch: [478][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0403 (0.0518)   Prec@1 99.000 (98.978)   Prec@5 100.000 (99.988)   [2018-05-02 23:23:26]
  **Train** Prec@1 98.994 Prec@5 99.984 Error@1 1.006
  **Test** Prec@1 77.670 Prec@5 93.970 Error@1 22.330

==>>[2018-05-02 23:23:34] [Epoch=479/540] [Need: 00:30:46] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [479][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0395 (0.0395)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:23:34]
  Epoch: [479][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0412 (0.0519)   Prec@1 99.000 (98.985)   Prec@5 100.000 (99.985)   [2018-05-02 23:23:45]
  Epoch: [479][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0307 (0.0531)   Prec@1 100.000 (98.970)   Prec@5 100.000 (99.988)   [2018-05-02 23:23:56]
  **Train** Prec@1 98.958 Prec@5 99.988 Error@1 1.042
  **Test** Prec@1 77.700 Prec@5 93.920 Error@1 22.300

==>>[2018-05-02 23:24:04] [Epoch=480/540] [Need: 00:30:15] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [480][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0852 (0.0852)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:24:04]
  Epoch: [480][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1159 (0.0489)   Prec@1 98.000 (99.139)   Prec@5 100.000 (99.980)   [2018-05-02 23:24:15]
  Epoch: [480][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0479 (0.0506)   Prec@1 100.000 (99.095)   Prec@5 100.000 (99.988)   [2018-05-02 23:24:26]
  **Train** Prec@1 99.092 Prec@5 99.986 Error@1 0.908
  **Test** Prec@1 77.710 Prec@5 93.830 Error@1 22.290

==>>[2018-05-02 23:24:34] [Epoch=481/540] [Need: 00:29:45] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [481][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0275 (0.0275)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:24:34]
  Epoch: [481][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0354 (0.0536)   Prec@1 100.000 (98.970)   Prec@5 100.000 (99.985)   [2018-05-02 23:24:45]
  Epoch: [481][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0399 (0.0525)   Prec@1 99.000 (98.995)   Prec@5 100.000 (99.985)   [2018-05-02 23:24:56]
  **Train** Prec@1 99.018 Prec@5 99.982 Error@1 0.982
  **Test** Prec@1 77.710 Prec@5 94.000 Error@1 22.290

==>>[2018-05-02 23:25:04] [Epoch=482/540] [Need: 00:29:15] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [482][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0281 (0.0281)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:25:04]
  Epoch: [482][200/500]   Time 0.053 (0.055)   Data 0.000 (0.000)   Loss 0.0631 (0.0501)   Prec@1 97.000 (99.159)   Prec@5 100.000 (99.990)   [2018-05-02 23:25:15]
  Epoch: [482][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0452 (0.0508)   Prec@1 100.000 (99.110)   Prec@5 100.000 (99.983)   [2018-05-02 23:25:26]
  **Train** Prec@1 99.116 Prec@5 99.986 Error@1 0.884
  **Test** Prec@1 77.650 Prec@5 93.950 Error@1 22.350

==>>[2018-05-02 23:25:34] [Epoch=483/540] [Need: 00:28:45] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [483][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0473 (0.0473)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:25:35]
  Epoch: [483][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0673 (0.0508)   Prec@1 99.000 (99.090)   Prec@5 100.000 (99.985)   [2018-05-02 23:25:45]
  Epoch: [483][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0259 (0.0513)   Prec@1 100.000 (99.025)   Prec@5 100.000 (99.988)   [2018-05-02 23:25:56]
  **Train** Prec@1 98.980 Prec@5 99.988 Error@1 1.020
  **Test** Prec@1 77.740 Prec@5 93.850 Error@1 22.260

==>>[2018-05-02 23:26:04] [Epoch=484/540] [Need: 00:28:14] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [484][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0472 (0.0472)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:26:05]
  Epoch: [484][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0317 (0.0508)   Prec@1 100.000 (99.060)   Prec@5 100.000 (99.970)   [2018-05-02 23:26:16]
  Epoch: [484][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0432 (0.0509)   Prec@1 99.000 (99.077)   Prec@5 100.000 (99.983)   [2018-05-02 23:26:26]
  **Train** Prec@1 99.052 Prec@5 99.984 Error@1 0.948
  **Test** Prec@1 77.440 Prec@5 93.970 Error@1 22.560

==>>[2018-05-02 23:26:35] [Epoch=485/540] [Need: 00:27:44] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [485][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0398 (0.0398)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:26:35]
  Epoch: [485][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0883 (0.0517)   Prec@1 97.000 (99.045)   Prec@5 100.000 (99.990)   [2018-05-02 23:26:46]
  Epoch: [485][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0440 (0.0515)   Prec@1 99.000 (99.025)   Prec@5 100.000 (99.993)   [2018-05-02 23:26:57]
  **Train** Prec@1 99.030 Prec@5 99.990 Error@1 0.970
  **Test** Prec@1 77.350 Prec@5 93.920 Error@1 22.650

==>>[2018-05-02 23:27:05] [Epoch=486/540] [Need: 00:27:14] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [486][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0358 (0.0358)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:27:05]
  Epoch: [486][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0360 (0.0496)   Prec@1 99.000 (99.174)   Prec@5 100.000 (99.990)   [2018-05-02 23:27:16]
  Epoch: [486][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0354 (0.0492)   Prec@1 100.000 (99.145)   Prec@5 100.000 (99.990)   [2018-05-02 23:27:27]
  **Train** Prec@1 99.102 Prec@5 99.988 Error@1 0.898
  **Test** Prec@1 77.490 Prec@5 93.920 Error@1 22.510

==>>[2018-05-02 23:27:35] [Epoch=487/540] [Need: 00:26:43] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [487][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0391 (0.0391)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:27:35]
  Epoch: [487][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0484 (0.0529)   Prec@1 99.000 (98.910)   Prec@5 100.000 (99.995)   [2018-05-02 23:27:46]
  Epoch: [487][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0372 (0.0514)   Prec@1 100.000 (98.990)   Prec@5 100.000 (99.995)   [2018-05-02 23:27:57]
  **Train** Prec@1 98.996 Prec@5 99.994 Error@1 1.004
  **Test** Prec@1 77.640 Prec@5 93.900 Error@1 22.360

==>>[2018-05-02 23:28:05] [Epoch=488/540] [Need: 00:26:13] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [488][000/500]   Time 0.088 (0.088)   Data 0.062 (0.062)   Loss 0.0675 (0.0675)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:28:05]
  Epoch: [488][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0592 (0.0512)   Prec@1 99.000 (99.090)   Prec@5 100.000 (99.990)   [2018-05-02 23:28:16]
  Epoch: [488][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0163 (0.0500)   Prec@1 100.000 (99.105)   Prec@5 100.000 (99.990)   [2018-05-02 23:28:27]
  **Train** Prec@1 99.124 Prec@5 99.992 Error@1 0.876
  **Test** Prec@1 77.360 Prec@5 93.790 Error@1 22.640

==>>[2018-05-02 23:28:35] [Epoch=489/540] [Need: 00:25:43] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [489][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0170 (0.0170)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:28:35]
  Epoch: [489][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0696 (0.0503)   Prec@1 99.000 (98.995)   Prec@5 100.000 (99.990)   [2018-05-02 23:28:46]
  Epoch: [489][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1133 (0.0516)   Prec@1 98.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 23:28:57]
  **Train** Prec@1 99.000 Prec@5 99.986 Error@1 1.000
  **Test** Prec@1 77.570 Prec@5 93.950 Error@1 22.430

==>>[2018-05-02 23:29:05] [Epoch=490/540] [Need: 00:25:13] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [490][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0574 (0.0574)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:29:05]
  Epoch: [490][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0527 (0.0527)   Prec@1 100.000 (99.015)   Prec@5 100.000 (99.985)   [2018-05-02 23:29:16]
  Epoch: [490][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0408 (0.0515)   Prec@1 100.000 (99.037)   Prec@5 100.000 (99.988)   [2018-05-02 23:29:27]
  **Train** Prec@1 99.056 Prec@5 99.986 Error@1 0.944
  **Test** Prec@1 77.650 Prec@5 93.950 Error@1 22.350

==>>[2018-05-02 23:29:35] [Epoch=491/540] [Need: 00:24:42] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [491][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.0838 (0.0838)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:29:35]
  Epoch: [491][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0502 (0.0512)   Prec@1 98.000 (98.995)   Prec@5 100.000 (100.000)   [2018-05-02 23:29:46]
  Epoch: [491][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0299 (0.0500)   Prec@1 99.000 (99.067)   Prec@5 100.000 (99.998)   [2018-05-02 23:29:57]
  **Train** Prec@1 99.040 Prec@5 99.994 Error@1 0.960
  **Test** Prec@1 77.680 Prec@5 93.910 Error@1 22.320

==>>[2018-05-02 23:30:05] [Epoch=492/540] [Need: 00:24:12] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [492][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0478 (0.0478)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:30:05]
  Epoch: [492][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1050 (0.0514)   Prec@1 97.000 (99.055)   Prec@5 100.000 (99.990)   [2018-05-02 23:30:16]
  Epoch: [492][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0684 (0.0519)   Prec@1 98.000 (99.035)   Prec@5 100.000 (99.988)   [2018-05-02 23:30:27]
  **Train** Prec@1 98.994 Prec@5 99.986 Error@1 1.006
  **Test** Prec@1 77.660 Prec@5 93.990 Error@1 22.340

==>>[2018-05-02 23:30:35] [Epoch=493/540] [Need: 00:23:42] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [493][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0366 (0.0366)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:30:35]
  Epoch: [493][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0450 (0.0529)   Prec@1 99.000 (98.955)   Prec@5 100.000 (99.985)   [2018-05-02 23:30:46]
  Epoch: [493][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0400 (0.0530)   Prec@1 100.000 (99.005)   Prec@5 100.000 (99.973)   [2018-05-02 23:30:57]
  **Train** Prec@1 98.996 Prec@5 99.976 Error@1 1.004
  **Test** Prec@1 77.760 Prec@5 93.800 Error@1 22.240

==>>[2018-05-02 23:31:05] [Epoch=494/540] [Need: 00:23:12] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [494][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0363 (0.0363)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:31:06]
  Epoch: [494][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0512 (0.0506)   Prec@1 99.000 (99.070)   Prec@5 100.000 (99.995)   [2018-05-02 23:31:16]
  Epoch: [494][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0327 (0.0520)   Prec@1 99.000 (98.990)   Prec@5 100.000 (99.993)   [2018-05-02 23:31:27]
  **Train** Prec@1 98.990 Prec@5 99.986 Error@1 1.010
  **Test** Prec@1 77.680 Prec@5 94.030 Error@1 22.320

==>>[2018-05-02 23:31:36] [Epoch=495/540] [Need: 00:22:41] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [495][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0304 (0.0304)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:31:36]
  Epoch: [495][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0313 (0.0519)   Prec@1 99.000 (99.020)   Prec@5 100.000 (99.975)   [2018-05-02 23:31:47]
  Epoch: [495][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0468 (0.0523)   Prec@1 100.000 (99.027)   Prec@5 100.000 (99.978)   [2018-05-02 23:31:57]
  **Train** Prec@1 99.020 Prec@5 99.980 Error@1 0.980
  **Test** Prec@1 77.420 Prec@5 93.840 Error@1 22.580

==>>[2018-05-02 23:32:06] [Epoch=496/540] [Need: 00:22:11] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [496][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0511 (0.0511)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:32:06]
  Epoch: [496][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0399 (0.0536)   Prec@1 99.000 (98.960)   Prec@5 100.000 (99.970)   [2018-05-02 23:32:17]
  Epoch: [496][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0207 (0.0521)   Prec@1 100.000 (99.020)   Prec@5 100.000 (99.980)   [2018-05-02 23:32:28]
  **Train** Prec@1 99.030 Prec@5 99.980 Error@1 0.970
  **Test** Prec@1 77.590 Prec@5 93.940 Error@1 22.410

==>>[2018-05-02 23:32:36] [Epoch=497/540] [Need: 00:21:41] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [497][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0457 (0.0457)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:32:36]
  Epoch: [497][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0280 (0.0498)   Prec@1 100.000 (99.055)   Prec@5 100.000 (99.975)   [2018-05-02 23:32:47]
  Epoch: [497][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0678 (0.0513)   Prec@1 99.000 (99.047)   Prec@5 100.000 (99.970)   [2018-05-02 23:32:58]
  **Train** Prec@1 99.022 Prec@5 99.974 Error@1 0.978
  **Test** Prec@1 77.520 Prec@5 93.870 Error@1 22.480

==>>[2018-05-02 23:33:06] [Epoch=498/540] [Need: 00:21:10] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [498][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.1203 (0.1203)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:33:06]
  Epoch: [498][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0446 (0.0543)   Prec@1 98.000 (98.995)   Prec@5 100.000 (99.975)   [2018-05-02 23:33:17]
  Epoch: [498][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0340 (0.0539)   Prec@1 100.000 (98.978)   Prec@5 100.000 (99.978)   [2018-05-02 23:33:28]
  **Train** Prec@1 99.012 Prec@5 99.972 Error@1 0.988
  **Test** Prec@1 77.370 Prec@5 93.920 Error@1 22.630

==>>[2018-05-02 23:33:36] [Epoch=499/540] [Need: 00:20:40] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [499][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.1112 (0.1112)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:33:36]
  Epoch: [499][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0386 (0.0513)   Prec@1 100.000 (99.090)   Prec@5 100.000 (99.985)   [2018-05-02 23:33:47]
  Epoch: [499][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0281 (0.0506)   Prec@1 100.000 (99.155)   Prec@5 100.000 (99.983)   [2018-05-02 23:33:58]
  **Train** Prec@1 99.112 Prec@5 99.982 Error@1 0.888
  **Test** Prec@1 77.340 Prec@5 93.780 Error@1 22.660

==>>[2018-05-02 23:34:06] [Epoch=500/540] [Need: 00:20:10] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [500][000/500]   Time 0.088 (0.088)   Data 0.061 (0.061)   Loss 0.0313 (0.0313)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:34:06]
  Epoch: [500][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1190 (0.0491)   Prec@1 96.000 (99.179)   Prec@5 100.000 (99.985)   [2018-05-02 23:34:17]
  Epoch: [500][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0391 (0.0513)   Prec@1 100.000 (99.065)   Prec@5 100.000 (99.978)   [2018-05-02 23:34:28]
  **Train** Prec@1 99.074 Prec@5 99.980 Error@1 0.926
  **Test** Prec@1 77.420 Prec@5 94.020 Error@1 22.580

==>>[2018-05-02 23:34:36] [Epoch=501/540] [Need: 00:19:40] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [501][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0458 (0.0458)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:34:36]
  Epoch: [501][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0670 (0.0524)   Prec@1 97.000 (98.960)   Prec@5 100.000 (99.985)   [2018-05-02 23:34:47]
  Epoch: [501][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0329 (0.0518)   Prec@1 99.000 (99.025)   Prec@5 100.000 (99.985)   [2018-05-02 23:34:58]
  **Train** Prec@1 99.008 Prec@5 99.982 Error@1 0.992
  **Test** Prec@1 77.530 Prec@5 93.960 Error@1 22.470

==>>[2018-05-02 23:35:06] [Epoch=502/540] [Need: 00:19:09] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [502][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.1273 (0.1273)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:35:06]
  Epoch: [502][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0449 (0.0528)   Prec@1 99.000 (98.940)   Prec@5 100.000 (99.970)   [2018-05-02 23:35:17]
  Epoch: [502][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0582 (0.0529)   Prec@1 98.000 (98.940)   Prec@5 100.000 (99.985)   [2018-05-02 23:35:28]
  **Train** Prec@1 98.982 Prec@5 99.986 Error@1 1.018
  **Test** Prec@1 77.560 Prec@5 93.780 Error@1 22.440

==>>[2018-05-02 23:35:36] [Epoch=503/540] [Need: 00:18:39] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [503][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0399 (0.0399)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:35:36]
  Epoch: [503][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0503 (0.0512)   Prec@1 99.000 (99.025)   Prec@5 100.000 (99.995)   [2018-05-02 23:35:47]
  Epoch: [503][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0591 (0.0513)   Prec@1 98.000 (99.015)   Prec@5 100.000 (99.993)   [2018-05-02 23:35:58]
  **Train** Prec@1 99.004 Prec@5 99.992 Error@1 0.996
  **Test** Prec@1 77.510 Prec@5 94.060 Error@1 22.490

==>>[2018-05-02 23:36:06] [Epoch=504/540] [Need: 00:18:09] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [504][000/500]   Time 0.089 (0.089)   Data 0.063 (0.063)   Loss 0.0225 (0.0225)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:36:06]
  Epoch: [504][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0705 (0.0548)   Prec@1 99.000 (98.876)   Prec@5 100.000 (99.975)   [2018-05-02 23:36:17]
  Epoch: [504][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0373 (0.0529)   Prec@1 100.000 (98.983)   Prec@5 100.000 (99.988)   [2018-05-02 23:36:28]
  **Train** Prec@1 98.976 Prec@5 99.988 Error@1 1.024
  **Test** Prec@1 77.430 Prec@5 93.890 Error@1 22.570

==>>[2018-05-02 23:36:36] [Epoch=505/540] [Need: 00:17:39] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [505][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0604 (0.0604)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:36:37]
  Epoch: [505][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0334 (0.0542)   Prec@1 100.000 (98.945)   Prec@5 100.000 (99.985)   [2018-05-02 23:36:48]
  Epoch: [505][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0327 (0.0523)   Prec@1 99.000 (98.983)   Prec@5 100.000 (99.985)   [2018-05-02 23:36:58]
  **Train** Prec@1 98.968 Prec@5 99.986 Error@1 1.032
  **Test** Prec@1 77.490 Prec@5 93.910 Error@1 22.510

==>>[2018-05-02 23:37:07] [Epoch=506/540] [Need: 00:17:08] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [506][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0828 (0.0828)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:37:07]
  Epoch: [506][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0837 (0.0531)   Prec@1 98.000 (99.020)   Prec@5 100.000 (99.990)   [2018-05-02 23:37:18]
  Epoch: [506][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0241 (0.0526)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 23:37:29]
  **Train** Prec@1 99.012 Prec@5 99.986 Error@1 0.988
  **Test** Prec@1 77.420 Prec@5 94.060 Error@1 22.580

==>>[2018-05-02 23:37:37] [Epoch=507/540] [Need: 00:16:38] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [507][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0343 (0.0343)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:37:37]
  Epoch: [507][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0251 (0.0512)   Prec@1 100.000 (99.025)   Prec@5 100.000 (99.995)   [2018-05-02 23:37:48]
  Epoch: [507][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0818 (0.0513)   Prec@1 98.000 (99.027)   Prec@5 100.000 (99.998)   [2018-05-02 23:37:59]
  **Train** Prec@1 99.030 Prec@5 99.998 Error@1 0.970
  **Test** Prec@1 77.550 Prec@5 94.010 Error@1 22.450

==>>[2018-05-02 23:38:07] [Epoch=508/540] [Need: 00:16:08] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [508][000/500]   Time 0.085 (0.085)   Data 0.060 (0.060)   Loss 0.0351 (0.0351)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:38:07]
  Epoch: [508][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0772 (0.0507)   Prec@1 97.000 (99.090)   Prec@5 100.000 (99.995)   [2018-05-02 23:38:18]
  Epoch: [508][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0579 (0.0512)   Prec@1 98.000 (99.090)   Prec@5 100.000 (99.990)   [2018-05-02 23:38:29]
  **Train** Prec@1 99.082 Prec@5 99.988 Error@1 0.918
  **Test** Prec@1 77.260 Prec@5 94.000 Error@1 22.740

==>>[2018-05-02 23:38:37] [Epoch=509/540] [Need: 00:15:37] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [509][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0280 (0.0280)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:38:37]
  Epoch: [509][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0420 (0.0514)   Prec@1 99.000 (98.990)   Prec@5 100.000 (99.990)   [2018-05-02 23:38:48]
  Epoch: [509][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0832 (0.0530)   Prec@1 99.000 (98.948)   Prec@5 100.000 (99.990)   [2018-05-02 23:38:59]
  **Train** Prec@1 98.964 Prec@5 99.992 Error@1 1.036
  **Test** Prec@1 77.540 Prec@5 93.990 Error@1 22.460

==>>[2018-05-02 23:39:07] [Epoch=510/540] [Need: 00:15:07] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [510][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0603 (0.0603)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:39:07]
  Epoch: [510][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0712 (0.0494)   Prec@1 98.000 (99.020)   Prec@5 100.000 (100.000)   [2018-05-02 23:39:18]
  Epoch: [510][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0510 (0.0505)   Prec@1 99.000 (99.032)   Prec@5 100.000 (99.995)   [2018-05-02 23:39:29]
  **Train** Prec@1 99.048 Prec@5 99.994 Error@1 0.952
  **Test** Prec@1 77.590 Prec@5 93.970 Error@1 22.410

==>>[2018-05-02 23:39:37] [Epoch=511/540] [Need: 00:14:37] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [511][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0293 (0.0293)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:39:37]
  Epoch: [511][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0697 (0.0513)   Prec@1 98.000 (99.030)   Prec@5 100.000 (99.985)   [2018-05-02 23:39:48]
  Epoch: [511][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0821 (0.0523)   Prec@1 98.000 (98.968)   Prec@5 100.000 (99.988)   [2018-05-02 23:39:59]
  **Train** Prec@1 98.974 Prec@5 99.986 Error@1 1.026
  **Test** Prec@1 77.470 Prec@5 93.990 Error@1 22.530

==>>[2018-05-02 23:40:07] [Epoch=512/540] [Need: 00:14:07] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [512][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0981 (0.0981)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:40:07]
  Epoch: [512][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0613 (0.0502)   Prec@1 99.000 (99.060)   Prec@5 100.000 (99.995)   [2018-05-02 23:40:18]
  Epoch: [512][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0536 (0.0512)   Prec@1 99.000 (99.030)   Prec@5 100.000 (99.995)   [2018-05-02 23:40:29]
  **Train** Prec@1 99.034 Prec@5 99.988 Error@1 0.966
  **Test** Prec@1 77.580 Prec@5 93.880 Error@1 22.420

==>>[2018-05-02 23:40:37] [Epoch=513/540] [Need: 00:13:36] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [513][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.0322 (0.0322)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:40:37]
  Epoch: [513][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0298 (0.0511)   Prec@1 100.000 (99.030)   Prec@5 100.000 (99.980)   [2018-05-02 23:40:48]
  Epoch: [513][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1054 (0.0520)   Prec@1 98.000 (98.970)   Prec@5 100.000 (99.983)   [2018-05-02 23:40:59]
  **Train** Prec@1 98.978 Prec@5 99.984 Error@1 1.022
  **Test** Prec@1 77.710 Prec@5 94.020 Error@1 22.290

==>>[2018-05-02 23:41:07] [Epoch=514/540] [Need: 00:13:06] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [514][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0330 (0.0330)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:41:07]
  Epoch: [514][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0463 (0.0522)   Prec@1 99.000 (98.930)   Prec@5 100.000 (100.000)   [2018-05-02 23:41:18]
  Epoch: [514][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0458 (0.0520)   Prec@1 100.000 (98.998)   Prec@5 100.000 (99.988)   [2018-05-02 23:41:29]
  **Train** Prec@1 99.002 Prec@5 99.988 Error@1 0.998
  **Test** Prec@1 77.650 Prec@5 93.960 Error@1 22.350

==>>[2018-05-02 23:41:37] [Epoch=515/540] [Need: 00:12:36] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [515][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0183 (0.0183)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:41:37]
  Epoch: [515][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0302 (0.0508)   Prec@1 100.000 (99.000)   Prec@5 100.000 (99.985)   [2018-05-02 23:41:48]
  Epoch: [515][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0450 (0.0518)   Prec@1 99.000 (98.968)   Prec@5 100.000 (99.988)   [2018-05-02 23:41:59]
  **Train** Prec@1 98.994 Prec@5 99.988 Error@1 1.006
  **Test** Prec@1 77.510 Prec@5 93.850 Error@1 22.490

==>>[2018-05-02 23:42:07] [Epoch=516/540] [Need: 00:12:06] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [516][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.1344 (0.1344)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:42:08]
  Epoch: [516][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0524 (0.0491)   Prec@1 99.000 (99.104)   Prec@5 100.000 (99.980)   [2018-05-02 23:42:18]
  Epoch: [516][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0434 (0.0516)   Prec@1 99.000 (99.027)   Prec@5 100.000 (99.978)   [2018-05-02 23:42:29]
  **Train** Prec@1 98.992 Prec@5 99.978 Error@1 1.008
  **Test** Prec@1 77.710 Prec@5 93.990 Error@1 22.290

==>>[2018-05-02 23:42:38] [Epoch=517/540] [Need: 00:11:35] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [517][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0630 (0.0630)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:42:38]
  Epoch: [517][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0540 (0.0523)   Prec@1 99.000 (99.050)   Prec@5 100.000 (99.990)   [2018-05-02 23:42:49]
  Epoch: [517][400/500]   Time 0.061 (0.055)   Data 0.000 (0.000)   Loss 0.0585 (0.0511)   Prec@1 99.000 (99.087)   Prec@5 100.000 (99.990)   [2018-05-02 23:43:00]
  **Train** Prec@1 99.098 Prec@5 99.988 Error@1 0.902
  **Test** Prec@1 77.590 Prec@5 93.920 Error@1 22.410

==>>[2018-05-02 23:43:08] [Epoch=518/540] [Need: 00:11:05] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [518][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0610 (0.0610)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:43:08]
  Epoch: [518][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0274 (0.0528)   Prec@1 100.000 (99.070)   Prec@5 100.000 (99.995)   [2018-05-02 23:43:19]
  Epoch: [518][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0341 (0.0532)   Prec@1 99.000 (99.020)   Prec@5 100.000 (99.993)   [2018-05-02 23:43:30]
  **Train** Prec@1 99.014 Prec@5 99.992 Error@1 0.986
  **Test** Prec@1 77.500 Prec@5 93.910 Error@1 22.500

==>>[2018-05-02 23:43:38] [Epoch=519/540] [Need: 00:10:35] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [519][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0467 (0.0467)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:43:38]
  Epoch: [519][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0725 (0.0518)   Prec@1 98.000 (99.025)   Prec@5 100.000 (99.985)   [2018-05-02 23:43:49]
  Epoch: [519][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0500 (0.0527)   Prec@1 99.000 (99.010)   Prec@5 100.000 (99.990)   [2018-05-02 23:44:00]
  **Train** Prec@1 99.054 Prec@5 99.992 Error@1 0.946
  **Test** Prec@1 77.490 Prec@5 93.820 Error@1 22.510

==>>[2018-05-02 23:44:08] [Epoch=520/540] [Need: 00:10:05] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [520][000/500]   Time 0.087 (0.087)   Data 0.061 (0.061)   Loss 0.0400 (0.0400)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:44:08]
  Epoch: [520][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0579 (0.0530)   Prec@1 99.000 (98.935)   Prec@5 100.000 (99.990)   [2018-05-02 23:44:19]
  Epoch: [520][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0331 (0.0516)   Prec@1 100.000 (98.990)   Prec@5 100.000 (99.995)   [2018-05-02 23:44:30]
  **Train** Prec@1 99.004 Prec@5 99.986 Error@1 0.996
  **Test** Prec@1 77.440 Prec@5 93.960 Error@1 22.560

==>>[2018-05-02 23:44:38] [Epoch=521/540] [Need: 00:09:34] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [521][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1013 (0.1013)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:44:38]
  Epoch: [521][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0401 (0.0508)   Prec@1 100.000 (99.035)   Prec@5 100.000 (99.990)   [2018-05-02 23:44:49]
  Epoch: [521][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0153 (0.0503)   Prec@1 100.000 (99.087)   Prec@5 100.000 (99.980)   [2018-05-02 23:45:00]
  **Train** Prec@1 99.076 Prec@5 99.980 Error@1 0.924
  **Test** Prec@1 77.390 Prec@5 93.990 Error@1 22.610

==>>[2018-05-02 23:45:08] [Epoch=522/540] [Need: 00:09:04] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [522][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0653 (0.0653)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:45:08]
  Epoch: [522][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0659 (0.0546)   Prec@1 98.000 (98.900)   Prec@5 100.000 (99.980)   [2018-05-02 23:45:19]
  Epoch: [522][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0722 (0.0533)   Prec@1 98.000 (98.935)   Prec@5 100.000 (99.985)   [2018-05-02 23:45:30]
  **Train** Prec@1 98.966 Prec@5 99.986 Error@1 1.034
  **Test** Prec@1 77.500 Prec@5 94.070 Error@1 22.500

==>>[2018-05-02 23:45:38] [Epoch=523/540] [Need: 00:08:34] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [523][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0383 (0.0383)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:45:38]
  Epoch: [523][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0560 (0.0520)   Prec@1 100.000 (99.104)   Prec@5 100.000 (99.980)   [2018-05-02 23:45:49]
  Epoch: [523][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0218 (0.0517)   Prec@1 100.000 (99.090)   Prec@5 100.000 (99.988)   [2018-05-02 23:46:00]
  **Train** Prec@1 99.116 Prec@5 99.990 Error@1 0.884
  **Test** Prec@1 77.500 Prec@5 93.950 Error@1 22.500

==>>[2018-05-02 23:46:08] [Epoch=524/540] [Need: 00:08:04] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [524][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0362 (0.0362)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:46:08]
  Epoch: [524][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0651 (0.0524)   Prec@1 98.000 (98.970)   Prec@5 100.000 (99.995)   [2018-05-02 23:46:19]
  Epoch: [524][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0356 (0.0510)   Prec@1 99.000 (99.015)   Prec@5 100.000 (99.990)   [2018-05-02 23:46:30]
  **Train** Prec@1 99.044 Prec@5 99.992 Error@1 0.956
  **Test** Prec@1 77.430 Prec@5 94.060 Error@1 22.570

==>>[2018-05-02 23:46:38] [Epoch=525/540] [Need: 00:07:33] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [525][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.0823 (0.0823)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:46:38]
  Epoch: [525][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0479 (0.0520)   Prec@1 99.000 (98.950)   Prec@5 100.000 (99.995)   [2018-05-02 23:46:49]
  Epoch: [525][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0726 (0.0515)   Prec@1 98.000 (98.988)   Prec@5 100.000 (99.993)   [2018-05-02 23:47:00]
  **Train** Prec@1 99.036 Prec@5 99.994 Error@1 0.964
  **Test** Prec@1 77.560 Prec@5 94.000 Error@1 22.440

==>>[2018-05-02 23:47:08] [Epoch=526/540] [Need: 00:07:03] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [526][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0384 (0.0384)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:47:09]
  Epoch: [526][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0555 (0.0528)   Prec@1 99.000 (99.075)   Prec@5 100.000 (99.990)   [2018-05-02 23:47:19]
  Epoch: [526][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0362 (0.0518)   Prec@1 100.000 (99.080)   Prec@5 100.000 (99.990)   [2018-05-02 23:47:30]
  **Train** Prec@1 99.066 Prec@5 99.986 Error@1 0.934
  **Test** Prec@1 77.460 Prec@5 94.070 Error@1 22.540

==>>[2018-05-02 23:47:38] [Epoch=527/540] [Need: 00:06:33] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [527][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0678 (0.0678)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:47:39]
  Epoch: [527][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0414 (0.0512)   Prec@1 100.000 (99.010)   Prec@5 100.000 (99.995)   [2018-05-02 23:47:50]
  Epoch: [527][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0575 (0.0525)   Prec@1 98.000 (98.995)   Prec@5 100.000 (99.993)   [2018-05-02 23:48:00]
  **Train** Prec@1 98.996 Prec@5 99.990 Error@1 1.004
  **Test** Prec@1 77.700 Prec@5 94.050 Error@1 22.300

==>>[2018-05-02 23:48:09] [Epoch=528/540] [Need: 00:06:03] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [528][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0813 (0.0813)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:48:09]
  Epoch: [528][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0478 (0.0513)   Prec@1 100.000 (98.980)   Prec@5 100.000 (100.000)   [2018-05-02 23:48:20]
  Epoch: [528][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0764 (0.0510)   Prec@1 99.000 (99.037)   Prec@5 100.000 (100.000)   [2018-05-02 23:48:31]
  **Train** Prec@1 99.040 Prec@5 99.998 Error@1 0.960
  **Test** Prec@1 77.560 Prec@5 93.990 Error@1 22.440

==>>[2018-05-02 23:48:39] [Epoch=529/540] [Need: 00:05:32] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [529][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0547 (0.0547)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:48:39]
  Epoch: [529][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0331 (0.0524)   Prec@1 100.000 (99.045)   Prec@5 100.000 (99.995)   [2018-05-02 23:48:50]
  Epoch: [529][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0373 (0.0525)   Prec@1 99.000 (98.985)   Prec@5 100.000 (99.998)   [2018-05-02 23:49:01]
  **Train** Prec@1 98.984 Prec@5 99.996 Error@1 1.016
  **Test** Prec@1 77.540 Prec@5 93.950 Error@1 22.460

==>>[2018-05-02 23:49:09] [Epoch=530/540] [Need: 00:05:02] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [530][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0412 (0.0412)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:49:09]
  Epoch: [530][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0123 (0.0502)   Prec@1 100.000 (99.090)   Prec@5 100.000 (99.990)   [2018-05-02 23:49:20]
  Epoch: [530][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0376 (0.0523)   Prec@1 100.000 (99.035)   Prec@5 100.000 (99.993)   [2018-05-02 23:49:31]
  **Train** Prec@1 99.050 Prec@5 99.992 Error@1 0.950
  **Test** Prec@1 77.700 Prec@5 93.970 Error@1 22.300

==>>[2018-05-02 23:49:39] [Epoch=531/540] [Need: 00:04:32] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [531][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0306 (0.0306)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:49:39]
  Epoch: [531][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0636 (0.0511)   Prec@1 99.000 (99.119)   Prec@5 100.000 (99.985)   [2018-05-02 23:49:50]
  Epoch: [531][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0417 (0.0518)   Prec@1 99.000 (99.082)   Prec@5 100.000 (99.983)   [2018-05-02 23:50:01]
  **Train** Prec@1 99.078 Prec@5 99.986 Error@1 0.922
  **Test** Prec@1 77.570 Prec@5 94.040 Error@1 22.430

==>>[2018-05-02 23:50:09] [Epoch=532/540] [Need: 00:04:01] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [532][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0625 (0.0625)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:50:09]
  Epoch: [532][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0774 (0.0499)   Prec@1 97.000 (99.005)   Prec@5 100.000 (99.990)   [2018-05-02 23:50:20]
  Epoch: [532][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0635 (0.0522)   Prec@1 99.000 (98.995)   Prec@5 100.000 (99.995)   [2018-05-02 23:50:31]
  **Train** Prec@1 99.022 Prec@5 99.990 Error@1 0.978
  **Test** Prec@1 77.630 Prec@5 94.000 Error@1 22.370

==>>[2018-05-02 23:50:39] [Epoch=533/540] [Need: 00:03:31] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [533][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0262 (0.0262)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:50:39]
  Epoch: [533][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0576 (0.0477)   Prec@1 99.000 (99.159)   Prec@5 100.000 (99.990)   [2018-05-02 23:50:50]
  Epoch: [533][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0491 (0.0497)   Prec@1 99.000 (99.110)   Prec@5 100.000 (99.988)   [2018-05-02 23:51:01]
  **Train** Prec@1 99.086 Prec@5 99.988 Error@1 0.914
  **Test** Prec@1 77.690 Prec@5 93.870 Error@1 22.310

==>>[2018-05-02 23:51:09] [Epoch=534/540] [Need: 00:03:01] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [534][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0418 (0.0418)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:51:09]
  Epoch: [534][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0489 (0.0493)   Prec@1 99.000 (99.109)   Prec@5 100.000 (99.990)   [2018-05-02 23:51:20]
  Epoch: [534][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0521 (0.0503)   Prec@1 99.000 (99.072)   Prec@5 100.000 (99.990)   [2018-05-02 23:51:31]
  **Train** Prec@1 99.058 Prec@5 99.986 Error@1 0.942
  **Test** Prec@1 77.800 Prec@5 93.860 Error@1 22.200

==>>[2018-05-02 23:51:39] [Epoch=535/540] [Need: 00:02:31] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [535][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0362 (0.0362)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:51:39]
  Epoch: [535][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0355 (0.0534)   Prec@1 100.000 (98.925)   Prec@5 100.000 (99.990)   [2018-05-02 23:51:50]
  Epoch: [535][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0217 (0.0529)   Prec@1 100.000 (98.958)   Prec@5 100.000 (99.995)   [2018-05-02 23:52:01]
  **Train** Prec@1 98.972 Prec@5 99.994 Error@1 1.028
  **Test** Prec@1 77.380 Prec@5 94.070 Error@1 22.620

==>>[2018-05-02 23:52:09] [Epoch=536/540] [Need: 00:02:00] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [536][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0334 (0.0334)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:52:09]
  Epoch: [536][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0331 (0.0528)   Prec@1 100.000 (98.965)   Prec@5 100.000 (99.985)   [2018-05-02 23:52:20]
  Epoch: [536][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0185 (0.0519)   Prec@1 100.000 (99.007)   Prec@5 100.000 (99.993)   [2018-05-02 23:52:31]
  **Train** Prec@1 99.014 Prec@5 99.984 Error@1 0.986
  **Test** Prec@1 77.670 Prec@5 94.040 Error@1 22.330

==>>[2018-05-02 23:52:39] [Epoch=537/540] [Need: 00:01:30] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [537][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.0394 (0.0394)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:52:39]
  Epoch: [537][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0706 (0.0525)   Prec@1 98.000 (99.000)   Prec@5 100.000 (99.990)   [2018-05-02 23:52:50]
  Epoch: [537][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0539 (0.0518)   Prec@1 99.000 (99.062)   Prec@5 100.000 (99.988)   [2018-05-02 23:53:01]
  **Train** Prec@1 99.058 Prec@5 99.990 Error@1 0.942
  **Test** Prec@1 77.560 Prec@5 93.930 Error@1 22.440

==>>[2018-05-02 23:53:09] [Epoch=538/540] [Need: 00:01:00] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [538][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0544 (0.0544)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:53:10]
  Epoch: [538][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0239 (0.0508)   Prec@1 100.000 (99.030)   Prec@5 100.000 (99.985)   [2018-05-02 23:53:20]
  Epoch: [538][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0674 (0.0512)   Prec@1 98.000 (99.022)   Prec@5 100.000 (99.990)   [2018-05-02 23:53:31]
  **Train** Prec@1 99.026 Prec@5 99.992 Error@1 0.974
  **Test** Prec@1 77.560 Prec@5 93.880 Error@1 22.440

==>>[2018-05-02 23:53:40] [Epoch=539/540] [Need: 00:00:30] [learning_rate=0.000001] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [539][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0476 (0.0476)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 23:53:40]
  Epoch: [539][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0595 (0.0504)   Prec@1 98.000 (99.090)   Prec@5 100.000 (99.995)   [2018-05-02 23:53:51]
  Epoch: [539][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0687 (0.0523)   Prec@1 99.000 (99.037)   Prec@5 100.000 (99.995)   [2018-05-02 23:54:01]
  **Train** Prec@1 99.024 Prec@5 99.994 Error@1 0.976
  **Test** Prec@1 77.530 Prec@5 94.030 Error@1 22.470
