save path : ./snapshots/simpnet
{'arch': 'simplenet', 'batch_size': 100, 'data_path': './data/cifar.python', 'dataset': 'cifar10', 'decay': 0.001, 'epochs': 540, 'evaluate': False, 'gammas': [0.1, 0.1, 0.1, 0.1, 0.1], 'learning_rate': 0.1, 'manualSeed': 253, 'momentum': 0.9, 'ngpu': 1, 'print_freq': 200, 'resume': '', 'save_path': './snapshots/simpnet', 'schedule': [100, 190, 306, 390, 440, 540], 'start_epoch': 0, 'use_cuda': True, 'workers': 2}
Random Seed: 253
python version : 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)  [GCC 7.2.0]
torch  version : 0.3.1
cudnn  version : 7005
=> creating model 'simplenet'
=> network :
 simplenet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (5): ReLU(inplace)
    (6): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (8): ReLU(inplace)
    (9): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (13): Dropout2d(p=0.1)
    (14): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (16): ReLU(inplace)
    (17): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True)
    (19): ReLU(inplace)
    (20): Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (22): ReLU(inplace)
    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (24): Dropout2d(p=0.1)
    (25): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (26): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (27): ReLU(inplace)
    (28): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (29): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (30): ReLU(inplace)
    (31): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (32): Dropout2d(p=0.1)
    (33): Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.05, affine=True)
    (35): ReLU(inplace)
    (36): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (37): Dropout2d(p=0.1)
    (38): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1))
    (39): BatchNorm2d(2048, eps=1e-05, momentum=0.05, affine=True)
    (40): ReLU(inplace)
    (41): Conv2d(2048, 256, kernel_size=[1, 1], stride=(1, 1))
    (42): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (43): ReLU(inplace)
    (44): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (45): Dropout2d(p=0.1)
    (46): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))
    (47): BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True)
    (48): ReLU(inplace)
  )
  (classifier): Linear(in_features=256, out_features=10, bias=True)
)
=> Seed '253'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> optimizer '{'optimizer': {'state': {}, 'param_groups': [{'lr': 0.1, 'rho': 0.9, 'eps': 0.001, 'weight_decay': 0.001, 'params': [139845985219592, 139845985219752, 139845836149688, 139845836149768, 139845836149848, 139845836149928, 139845836150008, 139845836150088, 139845836150168, 139845836150248, 139845836150328, 139845836150408, 139845836150488, 139845836150568, 139845836150648, 139845836150728, 139845836150888, 139845836150968, 139845836151048, 139845836151128, 139845836151208, 139845836151288, 139845836151368, 139845836151448, 139845836151528, 139845836151608, 139845836151688, 139845836151768, 139845836152008, 139845836152088, 139845836152168, 139845836152248, 139845836152328, 139845836152408, 139845836152488, 139845836152568, 139845836152728, 139845944440536, 139845944440616, 139845944440696, 139845944440856, 139845944440936, 139845944441016, 139845944441096, 139845944441176, 139845944441256, 139845944441336, 139845944441416, 139845944441576, 139845944441656, 139845944441736, 139845944441816, 139845944442056, 139845944442136]}]}}'
=> did not use any checkpoint for simplenet model

==>>[2018-05-02 14:41:10] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.100000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 1.645 (1.645)   Data 0.044 (0.044)   Loss 2.3601 (2.3601)   Prec@1 11.000 (11.000)   Prec@5 50.000 (50.000)   [2018-05-02 14:41:12]
  Epoch: [000][200/500]   Time 0.060 (0.065)   Data 0.000 (0.000)   Loss 1.6514 (1.7622)   Prec@1 38.000 (34.547)   Prec@5 86.000 (85.522)   [2018-05-02 14:41:24]
  Epoch: [000][400/500]   Time 0.054 (0.060)   Data 0.000 (0.000)   Loss 1.1497 (1.5883)   Prec@1 58.000 (41.242)   Prec@5 97.000 (89.294)   [2018-05-02 14:41:35]
  **Train** Prec@1 44.050 Prec@5 90.326 Error@1 55.950
  **Test** Prec@1 57.280 Prec@5 94.850 Error@1 42.720

==>>[2018-05-02 14:41:43] [Epoch=001/540] [Need: 04:43:37] [learning_rate=0.100000] [Best : Accuracy=57.28, Error=42.72]
  Epoch: [001][000/500]   Time 0.074 (0.074)   Data 0.048 (0.048)   Loss 1.0604 (1.0604)   Prec@1 65.000 (65.000)   Prec@5 92.000 (92.000)   [2018-05-02 14:41:43]
  Epoch: [001][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.9262 (1.1182)   Prec@1 69.000 (60.328)   Prec@5 97.000 (95.716)   [2018-05-02 14:41:54]
  Epoch: [001][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.8771 (1.0780)   Prec@1 66.000 (61.646)   Prec@5 97.000 (96.115)   [2018-05-02 14:42:05]
  **Train** Prec@1 62.518 Prec@5 96.308 Error@1 37.482
  **Test** Prec@1 67.080 Prec@5 96.480 Error@1 32.920

==>>[2018-05-02 14:42:13] [Epoch=002/540] [Need: 04:36:10] [learning_rate=0.100000] [Best : Accuracy=67.08, Error=32.92]
  Epoch: [002][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.9699 (0.9699)   Prec@1 67.000 (67.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:42:13]
  Epoch: [002][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 1.0636 (0.8918)   Prec@1 65.000 (68.801)   Prec@5 96.000 (97.353)   [2018-05-02 14:42:24]
  Epoch: [002][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.9400 (0.8674)   Prec@1 69.000 (69.793)   Prec@5 97.000 (97.603)   [2018-05-02 14:42:35]
  **Train** Prec@1 70.256 Prec@5 97.644 Error@1 29.744
  **Test** Prec@1 72.570 Prec@5 98.130 Error@1 27.430

==>>[2018-05-02 14:42:43] [Epoch=003/540] [Need: 04:34:17] [learning_rate=0.100000] [Best : Accuracy=72.57, Error=27.43]
  Epoch: [003][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 1.0410 (1.0410)   Prec@1 66.000 (66.000)   Prec@5 94.000 (94.000)   [2018-05-02 14:42:43]
  Epoch: [003][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.6323 (0.7717)   Prec@1 81.000 (73.537)   Prec@5 99.000 (97.746)   [2018-05-02 14:42:54]
  Epoch: [003][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.6689 (0.7489)   Prec@1 78.000 (74.172)   Prec@5 100.000 (97.985)   [2018-05-02 14:43:05]
  **Train** Prec@1 74.598 Prec@5 98.076 Error@1 25.402
  **Test** Prec@1 77.930 Prec@5 98.800 Error@1 22.070

==>>[2018-05-02 14:43:13] [Epoch=004/540] [Need: 04:33:09] [learning_rate=0.100000] [Best : Accuracy=77.93, Error=22.07]
  Epoch: [004][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.6553 (0.6553)   Prec@1 78.000 (78.000)   Prec@5 98.000 (98.000)   [2018-05-02 14:43:13]
  Epoch: [004][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.5717 (0.6766)   Prec@1 82.000 (76.811)   Prec@5 98.000 (98.423)   [2018-05-02 14:43:25]
  Epoch: [004][400/500]   Time 0.062 (0.057)   Data 0.000 (0.000)   Loss 0.5914 (0.6650)   Prec@1 83.000 (77.214)   Prec@5 100.000 (98.549)   [2018-05-02 14:43:36]
  **Train** Prec@1 77.512 Prec@5 98.568 Error@1 22.488
  **Test** Prec@1 78.440 Prec@5 98.650 Error@1 21.560

==>>[2018-05-02 14:43:45] [Epoch=005/540] [Need: 04:34:48] [learning_rate=0.100000] [Best : Accuracy=78.44, Error=21.56]
  Epoch: [005][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.5821 (0.5821)   Prec@1 80.000 (80.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:43:45]
  Epoch: [005][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.7158 (0.6129)   Prec@1 78.000 (79.179)   Prec@5 99.000 (98.816)   [2018-05-02 14:43:57]
  Epoch: [005][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.5933 (0.5973)   Prec@1 82.000 (79.753)   Prec@5 100.000 (98.853)   [2018-05-02 14:44:09]
  **Train** Prec@1 79.810 Prec@5 98.804 Error@1 20.190
  **Test** Prec@1 81.820 Prec@5 99.110 Error@1 18.180

==>>[2018-05-02 14:44:18] [Epoch=006/540] [Need: 04:37:00] [learning_rate=0.100000] [Best : Accuracy=81.82, Error=18.18]
  Epoch: [006][000/500]   Time 0.090 (0.090)   Data 0.062 (0.062)   Loss 0.5299 (0.5299)   Prec@1 83.000 (83.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:44:18]
  Epoch: [006][200/500]   Time 0.055 (0.059)   Data 0.000 (0.001)   Loss 0.5099 (0.5596)   Prec@1 84.000 (81.100)   Prec@5 99.000 (98.925)   [2018-05-02 14:44:30]
  Epoch: [006][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.4444 (0.5560)   Prec@1 84.000 (81.092)   Prec@5 100.000 (98.890)   [2018-05-02 14:44:41]
  **Train** Prec@1 81.122 Prec@5 98.898 Error@1 18.878
  **Test** Prec@1 81.370 Prec@5 99.000 Error@1 18.630

==>>[2018-05-02 14:44:50] [Epoch=007/540] [Need: 04:37:37] [learning_rate=0.100000] [Best : Accuracy=81.82, Error=18.18]
  Epoch: [007][000/500]   Time 0.083 (0.083)   Data 0.054 (0.054)   Loss 0.4054 (0.4054)   Prec@1 88.000 (88.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:44:50]
  Epoch: [007][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.6247 (0.5238)   Prec@1 78.000 (82.224)   Prec@5 98.000 (99.030)   [2018-05-02 14:45:01]
  Epoch: [007][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.5401 (0.5158)   Prec@1 78.000 (82.397)   Prec@5 99.000 (99.075)   [2018-05-02 14:45:12]
  **Train** Prec@1 82.622 Prec@5 99.064 Error@1 17.378
  **Test** Prec@1 81.710 Prec@5 99.050 Error@1 18.290

==>>[2018-05-02 14:45:21] [Epoch=008/540] [Need: 04:36:34] [learning_rate=0.100000] [Best : Accuracy=81.82, Error=18.18]
  Epoch: [008][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.3604 (0.3604)   Prec@1 88.000 (88.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:45:21]
  Epoch: [008][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.5383 (0.4879)   Prec@1 82.000 (83.463)   Prec@5 98.000 (99.154)   [2018-05-02 14:45:32]
  Epoch: [008][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.4860 (0.4863)   Prec@1 83.000 (83.494)   Prec@5 100.000 (99.162)   [2018-05-02 14:45:43]
  **Train** Prec@1 83.584 Prec@5 99.186 Error@1 16.416
  **Test** Prec@1 84.520 Prec@5 99.300 Error@1 15.480

==>>[2018-05-02 14:45:51] [Epoch=009/540] [Need: 04:35:05] [learning_rate=0.100000] [Best : Accuracy=84.52, Error=15.48]
  Epoch: [009][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.4881 (0.4881)   Prec@1 83.000 (83.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:45:51]
  Epoch: [009][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.3882 (0.4619)   Prec@1 85.000 (84.224)   Prec@5 100.000 (99.308)   [2018-05-02 14:46:02]
  Epoch: [009][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3784 (0.4569)   Prec@1 86.000 (84.377)   Prec@5 99.000 (99.317)   [2018-05-02 14:46:13]
  **Train** Prec@1 84.386 Prec@5 99.316 Error@1 15.614
  **Test** Prec@1 85.360 Prec@5 99.410 Error@1 14.640

==>>[2018-05-02 14:46:21] [Epoch=010/540] [Need: 04:33:46] [learning_rate=0.100000] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [010][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.2923 (0.2923)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:46:21]
  Epoch: [010][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3680 (0.4327)   Prec@1 87.000 (85.403)   Prec@5 99.000 (99.279)   [2018-05-02 14:46:32]
  Epoch: [010][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4327 (0.4319)   Prec@1 84.000 (85.406)   Prec@5 100.000 (99.314)   [2018-05-02 14:46:43]
  **Train** Prec@1 85.462 Prec@5 99.332 Error@1 14.538
  **Test** Prec@1 85.140 Prec@5 99.520 Error@1 14.860

==>>[2018-05-02 14:46:51] [Epoch=011/540] [Need: 04:32:40] [learning_rate=0.100000] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [011][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.4275 (0.4275)   Prec@1 86.000 (86.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:46:51]
  Epoch: [011][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.4716 (0.4069)   Prec@1 82.000 (86.194)   Prec@5 100.000 (99.478)   [2018-05-02 14:47:03]
  Epoch: [011][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.4700 (0.4092)   Prec@1 82.000 (86.105)   Prec@5 99.000 (99.466)   [2018-05-02 14:47:14]
  **Train** Prec@1 86.054 Prec@5 99.456 Error@1 13.946
  **Test** Prec@1 85.140 Prec@5 99.510 Error@1 14.860

==>>[2018-05-02 14:47:22] [Epoch=012/540] [Need: 04:31:56] [learning_rate=0.100000] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [012][000/500]   Time 0.080 (0.080)   Data 0.055 (0.055)   Loss 0.4190 (0.4190)   Prec@1 87.000 (87.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:47:22]
  Epoch: [012][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.5303 (0.3873)   Prec@1 82.000 (86.985)   Prec@5 98.000 (99.473)   [2018-05-02 14:47:33]
  Epoch: [012][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.6046 (0.3931)   Prec@1 81.000 (86.778)   Prec@5 96.000 (99.446)   [2018-05-02 14:47:44]
  **Train** Prec@1 86.650 Prec@5 99.456 Error@1 13.350
  **Test** Prec@1 84.110 Prec@5 99.360 Error@1 15.890

==>>[2018-05-02 14:47:52] [Epoch=013/540] [Need: 04:31:09] [learning_rate=0.100000] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [013][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.3567 (0.3567)   Prec@1 86.000 (86.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:47:53]
  Epoch: [013][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.4449 (0.3692)   Prec@1 85.000 (87.647)   Prec@5 100.000 (99.572)   [2018-05-02 14:48:04]
  Epoch: [013][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.5879 (0.3711)   Prec@1 84.000 (87.586)   Prec@5 98.000 (99.536)   [2018-05-02 14:48:15]
  **Train** Prec@1 87.432 Prec@5 99.522 Error@1 12.568
  **Test** Prec@1 86.800 Prec@5 99.480 Error@1 13.200

==>>[2018-05-02 14:48:23] [Epoch=014/540] [Need: 04:30:30] [learning_rate=0.100000] [Best : Accuracy=86.80, Error=13.20]
  Epoch: [014][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.2293 (0.2293)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:48:23]
  Epoch: [014][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3727 (0.3551)   Prec@1 83.000 (87.826)   Prec@5 100.000 (99.582)   [2018-05-02 14:48:34]
  Epoch: [014][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2798 (0.3601)   Prec@1 88.000 (87.683)   Prec@5 100.000 (99.544)   [2018-05-02 14:48:45]
  **Train** Prec@1 87.684 Prec@5 99.526 Error@1 12.316
  **Test** Prec@1 86.730 Prec@5 99.460 Error@1 13.270

==>>[2018-05-02 14:48:53] [Epoch=015/540] [Need: 04:29:34] [learning_rate=0.100000] [Best : Accuracy=86.80, Error=13.20]
  Epoch: [015][000/500]   Time 0.078 (0.078)   Data 0.053 (0.053)   Loss 0.4017 (0.4017)   Prec@1 87.000 (87.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:48:53]
  Epoch: [015][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4851 (0.3407)   Prec@1 83.000 (88.338)   Prec@5 99.000 (99.527)   [2018-05-02 14:49:04]
  Epoch: [015][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2898 (0.3504)   Prec@1 92.000 (88.125)   Prec@5 100.000 (99.516)   [2018-05-02 14:49:15]
  **Train** Prec@1 88.094 Prec@5 99.520 Error@1 11.906
  **Test** Prec@1 86.880 Prec@5 99.400 Error@1 13.120

==>>[2018-05-02 14:49:23] [Epoch=016/540] [Need: 04:28:41] [learning_rate=0.100000] [Best : Accuracy=86.88, Error=13.12]
  Epoch: [016][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.2823 (0.2823)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:49:23]
  Epoch: [016][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3942 (0.3280)   Prec@1 86.000 (88.910)   Prec@5 100.000 (99.672)   [2018-05-02 14:49:34]
  Epoch: [016][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3412 (0.3325)   Prec@1 86.000 (88.843)   Prec@5 99.000 (99.631)   [2018-05-02 14:49:45]
  **Train** Prec@1 88.674 Prec@5 99.596 Error@1 11.326
  **Test** Prec@1 84.880 Prec@5 99.180 Error@1 15.120

==>>[2018-05-02 14:49:54] [Epoch=017/540] [Need: 04:27:52] [learning_rate=0.100000] [Best : Accuracy=86.88, Error=13.12]
  Epoch: [017][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.5181 (0.5181)   Prec@1 80.000 (80.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:49:54]
  Epoch: [017][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.4354 (0.3139)   Prec@1 88.000 (89.254)   Prec@5 100.000 (99.672)   [2018-05-02 14:50:05]
  Epoch: [017][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2577 (0.3263)   Prec@1 92.000 (88.870)   Prec@5 99.000 (99.631)   [2018-05-02 14:50:16]
  **Train** Prec@1 88.942 Prec@5 99.632 Error@1 11.058
  **Test** Prec@1 87.430 Prec@5 99.540 Error@1 12.570

==>>[2018-05-02 14:50:24] [Epoch=018/540] [Need: 04:27:05] [learning_rate=0.100000] [Best : Accuracy=87.43, Error=12.57]
  Epoch: [018][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.2118 (0.2118)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:50:24]
  Epoch: [018][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3371 (0.3127)   Prec@1 88.000 (89.358)   Prec@5 99.000 (99.587)   [2018-05-02 14:50:35]
  Epoch: [018][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2936 (0.3189)   Prec@1 91.000 (89.239)   Prec@5 99.000 (99.581)   [2018-05-02 14:50:46]
  **Train** Prec@1 89.112 Prec@5 99.596 Error@1 10.888
  **Test** Prec@1 83.580 Prec@5 99.100 Error@1 16.420

==>>[2018-05-02 14:50:54] [Epoch=019/540] [Need: 04:26:18] [learning_rate=0.100000] [Best : Accuracy=87.43, Error=12.57]
  Epoch: [019][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.4244 (0.4244)   Prec@1 85.000 (85.000)   Prec@5 98.000 (98.000)   [2018-05-02 14:50:54]
  Epoch: [019][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.5639 (0.3135)   Prec@1 79.000 (89.502)   Prec@5 99.000 (99.667)   [2018-05-02 14:51:05]
  Epoch: [019][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.4253 (0.3139)   Prec@1 87.000 (89.564)   Prec@5 100.000 (99.698)   [2018-05-02 14:51:16]
  **Train** Prec@1 89.598 Prec@5 99.674 Error@1 10.402
  **Test** Prec@1 87.170 Prec@5 99.290 Error@1 12.830

==>>[2018-05-02 14:51:24] [Epoch=020/540] [Need: 04:25:38] [learning_rate=0.100000] [Best : Accuracy=87.43, Error=12.57]
  Epoch: [020][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.2608 (0.2608)   Prec@1 93.000 (93.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:51:24]
  Epoch: [020][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3186 (0.2951)   Prec@1 90.000 (90.100)   Prec@5 100.000 (99.652)   [2018-05-02 14:51:35]
  Epoch: [020][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.4716 (0.3021)   Prec@1 88.000 (89.840)   Prec@5 99.000 (99.658)   [2018-05-02 14:51:46]
  **Train** Prec@1 89.672 Prec@5 99.642 Error@1 10.328
  **Test** Prec@1 88.020 Prec@5 99.600 Error@1 11.980

==>>[2018-05-02 14:51:55] [Epoch=021/540] [Need: 04:25:10] [learning_rate=0.100000] [Best : Accuracy=88.02, Error=11.98]
  Epoch: [021][000/500]   Time 0.081 (0.081)   Data 0.052 (0.052)   Loss 0.2785 (0.2785)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:51:55]
  Epoch: [021][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2879 (0.2889)   Prec@1 91.000 (90.299)   Prec@5 100.000 (99.657)   [2018-05-02 14:52:06]
  Epoch: [021][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.4163 (0.2971)   Prec@1 86.000 (90.007)   Prec@5 100.000 (99.646)   [2018-05-02 14:52:17]
  **Train** Prec@1 89.946 Prec@5 99.624 Error@1 10.054
  **Test** Prec@1 85.250 Prec@5 99.580 Error@1 14.750

==>>[2018-05-02 14:52:26] [Epoch=022/540] [Need: 04:24:41] [learning_rate=0.100000] [Best : Accuracy=88.02, Error=11.98]
  Epoch: [022][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.2714 (0.2714)   Prec@1 86.000 (86.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:52:26]
  Epoch: [022][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.3408 (0.2757)   Prec@1 87.000 (90.721)   Prec@5 100.000 (99.726)   [2018-05-02 14:52:37]
  Epoch: [022][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.4356 (0.2847)   Prec@1 83.000 (90.406)   Prec@5 100.000 (99.703)   [2018-05-02 14:52:48]
  **Train** Prec@1 90.358 Prec@5 99.696 Error@1 9.642
  **Test** Prec@1 88.270 Prec@5 99.590 Error@1 11.730

==>>[2018-05-02 14:52:56] [Epoch=023/540] [Need: 04:24:10] [learning_rate=0.100000] [Best : Accuracy=88.27, Error=11.73]
  Epoch: [023][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.2374 (0.2374)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:52:56]
  Epoch: [023][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3933 (0.2747)   Prec@1 86.000 (90.776)   Prec@5 99.000 (99.716)   [2018-05-02 14:53:07]
  Epoch: [023][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.3720 (0.2810)   Prec@1 87.000 (90.506)   Prec@5 99.000 (99.728)   [2018-05-02 14:53:19]
  **Train** Prec@1 90.460 Prec@5 99.710 Error@1 9.540
  **Test** Prec@1 87.160 Prec@5 99.410 Error@1 12.840

==>>[2018-05-02 14:53:27] [Epoch=024/540] [Need: 04:23:38] [learning_rate=0.100000] [Best : Accuracy=88.27, Error=11.73]
  Epoch: [024][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.2477 (0.2477)   Prec@1 93.000 (93.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:53:27]
  Epoch: [024][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.2660 (0.2814)   Prec@1 91.000 (90.652)   Prec@5 100.000 (99.706)   [2018-05-02 14:53:38]
  Epoch: [024][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3724 (0.2834)   Prec@1 86.000 (90.581)   Prec@5 100.000 (99.696)   [2018-05-02 14:53:49]
  **Train** Prec@1 90.496 Prec@5 99.704 Error@1 9.504
  **Test** Prec@1 88.020 Prec@5 99.610 Error@1 11.980

==>>[2018-05-02 14:53:58] [Epoch=025/540] [Need: 04:23:12] [learning_rate=0.100000] [Best : Accuracy=88.27, Error=11.73]
  Epoch: [025][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.2405 (0.2405)   Prec@1 93.000 (93.000)   Prec@5 98.000 (98.000)   [2018-05-02 14:53:58]
  Epoch: [025][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.3671 (0.2645)   Prec@1 87.000 (91.189)   Prec@5 98.000 (99.746)   [2018-05-02 14:54:09]
  Epoch: [025][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2944 (0.2732)   Prec@1 89.000 (90.880)   Prec@5 100.000 (99.733)   [2018-05-02 14:54:20]
  **Train** Prec@1 90.838 Prec@5 99.742 Error@1 9.162
  **Test** Prec@1 89.410 Prec@5 99.540 Error@1 10.590

==>>[2018-05-02 14:54:29] [Epoch=026/540] [Need: 04:22:48] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [026][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.2083 (0.2083)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:54:29]
  Epoch: [026][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.2045 (0.2701)   Prec@1 94.000 (90.995)   Prec@5 100.000 (99.751)   [2018-05-02 14:54:40]
  Epoch: [026][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.3164 (0.2717)   Prec@1 86.000 (90.863)   Prec@5 99.000 (99.733)   [2018-05-02 14:54:51]
  **Train** Prec@1 90.814 Prec@5 99.724 Error@1 9.186
  **Test** Prec@1 89.120 Prec@5 99.620 Error@1 10.880

==>>[2018-05-02 14:54:59] [Epoch=027/540] [Need: 04:22:15] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [027][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.1933 (0.1933)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:54:59]
  Epoch: [027][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1917 (0.2618)   Prec@1 96.000 (91.274)   Prec@5 99.000 (99.761)   [2018-05-02 14:55:11]
  Epoch: [027][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1941 (0.2691)   Prec@1 94.000 (90.903)   Prec@5 99.000 (99.746)   [2018-05-02 14:55:22]
  **Train** Prec@1 90.892 Prec@5 99.726 Error@1 9.108
  **Test** Prec@1 83.790 Prec@5 99.400 Error@1 16.210

==>>[2018-05-02 14:55:30] [Epoch=028/540] [Need: 04:21:46] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [028][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1795 (0.1795)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:55:30]
  Epoch: [028][200/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.3063 (0.2634)   Prec@1 91.000 (91.035)   Prec@5 100.000 (99.751)   [2018-05-02 14:55:41]
  Epoch: [028][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.4629 (0.2663)   Prec@1 85.000 (90.973)   Prec@5 100.000 (99.756)   [2018-05-02 14:55:53]
  **Train** Prec@1 90.912 Prec@5 99.760 Error@1 9.088
  **Test** Prec@1 87.980 Prec@5 99.530 Error@1 12.020

==>>[2018-05-02 14:56:01] [Epoch=029/540] [Need: 04:21:18] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [029][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.1921 (0.1921)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:56:01]
  Epoch: [029][200/500]   Time 0.196 (0.059)   Data 0.000 (0.000)   Loss 0.2480 (0.2457)   Prec@1 92.000 (91.806)   Prec@5 100.000 (99.836)   [2018-05-02 14:56:13]
  Epoch: [029][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.2669 (0.2555)   Prec@1 92.000 (91.504)   Prec@5 100.000 (99.781)   [2018-05-02 14:56:24]
  **Train** Prec@1 91.470 Prec@5 99.774 Error@1 8.530
  **Test** Prec@1 89.040 Prec@5 99.410 Error@1 10.960

==>>[2018-05-02 14:56:33] [Epoch=030/540] [Need: 04:21:04] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [030][000/500]   Time 0.083 (0.083)   Data 0.053 (0.053)   Loss 0.1762 (0.1762)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:56:33]
  Epoch: [030][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2158 (0.2390)   Prec@1 91.000 (91.990)   Prec@5 100.000 (99.791)   [2018-05-02 14:56:44]
  Epoch: [030][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1189 (0.2496)   Prec@1 97.000 (91.591)   Prec@5 100.000 (99.773)   [2018-05-02 14:56:56]
  **Train** Prec@1 91.542 Prec@5 99.766 Error@1 8.458
  **Test** Prec@1 87.140 Prec@5 99.660 Error@1 12.860

==>>[2018-05-02 14:57:04] [Epoch=031/540] [Need: 04:20:48] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [031][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.1869 (0.1869)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:57:04]
  Epoch: [031][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.2861 (0.2369)   Prec@1 91.000 (91.940)   Prec@5 99.000 (99.841)   [2018-05-02 14:57:15]
  Epoch: [031][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.2743 (0.2466)   Prec@1 91.000 (91.658)   Prec@5 100.000 (99.810)   [2018-05-02 14:57:26]
  **Train** Prec@1 91.502 Prec@5 99.800 Error@1 8.498
  **Test** Prec@1 88.590 Prec@5 99.400 Error@1 11.410

==>>[2018-05-02 14:57:34] [Epoch=032/540] [Need: 04:20:10] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [032][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.3593 (0.3593)   Prec@1 89.000 (89.000)   Prec@5 99.000 (99.000)   [2018-05-02 14:57:35]
  Epoch: [032][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1772 (0.2442)   Prec@1 92.000 (91.990)   Prec@5 100.000 (99.781)   [2018-05-02 14:57:46]
  Epoch: [032][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.2743 (0.2444)   Prec@1 89.000 (91.870)   Prec@5 100.000 (99.778)   [2018-05-02 14:57:57]
  **Train** Prec@1 91.850 Prec@5 99.766 Error@1 8.150
  **Test** Prec@1 88.140 Prec@5 99.590 Error@1 11.860

==>>[2018-05-02 14:58:05] [Epoch=033/540] [Need: 04:19:42] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [033][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.3656 (0.3656)   Prec@1 87.000 (87.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:58:06]
  Epoch: [033][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2838 (0.2386)   Prec@1 91.000 (92.109)   Prec@5 100.000 (99.781)   [2018-05-02 14:58:17]
  Epoch: [033][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2742 (0.2430)   Prec@1 90.000 (92.005)   Prec@5 100.000 (99.758)   [2018-05-02 14:58:28]
  **Train** Prec@1 91.912 Prec@5 99.762 Error@1 8.088
  **Test** Prec@1 86.620 Prec@5 99.540 Error@1 13.380

==>>[2018-05-02 14:58:37] [Epoch=034/540] [Need: 04:19:21] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [034][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1675 (0.1675)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:58:37]
  Epoch: [034][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.2213 (0.2356)   Prec@1 94.000 (92.194)   Prec@5 100.000 (99.831)   [2018-05-02 14:58:48]
  Epoch: [034][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2974 (0.2383)   Prec@1 87.000 (92.017)   Prec@5 100.000 (99.800)   [2018-05-02 14:59:00]
  **Train** Prec@1 91.946 Prec@5 99.802 Error@1 8.054
  **Test** Prec@1 88.200 Prec@5 99.510 Error@1 11.800

==>>[2018-05-02 14:59:08] [Epoch=035/540] [Need: 04:19:01] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [035][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.2069 (0.2069)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:59:08]
  Epoch: [035][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.3030 (0.2256)   Prec@1 91.000 (92.418)   Prec@5 100.000 (99.806)   [2018-05-02 14:59:20]
  Epoch: [035][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2802 (0.2344)   Prec@1 89.000 (92.145)   Prec@5 100.000 (99.778)   [2018-05-02 14:59:31]
  **Train** Prec@1 91.958 Prec@5 99.780 Error@1 8.042
  **Test** Prec@1 86.960 Prec@5 99.410 Error@1 13.040

==>>[2018-05-02 14:59:40] [Epoch=036/540] [Need: 04:18:38] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [036][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.2084 (0.2084)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 14:59:40]
  Epoch: [036][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.3209 (0.2284)   Prec@1 90.000 (92.428)   Prec@5 100.000 (99.771)   [2018-05-02 14:59:51]
  Epoch: [036][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2014 (0.2346)   Prec@1 93.000 (92.209)   Prec@5 100.000 (99.778)   [2018-05-02 15:00:03]
  **Train** Prec@1 92.070 Prec@5 99.784 Error@1 7.930
  **Test** Prec@1 89.130 Prec@5 99.720 Error@1 10.870

==>>[2018-05-02 15:00:11] [Epoch=037/540] [Need: 04:18:18] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [037][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.2131 (0.2131)   Prec@1 90.000 (90.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:00:11]
  Epoch: [037][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.3111 (0.2178)   Prec@1 90.000 (92.493)   Prec@5 99.000 (99.831)   [2018-05-02 15:00:23]
  Epoch: [037][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.3929 (0.2292)   Prec@1 88.000 (92.107)   Prec@5 99.000 (99.830)   [2018-05-02 15:00:34]
  **Train** Prec@1 92.028 Prec@5 99.810 Error@1 7.972
  **Test** Prec@1 87.990 Prec@5 99.490 Error@1 12.010

==>>[2018-05-02 15:00:43] [Epoch=038/540] [Need: 04:17:55] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [038][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.1405 (0.1405)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:00:43]
  Epoch: [038][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2099 (0.2182)   Prec@1 94.000 (92.781)   Prec@5 100.000 (99.846)   [2018-05-02 15:00:54]
  Epoch: [038][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.1785 (0.2243)   Prec@1 94.000 (92.481)   Prec@5 100.000 (99.823)   [2018-05-02 15:01:05]
  **Train** Prec@1 92.344 Prec@5 99.804 Error@1 7.656
  **Test** Prec@1 85.380 Prec@5 99.430 Error@1 14.620

==>>[2018-05-02 15:01:14] [Epoch=039/540] [Need: 04:17:31] [learning_rate=0.100000] [Best : Accuracy=89.41, Error=10.59]
  Epoch: [039][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.1282 (0.1282)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:01:14]
  Epoch: [039][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1355 (0.2206)   Prec@1 97.000 (92.677)   Prec@5 100.000 (99.841)   [2018-05-02 15:01:25]
  Epoch: [039][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.1463 (0.2271)   Prec@1 94.000 (92.389)   Prec@5 100.000 (99.830)   [2018-05-02 15:01:37]
  **Train** Prec@1 92.212 Prec@5 99.822 Error@1 7.788
  **Test** Prec@1 89.450 Prec@5 99.610 Error@1 10.550

==>>[2018-05-02 15:01:45] [Epoch=040/540] [Need: 04:17:08] [learning_rate=0.100000] [Best : Accuracy=89.45, Error=10.55]
  Epoch: [040][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1731 (0.1731)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:01:45]
  Epoch: [040][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2274 (0.2191)   Prec@1 92.000 (92.851)   Prec@5 100.000 (99.900)   [2018-05-02 15:01:57]
  Epoch: [040][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.2636 (0.2293)   Prec@1 92.000 (92.474)   Prec@5 100.000 (99.823)   [2018-05-02 15:02:08]
  **Train** Prec@1 92.366 Prec@5 99.824 Error@1 7.634
  **Test** Prec@1 89.500 Prec@5 99.620 Error@1 10.500

==>>[2018-05-02 15:02:17] [Epoch=041/540] [Need: 04:16:44] [learning_rate=0.100000] [Best : Accuracy=89.50, Error=10.50]
  Epoch: [041][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.2350 (0.2350)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:02:17]
  Epoch: [041][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.2430 (0.2088)   Prec@1 93.000 (93.045)   Prec@5 99.000 (99.816)   [2018-05-02 15:02:28]
  Epoch: [041][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.1167 (0.2176)   Prec@1 98.000 (92.778)   Prec@5 100.000 (99.818)   [2018-05-02 15:02:40]
  **Train** Prec@1 92.738 Prec@5 99.808 Error@1 7.262
  **Test** Prec@1 89.170 Prec@5 99.740 Error@1 10.830

==>>[2018-05-02 15:02:48] [Epoch=042/540] [Need: 04:16:22] [learning_rate=0.100000] [Best : Accuracy=89.50, Error=10.50]
  Epoch: [042][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.1439 (0.1439)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:02:49]
  Epoch: [042][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.3229 (0.2170)   Prec@1 88.000 (92.771)   Prec@5 99.000 (99.776)   [2018-05-02 15:03:00]
  Epoch: [042][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.2507 (0.2248)   Prec@1 91.000 (92.454)   Prec@5 100.000 (99.815)   [2018-05-02 15:03:11]
  **Train** Prec@1 92.408 Prec@5 99.812 Error@1 7.592
  **Test** Prec@1 88.010 Prec@5 99.340 Error@1 11.990

==>>[2018-05-02 15:03:20] [Epoch=043/540] [Need: 04:15:58] [learning_rate=0.100000] [Best : Accuracy=89.50, Error=10.50]
  Epoch: [043][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.1975 (0.1975)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:03:20]
  Epoch: [043][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.2286 (0.2071)   Prec@1 91.000 (93.065)   Prec@5 100.000 (99.811)   [2018-05-02 15:03:31]
  Epoch: [043][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.2630 (0.2126)   Prec@1 91.000 (92.868)   Prec@5 100.000 (99.800)   [2018-05-02 15:03:43]
  **Train** Prec@1 92.768 Prec@5 99.774 Error@1 7.232
  **Test** Prec@1 89.840 Prec@5 99.650 Error@1 10.160

==>>[2018-05-02 15:03:51] [Epoch=044/540] [Need: 04:15:33] [learning_rate=0.100000] [Best : Accuracy=89.84, Error=10.16]
  Epoch: [044][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.1437 (0.1437)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:03:51]
  Epoch: [044][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.1952 (0.2101)   Prec@1 94.000 (92.995)   Prec@5 100.000 (99.836)   [2018-05-02 15:04:03]
  Epoch: [044][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.1513 (0.2148)   Prec@1 96.000 (92.820)   Prec@5 100.000 (99.848)   [2018-05-02 15:04:14]
  **Train** Prec@1 92.748 Prec@5 99.830 Error@1 7.252
  **Test** Prec@1 87.770 Prec@5 99.450 Error@1 12.230

==>>[2018-05-02 15:04:22] [Epoch=045/540] [Need: 04:15:04] [learning_rate=0.100000] [Best : Accuracy=89.84, Error=10.16]
  Epoch: [045][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.1425 (0.1425)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:04:23]
  Epoch: [045][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.2395 (0.2109)   Prec@1 91.000 (92.846)   Prec@5 100.000 (99.861)   [2018-05-02 15:04:34]
  Epoch: [045][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.2178 (0.2177)   Prec@1 91.000 (92.601)   Prec@5 100.000 (99.833)   [2018-05-02 15:04:45]
  **Train** Prec@1 92.574 Prec@5 99.836 Error@1 7.426
  **Test** Prec@1 90.250 Prec@5 99.610 Error@1 9.750

==>>[2018-05-02 15:04:54] [Epoch=046/540] [Need: 04:14:44] [learning_rate=0.100000] [Best : Accuracy=90.25, Error=9.75]
  Epoch: [046][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.1858 (0.1858)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:04:54]
  Epoch: [046][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1828 (0.2138)   Prec@1 93.000 (92.612)   Prec@5 100.000 (99.866)   [2018-05-02 15:05:06]
  Epoch: [046][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.1180 (0.2147)   Prec@1 96.000 (92.723)   Prec@5 100.000 (99.835)   [2018-05-02 15:05:17]
  **Train** Prec@1 92.688 Prec@5 99.832 Error@1 7.312
  **Test** Prec@1 88.700 Prec@5 99.460 Error@1 11.300

==>>[2018-05-02 15:05:26] [Epoch=047/540] [Need: 04:14:16] [learning_rate=0.100000] [Best : Accuracy=90.25, Error=9.75]
  Epoch: [047][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.2176 (0.2176)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:05:26]
  Epoch: [047][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.1739 (0.2101)   Prec@1 95.000 (92.950)   Prec@5 100.000 (99.791)   [2018-05-02 15:05:37]
  Epoch: [047][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.1795 (0.2129)   Prec@1 94.000 (92.845)   Prec@5 100.000 (99.815)   [2018-05-02 15:05:49]
  **Train** Prec@1 92.794 Prec@5 99.824 Error@1 7.206
  **Test** Prec@1 87.260 Prec@5 99.350 Error@1 12.740

==>>[2018-05-02 15:05:57] [Epoch=048/540] [Need: 04:13:54] [learning_rate=0.100000] [Best : Accuracy=90.25, Error=9.75]
  Epoch: [048][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.3199 (0.3199)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:05:57]
  Epoch: [048][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.2078 (0.2097)   Prec@1 92.000 (93.000)   Prec@5 100.000 (99.836)   [2018-05-02 15:06:09]
  Epoch: [048][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.1532 (0.2126)   Prec@1 94.000 (92.845)   Prec@5 100.000 (99.825)   [2018-05-02 15:06:20]
  **Train** Prec@1 92.784 Prec@5 99.830 Error@1 7.216
  **Test** Prec@1 88.270 Prec@5 99.510 Error@1 11.730

==>>[2018-05-02 15:06:29] [Epoch=049/540] [Need: 04:13:25] [learning_rate=0.100000] [Best : Accuracy=90.25, Error=9.75]
  Epoch: [049][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.2355 (0.2355)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:06:29]
  Epoch: [049][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2362 (0.2198)   Prec@1 92.000 (92.572)   Prec@5 99.000 (99.831)   [2018-05-02 15:06:40]
  Epoch: [049][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2410 (0.2218)   Prec@1 94.000 (92.471)   Prec@5 100.000 (99.820)   [2018-05-02 15:06:51]
  **Train** Prec@1 92.542 Prec@5 99.824 Error@1 7.458
  **Test** Prec@1 90.690 Prec@5 99.450 Error@1 9.310

==>>[2018-05-02 15:06:59] [Epoch=050/540] [Need: 04:12:45] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [050][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.2504 (0.2504)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:06:59]
  Epoch: [050][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1927 (0.2001)   Prec@1 96.000 (93.353)   Prec@5 100.000 (99.876)   [2018-05-02 15:07:10]
  Epoch: [050][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2088 (0.2058)   Prec@1 91.000 (93.122)   Prec@5 100.000 (99.835)   [2018-05-02 15:07:21]
  **Train** Prec@1 92.982 Prec@5 99.836 Error@1 7.018
  **Test** Prec@1 89.730 Prec@5 99.630 Error@1 10.270

==>>[2018-05-02 15:07:29] [Epoch=051/540] [Need: 04:12:05] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [051][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.2468 (0.2468)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:07:29]
  Epoch: [051][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1902 (0.2048)   Prec@1 94.000 (93.139)   Prec@5 100.000 (99.821)   [2018-05-02 15:07:40]
  Epoch: [051][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2583 (0.2084)   Prec@1 89.000 (93.007)   Prec@5 100.000 (99.830)   [2018-05-02 15:07:51]
  **Train** Prec@1 92.980 Prec@5 99.834 Error@1 7.020
  **Test** Prec@1 89.380 Prec@5 99.650 Error@1 10.620

==>>[2018-05-02 15:07:59] [Epoch=052/540] [Need: 04:11:27] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [052][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.2644 (0.2644)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:07:59]
  Epoch: [052][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1959 (0.2021)   Prec@1 92.000 (93.328)   Prec@5 100.000 (99.876)   [2018-05-02 15:08:10]
  Epoch: [052][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0887 (0.2025)   Prec@1 98.000 (93.254)   Prec@5 100.000 (99.870)   [2018-05-02 15:08:21]
  **Train** Prec@1 93.204 Prec@5 99.868 Error@1 6.796
  **Test** Prec@1 88.680 Prec@5 99.610 Error@1 11.320

==>>[2018-05-02 15:08:29] [Epoch=053/540] [Need: 04:10:49] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [053][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.2549 (0.2549)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:08:29]
  Epoch: [053][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1858 (0.2026)   Prec@1 95.000 (93.403)   Prec@5 100.000 (99.866)   [2018-05-02 15:08:40]
  Epoch: [053][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1710 (0.2071)   Prec@1 96.000 (93.239)   Prec@5 100.000 (99.840)   [2018-05-02 15:08:51]
  **Train** Prec@1 93.202 Prec@5 99.834 Error@1 6.798
  **Test** Prec@1 90.170 Prec@5 99.700 Error@1 9.830

==>>[2018-05-02 15:08:59] [Epoch=054/540] [Need: 04:10:12] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [054][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.3253 (0.3253)   Prec@1 89.000 (89.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:08:59]
  Epoch: [054][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1644 (0.1898)   Prec@1 96.000 (93.507)   Prec@5 100.000 (99.861)   [2018-05-02 15:09:10]
  Epoch: [054][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1832 (0.1979)   Prec@1 94.000 (93.292)   Prec@5 100.000 (99.873)   [2018-05-02 15:09:21]
  **Train** Prec@1 93.206 Prec@5 99.868 Error@1 6.794
  **Test** Prec@1 89.130 Prec@5 99.620 Error@1 10.870

==>>[2018-05-02 15:09:29] [Epoch=055/540] [Need: 04:09:35] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [055][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.1534 (0.1534)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:09:29]
  Epoch: [055][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1484 (0.1944)   Prec@1 94.000 (93.567)   Prec@5 100.000 (99.871)   [2018-05-02 15:09:40]
  Epoch: [055][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2336 (0.2045)   Prec@1 90.000 (93.224)   Prec@5 100.000 (99.865)   [2018-05-02 15:09:51]
  **Train** Prec@1 93.126 Prec@5 99.862 Error@1 6.874
  **Test** Prec@1 89.450 Prec@5 99.650 Error@1 10.550

==>>[2018-05-02 15:09:59] [Epoch=056/540] [Need: 04:08:56] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [056][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.1537 (0.1537)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:09:59]
  Epoch: [056][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2284 (0.1905)   Prec@1 93.000 (93.522)   Prec@5 100.000 (99.915)   [2018-05-02 15:10:10]
  Epoch: [056][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2670 (0.1980)   Prec@1 90.000 (93.327)   Prec@5 100.000 (99.878)   [2018-05-02 15:10:21]
  **Train** Prec@1 93.170 Prec@5 99.868 Error@1 6.830
  **Test** Prec@1 89.360 Prec@5 99.600 Error@1 10.640

==>>[2018-05-02 15:10:30] [Epoch=057/540] [Need: 04:08:20] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [057][000/500]   Time 0.078 (0.078)   Data 0.053 (0.053)   Loss 0.1908 (0.1908)   Prec@1 93.000 (93.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:10:30]
  Epoch: [057][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1438 (0.1882)   Prec@1 97.000 (93.751)   Prec@5 100.000 (99.876)   [2018-05-02 15:10:41]
  Epoch: [057][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1545 (0.1954)   Prec@1 95.000 (93.474)   Prec@5 100.000 (99.865)   [2018-05-02 15:10:52]
  **Train** Prec@1 93.368 Prec@5 99.840 Error@1 6.632
  **Test** Prec@1 89.640 Prec@5 99.620 Error@1 10.360

==>>[2018-05-02 15:11:00] [Epoch=058/540] [Need: 04:07:42] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [058][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.2611 (0.2611)   Prec@1 90.000 (90.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:11:00]
  Epoch: [058][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1333 (0.1829)   Prec@1 98.000 (94.050)   Prec@5 100.000 (99.886)   [2018-05-02 15:11:11]
  Epoch: [058][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3676 (0.1957)   Prec@1 87.000 (93.626)   Prec@5 99.000 (99.863)   [2018-05-02 15:11:21]
  **Train** Prec@1 93.534 Prec@5 99.854 Error@1 6.466
  **Test** Prec@1 88.850 Prec@5 99.680 Error@1 11.150

==>>[2018-05-02 15:11:30] [Epoch=059/540] [Need: 04:07:07] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [059][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.1893 (0.1893)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:11:30]
  Epoch: [059][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0713 (0.1813)   Prec@1 98.000 (94.134)   Prec@5 100.000 (99.891)   [2018-05-02 15:11:41]
  Epoch: [059][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.1323 (0.1981)   Prec@1 95.000 (93.414)   Prec@5 100.000 (99.838)   [2018-05-02 15:11:52]
  **Train** Prec@1 93.386 Prec@5 99.826 Error@1 6.614
  **Test** Prec@1 87.500 Prec@5 99.460 Error@1 12.500

==>>[2018-05-02 15:12:00] [Epoch=060/540] [Need: 04:06:33] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [060][000/500]   Time 0.080 (0.080)   Data 0.055 (0.055)   Loss 0.1713 (0.1713)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:12:00]
  Epoch: [060][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2078 (0.1886)   Prec@1 93.000 (93.736)   Prec@5 100.000 (99.866)   [2018-05-02 15:12:11]
  Epoch: [060][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1159 (0.1968)   Prec@1 98.000 (93.339)   Prec@5 100.000 (99.855)   [2018-05-02 15:12:22]
  **Train** Prec@1 93.256 Prec@5 99.852 Error@1 6.744
  **Test** Prec@1 88.500 Prec@5 99.450 Error@1 11.500

==>>[2018-05-02 15:12:31] [Epoch=061/540] [Need: 04:05:58] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [061][000/500]   Time 0.076 (0.076)   Data 0.051 (0.051)   Loss 0.1833 (0.1833)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:12:31]
  Epoch: [061][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1493 (0.1941)   Prec@1 98.000 (93.438)   Prec@5 100.000 (99.871)   [2018-05-02 15:12:42]
  Epoch: [061][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1696 (0.1977)   Prec@1 96.000 (93.324)   Prec@5 100.000 (99.840)   [2018-05-02 15:12:53]
  **Train** Prec@1 93.300 Prec@5 99.848 Error@1 6.700
  **Test** Prec@1 89.670 Prec@5 99.490 Error@1 10.330

==>>[2018-05-02 15:13:01] [Epoch=062/540] [Need: 04:05:21] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [062][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0890 (0.0890)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:13:01]
  Epoch: [062][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2067 (0.1913)   Prec@1 91.000 (93.657)   Prec@5 100.000 (99.881)   [2018-05-02 15:13:12]
  Epoch: [062][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1691 (0.1915)   Prec@1 95.000 (93.711)   Prec@5 100.000 (99.875)   [2018-05-02 15:13:23]
  **Train** Prec@1 93.576 Prec@5 99.864 Error@1 6.424
  **Test** Prec@1 87.960 Prec@5 99.600 Error@1 12.040

==>>[2018-05-02 15:13:31] [Epoch=063/540] [Need: 04:04:45] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [063][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.2279 (0.2279)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:13:31]
  Epoch: [063][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0787 (0.1849)   Prec@1 99.000 (93.781)   Prec@5 100.000 (99.856)   [2018-05-02 15:13:42]
  Epoch: [063][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1978 (0.1909)   Prec@1 93.000 (93.661)   Prec@5 100.000 (99.840)   [2018-05-02 15:13:53]
  **Train** Prec@1 93.600 Prec@5 99.840 Error@1 6.400
  **Test** Prec@1 87.940 Prec@5 99.610 Error@1 12.060

==>>[2018-05-02 15:14:01] [Epoch=064/540] [Need: 04:04:09] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [064][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.2016 (0.2016)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:14:01]
  Epoch: [064][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1282 (0.1894)   Prec@1 96.000 (93.746)   Prec@5 100.000 (99.836)   [2018-05-02 15:14:12]
  Epoch: [064][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1883 (0.1871)   Prec@1 96.000 (93.798)   Prec@5 100.000 (99.840)   [2018-05-02 15:14:23]
  **Train** Prec@1 93.714 Prec@5 99.836 Error@1 6.286
  **Test** Prec@1 87.000 Prec@5 99.540 Error@1 13.000

==>>[2018-05-02 15:14:31] [Epoch=065/540] [Need: 04:03:34] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [065][000/500]   Time 0.076 (0.076)   Data 0.051 (0.051)   Loss 0.1995 (0.1995)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:14:31]
  Epoch: [065][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1598 (0.1939)   Prec@1 94.000 (93.547)   Prec@5 100.000 (99.861)   [2018-05-02 15:14:42]
  Epoch: [065][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3253 (0.1978)   Prec@1 88.000 (93.349)   Prec@5 100.000 (99.845)   [2018-05-02 15:14:53]
  **Train** Prec@1 93.302 Prec@5 99.840 Error@1 6.698
  **Test** Prec@1 89.300 Prec@5 99.540 Error@1 10.700

==>>[2018-05-02 15:15:01] [Epoch=066/540] [Need: 04:02:58] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [066][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.1313 (0.1313)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:15:01]
  Epoch: [066][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.3751 (0.1820)   Prec@1 90.000 (93.766)   Prec@5 100.000 (99.856)   [2018-05-02 15:15:12]
  Epoch: [066][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1919 (0.1901)   Prec@1 91.000 (93.646)   Prec@5 100.000 (99.850)   [2018-05-02 15:15:23]
  **Train** Prec@1 93.566 Prec@5 99.854 Error@1 6.434
  **Test** Prec@1 89.010 Prec@5 99.530 Error@1 10.990

==>>[2018-05-02 15:15:31] [Epoch=067/540] [Need: 04:02:23] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [067][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.1096 (0.1096)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:15:31]
  Epoch: [067][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1796 (0.1806)   Prec@1 92.000 (94.005)   Prec@5 100.000 (99.886)   [2018-05-02 15:15:42]
  Epoch: [067][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2244 (0.1869)   Prec@1 91.000 (93.751)   Prec@5 100.000 (99.868)   [2018-05-02 15:15:53]
  **Train** Prec@1 93.654 Prec@5 99.866 Error@1 6.346
  **Test** Prec@1 88.290 Prec@5 99.540 Error@1 11.710

==>>[2018-05-02 15:16:01] [Epoch=068/540] [Need: 04:01:48] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [068][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.2830 (0.2830)   Prec@1 90.000 (90.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:16:01]
  Epoch: [068][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2003 (0.1795)   Prec@1 92.000 (93.975)   Prec@5 100.000 (99.900)   [2018-05-02 15:16:12]
  Epoch: [068][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1829 (0.1905)   Prec@1 93.000 (93.584)   Prec@5 100.000 (99.863)   [2018-05-02 15:16:23]
  **Train** Prec@1 93.560 Prec@5 99.864 Error@1 6.440
  **Test** Prec@1 89.540 Prec@5 99.650 Error@1 10.460

==>>[2018-05-02 15:16:32] [Epoch=069/540] [Need: 04:01:13] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [069][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0829 (0.0829)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:16:32]
  Epoch: [069][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2040 (0.1839)   Prec@1 91.000 (94.030)   Prec@5 100.000 (99.876)   [2018-05-02 15:16:43]
  Epoch: [069][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.3080 (0.1881)   Prec@1 87.000 (93.830)   Prec@5 100.000 (99.885)   [2018-05-02 15:16:54]
  **Train** Prec@1 93.768 Prec@5 99.874 Error@1 6.232
  **Test** Prec@1 87.710 Prec@5 99.260 Error@1 12.290

==>>[2018-05-02 15:17:02] [Epoch=070/540] [Need: 04:00:39] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [070][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.1940 (0.1940)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:17:02]
  Epoch: [070][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1902 (0.1814)   Prec@1 93.000 (93.950)   Prec@5 100.000 (99.886)   [2018-05-02 15:17:13]
  Epoch: [070][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1767 (0.1862)   Prec@1 93.000 (93.805)   Prec@5 100.000 (99.883)   [2018-05-02 15:17:24]
  **Train** Prec@1 93.754 Prec@5 99.896 Error@1 6.246
  **Test** Prec@1 88.930 Prec@5 99.620 Error@1 11.070

==>>[2018-05-02 15:17:32] [Epoch=071/540] [Need: 04:00:04] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [071][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.1762 (0.1762)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:17:32]
  Epoch: [071][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1242 (0.1783)   Prec@1 96.000 (94.020)   Prec@5 100.000 (99.910)   [2018-05-02 15:17:43]
  Epoch: [071][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1411 (0.1827)   Prec@1 95.000 (93.938)   Prec@5 100.000 (99.890)   [2018-05-02 15:17:54]
  **Train** Prec@1 93.882 Prec@5 99.886 Error@1 6.118
  **Test** Prec@1 88.820 Prec@5 99.390 Error@1 11.180

==>>[2018-05-02 15:18:02] [Epoch=072/540] [Need: 03:59:30] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [072][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.2443 (0.2443)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:18:02]
  Epoch: [072][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2090 (0.1746)   Prec@1 93.000 (94.413)   Prec@5 100.000 (99.881)   [2018-05-02 15:18:13]
  Epoch: [072][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2498 (0.1832)   Prec@1 91.000 (94.040)   Prec@5 100.000 (99.870)   [2018-05-02 15:18:24]
  **Train** Prec@1 93.820 Prec@5 99.864 Error@1 6.180
  **Test** Prec@1 88.850 Prec@5 99.450 Error@1 11.150

==>>[2018-05-02 15:18:32] [Epoch=073/540] [Need: 03:58:56] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [073][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.2254 (0.2254)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:18:32]
  Epoch: [073][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0993 (0.1670)   Prec@1 98.000 (94.453)   Prec@5 100.000 (99.881)   [2018-05-02 15:18:43]
  Epoch: [073][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1998 (0.1825)   Prec@1 95.000 (94.020)   Prec@5 100.000 (99.885)   [2018-05-02 15:18:54]
  **Train** Prec@1 93.918 Prec@5 99.878 Error@1 6.082
  **Test** Prec@1 90.680 Prec@5 99.640 Error@1 9.320

==>>[2018-05-02 15:19:02] [Epoch=074/540] [Need: 03:58:21] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [074][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.2063 (0.2063)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:19:02]
  Epoch: [074][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2199 (0.1785)   Prec@1 91.000 (94.090)   Prec@5 100.000 (99.896)   [2018-05-02 15:19:13]
  Epoch: [074][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3089 (0.1836)   Prec@1 91.000 (93.898)   Prec@5 99.000 (99.888)   [2018-05-02 15:19:24]
  **Train** Prec@1 93.654 Prec@5 99.890 Error@1 6.346
  **Test** Prec@1 85.950 Prec@5 99.590 Error@1 14.050

==>>[2018-05-02 15:19:32] [Epoch=075/540] [Need: 03:57:48] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [075][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.1192 (0.1192)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:19:32]
  Epoch: [075][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2990 (0.1844)   Prec@1 92.000 (93.920)   Prec@5 100.000 (99.826)   [2018-05-02 15:19:43]
  Epoch: [075][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1908 (0.1870)   Prec@1 95.000 (93.805)   Prec@5 100.000 (99.855)   [2018-05-02 15:19:54]
  **Train** Prec@1 93.734 Prec@5 99.858 Error@1 6.266
  **Test** Prec@1 89.820 Prec@5 99.740 Error@1 10.180

==>>[2018-05-02 15:20:02] [Epoch=076/540] [Need: 03:57:13] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [076][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.1556 (0.1556)   Prec@1 95.000 (95.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:20:03]
  Epoch: [076][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2398 (0.1808)   Prec@1 91.000 (93.985)   Prec@5 100.000 (99.881)   [2018-05-02 15:20:13]
  Epoch: [076][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1997 (0.1819)   Prec@1 93.000 (94.032)   Prec@5 100.000 (99.898)   [2018-05-02 15:20:24]
  **Train** Prec@1 93.934 Prec@5 99.876 Error@1 6.066
  **Test** Prec@1 89.980 Prec@5 99.570 Error@1 10.020

==>>[2018-05-02 15:20:33] [Epoch=077/540] [Need: 03:56:40] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [077][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0883 (0.0883)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:20:33]
  Epoch: [077][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2135 (0.1825)   Prec@1 91.000 (94.020)   Prec@5 100.000 (99.910)   [2018-05-02 15:20:44]
  Epoch: [077][400/500]   Time 0.061 (0.055)   Data 0.000 (0.000)   Loss 0.2419 (0.1881)   Prec@1 93.000 (93.843)   Prec@5 99.000 (99.893)   [2018-05-02 15:20:55]
  **Train** Prec@1 93.792 Prec@5 99.880 Error@1 6.208
  **Test** Prec@1 90.690 Prec@5 99.630 Error@1 9.310

==>>[2018-05-02 15:21:03] [Epoch=078/540] [Need: 03:56:06] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [078][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.1642 (0.1642)   Prec@1 94.000 (94.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:21:03]
  Epoch: [078][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1610 (0.1750)   Prec@1 95.000 (94.239)   Prec@5 100.000 (99.851)   [2018-05-02 15:21:14]
  Epoch: [078][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1839 (0.1840)   Prec@1 94.000 (93.900)   Prec@5 100.000 (99.850)   [2018-05-02 15:21:25]
  **Train** Prec@1 93.888 Prec@5 99.858 Error@1 6.112
  **Test** Prec@1 89.650 Prec@5 99.640 Error@1 10.350

==>>[2018-05-02 15:21:33] [Epoch=079/540] [Need: 03:55:32] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [079][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.1283 (0.1283)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:21:33]
  Epoch: [079][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1754 (0.1682)   Prec@1 96.000 (94.433)   Prec@5 100.000 (99.881)   [2018-05-02 15:21:44]
  Epoch: [079][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2252 (0.1819)   Prec@1 91.000 (93.925)   Prec@5 100.000 (99.860)   [2018-05-02 15:21:55]
  **Train** Prec@1 93.804 Prec@5 99.846 Error@1 6.196
  **Test** Prec@1 89.080 Prec@5 99.600 Error@1 10.920

==>>[2018-05-02 15:22:03] [Epoch=080/540] [Need: 03:54:58] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [080][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1666 (0.1666)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:22:03]
  Epoch: [080][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0837 (0.1680)   Prec@1 98.000 (94.438)   Prec@5 100.000 (99.920)   [2018-05-02 15:22:14]
  Epoch: [080][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1789 (0.1761)   Prec@1 93.000 (94.202)   Prec@5 99.000 (99.878)   [2018-05-02 15:22:25]
  **Train** Prec@1 93.974 Prec@5 99.870 Error@1 6.026
  **Test** Prec@1 85.490 Prec@5 99.370 Error@1 14.510

==>>[2018-05-02 15:22:33] [Epoch=081/540] [Need: 03:54:25] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [081][000/500]   Time 0.076 (0.076)   Data 0.051 (0.051)   Loss 0.1323 (0.1323)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:22:33]
  Epoch: [081][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0970 (0.1668)   Prec@1 97.000 (94.443)   Prec@5 100.000 (99.886)   [2018-05-02 15:22:44]
  Epoch: [081][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1326 (0.1775)   Prec@1 96.000 (94.092)   Prec@5 100.000 (99.865)   [2018-05-02 15:22:55]
  **Train** Prec@1 93.916 Prec@5 99.864 Error@1 6.084
  **Test** Prec@1 88.200 Prec@5 99.510 Error@1 11.800

==>>[2018-05-02 15:23:03] [Epoch=082/540] [Need: 03:53:51] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [082][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.1735 (0.1735)   Prec@1 92.000 (92.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:23:03]
  Epoch: [082][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1520 (0.1735)   Prec@1 94.000 (94.269)   Prec@5 100.000 (99.866)   [2018-05-02 15:23:14]
  Epoch: [082][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1750 (0.1805)   Prec@1 96.000 (94.007)   Prec@5 100.000 (99.865)   [2018-05-02 15:23:25]
  **Train** Prec@1 93.976 Prec@5 99.870 Error@1 6.024
  **Test** Prec@1 90.450 Prec@5 99.730 Error@1 9.550

==>>[2018-05-02 15:23:33] [Epoch=083/540] [Need: 03:53:18] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [083][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.1636 (0.1636)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:23:34]
  Epoch: [083][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1954 (0.1717)   Prec@1 92.000 (94.239)   Prec@5 100.000 (99.891)   [2018-05-02 15:23:44]
  Epoch: [083][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1856 (0.1767)   Prec@1 92.000 (94.125)   Prec@5 100.000 (99.900)   [2018-05-02 15:23:55]
  **Train** Prec@1 94.128 Prec@5 99.898 Error@1 5.872
  **Test** Prec@1 89.850 Prec@5 99.600 Error@1 10.150

==>>[2018-05-02 15:24:03] [Epoch=084/540] [Need: 03:52:44] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [084][000/500]   Time 0.080 (0.080)   Data 0.055 (0.055)   Loss 0.1699 (0.1699)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:24:04]
  Epoch: [084][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2632 (0.1739)   Prec@1 94.000 (94.139)   Prec@5 100.000 (99.896)   [2018-05-02 15:24:15]
  Epoch: [084][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2487 (0.1785)   Prec@1 90.000 (93.970)   Prec@5 99.000 (99.890)   [2018-05-02 15:24:25]
  **Train** Prec@1 93.832 Prec@5 99.886 Error@1 6.168
  **Test** Prec@1 87.610 Prec@5 99.500 Error@1 12.390

==>>[2018-05-02 15:24:34] [Epoch=085/540] [Need: 03:52:11] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [085][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.1412 (0.1412)   Prec@1 96.000 (96.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:24:34]
  Epoch: [085][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1626 (0.1760)   Prec@1 96.000 (94.174)   Prec@5 100.000 (99.915)   [2018-05-02 15:24:45]
  Epoch: [085][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1544 (0.1800)   Prec@1 95.000 (94.032)   Prec@5 100.000 (99.885)   [2018-05-02 15:24:56]
  **Train** Prec@1 93.888 Prec@5 99.882 Error@1 6.112
  **Test** Prec@1 88.560 Prec@5 99.370 Error@1 11.440

==>>[2018-05-02 15:25:04] [Epoch=086/540] [Need: 03:51:38] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [086][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.2376 (0.2376)   Prec@1 90.000 (90.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:25:04]
  Epoch: [086][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.1667 (0.1661)   Prec@1 94.000 (94.577)   Prec@5 100.000 (99.905)   [2018-05-02 15:25:15]
  Epoch: [086][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2059 (0.1728)   Prec@1 91.000 (94.349)   Prec@5 100.000 (99.918)   [2018-05-02 15:25:26]
  **Train** Prec@1 94.216 Prec@5 99.902 Error@1 5.784
  **Test** Prec@1 90.310 Prec@5 99.720 Error@1 9.690

==>>[2018-05-02 15:25:34] [Epoch=087/540] [Need: 03:51:05] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [087][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.1957 (0.1957)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:25:34]
  Epoch: [087][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1049 (0.1685)   Prec@1 96.000 (94.443)   Prec@5 100.000 (99.811)   [2018-05-02 15:25:45]
  Epoch: [087][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1890 (0.1763)   Prec@1 93.000 (94.115)   Prec@5 100.000 (99.848)   [2018-05-02 15:25:56]
  **Train** Prec@1 93.978 Prec@5 99.862 Error@1 6.022
  **Test** Prec@1 90.130 Prec@5 99.690 Error@1 9.870

==>>[2018-05-02 15:26:04] [Epoch=088/540] [Need: 03:50:31] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [088][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.2437 (0.2437)   Prec@1 91.000 (91.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:26:04]
  Epoch: [088][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2356 (0.1715)   Prec@1 93.000 (94.249)   Prec@5 100.000 (99.881)   [2018-05-02 15:26:15]
  Epoch: [088][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1801 (0.1805)   Prec@1 94.000 (94.132)   Prec@5 100.000 (99.878)   [2018-05-02 15:26:26]
  **Train** Prec@1 94.058 Prec@5 99.876 Error@1 5.942
  **Test** Prec@1 90.180 Prec@5 99.710 Error@1 9.820

==>>[2018-05-02 15:26:34] [Epoch=089/540] [Need: 03:49:59] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [089][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.1895 (0.1895)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:26:34]
  Epoch: [089][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0991 (0.1743)   Prec@1 97.000 (94.154)   Prec@5 100.000 (99.891)   [2018-05-02 15:26:45]
  Epoch: [089][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2899 (0.1759)   Prec@1 89.000 (94.120)   Prec@5 99.000 (99.885)   [2018-05-02 15:26:56]
  **Train** Prec@1 94.012 Prec@5 99.884 Error@1 5.988
  **Test** Prec@1 89.920 Prec@5 99.610 Error@1 10.080

==>>[2018-05-02 15:27:04] [Epoch=090/540] [Need: 03:49:25] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [090][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0959 (0.0959)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:27:04]
  Epoch: [090][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2499 (0.1670)   Prec@1 91.000 (94.333)   Prec@5 98.000 (99.881)   [2018-05-02 15:27:15]
  Epoch: [090][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1593 (0.1772)   Prec@1 94.000 (93.985)   Prec@5 100.000 (99.883)   [2018-05-02 15:27:26]
  **Train** Prec@1 93.930 Prec@5 99.872 Error@1 6.070
  **Test** Prec@1 90.490 Prec@5 99.670 Error@1 9.510

==>>[2018-05-02 15:27:34] [Epoch=091/540] [Need: 03:48:53] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [091][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.1495 (0.1495)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:27:35]
  Epoch: [091][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0980 (0.1650)   Prec@1 95.000 (94.547)   Prec@5 100.000 (99.930)   [2018-05-02 15:27:45]
  Epoch: [091][400/500]   Time 0.053 (0.055)   Data 0.000 (0.000)   Loss 0.2040 (0.1706)   Prec@1 93.000 (94.359)   Prec@5 100.000 (99.903)   [2018-05-02 15:27:56]
  **Train** Prec@1 94.274 Prec@5 99.894 Error@1 5.726
  **Test** Prec@1 90.060 Prec@5 99.600 Error@1 9.940

==>>[2018-05-02 15:28:04] [Epoch=092/540] [Need: 03:48:19] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [092][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1364 (0.1364)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:28:05]
  Epoch: [092][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2213 (0.1750)   Prec@1 91.000 (94.114)   Prec@5 100.000 (99.900)   [2018-05-02 15:28:15]
  Epoch: [092][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2409 (0.1802)   Prec@1 92.000 (93.925)   Prec@5 100.000 (99.898)   [2018-05-02 15:28:26]
  **Train** Prec@1 93.966 Prec@5 99.896 Error@1 6.034
  **Test** Prec@1 90.000 Prec@5 99.650 Error@1 10.000

==>>[2018-05-02 15:28:35] [Epoch=093/540] [Need: 03:47:47] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [093][000/500]   Time 0.076 (0.076)   Data 0.051 (0.051)   Loss 0.1522 (0.1522)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:28:35]
  Epoch: [093][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.2282 (0.1714)   Prec@1 91.000 (94.403)   Prec@5 100.000 (99.900)   [2018-05-02 15:28:46]
  Epoch: [093][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1128 (0.1757)   Prec@1 96.000 (94.207)   Prec@5 100.000 (99.898)   [2018-05-02 15:28:57]
  **Train** Prec@1 94.172 Prec@5 99.896 Error@1 5.828
  **Test** Prec@1 89.460 Prec@5 99.700 Error@1 10.540

==>>[2018-05-02 15:29:05] [Epoch=094/540] [Need: 03:47:14] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [094][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.1607 (0.1607)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:29:05]
  Epoch: [094][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.3157 (0.1646)   Prec@1 91.000 (94.627)   Prec@5 99.000 (99.900)   [2018-05-02 15:29:16]
  Epoch: [094][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1811 (0.1716)   Prec@1 94.000 (94.357)   Prec@5 100.000 (99.893)   [2018-05-02 15:29:27]
  **Train** Prec@1 94.282 Prec@5 99.892 Error@1 5.718
  **Test** Prec@1 86.220 Prec@5 99.040 Error@1 13.780

==>>[2018-05-02 15:29:35] [Epoch=095/540] [Need: 03:46:42] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [095][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.2315 (0.2315)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:29:35]
  Epoch: [095][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1059 (0.1690)   Prec@1 95.000 (94.403)   Prec@5 100.000 (99.960)   [2018-05-02 15:29:46]
  Epoch: [095][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1441 (0.1752)   Prec@1 94.000 (94.219)   Prec@5 100.000 (99.893)   [2018-05-02 15:29:57]
  **Train** Prec@1 94.186 Prec@5 99.894 Error@1 5.814
  **Test** Prec@1 89.390 Prec@5 99.530 Error@1 10.610

==>>[2018-05-02 15:30:05] [Epoch=096/540] [Need: 03:46:09] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [096][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.1046 (0.1046)   Prec@1 96.000 (96.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:30:05]
  Epoch: [096][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1151 (0.1667)   Prec@1 96.000 (94.318)   Prec@5 100.000 (99.930)   [2018-05-02 15:30:16]
  Epoch: [096][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1521 (0.1720)   Prec@1 93.000 (94.180)   Prec@5 100.000 (99.900)   [2018-05-02 15:30:27]
  **Train** Prec@1 94.126 Prec@5 99.902 Error@1 5.874
  **Test** Prec@1 89.560 Prec@5 99.640 Error@1 10.440

==>>[2018-05-02 15:30:35] [Epoch=097/540] [Need: 03:45:37] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [097][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.1763 (0.1763)   Prec@1 92.000 (92.000)   Prec@5 99.000 (99.000)   [2018-05-02 15:30:35]
  Epoch: [097][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1693 (0.1680)   Prec@1 96.000 (94.493)   Prec@5 100.000 (99.886)   [2018-05-02 15:30:46]
  Epoch: [097][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2131 (0.1741)   Prec@1 94.000 (94.322)   Prec@5 100.000 (99.888)   [2018-05-02 15:30:57]
  **Train** Prec@1 94.128 Prec@5 99.880 Error@1 5.872
  **Test** Prec@1 89.090 Prec@5 99.630 Error@1 10.910

==>>[2018-05-02 15:31:05] [Epoch=098/540] [Need: 03:45:04] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [098][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.1821 (0.1821)   Prec@1 93.000 (93.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:31:05]
  Epoch: [098][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.2842 (0.1726)   Prec@1 94.000 (94.164)   Prec@5 100.000 (99.881)   [2018-05-02 15:31:16]
  Epoch: [098][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0874 (0.1745)   Prec@1 97.000 (94.135)   Prec@5 100.000 (99.893)   [2018-05-02 15:31:27]
  **Train** Prec@1 94.008 Prec@5 99.904 Error@1 5.992
  **Test** Prec@1 89.200 Prec@5 99.570 Error@1 10.800

==>>[2018-05-02 15:31:35] [Epoch=099/540] [Need: 03:44:31] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [099][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.1643 (0.1643)   Prec@1 95.000 (95.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:31:35]
  Epoch: [099][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.2141 (0.1577)   Prec@1 92.000 (95.095)   Prec@5 100.000 (99.910)   [2018-05-02 15:31:46]
  Epoch: [099][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.1572 (0.1674)   Prec@1 96.000 (94.471)   Prec@5 100.000 (99.895)   [2018-05-02 15:31:57]
  **Train** Prec@1 94.312 Prec@5 99.888 Error@1 5.688
  **Test** Prec@1 90.400 Prec@5 99.630 Error@1 9.600

==>>[2018-05-02 15:32:05] [Epoch=100/540] [Need: 03:43:59] [learning_rate=0.100000] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [100][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.1538 (0.1538)   Prec@1 94.000 (94.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:32:06]
  Epoch: [100][200/500]   Time 0.059 (0.055)   Data 0.000 (0.000)   Loss 0.0560 (0.1163)   Prec@1 99.000 (96.388)   Prec@5 100.000 (99.950)   [2018-05-02 15:32:17]
  Epoch: [100][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0539 (0.1041)   Prec@1 99.000 (96.718)   Prec@5 100.000 (99.965)   [2018-05-02 15:32:28]
  **Train** Prec@1 96.822 Prec@5 99.966 Error@1 3.178
  **Test** Prec@1 93.900 Prec@5 99.820 Error@1 6.100

==>>[2018-05-02 15:32:36] [Epoch=101/540] [Need: 03:43:29] [learning_rate=0.010000] [Best : Accuracy=93.90, Error=6.10]
  Epoch: [101][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0502 (0.0502)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:32:36]
  Epoch: [101][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0350 (0.0755)   Prec@1 99.000 (97.716)   Prec@5 100.000 (99.950)   [2018-05-02 15:32:47]
  Epoch: [101][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0320 (0.0738)   Prec@1 100.000 (97.758)   Prec@5 100.000 (99.963)   [2018-05-02 15:32:58]
  **Train** Prec@1 97.754 Prec@5 99.970 Error@1 2.246
  **Test** Prec@1 94.290 Prec@5 99.830 Error@1 5.710

==>>[2018-05-02 15:33:06] [Epoch=102/540] [Need: 03:42:57] [learning_rate=0.010000] [Best : Accuracy=94.29, Error=5.71]
  Epoch: [102][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0924 (0.0924)   Prec@1 97.000 (97.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:33:06]
  Epoch: [102][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0615 (0.0671)   Prec@1 98.000 (97.945)   Prec@5 100.000 (99.995)   [2018-05-02 15:33:17]
  Epoch: [102][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.1063 (0.0638)   Prec@1 96.000 (98.065)   Prec@5 100.000 (99.993)   [2018-05-02 15:33:28]
  **Train** Prec@1 98.128 Prec@5 99.992 Error@1 1.872
  **Test** Prec@1 94.150 Prec@5 99.860 Error@1 5.850

==>>[2018-05-02 15:33:37] [Epoch=103/540] [Need: 03:42:25] [learning_rate=0.010000] [Best : Accuracy=94.29, Error=5.71]
  Epoch: [103][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0677 (0.0677)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:33:37]
  Epoch: [103][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0385 (0.0541)   Prec@1 99.000 (98.388)   Prec@5 100.000 (99.985)   [2018-05-02 15:33:48]
  Epoch: [103][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0953 (0.0561)   Prec@1 97.000 (98.307)   Prec@5 100.000 (99.983)   [2018-05-02 15:33:58]
  **Train** Prec@1 98.306 Prec@5 99.984 Error@1 1.694
  **Test** Prec@1 94.130 Prec@5 99.840 Error@1 5.870

==>>[2018-05-02 15:34:07] [Epoch=104/540] [Need: 03:41:52] [learning_rate=0.010000] [Best : Accuracy=94.29, Error=5.71]
  Epoch: [104][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0319 (0.0319)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:34:07]
  Epoch: [104][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0324 (0.0530)   Prec@1 99.000 (98.348)   Prec@5 100.000 (99.985)   [2018-05-02 15:34:18]
  Epoch: [104][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0425 (0.0521)   Prec@1 98.000 (98.414)   Prec@5 100.000 (99.985)   [2018-05-02 15:34:28]
  **Train** Prec@1 98.434 Prec@5 99.986 Error@1 1.566
  **Test** Prec@1 94.390 Prec@5 99.880 Error@1 5.610

==>>[2018-05-02 15:34:37] [Epoch=105/540] [Need: 03:41:20] [learning_rate=0.010000] [Best : Accuracy=94.39, Error=5.61]
  Epoch: [105][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0520 (0.0520)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:34:37]
  Epoch: [105][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0496 (0.0485)   Prec@1 99.000 (98.622)   Prec@5 100.000 (99.965)   [2018-05-02 15:34:48]
  Epoch: [105][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.1053 (0.0464)   Prec@1 97.000 (98.678)   Prec@5 100.000 (99.973)   [2018-05-02 15:34:59]
  **Train** Prec@1 98.668 Prec@5 99.978 Error@1 1.332
  **Test** Prec@1 94.380 Prec@5 99.870 Error@1 5.620

==>>[2018-05-02 15:35:08] [Epoch=106/540] [Need: 03:40:53] [learning_rate=0.010000] [Best : Accuracy=94.39, Error=5.61]
  Epoch: [106][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0427 (0.0427)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:35:08]
  Epoch: [106][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0365 (0.0468)   Prec@1 99.000 (98.557)   Prec@5 100.000 (99.990)   [2018-05-02 15:35:19]
  Epoch: [106][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0453 (0.0452)   Prec@1 99.000 (98.691)   Prec@5 100.000 (99.990)   [2018-05-02 15:35:31]
  **Train** Prec@1 98.726 Prec@5 99.992 Error@1 1.274
  **Test** Prec@1 94.440 Prec@5 99.860 Error@1 5.560

==>>[2018-05-02 15:35:39] [Epoch=107/540] [Need: 03:40:24] [learning_rate=0.010000] [Best : Accuracy=94.44, Error=5.56]
  Epoch: [107][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0412 (0.0412)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:35:39]
  Epoch: [107][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0519 (0.0429)   Prec@1 99.000 (98.766)   Prec@5 100.000 (99.985)   [2018-05-02 15:35:51]
  Epoch: [107][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0253 (0.0423)   Prec@1 100.000 (98.796)   Prec@5 100.000 (99.988)   [2018-05-02 15:36:02]
  **Train** Prec@1 98.758 Prec@5 99.990 Error@1 1.242
  **Test** Prec@1 94.520 Prec@5 99.850 Error@1 5.480

==>>[2018-05-02 15:36:11] [Epoch=108/540] [Need: 03:39:58] [learning_rate=0.010000] [Best : Accuracy=94.52, Error=5.48]
  Epoch: [108][000/500]   Time 0.089 (0.089)   Data 0.061 (0.061)   Loss 0.0881 (0.0881)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:36:11]
  Epoch: [108][200/500]   Time 0.059 (0.060)   Data 0.000 (0.001)   Loss 0.0166 (0.0393)   Prec@1 100.000 (98.866)   Prec@5 100.000 (99.990)   [2018-05-02 15:36:23]
  Epoch: [108][400/500]   Time 0.055 (0.059)   Data 0.000 (0.000)   Loss 0.0406 (0.0395)   Prec@1 99.000 (98.858)   Prec@5 100.000 (99.993)   [2018-05-02 15:36:34]
  **Train** Prec@1 98.868 Prec@5 99.992 Error@1 1.132
  **Test** Prec@1 94.480 Prec@5 99.890 Error@1 5.520

==>>[2018-05-02 15:36:43] [Epoch=109/540] [Need: 03:39:32] [learning_rate=0.010000] [Best : Accuracy=94.52, Error=5.48]
  Epoch: [109][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0223 (0.0223)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:36:43]
  Epoch: [109][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0128 (0.0353)   Prec@1 100.000 (98.985)   Prec@5 100.000 (99.995)   [2018-05-02 15:36:55]
  Epoch: [109][400/500]   Time 0.066 (0.060)   Data 0.000 (0.000)   Loss 0.0257 (0.0335)   Prec@1 99.000 (99.030)   Prec@5 100.000 (99.995)   [2018-05-02 15:37:07]
  **Train** Prec@1 99.018 Prec@5 99.992 Error@1 0.982
  **Test** Prec@1 94.440 Prec@5 99.890 Error@1 5.560

==>>[2018-05-02 15:37:15] [Epoch=110/540] [Need: 03:39:09] [learning_rate=0.010000] [Best : Accuracy=94.52, Error=5.48]
  Epoch: [110][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0406 (0.0406)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:37:15]
  Epoch: [110][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0127 (0.0350)   Prec@1 100.000 (99.030)   Prec@5 100.000 (99.990)   [2018-05-02 15:37:27]
  Epoch: [110][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0307 (0.0346)   Prec@1 99.000 (99.020)   Prec@5 100.000 (99.995)   [2018-05-02 15:37:38]
  **Train** Prec@1 99.014 Prec@5 99.992 Error@1 0.986
  **Test** Prec@1 94.580 Prec@5 99.860 Error@1 5.420

==>>[2018-05-02 15:37:47] [Epoch=111/540] [Need: 03:38:43] [learning_rate=0.010000] [Best : Accuracy=94.58, Error=5.42]
  Epoch: [111][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0157 (0.0157)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:37:47]
  Epoch: [111][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0218 (0.0328)   Prec@1 99.000 (99.070)   Prec@5 100.000 (99.995)   [2018-05-02 15:37:59]
  Epoch: [111][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0175 (0.0319)   Prec@1 100.000 (99.075)   Prec@5 100.000 (99.995)   [2018-05-02 15:38:10]
  **Train** Prec@1 99.054 Prec@5 99.996 Error@1 0.946
  **Test** Prec@1 94.600 Prec@5 99.860 Error@1 5.400

==>>[2018-05-02 15:38:18] [Epoch=112/540] [Need: 03:38:15] [learning_rate=0.010000] [Best : Accuracy=94.60, Error=5.40]
  Epoch: [112][000/500]   Time 0.080 (0.080)   Data 0.055 (0.055)   Loss 0.0247 (0.0247)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:38:18]
  Epoch: [112][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0395 (0.0331)   Prec@1 99.000 (99.025)   Prec@5 100.000 (99.995)   [2018-05-02 15:38:29]
  Epoch: [112][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0519 (0.0330)   Prec@1 98.000 (99.022)   Prec@5 100.000 (99.998)   [2018-05-02 15:38:40]
  **Train** Prec@1 99.036 Prec@5 99.998 Error@1 0.964
  **Test** Prec@1 94.460 Prec@5 99.860 Error@1 5.540

==>>[2018-05-02 15:38:49] [Epoch=113/540] [Need: 03:37:45] [learning_rate=0.010000] [Best : Accuracy=94.60, Error=5.40]
  Epoch: [113][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0158 (0.0158)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:38:49]
  Epoch: [113][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0264 (0.0306)   Prec@1 99.000 (99.119)   Prec@5 100.000 (100.000)   [2018-05-02 15:39:00]
  Epoch: [113][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0130 (0.0307)   Prec@1 100.000 (99.112)   Prec@5 100.000 (100.000)   [2018-05-02 15:39:11]
  **Train** Prec@1 99.130 Prec@5 99.998 Error@1 0.870
  **Test** Prec@1 94.510 Prec@5 99.870 Error@1 5.490

==>>[2018-05-02 15:39:19] [Epoch=114/540] [Need: 03:37:14] [learning_rate=0.010000] [Best : Accuracy=94.60, Error=5.40]
  Epoch: [114][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0116 (0.0116)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:39:19]
  Epoch: [114][200/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0149 (0.0272)   Prec@1 100.000 (99.224)   Prec@5 100.000 (100.000)   [2018-05-02 15:39:31]
  Epoch: [114][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0252 (0.0277)   Prec@1 99.000 (99.219)   Prec@5 100.000 (99.998)   [2018-05-02 15:39:42]
  **Train** Prec@1 99.236 Prec@5 99.998 Error@1 0.764
  **Test** Prec@1 94.580 Prec@5 99.850 Error@1 5.420

==>>[2018-05-02 15:39:50] [Epoch=115/540] [Need: 03:36:43] [learning_rate=0.010000] [Best : Accuracy=94.60, Error=5.40]
  Epoch: [115][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0123 (0.0123)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:39:50]
  Epoch: [115][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0432 (0.0282)   Prec@1 99.000 (99.269)   Prec@5 100.000 (99.995)   [2018-05-02 15:40:01]
  Epoch: [115][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0069 (0.0276)   Prec@1 100.000 (99.269)   Prec@5 100.000 (99.993)   [2018-05-02 15:40:12]
  **Train** Prec@1 99.258 Prec@5 99.994 Error@1 0.742
  **Test** Prec@1 94.780 Prec@5 99.860 Error@1 5.220

==>>[2018-05-02 15:40:20] [Epoch=116/540] [Need: 03:36:11] [learning_rate=0.010000] [Best : Accuracy=94.78, Error=5.22]
  Epoch: [116][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0244 (0.0244)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:40:20]
  Epoch: [116][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0145 (0.0277)   Prec@1 100.000 (99.199)   Prec@5 100.000 (100.000)   [2018-05-02 15:40:31]
  Epoch: [116][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0173 (0.0270)   Prec@1 100.000 (99.249)   Prec@5 100.000 (99.998)   [2018-05-02 15:40:42]
  **Train** Prec@1 99.244 Prec@5 99.998 Error@1 0.756
  **Test** Prec@1 94.560 Prec@5 99.900 Error@1 5.440

==>>[2018-05-02 15:40:50] [Epoch=117/540] [Need: 03:35:38] [learning_rate=0.010000] [Best : Accuracy=94.78, Error=5.22]
  Epoch: [117][000/500]   Time 0.076 (0.076)   Data 0.051 (0.051)   Loss 0.0320 (0.0320)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:40:50]
  Epoch: [117][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0502 (0.0246)   Prec@1 99.000 (99.423)   Prec@5 100.000 (99.995)   [2018-05-02 15:41:01]
  Epoch: [117][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0512 (0.0260)   Prec@1 98.000 (99.324)   Prec@5 100.000 (99.995)   [2018-05-02 15:41:12]
  **Train** Prec@1 99.340 Prec@5 99.994 Error@1 0.660
  **Test** Prec@1 94.650 Prec@5 99.840 Error@1 5.350

==>>[2018-05-02 15:41:20] [Epoch=118/540] [Need: 03:35:06] [learning_rate=0.010000] [Best : Accuracy=94.78, Error=5.22]
  Epoch: [118][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0105 (0.0105)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:41:20]
  Epoch: [118][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0108 (0.0250)   Prec@1 100.000 (99.318)   Prec@5 100.000 (100.000)   [2018-05-02 15:41:31]
  Epoch: [118][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0851 (0.0242)   Prec@1 98.000 (99.352)   Prec@5 100.000 (100.000)   [2018-05-02 15:41:42]
  **Train** Prec@1 99.342 Prec@5 99.998 Error@1 0.658
  **Test** Prec@1 94.700 Prec@5 99.860 Error@1 5.300

==>>[2018-05-02 15:41:50] [Epoch=119/540] [Need: 03:34:33] [learning_rate=0.010000] [Best : Accuracy=94.78, Error=5.22]
  Epoch: [119][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0177 (0.0177)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:41:50]
  Epoch: [119][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0075 (0.0228)   Prec@1 100.000 (99.403)   Prec@5 100.000 (99.995)   [2018-05-02 15:42:01]
  Epoch: [119][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0131 (0.0234)   Prec@1 100.000 (99.389)   Prec@5 100.000 (99.995)   [2018-05-02 15:42:12]
  **Train** Prec@1 99.380 Prec@5 99.996 Error@1 0.620
  **Test** Prec@1 94.560 Prec@5 99.860 Error@1 5.440

==>>[2018-05-02 15:42:20] [Epoch=120/540] [Need: 03:34:01] [learning_rate=0.010000] [Best : Accuracy=94.78, Error=5.22]
  Epoch: [120][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0248 (0.0248)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:42:20]
  Epoch: [120][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0318 (0.0222)   Prec@1 99.000 (99.388)   Prec@5 100.000 (100.000)   [2018-05-02 15:42:31]
  Epoch: [120][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0332 (0.0218)   Prec@1 99.000 (99.416)   Prec@5 100.000 (99.998)   [2018-05-02 15:42:42]
  **Train** Prec@1 99.410 Prec@5 99.996 Error@1 0.590
  **Test** Prec@1 94.710 Prec@5 99.870 Error@1 5.290

==>>[2018-05-02 15:42:50] [Epoch=121/540] [Need: 03:33:28] [learning_rate=0.010000] [Best : Accuracy=94.78, Error=5.22]
  Epoch: [121][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0447 (0.0447)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:42:50]
  Epoch: [121][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0356 (0.0219)   Prec@1 99.000 (99.358)   Prec@5 100.000 (100.000)   [2018-05-02 15:43:01]
  Epoch: [121][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0096 (0.0217)   Prec@1 100.000 (99.426)   Prec@5 100.000 (100.000)   [2018-05-02 15:43:12]
  **Train** Prec@1 99.418 Prec@5 100.000 Error@1 0.582
  **Test** Prec@1 94.580 Prec@5 99.870 Error@1 5.420

==>>[2018-05-02 15:43:20] [Epoch=122/540] [Need: 03:32:56] [learning_rate=0.010000] [Best : Accuracy=94.78, Error=5.22]
  Epoch: [122][000/500]   Time 0.078 (0.078)   Data 0.053 (0.053)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:43:20]
  Epoch: [122][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0055 (0.0217)   Prec@1 100.000 (99.498)   Prec@5 100.000 (100.000)   [2018-05-02 15:43:31]
  Epoch: [122][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0574 (0.0215)   Prec@1 98.000 (99.439)   Prec@5 100.000 (100.000)   [2018-05-02 15:43:42]
  **Train** Prec@1 99.422 Prec@5 100.000 Error@1 0.578
  **Test** Prec@1 94.800 Prec@5 99.860 Error@1 5.200

==>>[2018-05-02 15:43:50] [Epoch=123/540] [Need: 03:32:24] [learning_rate=0.010000] [Best : Accuracy=94.80, Error=5.20]
  Epoch: [123][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0685 (0.0685)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:43:50]
  Epoch: [123][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0178 (0.0208)   Prec@1 99.000 (99.418)   Prec@5 100.000 (100.000)   [2018-05-02 15:44:01]
  Epoch: [123][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0148 (0.0206)   Prec@1 99.000 (99.451)   Prec@5 100.000 (100.000)   [2018-05-02 15:44:12]
  **Train** Prec@1 99.416 Prec@5 100.000 Error@1 0.584
  **Test** Prec@1 94.670 Prec@5 99.880 Error@1 5.330

==>>[2018-05-02 15:44:20] [Epoch=124/540] [Need: 03:31:52] [learning_rate=0.010000] [Best : Accuracy=94.80, Error=5.20]
  Epoch: [124][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0125 (0.0125)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:44:20]
  Epoch: [124][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0264 (0.0207)   Prec@1 99.000 (99.458)   Prec@5 100.000 (99.995)   [2018-05-02 15:44:31]
  Epoch: [124][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0728 (0.0206)   Prec@1 98.000 (99.476)   Prec@5 100.000 (99.998)   [2018-05-02 15:44:43]
  **Train** Prec@1 99.466 Prec@5 99.998 Error@1 0.534
  **Test** Prec@1 94.730 Prec@5 99.850 Error@1 5.270

==>>[2018-05-02 15:44:51] [Epoch=125/540] [Need: 03:31:22] [learning_rate=0.010000] [Best : Accuracy=94.80, Error=5.20]
  Epoch: [125][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0175 (0.0175)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:44:51]
  Epoch: [125][200/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0207)   Prec@1 100.000 (99.552)   Prec@5 100.000 (99.995)   [2018-05-02 15:45:02]
  Epoch: [125][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0153 (0.0203)   Prec@1 100.000 (99.539)   Prec@5 100.000 (99.995)   [2018-05-02 15:45:13]
  **Train** Prec@1 99.514 Prec@5 99.996 Error@1 0.486
  **Test** Prec@1 94.820 Prec@5 99.850 Error@1 5.180

==>>[2018-05-02 15:45:21] [Epoch=126/540] [Need: 03:30:49] [learning_rate=0.010000] [Best : Accuracy=94.82, Error=5.18]
  Epoch: [126][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0221 (0.0221)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:45:21]
  Epoch: [126][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0089 (0.0196)   Prec@1 100.000 (99.493)   Prec@5 100.000 (100.000)   [2018-05-02 15:45:32]
  Epoch: [126][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0151 (0.0201)   Prec@1 100.000 (99.509)   Prec@5 100.000 (100.000)   [2018-05-02 15:45:43]
  **Train** Prec@1 99.496 Prec@5 99.998 Error@1 0.504
  **Test** Prec@1 94.680 Prec@5 99.910 Error@1 5.320

==>>[2018-05-02 15:45:51] [Epoch=127/540] [Need: 03:30:17] [learning_rate=0.010000] [Best : Accuracy=94.82, Error=5.18]
  Epoch: [127][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:45:51]
  Epoch: [127][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0090 (0.0196)   Prec@1 100.000 (99.473)   Prec@5 100.000 (100.000)   [2018-05-02 15:46:02]
  Epoch: [127][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0160 (0.0191)   Prec@1 100.000 (99.511)   Prec@5 100.000 (100.000)   [2018-05-02 15:46:13]
  **Train** Prec@1 99.518 Prec@5 100.000 Error@1 0.482
  **Test** Prec@1 94.720 Prec@5 99.860 Error@1 5.280

==>>[2018-05-02 15:46:21] [Epoch=128/540] [Need: 03:29:45] [learning_rate=0.010000] [Best : Accuracy=94.82, Error=5.18]
  Epoch: [128][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0285 (0.0285)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:46:21]
  Epoch: [128][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0390 (0.0189)   Prec@1 99.000 (99.522)   Prec@5 100.000 (99.995)   [2018-05-02 15:46:32]
  Epoch: [128][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0062 (0.0190)   Prec@1 100.000 (99.514)   Prec@5 100.000 (99.998)   [2018-05-02 15:46:43]
  **Train** Prec@1 99.508 Prec@5 99.998 Error@1 0.492
  **Test** Prec@1 94.760 Prec@5 99.880 Error@1 5.240

==>>[2018-05-02 15:46:51] [Epoch=129/540] [Need: 03:29:13] [learning_rate=0.010000] [Best : Accuracy=94.82, Error=5.18]
  Epoch: [129][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0213 (0.0213)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:46:51]
  Epoch: [129][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0240 (0.0173)   Prec@1 99.000 (99.547)   Prec@5 100.000 (99.995)   [2018-05-02 15:47:02]
  Epoch: [129][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0322 (0.0175)   Prec@1 99.000 (99.546)   Prec@5 100.000 (99.998)   [2018-05-02 15:47:13]
  **Train** Prec@1 99.518 Prec@5 99.998 Error@1 0.482
  **Test** Prec@1 94.620 Prec@5 99.870 Error@1 5.380

==>>[2018-05-02 15:47:21] [Epoch=130/540] [Need: 03:28:41] [learning_rate=0.010000] [Best : Accuracy=94.82, Error=5.18]
  Epoch: [130][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.0115 (0.0115)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:47:21]
  Epoch: [130][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0208 (0.0190)   Prec@1 99.000 (99.537)   Prec@5 100.000 (100.000)   [2018-05-02 15:47:32]
  Epoch: [130][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0122 (0.0184)   Prec@1 100.000 (99.539)   Prec@5 100.000 (100.000)   [2018-05-02 15:47:43]
  **Train** Prec@1 99.540 Prec@5 100.000 Error@1 0.460
  **Test** Prec@1 94.720 Prec@5 99.870 Error@1 5.280

==>>[2018-05-02 15:47:51] [Epoch=131/540] [Need: 03:28:09] [learning_rate=0.010000] [Best : Accuracy=94.82, Error=5.18]
  Epoch: [131][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:47:51]
  Epoch: [131][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0149 (0.0178)   Prec@1 100.000 (99.512)   Prec@5 100.000 (100.000)   [2018-05-02 15:48:02]
  Epoch: [131][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0081 (0.0181)   Prec@1 100.000 (99.524)   Prec@5 100.000 (100.000)   [2018-05-02 15:48:13]
  **Train** Prec@1 99.550 Prec@5 100.000 Error@1 0.450
  **Test** Prec@1 94.850 Prec@5 99.850 Error@1 5.150

==>>[2018-05-02 15:48:21] [Epoch=132/540] [Need: 03:27:37] [learning_rate=0.010000] [Best : Accuracy=94.85, Error=5.15]
  Epoch: [132][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:48:22]
  Epoch: [132][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0111 (0.0160)   Prec@1 100.000 (99.602)   Prec@5 100.000 (100.000)   [2018-05-02 15:48:32]
  Epoch: [132][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0111 (0.0158)   Prec@1 100.000 (99.626)   Prec@5 100.000 (100.000)   [2018-05-02 15:48:43]
  **Train** Prec@1 99.592 Prec@5 100.000 Error@1 0.408
  **Test** Prec@1 94.670 Prec@5 99.850 Error@1 5.330

==>>[2018-05-02 15:48:52] [Epoch=133/540] [Need: 03:27:05] [learning_rate=0.010000] [Best : Accuracy=94.85, Error=5.15]
  Epoch: [133][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0173 (0.0173)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:48:52]
  Epoch: [133][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0082 (0.0156)   Prec@1 100.000 (99.652)   Prec@5 100.000 (99.995)   [2018-05-02 15:49:03]
  Epoch: [133][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0099 (0.0159)   Prec@1 100.000 (99.646)   Prec@5 100.000 (99.998)   [2018-05-02 15:49:14]
  **Train** Prec@1 99.634 Prec@5 99.998 Error@1 0.366
  **Test** Prec@1 94.790 Prec@5 99.880 Error@1 5.210

==>>[2018-05-02 15:49:22] [Epoch=134/540] [Need: 03:26:33] [learning_rate=0.010000] [Best : Accuracy=94.85, Error=5.15]
  Epoch: [134][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:49:22]
  Epoch: [134][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0168 (0.0170)   Prec@1 99.000 (99.552)   Prec@5 100.000 (100.000)   [2018-05-02 15:49:33]
  Epoch: [134][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0086 (0.0177)   Prec@1 100.000 (99.534)   Prec@5 100.000 (99.995)   [2018-05-02 15:49:44]
  **Train** Prec@1 99.538 Prec@5 99.996 Error@1 0.462
  **Test** Prec@1 94.670 Prec@5 99.840 Error@1 5.330

==>>[2018-05-02 15:49:52] [Epoch=135/540] [Need: 03:26:01] [learning_rate=0.010000] [Best : Accuracy=94.85, Error=5.15]
  Epoch: [135][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:49:52]
  Epoch: [135][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0168)   Prec@1 100.000 (99.612)   Prec@5 100.000 (100.000)   [2018-05-02 15:50:03]
  Epoch: [135][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0060 (0.0172)   Prec@1 100.000 (99.589)   Prec@5 100.000 (100.000)   [2018-05-02 15:50:14]
  **Train** Prec@1 99.596 Prec@5 100.000 Error@1 0.404
  **Test** Prec@1 94.920 Prec@5 99.860 Error@1 5.080

==>>[2018-05-02 15:50:22] [Epoch=136/540] [Need: 03:25:29] [learning_rate=0.010000] [Best : Accuracy=94.92, Error=5.08]
  Epoch: [136][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0092 (0.0092)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:50:22]
  Epoch: [136][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0212 (0.0151)   Prec@1 99.000 (99.642)   Prec@5 100.000 (100.000)   [2018-05-02 15:50:33]
  Epoch: [136][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0056 (0.0159)   Prec@1 100.000 (99.636)   Prec@5 100.000 (100.000)   [2018-05-02 15:50:44]
  **Train** Prec@1 99.624 Prec@5 100.000 Error@1 0.376
  **Test** Prec@1 95.010 Prec@5 99.890 Error@1 4.990

==>>[2018-05-02 15:50:52] [Epoch=137/540] [Need: 03:24:57] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [137][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0148 (0.0148)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:50:52]
  Epoch: [137][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0070 (0.0156)   Prec@1 100.000 (99.577)   Prec@5 100.000 (100.000)   [2018-05-02 15:51:03]
  Epoch: [137][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0156)   Prec@1 100.000 (99.579)   Prec@5 100.000 (100.000)   [2018-05-02 15:51:14]
  **Train** Prec@1 99.568 Prec@5 100.000 Error@1 0.432
  **Test** Prec@1 94.960 Prec@5 99.880 Error@1 5.040

==>>[2018-05-02 15:51:22] [Epoch=138/540] [Need: 03:24:26] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [138][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0144 (0.0144)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:51:22]
  Epoch: [138][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0084 (0.0154)   Prec@1 100.000 (99.677)   Prec@5 100.000 (100.000)   [2018-05-02 15:51:33]
  Epoch: [138][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0180 (0.0159)   Prec@1 99.000 (99.626)   Prec@5 100.000 (100.000)   [2018-05-02 15:51:44]
  **Train** Prec@1 99.614 Prec@5 100.000 Error@1 0.386
  **Test** Prec@1 94.730 Prec@5 99.850 Error@1 5.270

==>>[2018-05-02 15:51:52] [Epoch=139/540] [Need: 03:23:54] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [139][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0161 (0.0161)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:51:52]
  Epoch: [139][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0152 (0.0148)   Prec@1 99.000 (99.637)   Prec@5 100.000 (100.000)   [2018-05-02 15:52:03]
  Epoch: [139][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0238 (0.0146)   Prec@1 99.000 (99.668)   Prec@5 100.000 (100.000)   [2018-05-02 15:52:14]
  **Train** Prec@1 99.646 Prec@5 100.000 Error@1 0.354
  **Test** Prec@1 94.820 Prec@5 99.870 Error@1 5.180

==>>[2018-05-02 15:52:22] [Epoch=140/540] [Need: 03:23:22] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [140][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0310 (0.0310)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:52:22]
  Epoch: [140][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0161)   Prec@1 100.000 (99.577)   Prec@5 100.000 (100.000)   [2018-05-02 15:52:33]
  Epoch: [140][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0151)   Prec@1 100.000 (99.631)   Prec@5 100.000 (100.000)   [2018-05-02 15:52:44]
  **Train** Prec@1 99.610 Prec@5 100.000 Error@1 0.390
  **Test** Prec@1 94.850 Prec@5 99.850 Error@1 5.150

==>>[2018-05-02 15:52:52] [Epoch=141/540] [Need: 03:22:50] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [141][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:52:52]
  Epoch: [141][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0096 (0.0146)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-02 15:53:03]
  Epoch: [141][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0090 (0.0153)   Prec@1 100.000 (99.638)   Prec@5 100.000 (100.000)   [2018-05-02 15:53:14]
  **Train** Prec@1 99.634 Prec@5 100.000 Error@1 0.366
  **Test** Prec@1 94.770 Prec@5 99.820 Error@1 5.230

==>>[2018-05-02 15:53:22] [Epoch=142/540] [Need: 03:22:19] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [142][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0778 (0.0778)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:53:22]
  Epoch: [142][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0089 (0.0139)   Prec@1 100.000 (99.662)   Prec@5 100.000 (100.000)   [2018-05-02 15:53:33]
  Epoch: [142][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0059 (0.0145)   Prec@1 100.000 (99.646)   Prec@5 100.000 (100.000)   [2018-05-02 15:53:44]
  **Train** Prec@1 99.636 Prec@5 100.000 Error@1 0.364
  **Test** Prec@1 94.830 Prec@5 99.850 Error@1 5.170

==>>[2018-05-02 15:53:52] [Epoch=143/540] [Need: 03:21:47] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [143][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:53:52]
  Epoch: [143][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0140)   Prec@1 100.000 (99.667)   Prec@5 100.000 (100.000)   [2018-05-02 15:54:03]
  Epoch: [143][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0149 (0.0152)   Prec@1 99.000 (99.636)   Prec@5 100.000 (100.000)   [2018-05-02 15:54:14]
  **Train** Prec@1 99.642 Prec@5 100.000 Error@1 0.358
  **Test** Prec@1 94.670 Prec@5 99.810 Error@1 5.330

==>>[2018-05-02 15:54:22] [Epoch=144/540] [Need: 03:21:15] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [144][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:54:22]
  Epoch: [144][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0141)   Prec@1 100.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-02 15:54:33]
  Epoch: [144][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0294 (0.0140)   Prec@1 99.000 (99.701)   Prec@5 100.000 (100.000)   [2018-05-02 15:54:44]
  **Train** Prec@1 99.694 Prec@5 100.000 Error@1 0.306
  **Test** Prec@1 94.670 Prec@5 99.870 Error@1 5.330

==>>[2018-05-02 15:54:52] [Epoch=145/540] [Need: 03:20:43] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [145][000/500]   Time 0.078 (0.078)   Data 0.053 (0.053)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:54:52]
  Epoch: [145][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0143)   Prec@1 100.000 (99.667)   Prec@5 100.000 (100.000)   [2018-05-02 15:55:03]
  Epoch: [145][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0070 (0.0144)   Prec@1 100.000 (99.688)   Prec@5 100.000 (100.000)   [2018-05-02 15:55:14]
  **Train** Prec@1 99.666 Prec@5 100.000 Error@1 0.334
  **Test** Prec@1 94.720 Prec@5 99.860 Error@1 5.280

==>>[2018-05-02 15:55:22] [Epoch=146/540] [Need: 03:20:12] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [146][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0497 (0.0497)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:55:22]
  Epoch: [146][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0247 (0.0151)   Prec@1 99.000 (99.607)   Prec@5 100.000 (100.000)   [2018-05-02 15:55:33]
  Epoch: [146][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0076 (0.0160)   Prec@1 100.000 (99.581)   Prec@5 100.000 (100.000)   [2018-05-02 15:55:45]
  **Train** Prec@1 99.588 Prec@5 100.000 Error@1 0.412
  **Test** Prec@1 94.720 Prec@5 99.820 Error@1 5.280

==>>[2018-05-02 15:55:53] [Epoch=147/540] [Need: 03:19:41] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [147][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0252 (0.0252)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:55:53]
  Epoch: [147][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0094 (0.0154)   Prec@1 100.000 (99.627)   Prec@5 100.000 (100.000)   [2018-05-02 15:56:04]
  Epoch: [147][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0290 (0.0151)   Prec@1 99.000 (99.651)   Prec@5 100.000 (100.000)   [2018-05-02 15:56:15]
  **Train** Prec@1 99.664 Prec@5 100.000 Error@1 0.336
  **Test** Prec@1 94.700 Prec@5 99.850 Error@1 5.300

==>>[2018-05-02 15:56:24] [Epoch=148/540] [Need: 03:19:12] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [148][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0122 (0.0122)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:56:24]
  Epoch: [148][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0259 (0.0134)   Prec@1 99.000 (99.657)   Prec@5 100.000 (100.000)   [2018-05-02 15:56:35]
  Epoch: [148][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0132 (0.0135)   Prec@1 99.000 (99.676)   Prec@5 100.000 (100.000)   [2018-05-02 15:56:47]
  **Train** Prec@1 99.670 Prec@5 100.000 Error@1 0.330
  **Test** Prec@1 94.750 Prec@5 99.830 Error@1 5.250

==>>[2018-05-02 15:56:55] [Epoch=149/540] [Need: 03:18:44] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [149][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0101 (0.0101)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:56:55]
  Epoch: [149][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0110 (0.0140)   Prec@1 100.000 (99.657)   Prec@5 100.000 (100.000)   [2018-05-02 15:57:07]
  Epoch: [149][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0054 (0.0150)   Prec@1 100.000 (99.606)   Prec@5 100.000 (100.000)   [2018-05-02 15:57:18]
  **Train** Prec@1 99.606 Prec@5 100.000 Error@1 0.394
  **Test** Prec@1 94.660 Prec@5 99.830 Error@1 5.340

==>>[2018-05-02 15:57:26] [Epoch=150/540] [Need: 03:18:14] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [150][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:57:26]
  Epoch: [150][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0117 (0.0127)   Prec@1 100.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-02 15:57:37]
  Epoch: [150][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0191 (0.0138)   Prec@1 100.000 (99.673)   Prec@5 100.000 (100.000)   [2018-05-02 15:57:48]
  **Train** Prec@1 99.666 Prec@5 100.000 Error@1 0.334
  **Test** Prec@1 94.690 Prec@5 99.830 Error@1 5.310

==>>[2018-05-02 15:57:56] [Epoch=151/540] [Need: 03:17:43] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [151][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0244 (0.0244)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:57:56]
  Epoch: [151][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0325 (0.0143)   Prec@1 99.000 (99.657)   Prec@5 100.000 (100.000)   [2018-05-02 15:58:07]
  Epoch: [151][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0059 (0.0144)   Prec@1 100.000 (99.636)   Prec@5 100.000 (100.000)   [2018-05-02 15:58:18]
  **Train** Prec@1 99.658 Prec@5 100.000 Error@1 0.342
  **Test** Prec@1 94.850 Prec@5 99.850 Error@1 5.150

==>>[2018-05-02 15:58:26] [Epoch=152/540] [Need: 03:17:11] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [152][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0249 (0.0249)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:58:26]
  Epoch: [152][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0081 (0.0153)   Prec@1 100.000 (99.627)   Prec@5 100.000 (99.995)   [2018-05-02 15:58:37]
  Epoch: [152][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0066 (0.0156)   Prec@1 100.000 (99.608)   Prec@5 100.000 (99.995)   [2018-05-02 15:58:48]
  **Train** Prec@1 99.616 Prec@5 99.996 Error@1 0.384
  **Test** Prec@1 94.670 Prec@5 99.880 Error@1 5.330

==>>[2018-05-02 15:58:56] [Epoch=153/540] [Need: 03:16:40] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [153][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:58:57]
  Epoch: [153][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0148)   Prec@1 100.000 (99.652)   Prec@5 100.000 (100.000)   [2018-05-02 15:59:07]
  Epoch: [153][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0077 (0.0144)   Prec@1 100.000 (99.666)   Prec@5 100.000 (100.000)   [2018-05-02 15:59:18]
  **Train** Prec@1 99.670 Prec@5 100.000 Error@1 0.330
  **Test** Prec@1 94.660 Prec@5 99.850 Error@1 5.340

==>>[2018-05-02 15:59:26] [Epoch=154/540] [Need: 03:16:08] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [154][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0177 (0.0177)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:59:27]
  Epoch: [154][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0135)   Prec@1 100.000 (99.706)   Prec@5 100.000 (100.000)   [2018-05-02 15:59:37]
  Epoch: [154][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0099 (0.0128)   Prec@1 100.000 (99.726)   Prec@5 100.000 (100.000)   [2018-05-02 15:59:48]
  **Train** Prec@1 99.712 Prec@5 100.000 Error@1 0.288
  **Test** Prec@1 94.650 Prec@5 99.850 Error@1 5.350

==>>[2018-05-02 15:59:56] [Epoch=155/540] [Need: 03:15:37] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [155][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0097 (0.0097)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 15:59:57]
  Epoch: [155][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0103 (0.0149)   Prec@1 100.000 (99.632)   Prec@5 100.000 (100.000)   [2018-05-02 16:00:08]
  Epoch: [155][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0337 (0.0129)   Prec@1 99.000 (99.703)   Prec@5 100.000 (100.000)   [2018-05-02 16:00:18]
  **Train** Prec@1 99.710 Prec@5 100.000 Error@1 0.290
  **Test** Prec@1 94.830 Prec@5 99.840 Error@1 5.170

==>>[2018-05-02 16:00:27] [Epoch=156/540] [Need: 03:15:05] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [156][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0050 (0.0050)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:00:27]
  Epoch: [156][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0047 (0.0120)   Prec@1 100.000 (99.736)   Prec@5 100.000 (100.000)   [2018-05-02 16:00:38]
  Epoch: [156][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0068 (0.0119)   Prec@1 100.000 (99.746)   Prec@5 100.000 (100.000)   [2018-05-02 16:00:49]
  **Train** Prec@1 99.722 Prec@5 100.000 Error@1 0.278
  **Test** Prec@1 94.740 Prec@5 99.840 Error@1 5.260

==>>[2018-05-02 16:00:57] [Epoch=157/540] [Need: 03:14:34] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [157][000/500]   Time 0.077 (0.077)   Data 0.050 (0.050)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:00:57]
  Epoch: [157][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0069 (0.0133)   Prec@1 100.000 (99.677)   Prec@5 100.000 (100.000)   [2018-05-02 16:01:08]
  Epoch: [157][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0646 (0.0138)   Prec@1 98.000 (99.691)   Prec@5 100.000 (99.998)   [2018-05-02 16:01:19]
  **Train** Prec@1 99.684 Prec@5 99.998 Error@1 0.316
  **Test** Prec@1 94.520 Prec@5 99.880 Error@1 5.480

==>>[2018-05-02 16:01:27] [Epoch=158/540] [Need: 03:14:02] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [158][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0134 (0.0134)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:01:27]
  Epoch: [158][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0079 (0.0133)   Prec@1 100.000 (99.701)   Prec@5 100.000 (100.000)   [2018-05-02 16:01:38]
  Epoch: [158][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0266 (0.0134)   Prec@1 99.000 (99.681)   Prec@5 100.000 (100.000)   [2018-05-02 16:01:49]
  **Train** Prec@1 99.684 Prec@5 100.000 Error@1 0.316
  **Test** Prec@1 94.590 Prec@5 99.830 Error@1 5.410

==>>[2018-05-02 16:01:57] [Epoch=159/540] [Need: 03:13:31] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [159][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:01:57]
  Epoch: [159][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0113 (0.0106)   Prec@1 100.000 (99.826)   Prec@5 100.000 (100.000)   [2018-05-02 16:02:08]
  Epoch: [159][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0047 (0.0115)   Prec@1 100.000 (99.771)   Prec@5 100.000 (100.000)   [2018-05-02 16:02:19]
  **Train** Prec@1 99.758 Prec@5 100.000 Error@1 0.242
  **Test** Prec@1 94.760 Prec@5 99.790 Error@1 5.240

==>>[2018-05-02 16:02:27] [Epoch=160/540] [Need: 03:12:59] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [160][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:02:27]
  Epoch: [160][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0134)   Prec@1 100.000 (99.682)   Prec@5 100.000 (100.000)   [2018-05-02 16:02:38]
  Epoch: [160][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0274 (0.0133)   Prec@1 98.000 (99.698)   Prec@5 100.000 (100.000)   [2018-05-02 16:02:49]
  **Train** Prec@1 99.696 Prec@5 100.000 Error@1 0.304
  **Test** Prec@1 94.800 Prec@5 99.810 Error@1 5.200

==>>[2018-05-02 16:02:57] [Epoch=161/540] [Need: 03:12:29] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [161][000/500]   Time 0.078 (0.078)   Data 0.053 (0.053)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:02:58]
  Epoch: [161][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0070 (0.0130)   Prec@1 100.000 (99.692)   Prec@5 100.000 (99.995)   [2018-05-02 16:03:08]
  Epoch: [161][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0064 (0.0121)   Prec@1 100.000 (99.726)   Prec@5 100.000 (99.998)   [2018-05-02 16:03:19]
  **Train** Prec@1 99.726 Prec@5 99.998 Error@1 0.274
  **Test** Prec@1 94.840 Prec@5 99.810 Error@1 5.160

==>>[2018-05-02 16:03:27] [Epoch=162/540] [Need: 03:11:58] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [162][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:03:28]
  Epoch: [162][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0471 (0.0120)   Prec@1 99.000 (99.766)   Prec@5 100.000 (100.000)   [2018-05-02 16:03:38]
  Epoch: [162][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0127)   Prec@1 100.000 (99.733)   Prec@5 100.000 (100.000)   [2018-05-02 16:03:49]
  **Train** Prec@1 99.726 Prec@5 100.000 Error@1 0.274
  **Test** Prec@1 94.690 Prec@5 99.810 Error@1 5.310

==>>[2018-05-02 16:03:57] [Epoch=163/540] [Need: 03:11:26] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [163][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0369 (0.0369)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:03:58]
  Epoch: [163][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0122)   Prec@1 100.000 (99.736)   Prec@5 100.000 (100.000)   [2018-05-02 16:04:09]
  Epoch: [163][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0125)   Prec@1 100.000 (99.736)   Prec@5 100.000 (100.000)   [2018-05-02 16:04:19]
  **Train** Prec@1 99.708 Prec@5 100.000 Error@1 0.292
  **Test** Prec@1 94.910 Prec@5 99.860 Error@1 5.090

==>>[2018-05-02 16:04:28] [Epoch=164/540] [Need: 03:10:55] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [164][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:04:28]
  Epoch: [164][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0084 (0.0130)   Prec@1 100.000 (99.687)   Prec@5 100.000 (99.995)   [2018-05-02 16:04:39]
  Epoch: [164][400/500]   Time 0.058 (0.055)   Data 0.000 (0.000)   Loss 0.0081 (0.0131)   Prec@1 100.000 (99.706)   Prec@5 100.000 (99.995)   [2018-05-02 16:04:50]
  **Train** Prec@1 99.704 Prec@5 99.994 Error@1 0.296
  **Test** Prec@1 94.630 Prec@5 99.830 Error@1 5.370

==>>[2018-05-02 16:04:58] [Epoch=165/540] [Need: 03:10:25] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [165][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0383 (0.0383)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:04:58]
  Epoch: [165][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0050 (0.0131)   Prec@1 100.000 (99.677)   Prec@5 100.000 (99.995)   [2018-05-02 16:05:10]
  Epoch: [165][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0063 (0.0133)   Prec@1 100.000 (99.693)   Prec@5 100.000 (99.998)   [2018-05-02 16:05:21]
  **Train** Prec@1 99.702 Prec@5 99.998 Error@1 0.298
  **Test** Prec@1 94.420 Prec@5 99.810 Error@1 5.580

==>>[2018-05-02 16:05:29] [Epoch=166/540] [Need: 03:09:55] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [166][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:05:29]
  Epoch: [166][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0110)   Prec@1 100.000 (99.781)   Prec@5 100.000 (100.000)   [2018-05-02 16:05:40]
  Epoch: [166][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0079 (0.0126)   Prec@1 100.000 (99.716)   Prec@5 100.000 (100.000)   [2018-05-02 16:05:51]
  **Train** Prec@1 99.722 Prec@5 100.000 Error@1 0.278
  **Test** Prec@1 94.730 Prec@5 99.810 Error@1 5.270

==>>[2018-05-02 16:06:00] [Epoch=167/540] [Need: 03:09:25] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [167][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:06:00]
  Epoch: [167][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0059 (0.0124)   Prec@1 100.000 (99.721)   Prec@5 100.000 (100.000)   [2018-05-02 16:06:11]
  Epoch: [167][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0454 (0.0125)   Prec@1 99.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-02 16:06:22]
  **Train** Prec@1 99.708 Prec@5 100.000 Error@1 0.292
  **Test** Prec@1 94.750 Prec@5 99.860 Error@1 5.250

==>>[2018-05-02 16:06:31] [Epoch=168/540] [Need: 03:08:55] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [168][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:06:31]
  Epoch: [168][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0265 (0.0120)   Prec@1 98.000 (99.721)   Prec@5 100.000 (100.000)   [2018-05-02 16:06:42]
  Epoch: [168][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0584 (0.0130)   Prec@1 99.000 (99.696)   Prec@5 100.000 (100.000)   [2018-05-02 16:06:53]
  **Train** Prec@1 99.672 Prec@5 100.000 Error@1 0.328
  **Test** Prec@1 94.520 Prec@5 99.820 Error@1 5.480

==>>[2018-05-02 16:07:01] [Epoch=169/540] [Need: 03:08:26] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [169][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:07:02]
  Epoch: [169][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0161 (0.0127)   Prec@1 99.000 (99.711)   Prec@5 100.000 (100.000)   [2018-05-02 16:07:13]
  Epoch: [169][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0043 (0.0133)   Prec@1 100.000 (99.668)   Prec@5 100.000 (100.000)   [2018-05-02 16:07:24]
  **Train** Prec@1 99.672 Prec@5 100.000 Error@1 0.328
  **Test** Prec@1 94.690 Prec@5 99.860 Error@1 5.310

==>>[2018-05-02 16:07:32] [Epoch=170/540] [Need: 03:07:56] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [170][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0141 (0.0141)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:07:32]
  Epoch: [170][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0202 (0.0141)   Prec@1 99.000 (99.692)   Prec@5 100.000 (100.000)   [2018-05-02 16:07:44]
  Epoch: [170][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0193 (0.0144)   Prec@1 99.000 (99.661)   Prec@5 100.000 (100.000)   [2018-05-02 16:07:55]
  **Train** Prec@1 99.668 Prec@5 100.000 Error@1 0.332
  **Test** Prec@1 94.700 Prec@5 99.850 Error@1 5.300

==>>[2018-05-02 16:08:03] [Epoch=171/540] [Need: 03:07:26] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [171][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:08:03]
  Epoch: [171][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0067 (0.0113)   Prec@1 100.000 (99.751)   Prec@5 100.000 (100.000)   [2018-05-02 16:08:15]
  Epoch: [171][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0050 (0.0117)   Prec@1 100.000 (99.746)   Prec@5 100.000 (100.000)   [2018-05-02 16:08:26]
  **Train** Prec@1 99.742 Prec@5 100.000 Error@1 0.258
  **Test** Prec@1 94.640 Prec@5 99.890 Error@1 5.360

==>>[2018-05-02 16:08:34] [Epoch=172/540] [Need: 03:06:57] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [172][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0142 (0.0142)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:08:34]
  Epoch: [172][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0038 (0.0136)   Prec@1 100.000 (99.637)   Prec@5 100.000 (100.000)   [2018-05-02 16:08:46]
  Epoch: [172][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0146 (0.0127)   Prec@1 99.000 (99.683)   Prec@5 100.000 (100.000)   [2018-05-02 16:08:57]
  **Train** Prec@1 99.678 Prec@5 100.000 Error@1 0.322
  **Test** Prec@1 94.730 Prec@5 99.780 Error@1 5.270

==>>[2018-05-02 16:09:05] [Epoch=173/540] [Need: 03:06:28] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [173][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:09:05]
  Epoch: [173][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0078 (0.0123)   Prec@1 100.000 (99.721)   Prec@5 100.000 (100.000)   [2018-05-02 16:09:16]
  Epoch: [173][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0625 (0.0123)   Prec@1 99.000 (99.743)   Prec@5 100.000 (100.000)   [2018-05-02 16:09:28]
  **Train** Prec@1 99.734 Prec@5 100.000 Error@1 0.266
  **Test** Prec@1 94.650 Prec@5 99.790 Error@1 5.350

==>>[2018-05-02 16:09:36] [Epoch=174/540] [Need: 03:05:58] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [174][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0145 (0.0145)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:09:36]
  Epoch: [174][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0074 (0.0121)   Prec@1 100.000 (99.766)   Prec@5 100.000 (100.000)   [2018-05-02 16:09:47]
  Epoch: [174][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0107 (0.0129)   Prec@1 100.000 (99.726)   Prec@5 100.000 (100.000)   [2018-05-02 16:09:58]
  **Train** Prec@1 99.712 Prec@5 100.000 Error@1 0.288
  **Test** Prec@1 94.810 Prec@5 99.840 Error@1 5.190

==>>[2018-05-02 16:10:07] [Epoch=175/540] [Need: 03:05:28] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [175][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0129 (0.0129)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:10:07]
  Epoch: [175][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0274 (0.0127)   Prec@1 99.000 (99.721)   Prec@5 100.000 (100.000)   [2018-05-02 16:10:18]
  Epoch: [175][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0049 (0.0121)   Prec@1 100.000 (99.741)   Prec@5 100.000 (100.000)   [2018-05-02 16:10:29]
  **Train** Prec@1 99.752 Prec@5 100.000 Error@1 0.248
  **Test** Prec@1 94.640 Prec@5 99.810 Error@1 5.360

==>>[2018-05-02 16:10:37] [Epoch=176/540] [Need: 03:04:58] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [176][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:10:37]
  Epoch: [176][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0066 (0.0129)   Prec@1 100.000 (99.697)   Prec@5 100.000 (100.000)   [2018-05-02 16:10:49]
  Epoch: [176][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0075 (0.0124)   Prec@1 100.000 (99.738)   Prec@5 100.000 (100.000)   [2018-05-02 16:11:00]
  **Train** Prec@1 99.732 Prec@5 100.000 Error@1 0.268
  **Test** Prec@1 94.600 Prec@5 99.820 Error@1 5.400

==>>[2018-05-02 16:11:08] [Epoch=177/540] [Need: 03:04:28] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [177][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0096 (0.0096)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:11:08]
  Epoch: [177][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0124)   Prec@1 100.000 (99.726)   Prec@5 100.000 (100.000)   [2018-05-02 16:11:20]
  Epoch: [177][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0373 (0.0126)   Prec@1 99.000 (99.718)   Prec@5 100.000 (100.000)   [2018-05-02 16:11:31]
  **Train** Prec@1 99.724 Prec@5 100.000 Error@1 0.276
  **Test** Prec@1 94.480 Prec@5 99.800 Error@1 5.520

==>>[2018-05-02 16:11:39] [Epoch=178/540] [Need: 03:03:58] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [178][000/500]   Time 0.082 (0.082)   Data 0.053 (0.053)   Loss 0.0127 (0.0127)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:11:39]
  Epoch: [178][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0043 (0.0130)   Prec@1 100.000 (99.652)   Prec@5 100.000 (100.000)   [2018-05-02 16:11:50]
  Epoch: [178][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0066 (0.0123)   Prec@1 100.000 (99.726)   Prec@5 100.000 (100.000)   [2018-05-02 16:12:02]
  **Train** Prec@1 99.718 Prec@5 100.000 Error@1 0.282
  **Test** Prec@1 94.520 Prec@5 99.810 Error@1 5.480

==>>[2018-05-02 16:12:10] [Epoch=179/540] [Need: 03:03:29] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [179][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0310 (0.0310)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:12:10]
  Epoch: [179][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0044 (0.0143)   Prec@1 100.000 (99.657)   Prec@5 100.000 (100.000)   [2018-05-02 16:12:21]
  Epoch: [179][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0142 (0.0145)   Prec@1 99.000 (99.661)   Prec@5 100.000 (100.000)   [2018-05-02 16:12:33]
  **Train** Prec@1 99.650 Prec@5 100.000 Error@1 0.350
  **Test** Prec@1 94.470 Prec@5 99.840 Error@1 5.530

==>>[2018-05-02 16:12:42] [Epoch=180/540] [Need: 03:03:00] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [180][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:12:42]
  Epoch: [180][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0460 (0.0130)   Prec@1 98.000 (99.687)   Prec@5 100.000 (99.995)   [2018-05-02 16:12:53]
  Epoch: [180][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0472 (0.0143)   Prec@1 99.000 (99.658)   Prec@5 100.000 (99.998)   [2018-05-02 16:13:05]
  **Train** Prec@1 99.666 Prec@5 99.998 Error@1 0.334
  **Test** Prec@1 94.670 Prec@5 99.820 Error@1 5.330

==>>[2018-05-02 16:13:14] [Epoch=181/540] [Need: 03:02:33] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [181][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0092 (0.0092)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:13:14]
  Epoch: [181][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0139)   Prec@1 100.000 (99.637)   Prec@5 100.000 (100.000)   [2018-05-02 16:13:25]
  Epoch: [181][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0179 (0.0143)   Prec@1 99.000 (99.618)   Prec@5 100.000 (100.000)   [2018-05-02 16:13:37]
  **Train** Prec@1 99.632 Prec@5 100.000 Error@1 0.368
  **Test** Prec@1 94.620 Prec@5 99.810 Error@1 5.380

==>>[2018-05-02 16:13:45] [Epoch=182/540] [Need: 03:02:04] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [182][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:13:45]
  Epoch: [182][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0110 (0.0120)   Prec@1 100.000 (99.746)   Prec@5 100.000 (100.000)   [2018-05-02 16:13:57]
  Epoch: [182][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0330 (0.0130)   Prec@1 98.000 (99.703)   Prec@5 100.000 (100.000)   [2018-05-02 16:14:08]
  **Train** Prec@1 99.704 Prec@5 99.998 Error@1 0.296
  **Test** Prec@1 94.640 Prec@5 99.820 Error@1 5.360

==>>[2018-05-02 16:14:17] [Epoch=183/540] [Need: 03:01:36] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [183][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:14:17]
  Epoch: [183][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0048 (0.0128)   Prec@1 100.000 (99.761)   Prec@5 100.000 (100.000)   [2018-05-02 16:14:29]
  Epoch: [183][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0225 (0.0124)   Prec@1 99.000 (99.753)   Prec@5 100.000 (100.000)   [2018-05-02 16:14:40]
  **Train** Prec@1 99.726 Prec@5 100.000 Error@1 0.274
  **Test** Prec@1 94.730 Prec@5 99.810 Error@1 5.270

==>>[2018-05-02 16:14:49] [Epoch=184/540] [Need: 03:01:09] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [184][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0329 (0.0329)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:14:49]
  Epoch: [184][200/500]   Time 0.062 (0.058)   Data 0.000 (0.000)   Loss 0.0063 (0.0117)   Prec@1 100.000 (99.766)   Prec@5 100.000 (100.000)   [2018-05-02 16:15:01]
  Epoch: [184][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0932 (0.0142)   Prec@1 98.000 (99.698)   Prec@5 100.000 (100.000)   [2018-05-02 16:15:12]
  **Train** Prec@1 99.686 Prec@5 100.000 Error@1 0.314
  **Test** Prec@1 94.370 Prec@5 99.850 Error@1 5.630

==>>[2018-05-02 16:15:21] [Epoch=185/540] [Need: 03:00:41] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [185][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:15:21]
  Epoch: [185][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0047 (0.0131)   Prec@1 100.000 (99.687)   Prec@5 100.000 (100.000)   [2018-05-02 16:15:33]
  Epoch: [185][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0125 (0.0134)   Prec@1 100.000 (99.696)   Prec@5 100.000 (100.000)   [2018-05-02 16:15:45]
  **Train** Prec@1 99.684 Prec@5 100.000 Error@1 0.316
  **Test** Prec@1 94.400 Prec@5 99.890 Error@1 5.600

==>>[2018-05-02 16:15:53] [Epoch=186/540] [Need: 03:00:14] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [186][000/500]   Time 0.090 (0.090)   Data 0.063 (0.063)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:15:53]
  Epoch: [186][200/500]   Time 0.057 (0.059)   Data 0.000 (0.001)   Loss 0.0090 (0.0124)   Prec@1 100.000 (99.726)   Prec@5 100.000 (100.000)   [2018-05-02 16:16:05]
  Epoch: [186][400/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.0053 (0.0138)   Prec@1 100.000 (99.666)   Prec@5 100.000 (99.998)   [2018-05-02 16:16:17]
  **Train** Prec@1 99.676 Prec@5 99.998 Error@1 0.324
  **Test** Prec@1 94.600 Prec@5 99.890 Error@1 5.400

==>>[2018-05-02 16:16:26] [Epoch=187/540] [Need: 02:59:47] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [187][000/500]   Time 0.093 (0.093)   Data 0.064 (0.064)   Loss 0.0109 (0.0109)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:16:26]
  Epoch: [187][200/500]   Time 0.060 (0.060)   Data 0.000 (0.001)   Loss 0.0500 (0.0140)   Prec@1 99.000 (99.657)   Prec@5 100.000 (100.000)   [2018-05-02 16:16:37]
  Epoch: [187][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0053 (0.0140)   Prec@1 100.000 (99.673)   Prec@5 100.000 (99.998)   [2018-05-02 16:16:49]
  **Train** Prec@1 99.672 Prec@5 99.998 Error@1 0.328
  **Test** Prec@1 94.460 Prec@5 99.830 Error@1 5.540

==>>[2018-05-02 16:16:58] [Epoch=188/540] [Need: 02:59:19] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [188][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:16:58]
  Epoch: [188][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0612 (0.0150)   Prec@1 98.000 (99.607)   Prec@5 100.000 (100.000)   [2018-05-02 16:17:10]
  Epoch: [188][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0134 (0.0146)   Prec@1 100.000 (99.636)   Prec@5 100.000 (100.000)   [2018-05-02 16:17:21]
  **Train** Prec@1 99.634 Prec@5 100.000 Error@1 0.366
  **Test** Prec@1 94.490 Prec@5 99.840 Error@1 5.510

==>>[2018-05-02 16:17:30] [Epoch=189/540] [Need: 02:58:51] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [189][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:17:30]
  Epoch: [189][200/500]   Time 0.063 (0.059)   Data 0.000 (0.000)   Loss 0.0155 (0.0148)   Prec@1 100.000 (99.617)   Prec@5 100.000 (100.000)   [2018-05-02 16:17:42]
  Epoch: [189][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0044 (0.0137)   Prec@1 100.000 (99.658)   Prec@5 100.000 (100.000)   [2018-05-02 16:17:53]
  **Train** Prec@1 99.684 Prec@5 100.000 Error@1 0.316
  **Test** Prec@1 94.490 Prec@5 99.840 Error@1 5.510

==>>[2018-05-02 16:18:02] [Epoch=190/540] [Need: 02:58:23] [learning_rate=0.010000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [190][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0072 (0.0072)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:18:02]
  Epoch: [190][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0117)   Prec@1 100.000 (99.766)   Prec@5 100.000 (100.000)   [2018-05-02 16:18:13]
  Epoch: [190][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0115)   Prec@1 100.000 (99.758)   Prec@5 100.000 (100.000)   [2018-05-02 16:18:25]
  **Train** Prec@1 99.758 Prec@5 100.000 Error@1 0.242
  **Test** Prec@1 94.520 Prec@5 99.830 Error@1 5.480

==>>[2018-05-02 16:18:33] [Epoch=191/540] [Need: 02:57:54] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [191][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:18:33]
  Epoch: [191][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0084 (0.0108)   Prec@1 100.000 (99.801)   Prec@5 100.000 (100.000)   [2018-05-02 16:18:45]
  Epoch: [191][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0111)   Prec@1 100.000 (99.778)   Prec@5 100.000 (100.000)   [2018-05-02 16:18:56]
  **Train** Prec@1 99.776 Prec@5 100.000 Error@1 0.224
  **Test** Prec@1 94.460 Prec@5 99.820 Error@1 5.540

==>>[2018-05-02 16:19:04] [Epoch=192/540] [Need: 02:57:25] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [192][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:19:05]
  Epoch: [192][200/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0375 (0.0096)   Prec@1 99.000 (99.826)   Prec@5 100.000 (100.000)   [2018-05-02 16:19:16]
  Epoch: [192][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0066 (0.0096)   Prec@1 100.000 (99.830)   Prec@5 100.000 (100.000)   [2018-05-02 16:19:27]
  **Train** Prec@1 99.830 Prec@5 100.000 Error@1 0.170
  **Test** Prec@1 94.590 Prec@5 99.840 Error@1 5.410

==>>[2018-05-02 16:19:36] [Epoch=193/540] [Need: 02:56:56] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [193][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:19:36]
  Epoch: [193][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0096)   Prec@1 100.000 (99.801)   Prec@5 100.000 (100.000)   [2018-05-02 16:19:47]
  Epoch: [193][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0095)   Prec@1 100.000 (99.810)   Prec@5 100.000 (100.000)   [2018-05-02 16:19:59]
  **Train** Prec@1 99.810 Prec@5 100.000 Error@1 0.190
  **Test** Prec@1 94.660 Prec@5 99.840 Error@1 5.340

==>>[2018-05-02 16:20:07] [Epoch=194/540] [Need: 02:56:26] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [194][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0129 (0.0129)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:20:07]
  Epoch: [194][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0094)   Prec@1 100.000 (99.806)   Prec@5 100.000 (100.000)   [2018-05-02 16:20:18]
  Epoch: [194][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0073 (0.0095)   Prec@1 100.000 (99.808)   Prec@5 100.000 (100.000)   [2018-05-02 16:20:30]
  **Train** Prec@1 99.810 Prec@5 100.000 Error@1 0.190
  **Test** Prec@1 94.640 Prec@5 99.870 Error@1 5.360

==>>[2018-05-02 16:20:38] [Epoch=195/540] [Need: 02:55:57] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [195][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0179 (0.0179)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:20:38]
  Epoch: [195][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0090)   Prec@1 100.000 (99.811)   Prec@5 100.000 (100.000)   [2018-05-02 16:20:50]
  Epoch: [195][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0445 (0.0090)   Prec@1 99.000 (99.820)   Prec@5 100.000 (100.000)   [2018-05-02 16:21:01]
  **Train** Prec@1 99.822 Prec@5 100.000 Error@1 0.178
  **Test** Prec@1 94.640 Prec@5 99.810 Error@1 5.360

==>>[2018-05-02 16:21:09] [Epoch=196/540] [Need: 02:55:27] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [196][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:21:10]
  Epoch: [196][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0106 (0.0087)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-05-02 16:21:21]
  Epoch: [196][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0156 (0.0086)   Prec@1 99.000 (99.850)   Prec@5 100.000 (100.000)   [2018-05-02 16:21:32]
  **Train** Prec@1 99.848 Prec@5 100.000 Error@1 0.152
  **Test** Prec@1 94.700 Prec@5 99.830 Error@1 5.300

==>>[2018-05-02 16:21:41] [Epoch=197/540] [Need: 02:54:58] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [197][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:21:41]
  Epoch: [197][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0087 (0.0100)   Prec@1 100.000 (99.796)   Prec@5 100.000 (99.995)   [2018-05-02 16:21:52]
  Epoch: [197][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0267 (0.0096)   Prec@1 99.000 (99.805)   Prec@5 100.000 (99.998)   [2018-05-02 16:22:04]
  **Train** Prec@1 99.804 Prec@5 99.998 Error@1 0.196
  **Test** Prec@1 94.720 Prec@5 99.840 Error@1 5.280

==>>[2018-05-02 16:22:12] [Epoch=198/540] [Need: 02:54:28] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [198][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:22:12]
  Epoch: [198][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0052 (0.0089)   Prec@1 100.000 (99.836)   Prec@5 100.000 (100.000)   [2018-05-02 16:22:24]
  Epoch: [198][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0065 (0.0089)   Prec@1 100.000 (99.828)   Prec@5 100.000 (100.000)   [2018-05-02 16:22:35]
  **Train** Prec@1 99.834 Prec@5 100.000 Error@1 0.166
  **Test** Prec@1 94.690 Prec@5 99.870 Error@1 5.310

==>>[2018-05-02 16:22:43] [Epoch=199/540] [Need: 02:53:59] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [199][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:22:43]
  Epoch: [199][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0075 (0.0083)   Prec@1 100.000 (99.861)   Prec@5 100.000 (100.000)   [2018-05-02 16:22:55]
  Epoch: [199][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0079)   Prec@1 100.000 (99.873)   Prec@5 100.000 (100.000)   [2018-05-02 16:23:06]
  **Train** Prec@1 99.880 Prec@5 100.000 Error@1 0.120
  **Test** Prec@1 94.810 Prec@5 99.810 Error@1 5.190

==>>[2018-05-02 16:23:15] [Epoch=200/540] [Need: 02:53:29] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [200][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:23:15]
  Epoch: [200][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0447 (0.0085)   Prec@1 99.000 (99.861)   Prec@5 100.000 (100.000)   [2018-05-02 16:23:26]
  Epoch: [200][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0122 (0.0085)   Prec@1 100.000 (99.838)   Prec@5 100.000 (100.000)   [2018-05-02 16:23:37]
  **Train** Prec@1 99.854 Prec@5 99.998 Error@1 0.146
  **Test** Prec@1 94.760 Prec@5 99.840 Error@1 5.240

==>>[2018-05-02 16:23:46] [Epoch=201/540] [Need: 02:53:00] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [201][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:23:46]
  Epoch: [201][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0061 (0.0094)   Prec@1 100.000 (99.851)   Prec@5 100.000 (100.000)   [2018-05-02 16:23:57]
  Epoch: [201][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0042 (0.0092)   Prec@1 100.000 (99.848)   Prec@5 100.000 (100.000)   [2018-05-02 16:24:09]
  **Train** Prec@1 99.842 Prec@5 100.000 Error@1 0.158
  **Test** Prec@1 94.730 Prec@5 99.820 Error@1 5.270

==>>[2018-05-02 16:24:17] [Epoch=202/540] [Need: 02:52:31] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [202][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:24:18]
  Epoch: [202][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0052 (0.0081)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-02 16:24:29]
  Epoch: [202][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0052 (0.0076)   Prec@1 100.000 (99.890)   Prec@5 100.000 (100.000)   [2018-05-02 16:24:40]
  **Train** Prec@1 99.874 Prec@5 100.000 Error@1 0.126
  **Test** Prec@1 94.660 Prec@5 99.860 Error@1 5.340

==>>[2018-05-02 16:24:49] [Epoch=203/540] [Need: 02:52:01] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [203][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:24:49]
  Epoch: [203][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0070 (0.0071)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:25:00]
  Epoch: [203][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0078)   Prec@1 100.000 (99.878)   Prec@5 100.000 (100.000)   [2018-05-02 16:25:12]
  **Train** Prec@1 99.878 Prec@5 100.000 Error@1 0.122
  **Test** Prec@1 94.770 Prec@5 99.840 Error@1 5.230

==>>[2018-05-02 16:25:20] [Epoch=204/540] [Need: 02:51:32] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [204][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:25:20]
  Epoch: [204][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0084 (0.0080)   Prec@1 100.000 (99.876)   Prec@5 100.000 (100.000)   [2018-05-02 16:25:31]
  Epoch: [204][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0045 (0.0081)   Prec@1 100.000 (99.865)   Prec@5 100.000 (100.000)   [2018-05-02 16:25:43]
  **Train** Prec@1 99.872 Prec@5 100.000 Error@1 0.128
  **Test** Prec@1 94.760 Prec@5 99.840 Error@1 5.240

==>>[2018-05-02 16:25:51] [Epoch=205/540] [Need: 02:51:02] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [205][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0107 (0.0107)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:25:51]
  Epoch: [205][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.851)   Prec@5 100.000 (100.000)   [2018-05-02 16:26:03]
  Epoch: [205][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0065 (0.0084)   Prec@1 100.000 (99.858)   Prec@5 100.000 (100.000)   [2018-05-02 16:26:14]
  **Train** Prec@1 99.854 Prec@5 100.000 Error@1 0.146
  **Test** Prec@1 94.830 Prec@5 99.880 Error@1 5.170

==>>[2018-05-02 16:26:23] [Epoch=206/540] [Need: 02:50:33] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [206][000/500]   Time 0.092 (0.092)   Data 0.065 (0.065)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:26:23]
  Epoch: [206][200/500]   Time 0.057 (0.057)   Data 0.000 (0.001)   Loss 0.0084 (0.0086)   Prec@1 100.000 (99.876)   Prec@5 100.000 (100.000)   [2018-05-02 16:26:34]
  Epoch: [206][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0079)   Prec@1 100.000 (99.888)   Prec@5 100.000 (100.000)   [2018-05-02 16:26:46]
  **Train** Prec@1 99.884 Prec@5 100.000 Error@1 0.116
  **Test** Prec@1 94.790 Prec@5 99.860 Error@1 5.210

==>>[2018-05-02 16:26:54] [Epoch=207/540] [Need: 02:50:03] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [207][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:26:54]
  Epoch: [207][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0082)   Prec@1 100.000 (99.866)   Prec@5 100.000 (100.000)   [2018-05-02 16:27:06]
  Epoch: [207][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0283 (0.0082)   Prec@1 99.000 (99.865)   Prec@5 100.000 (100.000)   [2018-05-02 16:27:17]
  **Train** Prec@1 99.868 Prec@5 100.000 Error@1 0.132
  **Test** Prec@1 94.850 Prec@5 99.840 Error@1 5.150

==>>[2018-05-02 16:27:26] [Epoch=208/540] [Need: 02:49:34] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [208][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:27:26]
  Epoch: [208][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0043 (0.0065)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:27:37]
  Epoch: [208][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0077)   Prec@1 100.000 (99.873)   Prec@5 100.000 (100.000)   [2018-05-02 16:27:48]
  **Train** Prec@1 99.872 Prec@5 100.000 Error@1 0.128
  **Test** Prec@1 94.760 Prec@5 99.850 Error@1 5.240

==>>[2018-05-02 16:27:57] [Epoch=209/540] [Need: 02:49:05] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [209][000/500]   Time 0.081 (0.081)   Data 0.052 (0.052)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:27:57]
  Epoch: [209][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0080)   Prec@1 100.000 (99.841)   Prec@5 100.000 (100.000)   [2018-05-02 16:28:09]
  Epoch: [209][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0080)   Prec@1 100.000 (99.848)   Prec@5 100.000 (100.000)   [2018-05-02 16:28:20]
  **Train** Prec@1 99.846 Prec@5 100.000 Error@1 0.154
  **Test** Prec@1 94.800 Prec@5 99.830 Error@1 5.200

==>>[2018-05-02 16:28:28] [Epoch=210/540] [Need: 02:48:35] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [210][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0247 (0.0247)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:28:28]
  Epoch: [210][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0062 (0.0075)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:28:40]
  Epoch: [210][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0122 (0.0078)   Prec@1 99.000 (99.895)   Prec@5 100.000 (100.000)   [2018-05-02 16:28:51]
  **Train** Prec@1 99.890 Prec@5 100.000 Error@1 0.110
  **Test** Prec@1 94.700 Prec@5 99.870 Error@1 5.300

==>>[2018-05-02 16:29:00] [Epoch=211/540] [Need: 02:48:06] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [211][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:29:00]
  Epoch: [211][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0039 (0.0074)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-02 16:29:12]
  Epoch: [211][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0052 (0.0078)   Prec@1 100.000 (99.865)   Prec@5 100.000 (99.998)   [2018-05-02 16:29:23]
  **Train** Prec@1 99.868 Prec@5 99.998 Error@1 0.132
  **Test** Prec@1 94.880 Prec@5 99.870 Error@1 5.120

==>>[2018-05-02 16:29:32] [Epoch=212/540] [Need: 02:47:37] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [212][000/500]   Time 0.101 (0.101)   Data 0.071 (0.071)   Loss 0.0027 (0.0027)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:29:32]
  Epoch: [212][200/500]   Time 0.058 (0.058)   Data 0.000 (0.001)   Loss 0.0071 (0.0074)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 16:29:44]
  Epoch: [212][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0069 (0.0074)   Prec@1 100.000 (99.893)   Prec@5 100.000 (100.000)   [2018-05-02 16:29:55]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 94.810 Prec@5 99.840 Error@1 5.190

==>>[2018-05-02 16:30:04] [Epoch=213/540] [Need: 02:47:09] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [213][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:30:04]
  Epoch: [213][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0029 (0.0075)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:30:16]
  Epoch: [213][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0074)   Prec@1 100.000 (99.883)   Prec@5 100.000 (100.000)   [2018-05-02 16:30:27]
  **Train** Prec@1 99.882 Prec@5 100.000 Error@1 0.118
  **Test** Prec@1 94.810 Prec@5 99.850 Error@1 5.190

==>>[2018-05-02 16:30:36] [Epoch=214/540] [Need: 02:46:40] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [214][000/500]   Time 0.082 (0.082)   Data 0.053 (0.053)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:30:36]
  Epoch: [214][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0132 (0.0073)   Prec@1 99.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:30:47]
  Epoch: [214][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0076 (0.0075)   Prec@1 100.000 (99.893)   Prec@5 100.000 (100.000)   [2018-05-02 16:30:59]
  **Train** Prec@1 99.884 Prec@5 100.000 Error@1 0.116
  **Test** Prec@1 94.870 Prec@5 99.860 Error@1 5.130

==>>[2018-05-02 16:31:07] [Epoch=215/540] [Need: 02:46:10] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [215][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:31:07]
  Epoch: [215][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0046 (0.0069)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:31:19]
  Epoch: [215][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0073)   Prec@1 100.000 (99.880)   Prec@5 100.000 (100.000)   [2018-05-02 16:31:30]
  **Train** Prec@1 99.890 Prec@5 100.000 Error@1 0.110
  **Test** Prec@1 94.860 Prec@5 99.880 Error@1 5.140

==>>[2018-05-02 16:31:38] [Epoch=216/540] [Need: 02:45:40] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [216][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:31:38]
  Epoch: [216][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0080 (0.0067)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:31:49]
  Epoch: [216][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0066)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-02 16:32:01]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 94.830 Prec@5 99.850 Error@1 5.170

==>>[2018-05-02 16:32:09] [Epoch=217/540] [Need: 02:45:10] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [217][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:32:10]
  Epoch: [217][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0094 (0.0073)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-05-02 16:32:21]
  Epoch: [217][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0072)   Prec@1 100.000 (99.883)   Prec@5 100.000 (100.000)   [2018-05-02 16:32:32]
  **Train** Prec@1 99.886 Prec@5 100.000 Error@1 0.114
  **Test** Prec@1 94.770 Prec@5 99.860 Error@1 5.230

==>>[2018-05-02 16:32:41] [Epoch=218/540] [Need: 02:44:40] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [218][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:32:41]
  Epoch: [218][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0056 (0.0075)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-02 16:32:52]
  Epoch: [218][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0079)   Prec@1 100.000 (99.855)   Prec@5 100.000 (100.000)   [2018-05-02 16:33:04]
  **Train** Prec@1 99.864 Prec@5 100.000 Error@1 0.136
  **Test** Prec@1 94.800 Prec@5 99.880 Error@1 5.200

==>>[2018-05-02 16:33:12] [Epoch=219/540] [Need: 02:44:11] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [219][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:33:12]
  Epoch: [219][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0089 (0.0062)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:33:24]
  Epoch: [219][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0069)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:33:35]
  **Train** Prec@1 99.896 Prec@5 100.000 Error@1 0.104
  **Test** Prec@1 94.730 Prec@5 99.870 Error@1 5.270

==>>[2018-05-02 16:33:43] [Epoch=220/540] [Need: 02:43:41] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [220][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:33:43]
  Epoch: [220][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0075 (0.0066)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:33:55]
  Epoch: [220][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0070)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-05-02 16:34:06]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 94.770 Prec@5 99.850 Error@1 5.230

==>>[2018-05-02 16:34:15] [Epoch=221/540] [Need: 02:43:11] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [221][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0098 (0.0098)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:34:15]
  Epoch: [221][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0237 (0.0076)   Prec@1 99.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-02 16:34:26]
  Epoch: [221][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0075)   Prec@1 100.000 (99.885)   Prec@5 100.000 (100.000)   [2018-05-02 16:34:38]
  **Train** Prec@1 99.886 Prec@5 100.000 Error@1 0.114
  **Test** Prec@1 94.780 Prec@5 99.840 Error@1 5.220

==>>[2018-05-02 16:34:46] [Epoch=222/540] [Need: 02:42:42] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [222][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:34:46]
  Epoch: [222][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0061 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:34:58]
  Epoch: [222][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0058 (0.0067)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-05-02 16:35:09]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 94.690 Prec@5 99.870 Error@1 5.310

==>>[2018-05-02 16:35:18] [Epoch=223/540] [Need: 02:42:12] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [223][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:35:18]
  Epoch: [223][200/500]   Time 0.062 (0.057)   Data 0.000 (0.000)   Loss 0.0052 (0.0070)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:35:29]
  Epoch: [223][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0069)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 16:35:41]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 94.750 Prec@5 99.880 Error@1 5.250

==>>[2018-05-02 16:35:49] [Epoch=224/540] [Need: 02:41:42] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [224][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:35:49]
  Epoch: [224][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0042 (0.0082)   Prec@1 100.000 (99.876)   Prec@5 100.000 (100.000)   [2018-05-02 16:36:01]
  Epoch: [224][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0077)   Prec@1 100.000 (99.885)   Prec@5 100.000 (100.000)   [2018-05-02 16:36:12]
  **Train** Prec@1 99.878 Prec@5 100.000 Error@1 0.122
  **Test** Prec@1 94.850 Prec@5 99.850 Error@1 5.150

==>>[2018-05-02 16:36:21] [Epoch=225/540] [Need: 02:41:13] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [225][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0148 (0.0148)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:36:21]
  Epoch: [225][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0048 (0.0065)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 16:36:32]
  Epoch: [225][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0044 (0.0067)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 16:36:44]
  **Train** Prec@1 99.900 Prec@5 100.000 Error@1 0.100
  **Test** Prec@1 94.860 Prec@5 99.890 Error@1 5.140

==>>[2018-05-02 16:36:52] [Epoch=226/540] [Need: 02:40:43] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [226][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:36:52]
  Epoch: [226][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0239 (0.0070)   Prec@1 99.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-02 16:37:04]
  Epoch: [226][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0085 (0.0067)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 16:37:15]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 94.780 Prec@5 99.860 Error@1 5.220

==>>[2018-05-02 16:37:23] [Epoch=227/540] [Need: 02:40:13] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [227][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:37:24]
  Epoch: [227][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0271 (0.0063)   Prec@1 99.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:37:35]
  Epoch: [227][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0068)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 16:37:46]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 94.740 Prec@5 99.900 Error@1 5.260

==>>[2018-05-02 16:37:54] [Epoch=228/540] [Need: 02:39:42] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [228][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:37:54]
  Epoch: [228][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0085 (0.0070)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:38:05]
  Epoch: [228][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0070)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-05-02 16:38:16]
  **Train** Prec@1 99.900 Prec@5 100.000 Error@1 0.100
  **Test** Prec@1 94.860 Prec@5 99.860 Error@1 5.140

==>>[2018-05-02 16:38:24] [Epoch=229/540] [Need: 02:39:10] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [229][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:38:24]
  Epoch: [229][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0071)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-02 16:38:35]
  Epoch: [229][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0068)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-02 16:38:46]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 94.880 Prec@5 99.830 Error@1 5.120

==>>[2018-05-02 16:38:54] [Epoch=230/540] [Need: 02:38:39] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [230][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0084 (0.0084)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:38:54]
  Epoch: [230][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0104 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:39:05]
  Epoch: [230][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0050 (0.0065)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 16:39:16]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 94.830 Prec@5 99.870 Error@1 5.170

==>>[2018-05-02 16:39:24] [Epoch=231/540] [Need: 02:38:07] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [231][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:39:24]
  Epoch: [231][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0128 (0.0066)   Prec@1 99.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:39:35]
  Epoch: [231][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0070)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-02 16:39:46]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 94.890 Prec@5 99.850 Error@1 5.110

==>>[2018-05-02 16:39:54] [Epoch=232/540] [Need: 02:37:36] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [232][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:39:54]
  Epoch: [232][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0064)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 16:40:05]
  Epoch: [232][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0063)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 16:40:16]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.820 Prec@5 99.830 Error@1 5.180

==>>[2018-05-02 16:40:24] [Epoch=233/540] [Need: 02:37:05] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [233][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:40:25]
  Epoch: [233][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0063)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:40:36]
  Epoch: [233][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0065)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-02 16:40:47]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 94.840 Prec@5 99.860 Error@1 5.160

==>>[2018-05-02 16:40:56] [Epoch=234/540] [Need: 02:36:35] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [234][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:40:56]
  Epoch: [234][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0060 (0.0068)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 16:41:07]
  Epoch: [234][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0062 (0.0068)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 16:41:19]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 94.890 Prec@5 99.810 Error@1 5.110

==>>[2018-05-02 16:41:27] [Epoch=235/540] [Need: 02:36:05] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [235][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:41:27]
  Epoch: [235][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0074)   Prec@1 100.000 (99.876)   Prec@5 100.000 (100.000)   [2018-05-02 16:41:39]
  Epoch: [235][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0073)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-05-02 16:41:50]
  **Train** Prec@1 99.898 Prec@5 100.000 Error@1 0.102
  **Test** Prec@1 94.860 Prec@5 99.860 Error@1 5.140

==>>[2018-05-02 16:41:59] [Epoch=236/540] [Need: 02:35:35] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [236][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0108 (0.0108)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:41:59]
  Epoch: [236][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0065)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:42:10]
  Epoch: [236][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0036 (0.0066)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-02 16:42:22]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 94.810 Prec@5 99.810 Error@1 5.190

==>>[2018-05-02 16:42:31] [Epoch=237/540] [Need: 02:35:06] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [237][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:42:31]
  Epoch: [237][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0047 (0.0071)   Prec@1 100.000 (99.891)   Prec@5 100.000 (100.000)   [2018-05-02 16:42:43]
  Epoch: [237][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0069)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2018-05-02 16:42:54]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 94.880 Prec@5 99.860 Error@1 5.120

==>>[2018-05-02 16:43:03] [Epoch=238/540] [Need: 02:34:37] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [238][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:43:03]
  Epoch: [238][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 16:43:15]
  Epoch: [238][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0075 (0.0057)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 16:43:26]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.870 Prec@5 99.840 Error@1 5.130

==>>[2018-05-02 16:43:35] [Epoch=239/540] [Need: 02:34:08] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [239][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0027 (0.0027)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:43:35]
  Epoch: [239][200/500]   Time 0.066 (0.060)   Data 0.000 (0.000)   Loss 0.0039 (0.0061)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 16:43:47]
  Epoch: [239][400/500]   Time 0.056 (0.059)   Data 0.000 (0.000)   Loss 0.0053 (0.0060)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:43:59]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.920 Prec@5 99.800 Error@1 5.080

==>>[2018-05-02 16:44:07] [Epoch=240/540] [Need: 02:33:40] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [240][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.0139 (0.0139)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:44:07]
  Epoch: [240][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0040 (0.0066)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 16:44:19]
  Epoch: [240][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0040 (0.0066)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:44:31]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 94.920 Prec@5 99.850 Error@1 5.080

==>>[2018-05-02 16:44:40] [Epoch=241/540] [Need: 02:33:11] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [241][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:44:40]
  Epoch: [241][200/500]   Time 0.057 (0.060)   Data 0.000 (0.000)   Loss 0.0042 (0.0068)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-05-02 16:44:52]
  Epoch: [241][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0051 (0.0066)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:45:03]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 94.880 Prec@5 99.830 Error@1 5.120

==>>[2018-05-02 16:45:12] [Epoch=242/540] [Need: 02:32:42] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [242][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0137 (0.0137)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:45:12]
  Epoch: [242][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0036 (0.0064)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 16:45:24]
  Epoch: [242][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0037 (0.0065)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:45:35]
  **Train** Prec@1 99.910 Prec@5 100.000 Error@1 0.090
  **Test** Prec@1 94.890 Prec@5 99.860 Error@1 5.110

==>>[2018-05-02 16:45:44] [Epoch=243/540] [Need: 02:32:12] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [243][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:45:44]
  Epoch: [243][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0445 (0.0067)   Prec@1 98.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:45:55]
  Epoch: [243][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0032 (0.0066)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:46:07]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.840 Prec@5 99.870 Error@1 5.160

==>>[2018-05-02 16:46:15] [Epoch=244/540] [Need: 02:31:43] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [244][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.0051 (0.0051)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:46:15]
  Epoch: [244][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0029 (0.0067)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:46:27]
  Epoch: [244][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0065)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-02 16:46:38]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 94.880 Prec@5 99.860 Error@1 5.120

==>>[2018-05-02 16:46:47] [Epoch=245/540] [Need: 02:31:13] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [245][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0247 (0.0247)   Prec@1 98.000 (98.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:46:47]
  Epoch: [245][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0066)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 16:46:58]
  Epoch: [245][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0068 (0.0064)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-02 16:47:10]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.830 Prec@5 99.840 Error@1 5.170

==>>[2018-05-02 16:47:18] [Epoch=246/540] [Need: 02:30:43] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [246][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0130 (0.0130)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:47:18]
  Epoch: [246][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0372 (0.0062)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:47:30]
  Epoch: [246][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0066)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:47:41]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 94.870 Prec@5 99.830 Error@1 5.130

==>>[2018-05-02 16:47:50] [Epoch=247/540] [Need: 02:30:13] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [247][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:47:50]
  Epoch: [247][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0063)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:48:01]
  Epoch: [247][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0066 (0.0065)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-02 16:48:12]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 94.780 Prec@5 99.860 Error@1 5.220

==>>[2018-05-02 16:48:21] [Epoch=248/540] [Need: 02:29:43] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [248][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:48:21]
  Epoch: [248][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0048 (0.0058)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 16:48:32]
  Epoch: [248][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0082 (0.0059)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 16:48:44]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.870 Prec@5 99.820 Error@1 5.130

==>>[2018-05-02 16:48:52] [Epoch=249/540] [Need: 02:29:13] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [249][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:48:52]
  Epoch: [249][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0066)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 16:49:04]
  Epoch: [249][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0070 (0.0065)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-02 16:49:15]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 94.890 Prec@5 99.870 Error@1 5.110

==>>[2018-05-02 16:49:24] [Epoch=250/540] [Need: 02:28:43] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [250][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:49:24]
  Epoch: [250][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:49:35]
  Epoch: [250][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0059)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 16:49:47]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.940 Prec@5 99.860 Error@1 5.060

==>>[2018-05-02 16:49:55] [Epoch=251/540] [Need: 02:28:13] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [251][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:49:55]
  Epoch: [251][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0058 (0.0058)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 16:50:07]
  Epoch: [251][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0077 (0.0059)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 16:50:18]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 94.840 Prec@5 99.820 Error@1 5.160

==>>[2018-05-02 16:50:26] [Epoch=252/540] [Need: 02:27:43] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [252][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:50:26]
  Epoch: [252][200/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0049 (0.0064)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:50:38]
  Epoch: [252][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0180 (0.0064)   Prec@1 99.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:50:49]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.960 Prec@5 99.850 Error@1 5.040

==>>[2018-05-02 16:50:58] [Epoch=253/540] [Need: 02:27:13] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [253][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:50:58]
  Epoch: [253][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0030 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 16:51:09]
  Epoch: [253][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0105 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:51:21]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 94.880 Prec@5 99.810 Error@1 5.120

==>>[2018-05-02 16:51:29] [Epoch=254/540] [Need: 02:26:43] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [254][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:51:29]
  Epoch: [254][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0061)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:51:41]
  Epoch: [254][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0055 (0.0063)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 16:51:52]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.900 Prec@5 99.840 Error@1 5.100

==>>[2018-05-02 16:52:00] [Epoch=255/540] [Need: 02:26:12] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [255][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:52:01]
  Epoch: [255][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0067)   Prec@1 100.000 (99.886)   Prec@5 100.000 (100.000)   [2018-05-02 16:52:12]
  Epoch: [255][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0065)   Prec@1 100.000 (99.890)   Prec@5 100.000 (100.000)   [2018-05-02 16:52:23]
  **Train** Prec@1 99.892 Prec@5 100.000 Error@1 0.108
  **Test** Prec@1 94.900 Prec@5 99.870 Error@1 5.100

==>>[2018-05-02 16:52:32] [Epoch=256/540] [Need: 02:25:42] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [256][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:52:32]
  Epoch: [256][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0068 (0.0065)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:52:43]
  Epoch: [256][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0065)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-02 16:52:54]
  **Train** Prec@1 99.906 Prec@5 100.000 Error@1 0.094
  **Test** Prec@1 94.930 Prec@5 99.890 Error@1 5.070

==>>[2018-05-02 16:53:03] [Epoch=257/540] [Need: 02:25:12] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [257][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:53:03]
  Epoch: [257][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0184 (0.0060)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:53:14]
  Epoch: [257][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0062)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:53:26]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.920 Prec@5 99.850 Error@1 5.080

==>>[2018-05-02 16:53:34] [Epoch=258/540] [Need: 02:24:41] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [258][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:53:34]
  Epoch: [258][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 16:53:45]
  Epoch: [258][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0252 (0.0063)   Prec@1 99.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 16:53:57]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.820 Prec@5 99.860 Error@1 5.180

==>>[2018-05-02 16:54:05] [Epoch=259/540] [Need: 02:24:11] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [259][000/500]   Time 0.085 (0.085)   Data 0.056 (0.056)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:54:05]
  Epoch: [259][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0072 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 16:54:17]
  Epoch: [259][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:54:28]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.940 Prec@5 99.890 Error@1 5.060

==>>[2018-05-02 16:54:36] [Epoch=260/540] [Need: 02:23:40] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [260][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:54:36]
  Epoch: [260][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0075 (0.0061)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:54:48]
  Epoch: [260][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0064)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:54:59]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.010 Prec@5 99.890 Error@1 4.990

==>>[2018-05-02 16:55:08] [Epoch=261/540] [Need: 02:23:10] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [261][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:55:08]
  Epoch: [261][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0064)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:55:19]
  Epoch: [261][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 16:55:30]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.890 Prec@5 99.850 Error@1 5.110

==>>[2018-05-02 16:55:39] [Epoch=262/540] [Need: 02:22:40] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [262][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:55:39]
  Epoch: [262][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0035 (0.0058)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 16:55:50]
  Epoch: [262][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0056 (0.0057)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 16:56:02]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.910 Prec@5 99.830 Error@1 5.090

==>>[2018-05-02 16:56:10] [Epoch=263/540] [Need: 02:22:10] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [263][000/500]   Time 0.087 (0.087)   Data 0.058 (0.058)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:56:10]
  Epoch: [263][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0037 (0.0057)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 16:56:22]
  Epoch: [263][400/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.0053 (0.0060)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 16:56:33]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.910 Prec@5 99.870 Error@1 5.090

==>>[2018-05-02 16:56:42] [Epoch=264/540] [Need: 02:21:40] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [264][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:56:42]
  Epoch: [264][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0061)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 16:56:53]
  Epoch: [264][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0065)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 16:57:05]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 94.970 Prec@5 99.870 Error@1 5.030

==>>[2018-05-02 16:57:13] [Epoch=265/540] [Need: 02:21:10] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [265][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:57:14]
  Epoch: [265][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0143 (0.0066)   Prec@1 99.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:57:25]
  Epoch: [265][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0065)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 16:57:36]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 94.930 Prec@5 99.870 Error@1 5.070

==>>[2018-05-02 16:57:45] [Epoch=266/540] [Need: 02:20:39] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [266][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:57:45]
  Epoch: [266][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0026 (0.0064)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 16:57:56]
  Epoch: [266][400/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0336 (0.0063)   Prec@1 99.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:58:08]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 94.850 Prec@5 99.830 Error@1 5.150

==>>[2018-05-02 16:58:16] [Epoch=267/540] [Need: 02:20:09] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [267][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:58:16]
  Epoch: [267][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0036 (0.0058)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 16:58:28]
  Epoch: [267][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0061 (0.0060)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 16:58:39]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.980 Prec@5 99.870 Error@1 5.020

==>>[2018-05-02 16:58:48] [Epoch=268/540] [Need: 02:19:39] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [268][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0165 (0.0165)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:58:48]
  Epoch: [268][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0077 (0.0060)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 16:58:59]
  Epoch: [268][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0059 (0.0066)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 16:59:10]
  **Train** Prec@1 99.904 Prec@5 100.000 Error@1 0.096
  **Test** Prec@1 95.010 Prec@5 99.880 Error@1 4.990

==>>[2018-05-02 16:59:18] [Epoch=269/540] [Need: 02:19:08] [learning_rate=0.001000] [Best : Accuracy=95.01, Error=4.99]
  Epoch: [269][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.0051 (0.0051)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:59:18]
  Epoch: [269][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:59:29]
  Epoch: [269][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0059)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 16:59:40]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.050 Prec@5 99.830 Error@1 4.950

==>>[2018-05-02 16:59:48] [Epoch=270/540] [Need: 02:18:36] [learning_rate=0.001000] [Best : Accuracy=95.05, Error=4.95]
  Epoch: [270][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 16:59:48]
  Epoch: [270][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 16:59:59]
  Epoch: [270][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:00:10]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.910 Prec@5 99.850 Error@1 5.090

==>>[2018-05-02 17:00:18] [Epoch=271/540] [Need: 02:18:05] [learning_rate=0.001000] [Best : Accuracy=95.05, Error=4.95]
  Epoch: [271][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:00:18]
  Epoch: [271][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0068)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 17:00:29]
  Epoch: [271][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0065 (0.0066)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 17:00:40]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 95.010 Prec@5 99.850 Error@1 4.990

==>>[2018-05-02 17:00:48] [Epoch=272/540] [Need: 02:17:33] [learning_rate=0.001000] [Best : Accuracy=95.05, Error=4.95]
  Epoch: [272][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:00:48]
  Epoch: [272][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0055 (0.0067)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 17:00:59]
  Epoch: [272][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0062)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:01:10]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.910 Prec@5 99.890 Error@1 5.090

==>>[2018-05-02 17:01:18] [Epoch=273/540] [Need: 02:17:02] [learning_rate=0.001000] [Best : Accuracy=95.05, Error=4.95]
  Epoch: [273][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:01:18]
  Epoch: [273][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0065)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 17:01:29]
  Epoch: [273][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0064)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-02 17:01:40]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 95.020 Prec@5 99.860 Error@1 4.980

==>>[2018-05-02 17:01:48] [Epoch=274/540] [Need: 02:16:30] [learning_rate=0.001000] [Best : Accuracy=95.05, Error=4.95]
  Epoch: [274][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:01:48]
  Epoch: [274][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:01:59]
  Epoch: [274][400/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:02:10]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.950 Prec@5 99.860 Error@1 5.050

==>>[2018-05-02 17:02:18] [Epoch=275/540] [Need: 02:15:59] [learning_rate=0.001000] [Best : Accuracy=95.05, Error=4.95]
  Epoch: [275][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:02:18]
  Epoch: [275][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:02:30]
  Epoch: [275][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:02:41]
  **Train** Prec@1 99.940 Prec@5 99.998 Error@1 0.060
  **Test** Prec@1 95.130 Prec@5 99.800 Error@1 4.870

==>>[2018-05-02 17:02:50] [Epoch=276/540] [Need: 02:15:29] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [276][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:02:50]
  Epoch: [276][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0059)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:03:01]
  Epoch: [276][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0058)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 17:03:13]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.000 Prec@5 99.850 Error@1 5.000

==>>[2018-05-02 17:03:21] [Epoch=277/540] [Need: 02:14:58] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [277][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:03:21]
  Epoch: [277][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0061)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 17:03:33]
  Epoch: [277][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0043 (0.0062)   Prec@1 100.000 (99.895)   Prec@5 100.000 (100.000)   [2018-05-02 17:03:44]
  **Train** Prec@1 99.902 Prec@5 100.000 Error@1 0.098
  **Test** Prec@1 94.930 Prec@5 99.840 Error@1 5.070

==>>[2018-05-02 17:03:53] [Epoch=278/540] [Need: 02:14:28] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [278][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:03:53]
  Epoch: [278][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0087 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:04:04]
  Epoch: [278][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0079 (0.0056)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 17:04:15]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.940 Prec@5 99.850 Error@1 5.060

==>>[2018-05-02 17:04:24] [Epoch=279/540] [Need: 02:13:58] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [279][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0027 (0.0027)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:04:24]
  Epoch: [279][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:04:35]
  Epoch: [279][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0049 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:04:47]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.920 Prec@5 99.850 Error@1 5.080

==>>[2018-05-02 17:04:55] [Epoch=280/540] [Need: 02:13:28] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [280][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:04:55]
  Epoch: [280][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0064)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 17:05:06]
  Epoch: [280][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0040 (0.0061)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-02 17:05:17]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 94.940 Prec@5 99.830 Error@1 5.060

==>>[2018-05-02 17:05:25] [Epoch=281/540] [Need: 02:12:56] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [281][000/500]   Time 0.078 (0.078)   Data 0.053 (0.053)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:05:25]
  Epoch: [281][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:05:36]
  Epoch: [281][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:05:47]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.870 Prec@5 99.860 Error@1 5.130

==>>[2018-05-02 17:05:55] [Epoch=282/540] [Need: 02:12:25] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [282][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:05:56]
  Epoch: [282][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:06:06]
  Epoch: [282][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0053)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:06:17]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.900 Prec@5 99.820 Error@1 5.100

==>>[2018-05-02 17:06:25] [Epoch=283/540] [Need: 02:11:53] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [283][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:06:26]
  Epoch: [283][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0060)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:06:36]
  Epoch: [283][400/500]   Time 0.059 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0063)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:06:48]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.920 Prec@5 99.870 Error@1 5.080

==>>[2018-05-02 17:06:56] [Epoch=284/540] [Need: 02:11:22] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [284][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:06:56]
  Epoch: [284][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0234 (0.0062)   Prec@1 99.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 17:07:08]
  Epoch: [284][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0063)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:07:19]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 94.990 Prec@5 99.830 Error@1 5.010

==>>[2018-05-02 17:07:28] [Epoch=285/540] [Need: 02:10:52] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [285][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:07:28]
  Epoch: [285][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0064)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:07:39]
  Epoch: [285][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:07:50]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.940 Prec@5 99.880 Error@1 5.060

==>>[2018-05-02 17:07:59] [Epoch=286/540] [Need: 02:10:22] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [286][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0224 (0.0224)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:07:59]
  Epoch: [286][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0048 (0.0065)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 17:08:10]
  Epoch: [286][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0061)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:08:22]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.930 Prec@5 99.860 Error@1 5.070

==>>[2018-05-02 17:08:30] [Epoch=287/540] [Need: 02:09:51] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [287][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:08:30]
  Epoch: [287][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:08:42]
  Epoch: [287][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0060)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:08:53]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.880 Prec@5 99.840 Error@1 5.120

==>>[2018-05-02 17:09:01] [Epoch=288/540] [Need: 02:09:21] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [288][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:09:02]
  Epoch: [288][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0048 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:09:13]
  Epoch: [288][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0059)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:09:24]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 94.920 Prec@5 99.840 Error@1 5.080

==>>[2018-05-02 17:09:33] [Epoch=289/540] [Need: 02:08:51] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [289][000/500]   Time 0.081 (0.081)   Data 0.052 (0.052)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:09:33]
  Epoch: [289][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0027 (0.0061)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 17:09:44]
  Epoch: [289][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0060)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-02 17:09:56]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.840 Prec@5 99.850 Error@1 5.160

==>>[2018-05-02 17:10:04] [Epoch=290/540] [Need: 02:08:20] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [290][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:10:04]
  Epoch: [290][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0066)   Prec@1 100.000 (99.896)   Prec@5 100.000 (100.000)   [2018-05-02 17:10:16]
  Epoch: [290][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0043 (0.0061)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:10:27]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.910 Prec@5 99.850 Error@1 5.090

==>>[2018-05-02 17:10:36] [Epoch=291/540] [Need: 02:07:50] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [291][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0338 (0.0338)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:10:36]
  Epoch: [291][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:10:47]
  Epoch: [291][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0044 (0.0060)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:10:59]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.900 Prec@5 99.850 Error@1 5.100

==>>[2018-05-02 17:11:07] [Epoch=292/540] [Need: 02:07:20] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [292][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:11:07]
  Epoch: [292][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0048 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:11:19]
  Epoch: [292][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0213 (0.0057)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:11:30]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.850 Prec@5 99.820 Error@1 5.150

==>>[2018-05-02 17:11:39] [Epoch=293/540] [Need: 02:06:50] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [293][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:11:39]
  Epoch: [293][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:11:50]
  Epoch: [293][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0187 (0.0063)   Prec@1 99.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-02 17:12:02]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 94.840 Prec@5 99.860 Error@1 5.160

==>>[2018-05-02 17:12:10] [Epoch=294/540] [Need: 02:06:19] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [294][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:12:10]
  Epoch: [294][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:12:21]
  Epoch: [294][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0058)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:12:33]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.910 Prec@5 99.840 Error@1 5.090

==>>[2018-05-02 17:12:41] [Epoch=295/540] [Need: 02:05:49] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [295][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:12:41]
  Epoch: [295][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0057 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:12:53]
  Epoch: [295][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:13:04]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.850 Prec@5 99.860 Error@1 5.150

==>>[2018-05-02 17:13:13] [Epoch=296/540] [Need: 02:05:19] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [296][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:13:13]
  Epoch: [296][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:13:24]
  Epoch: [296][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:13:36]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.940 Prec@5 99.840 Error@1 5.060

==>>[2018-05-02 17:13:44] [Epoch=297/540] [Need: 02:04:48] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [297][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:13:44]
  Epoch: [297][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:13:56]
  Epoch: [297][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0054 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:14:07]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.920 Prec@5 99.870 Error@1 5.080

==>>[2018-05-02 17:14:16] [Epoch=298/540] [Need: 02:04:18] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [298][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:14:16]
  Epoch: [298][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0045 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:14:27]
  Epoch: [298][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0061 (0.0055)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 17:14:39]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.940 Prec@5 99.830 Error@1 5.060

==>>[2018-05-02 17:14:47] [Epoch=299/540] [Need: 02:03:48] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [299][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:14:47]
  Epoch: [299][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0028 (0.0056)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:14:59]
  Epoch: [299][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0037 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:15:10]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.860 Prec@5 99.880 Error@1 5.140

==>>[2018-05-02 17:15:19] [Epoch=300/540] [Need: 02:03:17] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [300][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:15:19]
  Epoch: [300][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0045 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:15:30]
  Epoch: [300][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:15:42]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.940 Prec@5 99.870 Error@1 5.060

==>>[2018-05-02 17:15:51] [Epoch=301/540] [Need: 02:02:47] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [301][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:15:51]
  Epoch: [301][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0042 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:16:02]
  Epoch: [301][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 17:16:14]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.920 Prec@5 99.850 Error@1 5.080

==>>[2018-05-02 17:16:22] [Epoch=302/540] [Need: 02:02:17] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [302][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:16:22]
  Epoch: [302][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0032 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:16:34]
  Epoch: [302][400/500]   Time 0.063 (0.058)   Data 0.000 (0.000)   Loss 0.0059 (0.0059)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 17:16:46]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 94.980 Prec@5 99.820 Error@1 5.020

==>>[2018-05-02 17:16:54] [Epoch=303/540] [Need: 02:01:48] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [303][000/500]   Time 0.086 (0.086)   Data 0.060 (0.060)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:16:54]
  Epoch: [303][200/500]   Time 0.064 (0.058)   Data 0.000 (0.000)   Loss 0.0045 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:17:06]
  Epoch: [303][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0030 (0.0057)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:17:18]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.070 Prec@5 99.850 Error@1 4.930

==>>[2018-05-02 17:17:27] [Epoch=304/540] [Need: 02:01:18] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [304][000/500]   Time 0.087 (0.087)   Data 0.059 (0.059)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:17:27]
  Epoch: [304][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0045 (0.0059)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:17:39]
  Epoch: [304][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0045 (0.0053)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-05-02 17:17:50]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 95.020 Prec@5 99.820 Error@1 4.980

==>>[2018-05-02 17:17:58] [Epoch=305/540] [Need: 02:00:47] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [305][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:17:58]
  Epoch: [305][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0069 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:18:09]
  Epoch: [305][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0057 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:18:20]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.000 Prec@5 99.860 Error@1 5.000

==>>[2018-05-02 17:18:28] [Epoch=306/540] [Need: 02:00:16] [learning_rate=0.001000] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [306][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:18:28]
  Epoch: [306][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0057)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:18:39]
  Epoch: [306][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0056)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 17:18:50]
  **Train** Prec@1 99.956 Prec@5 99.998 Error@1 0.044
  **Test** Prec@1 95.010 Prec@5 99.800 Error@1 4.990

==>>[2018-05-02 17:18:58] [Epoch=307/540] [Need: 01:59:44] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [307][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:18:58]
  Epoch: [307][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:19:09]
  Epoch: [307][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0058)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 17:19:20]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.980 Prec@5 99.860 Error@1 5.020

==>>[2018-05-02 17:19:28] [Epoch=308/540] [Need: 01:59:13] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [308][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:19:28]
  Epoch: [308][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0057)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:19:39]
  Epoch: [308][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0313 (0.0057)   Prec@1 99.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:19:50]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.910 Prec@5 99.870 Error@1 5.090

==>>[2018-05-02 17:19:58] [Epoch=309/540] [Need: 01:58:42] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [309][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:19:58]
  Epoch: [309][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0094 (0.0072)   Prec@1 100.000 (99.881)   Prec@5 100.000 (100.000)   [2018-05-02 17:20:09]
  Epoch: [309][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0063)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:20:20]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.020 Prec@5 99.870 Error@1 4.980

==>>[2018-05-02 17:20:28] [Epoch=310/540] [Need: 01:58:10] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [310][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0094 (0.0094)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:20:28]
  Epoch: [310][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0118 (0.0062)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 17:20:39]
  Epoch: [310][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:20:50]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.000 Prec@5 99.800 Error@1 5.000

==>>[2018-05-02 17:20:58] [Epoch=311/540] [Need: 01:57:39] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [311][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:20:58]
  Epoch: [311][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0060)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 17:21:09]
  Epoch: [311][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0061)   Prec@1 100.000 (99.913)   Prec@5 100.000 (100.000)   [2018-05-02 17:21:20]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.940 Prec@5 99.840 Error@1 5.060

==>>[2018-05-02 17:21:28] [Epoch=312/540] [Need: 01:57:07] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [312][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:21:28]
  Epoch: [312][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0061)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 17:21:39]
  Epoch: [312][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0082 (0.0059)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:21:50]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.940 Prec@5 99.860 Error@1 5.060

==>>[2018-05-02 17:21:58] [Epoch=313/540] [Need: 01:56:36] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [313][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:21:58]
  Epoch: [313][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0060 (0.0059)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:22:09]
  Epoch: [313][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0059)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:22:20]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 95.010 Prec@5 99.860 Error@1 4.990

==>>[2018-05-02 17:22:28] [Epoch=314/540] [Need: 01:56:05] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [314][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:22:28]
  Epoch: [314][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:22:39]
  Epoch: [314][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0103 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:22:51]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.970 Prec@5 99.880 Error@1 5.030

==>>[2018-05-02 17:22:59] [Epoch=315/540] [Need: 01:55:34] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [315][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:22:59]
  Epoch: [315][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0077 (0.0062)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:23:10]
  Epoch: [315][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0062 (0.0060)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:23:21]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.040 Prec@5 99.860 Error@1 4.960

==>>[2018-05-02 17:23:29] [Epoch=316/540] [Need: 01:55:02] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [316][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0105 (0.0105)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:23:29]
  Epoch: [316][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:23:40]
  Epoch: [316][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0158 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:23:51]
  **Train** Prec@1 99.924 Prec@5 99.998 Error@1 0.076
  **Test** Prec@1 94.980 Prec@5 99.880 Error@1 5.020

==>>[2018-05-02 17:23:59] [Epoch=317/540] [Need: 01:54:31] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [317][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:23:59]
  Epoch: [317][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0053 (0.0061)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 17:24:10]
  Epoch: [317][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0059)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:24:21]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 95.030 Prec@5 99.830 Error@1 4.970

==>>[2018-05-02 17:24:29] [Epoch=318/540] [Need: 01:54:00] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [318][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:24:29]
  Epoch: [318][200/500]   Time 0.057 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:24:40]
  Epoch: [318][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:24:52]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.980 Prec@5 99.870 Error@1 5.020

==>>[2018-05-02 17:25:00] [Epoch=319/540] [Need: 01:53:29] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [319][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0027 (0.0027)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:25:01]
  Epoch: [319][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:25:12]
  Epoch: [319][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0061 (0.0056)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:25:24]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.040 Prec@5 99.880 Error@1 4.960

==>>[2018-05-02 17:25:32] [Epoch=320/540] [Need: 01:52:59] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [320][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:25:32]
  Epoch: [320][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0064)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:25:44]
  Epoch: [320][400/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.0202 (0.0058)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:25:55]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.910 Prec@5 99.880 Error@1 5.090

==>>[2018-05-02 17:26:04] [Epoch=321/540] [Need: 01:52:29] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [321][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:26:04]
  Epoch: [321][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:26:16]
  Epoch: [321][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0032 (0.0059)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-02 17:26:27]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.030 Prec@5 99.870 Error@1 4.970

==>>[2018-05-02 17:26:36] [Epoch=322/540] [Need: 01:51:59] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [322][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:26:36]
  Epoch: [322][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:26:47]
  Epoch: [322][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:26:59]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.070 Prec@5 99.850 Error@1 4.930

==>>[2018-05-02 17:27:07] [Epoch=323/540] [Need: 01:51:28] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [323][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:27:07]
  Epoch: [323][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0036 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:27:19]
  Epoch: [323][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0031 (0.0059)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:27:31]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 94.940 Prec@5 99.850 Error@1 5.060

==>>[2018-05-02 17:27:39] [Epoch=324/540] [Need: 01:50:58] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [324][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:27:40]
  Epoch: [324][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0048 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:27:51]
  Epoch: [324][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0139 (0.0058)   Prec@1 99.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:28:02]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.970 Prec@5 99.870 Error@1 5.030

==>>[2018-05-02 17:28:11] [Epoch=325/540] [Need: 01:50:28] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [325][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:28:11]
  Epoch: [325][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:28:23]
  Epoch: [325][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0111 (0.0056)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 17:28:34]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 95.030 Prec@5 99.860 Error@1 4.970

==>>[2018-05-02 17:28:42] [Epoch=326/540] [Need: 01:49:58] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [326][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:28:42]
  Epoch: [326][200/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0045 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:28:54]
  Epoch: [326][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0083 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:29:05]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 95.030 Prec@5 99.840 Error@1 4.970

==>>[2018-05-02 17:29:14] [Epoch=327/540] [Need: 01:49:27] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [327][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:29:14]
  Epoch: [327][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:29:25]
  Epoch: [327][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:29:37]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.940 Prec@5 99.860 Error@1 5.060

==>>[2018-05-02 17:29:45] [Epoch=328/540] [Need: 01:48:57] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [328][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:29:45]
  Epoch: [328][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0060)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:29:57]
  Epoch: [328][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:30:08]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.000 Prec@5 99.850 Error@1 5.000

==>>[2018-05-02 17:30:17] [Epoch=329/540] [Need: 01:48:26] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [329][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:30:17]
  Epoch: [329][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:30:28]
  Epoch: [329][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:30:40]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.950 Prec@5 99.840 Error@1 5.050

==>>[2018-05-02 17:30:48] [Epoch=330/540] [Need: 01:47:56] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [330][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:30:48]
  Epoch: [330][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0054 (0.0047)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-05-02 17:30:59]
  Epoch: [330][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0052)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-02 17:31:11]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.060 Prec@5 99.850 Error@1 4.940

==>>[2018-05-02 17:31:19] [Epoch=331/540] [Need: 01:47:25] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [331][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:31:19]
  Epoch: [331][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:31:31]
  Epoch: [331][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:31:42]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.020 Prec@5 99.810 Error@1 4.980

==>>[2018-05-02 17:31:50] [Epoch=332/540] [Need: 01:46:55] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [332][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:31:51]
  Epoch: [332][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0205 (0.0055)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:32:02]
  Epoch: [332][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:32:13]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.010 Prec@5 99.870 Error@1 4.990

==>>[2018-05-02 17:32:22] [Epoch=333/540] [Need: 01:46:24] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [333][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:32:22]
  Epoch: [333][200/500]   Time 0.060 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:32:33]
  Epoch: [333][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:32:45]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.010 Prec@5 99.820 Error@1 4.990

==>>[2018-05-02 17:32:53] [Epoch=334/540] [Need: 01:45:54] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [334][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:32:53]
  Epoch: [334][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0065 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:33:05]
  Epoch: [334][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0058)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:33:16]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.920 Prec@5 99.870 Error@1 5.080

==>>[2018-05-02 17:33:25] [Epoch=335/540] [Need: 01:45:23] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [335][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:33:25]
  Epoch: [335][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:33:36]
  Epoch: [335][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:33:47]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.940 Prec@5 99.850 Error@1 5.060

==>>[2018-05-02 17:33:56] [Epoch=336/540] [Need: 01:44:52] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [336][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:33:56]
  Epoch: [336][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0251 (0.0057)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:34:07]
  Epoch: [336][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:34:19]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.950 Prec@5 99.860 Error@1 5.050

==>>[2018-05-02 17:34:27] [Epoch=337/540] [Need: 01:44:22] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [337][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:34:27]
  Epoch: [337][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:34:39]
  Epoch: [337][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0056 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:34:50]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.980 Prec@5 99.880 Error@1 5.020

==>>[2018-05-02 17:34:58] [Epoch=338/540] [Need: 01:43:51] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [338][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:34:59]
  Epoch: [338][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (99.995)   [2018-05-02 17:35:10]
  Epoch: [338][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (99.998)   [2018-05-02 17:35:21]
  **Train** Prec@1 99.938 Prec@5 99.998 Error@1 0.062
  **Test** Prec@1 95.040 Prec@5 99.870 Error@1 4.960

==>>[2018-05-02 17:35:30] [Epoch=339/540] [Need: 01:43:21] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [339][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:35:30]
  Epoch: [339][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:35:41]
  Epoch: [339][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0118 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:35:53]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.010 Prec@5 99.880 Error@1 4.990

==>>[2018-05-02 17:36:01] [Epoch=340/540] [Need: 01:42:50] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [340][000/500]   Time 0.139 (0.139)   Data 0.112 (0.112)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:36:01]
  Epoch: [340][200/500]   Time 0.057 (0.057)   Data 0.000 (0.001)   Loss 0.0029 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:36:12]
  Epoch: [340][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:36:24]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.950 Prec@5 99.840 Error@1 5.050

==>>[2018-05-02 17:36:32] [Epoch=341/540] [Need: 01:42:19] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [341][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:36:32]
  Epoch: [341][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:36:44]
  Epoch: [341][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0075 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:36:55]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.980 Prec@5 99.880 Error@1 5.020

==>>[2018-05-02 17:37:04] [Epoch=342/540] [Need: 01:41:49] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [342][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:37:04]
  Epoch: [342][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0132 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:37:15]
  Epoch: [342][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0049 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:37:26]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.990 Prec@5 99.880 Error@1 5.010

==>>[2018-05-02 17:37:35] [Epoch=343/540] [Need: 01:41:18] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [343][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:37:35]
  Epoch: [343][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0082 (0.0059)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:37:46]
  Epoch: [343][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0063)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-02 17:37:58]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.000 Prec@5 99.860 Error@1 5.000

==>>[2018-05-02 17:38:06] [Epoch=344/540] [Need: 01:40:47] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [344][000/500]   Time 0.081 (0.081)   Data 0.056 (0.056)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:38:06]
  Epoch: [344][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:38:17]
  Epoch: [344][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0067 (0.0057)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 17:38:29]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.960 Prec@5 99.820 Error@1 5.040

==>>[2018-05-02 17:38:37] [Epoch=345/540] [Need: 01:40:17] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [345][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:38:37]
  Epoch: [345][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:38:49]
  Epoch: [345][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:39:00]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 95.020 Prec@5 99.860 Error@1 4.980

==>>[2018-05-02 17:39:09] [Epoch=346/540] [Need: 01:39:46] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [346][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:39:09]
  Epoch: [346][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0067)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 17:39:20]
  Epoch: [346][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0063)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:39:31]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.900 Prec@5 99.880 Error@1 5.100

==>>[2018-05-02 17:39:40] [Epoch=347/540] [Need: 01:39:16] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [347][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0102 (0.0102)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:39:40]
  Epoch: [347][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0059)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 17:39:51]
  Epoch: [347][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:40:03]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 95.010 Prec@5 99.880 Error@1 4.990

==>>[2018-05-02 17:40:11] [Epoch=348/540] [Need: 01:38:45] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [348][000/500]   Time 0.085 (0.085)   Data 0.056 (0.056)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:40:11]
  Epoch: [348][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:40:23]
  Epoch: [348][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0048 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:40:34]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.980 Prec@5 99.890 Error@1 5.020

==>>[2018-05-02 17:40:43] [Epoch=349/540] [Need: 01:38:14] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [349][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:40:43]
  Epoch: [349][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:40:54]
  Epoch: [349][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:41:05]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.940 Prec@5 99.860 Error@1 5.060

==>>[2018-05-02 17:41:14] [Epoch=350/540] [Need: 01:37:44] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [350][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:41:14]
  Epoch: [350][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0052)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-02 17:41:25]
  Epoch: [350][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0052 (0.0056)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:41:37]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.920 Prec@5 99.850 Error@1 5.080

==>>[2018-05-02 17:41:45] [Epoch=351/540] [Need: 01:37:13] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [351][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:41:45]
  Epoch: [351][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0062)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 17:41:56]
  Epoch: [351][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0081 (0.0063)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:42:08]
  **Train** Prec@1 99.912 Prec@5 100.000 Error@1 0.088
  **Test** Prec@1 94.990 Prec@5 99.850 Error@1 5.010

==>>[2018-05-02 17:42:16] [Epoch=352/540] [Need: 01:36:42] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [352][000/500]   Time 0.087 (0.087)   Data 0.058 (0.058)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:42:16]
  Epoch: [352][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:42:28]
  Epoch: [352][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0052)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-02 17:42:39]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.900 Prec@5 99.870 Error@1 5.100

==>>[2018-05-02 17:42:48] [Epoch=353/540] [Need: 01:36:12] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [353][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:42:48]
  Epoch: [353][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0080 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:42:59]
  Epoch: [353][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:43:11]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.000 Prec@5 99.880 Error@1 5.000

==>>[2018-05-02 17:43:19] [Epoch=354/540] [Need: 01:35:41] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [354][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:43:19]
  Epoch: [354][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:43:30]
  Epoch: [354][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0058)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:43:42]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.950 Prec@5 99.850 Error@1 5.050

==>>[2018-05-02 17:43:50] [Epoch=355/540] [Need: 01:35:11] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [355][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0051 (0.0051)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:43:50]
  Epoch: [355][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0058)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:44:02]
  Epoch: [355][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0060)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:44:13]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.960 Prec@5 99.860 Error@1 5.040

==>>[2018-05-02 17:44:22] [Epoch=356/540] [Need: 01:34:40] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [356][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0096 (0.0096)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:44:22]
  Epoch: [356][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0059 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:44:33]
  Epoch: [356][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0067 (0.0057)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 17:44:44]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.960 Prec@5 99.830 Error@1 5.040

==>>[2018-05-02 17:44:53] [Epoch=357/540] [Need: 01:34:09] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [357][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:44:53]
  Epoch: [357][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0050 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:45:04]
  Epoch: [357][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0074 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:45:16]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.970 Prec@5 99.830 Error@1 5.030

==>>[2018-05-02 17:45:24] [Epoch=358/540] [Need: 01:33:39] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [358][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:45:24]
  Epoch: [358][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0044 (0.0054)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-02 17:45:36]
  Epoch: [358][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0199 (0.0055)   Prec@1 99.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:45:47]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.940 Prec@5 99.850 Error@1 5.060

==>>[2018-05-02 17:45:55] [Epoch=359/540] [Need: 01:33:08] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [359][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:45:55]
  Epoch: [359][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0056)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:46:07]
  Epoch: [359][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0054)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-05-02 17:46:18]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 94.980 Prec@5 99.850 Error@1 5.020

==>>[2018-05-02 17:46:27] [Epoch=360/540] [Need: 01:32:37] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [360][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:46:27]
  Epoch: [360][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0039 (0.0062)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:46:38]
  Epoch: [360][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:46:50]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.990 Prec@5 99.810 Error@1 5.010

==>>[2018-05-02 17:46:59] [Epoch=361/540] [Need: 01:32:07] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [361][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:46:59]
  Epoch: [361][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0069 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:47:10]
  Epoch: [361][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0059 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:47:21]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 95.020 Prec@5 99.840 Error@1 4.980

==>>[2018-05-02 17:47:30] [Epoch=362/540] [Need: 01:31:36] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [362][000/500]   Time 0.080 (0.080)   Data 0.055 (0.055)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:47:30]
  Epoch: [362][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0060 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:47:41]
  Epoch: [362][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0102 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 17:47:53]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.910 Prec@5 99.870 Error@1 5.090

==>>[2018-05-02 17:48:01] [Epoch=363/540] [Need: 01:31:06] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [363][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:48:01]
  Epoch: [363][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0050)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:48:13]
  Epoch: [363][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0110 (0.0055)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 17:48:24]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.930 Prec@5 99.860 Error@1 5.070

==>>[2018-05-02 17:48:32] [Epoch=364/540] [Need: 01:30:35] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [364][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0102 (0.0102)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:48:32]
  Epoch: [364][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 17:48:44]
  Epoch: [364][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 17:48:55]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.920 Prec@5 99.830 Error@1 5.080

==>>[2018-05-02 17:49:04] [Epoch=365/540] [Need: 01:30:04] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [365][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0138 (0.0138)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:49:04]
  Epoch: [365][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:49:15]
  Epoch: [365][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 17:49:27]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.900 Prec@5 99.860 Error@1 5.100

==>>[2018-05-02 17:49:35] [Epoch=366/540] [Need: 01:29:33] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [366][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:49:35]
  Epoch: [366][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0055 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:49:46]
  Epoch: [366][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0057)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 17:49:58]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 94.990 Prec@5 99.840 Error@1 5.010

==>>[2018-05-02 17:50:06] [Epoch=367/540] [Need: 01:29:03] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [367][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:50:06]
  Epoch: [367][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0060 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:50:18]
  Epoch: [367][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:50:29]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.970 Prec@5 99.830 Error@1 5.030

==>>[2018-05-02 17:50:37] [Epoch=368/540] [Need: 01:28:32] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [368][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:50:37]
  Epoch: [368][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0027 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 17:50:49]
  Epoch: [368][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0055)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 17:51:00]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 94.980 Prec@5 99.830 Error@1 5.020

==>>[2018-05-02 17:51:09] [Epoch=369/540] [Need: 01:28:01] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [369][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0152 (0.0152)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:51:09]
  Epoch: [369][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:51:20]
  Epoch: [369][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0040 (0.0053)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 17:51:32]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 94.900 Prec@5 99.840 Error@1 5.100

==>>[2018-05-02 17:51:40] [Epoch=370/540] [Need: 01:27:31] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [370][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:51:40]
  Epoch: [370][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:51:52]
  Epoch: [370][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0056)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:52:03]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.960 Prec@5 99.860 Error@1 5.040

==>>[2018-05-02 17:52:11] [Epoch=371/540] [Need: 01:27:00] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [371][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:52:11]
  Epoch: [371][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0042 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:52:23]
  Epoch: [371][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0076 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:52:34]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.930 Prec@5 99.850 Error@1 5.070

==>>[2018-05-02 17:52:43] [Epoch=372/540] [Need: 01:26:29] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [372][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0026 (0.0026)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:52:43]
  Epoch: [372][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0060)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:52:54]
  Epoch: [372][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0066 (0.0058)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:53:05]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.900 Prec@5 99.840 Error@1 5.100

==>>[2018-05-02 17:53:14] [Epoch=373/540] [Need: 01:25:58] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [373][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:53:14]
  Epoch: [373][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0058)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 17:53:25]
  Epoch: [373][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0059 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:53:37]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.950 Prec@5 99.870 Error@1 5.050

==>>[2018-05-02 17:53:45] [Epoch=374/540] [Need: 01:25:28] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [374][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:53:45]
  Epoch: [374][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0060)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:53:57]
  Epoch: [374][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0058)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:54:08]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.040 Prec@5 99.860 Error@1 4.960

==>>[2018-05-02 17:54:16] [Epoch=375/540] [Need: 01:24:57] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [375][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:54:16]
  Epoch: [375][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0028 (0.0061)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 17:54:28]
  Epoch: [375][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:54:39]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.980 Prec@5 99.870 Error@1 5.020

==>>[2018-05-02 17:54:48] [Epoch=376/540] [Need: 01:24:26] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [376][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:54:48]
  Epoch: [376][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0054)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:54:59]
  Epoch: [376][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0056)   Prec@1 100.000 (99.933)   Prec@5 100.000 (99.998)   [2018-05-02 17:55:10]
  **Train** Prec@1 99.938 Prec@5 99.998 Error@1 0.062
  **Test** Prec@1 95.030 Prec@5 99.870 Error@1 4.970

==>>[2018-05-02 17:55:19] [Epoch=377/540] [Need: 01:23:56] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [377][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:55:19]
  Epoch: [377][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0029 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:55:31]
  Epoch: [377][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0112 (0.0056)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 17:55:42]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.030 Prec@5 99.850 Error@1 4.970

==>>[2018-05-02 17:55:51] [Epoch=378/540] [Need: 01:23:25] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [378][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:55:51]
  Epoch: [378][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:56:02]
  Epoch: [378][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0040 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:56:13]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.970 Prec@5 99.850 Error@1 5.030

==>>[2018-05-02 17:56:21] [Epoch=379/540] [Need: 01:22:54] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [379][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:56:22]
  Epoch: [379][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0054)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:56:33]
  Epoch: [379][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0036 (0.0053)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 17:56:44]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.950 Prec@5 99.850 Error@1 5.050

==>>[2018-05-02 17:56:52] [Epoch=380/540] [Need: 01:22:23] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [380][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:56:52]
  Epoch: [380][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0029 (0.0062)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 17:57:04]
  Epoch: [380][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 17:57:15]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 94.890 Prec@5 99.870 Error@1 5.110

==>>[2018-05-02 17:57:23] [Epoch=381/540] [Need: 01:21:52] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [381][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:57:23]
  Epoch: [381][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0041 (0.0052)   Prec@1 100.000 (99.980)   Prec@5 100.000 (100.000)   [2018-05-02 17:57:35]
  Epoch: [381][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0033 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 17:57:46]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 94.830 Prec@5 99.850 Error@1 5.170

==>>[2018-05-02 17:57:54] [Epoch=382/540] [Need: 01:21:21] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [382][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:57:54]
  Epoch: [382][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0085 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 17:58:06]
  Epoch: [382][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0052 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:58:17]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.050 Prec@5 99.820 Error@1 4.950

==>>[2018-05-02 17:58:25] [Epoch=383/540] [Need: 01:20:50] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [383][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0118 (0.0118)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:58:25]
  Epoch: [383][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0040 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 17:58:36]
  Epoch: [383][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0038 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 17:58:48]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.990 Prec@5 99.850 Error@1 5.010

==>>[2018-05-02 17:58:56] [Epoch=384/540] [Need: 01:20:20] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [384][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:58:56]
  Epoch: [384][200/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.0066 (0.0061)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 17:59:07]
  Epoch: [384][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0055 (0.0057)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 17:59:19]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.930 Prec@5 99.860 Error@1 5.070

==>>[2018-05-02 17:59:27] [Epoch=385/540] [Need: 01:19:49] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [385][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0050 (0.0050)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:59:27]
  Epoch: [385][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0119 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 17:59:38]
  Epoch: [385][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0085 (0.0052)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-02 17:59:50]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 94.950 Prec@5 99.850 Error@1 5.050

==>>[2018-05-02 17:59:58] [Epoch=386/540] [Need: 01:19:18] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [386][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 17:59:58]
  Epoch: [386][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0093 (0.0058)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:00:09]
  Epoch: [386][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0056)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:00:20]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.930 Prec@5 99.830 Error@1 5.070

==>>[2018-05-02 18:00:29] [Epoch=387/540] [Need: 01:18:47] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [387][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:00:29]
  Epoch: [387][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0060 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:00:40]
  Epoch: [387][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:00:51]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 94.970 Prec@5 99.860 Error@1 5.030

==>>[2018-05-02 18:01:00] [Epoch=388/540] [Need: 01:18:16] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [388][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:01:00]
  Epoch: [388][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:01:11]
  Epoch: [388][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0038 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:01:22]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.920 Prec@5 99.820 Error@1 5.080

==>>[2018-05-02 18:01:31] [Epoch=389/540] [Need: 01:17:45] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [389][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0219 (0.0219)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:01:31]
  Epoch: [389][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0346 (0.0062)   Prec@1 99.000 (99.925)   Prec@5 100.000 (99.995)   [2018-05-02 18:01:42]
  Epoch: [389][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0057)   Prec@1 100.000 (99.938)   Prec@5 100.000 (99.998)   [2018-05-02 18:01:53]
  **Train** Prec@1 99.938 Prec@5 99.998 Error@1 0.062
  **Test** Prec@1 95.010 Prec@5 99.880 Error@1 4.990

==>>[2018-05-02 18:02:01] [Epoch=390/540] [Need: 01:17:14] [learning_rate=0.000100] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [390][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:02:01]
  Epoch: [390][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:02:13]
  Epoch: [390][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:02:24]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 94.880 Prec@5 99.850 Error@1 5.120

==>>[2018-05-02 18:02:32] [Epoch=391/540] [Need: 01:16:43] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [391][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:02:32]
  Epoch: [391][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0072 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:02:44]
  Epoch: [391][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0140 (0.0057)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:02:55]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.950 Prec@5 99.870 Error@1 5.050

==>>[2018-05-02 18:03:03] [Epoch=392/540] [Need: 01:16:12] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [392][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:03:03]
  Epoch: [392][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0053)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:03:15]
  Epoch: [392][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0137 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:03:26]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.940 Prec@5 99.860 Error@1 5.060

==>>[2018-05-02 18:03:34] [Epoch=393/540] [Need: 01:15:41] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [393][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:03:34]
  Epoch: [393][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 18:03:45]
  Epoch: [393][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0057)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:03:56]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.990 Prec@5 99.870 Error@1 5.010

==>>[2018-05-02 18:04:04] [Epoch=394/540] [Need: 01:15:10] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [394][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:04:04]
  Epoch: [394][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0163 (0.0055)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:04:15]
  Epoch: [394][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:04:27]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.960 Prec@5 99.880 Error@1 5.040

==>>[2018-05-02 18:04:35] [Epoch=395/540] [Need: 01:14:39] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [395][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0122 (0.0122)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:04:35]
  Epoch: [395][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:04:46]
  Epoch: [395][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:04:57]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.960 Prec@5 99.900 Error@1 5.040

==>>[2018-05-02 18:05:06] [Epoch=396/540] [Need: 01:14:08] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [396][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0222 (0.0222)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:05:06]
  Epoch: [396][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:05:17]
  Epoch: [396][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0109 (0.0054)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 18:05:28]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.030 Prec@5 99.840 Error@1 4.970

==>>[2018-05-02 18:05:37] [Epoch=397/540] [Need: 01:13:38] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [397][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:05:37]
  Epoch: [397][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0054 (0.0055)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:05:48]
  Epoch: [397][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:05:59]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.900 Prec@5 99.850 Error@1 5.100

==>>[2018-05-02 18:06:07] [Epoch=398/540] [Need: 01:13:07] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [398][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:06:08]
  Epoch: [398][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0056 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:06:19]
  Epoch: [398][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0223 (0.0055)   Prec@1 99.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:06:30]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.010 Prec@5 99.840 Error@1 4.990

==>>[2018-05-02 18:06:38] [Epoch=399/540] [Need: 01:12:36] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [399][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:06:38]
  Epoch: [399][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0056)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:06:49]
  Epoch: [399][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0053)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:07:00]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.000 Prec@5 99.860 Error@1 5.000

==>>[2018-05-02 18:07:09] [Epoch=400/540] [Need: 01:12:05] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [400][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:07:09]
  Epoch: [400][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0029 (0.0060)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:07:20]
  Epoch: [400][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0033 (0.0056)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:07:31]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.900 Prec@5 99.880 Error@1 5.100

==>>[2018-05-02 18:07:40] [Epoch=401/540] [Need: 01:11:34] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [401][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:07:40]
  Epoch: [401][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0033 (0.0049)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-02 18:07:51]
  Epoch: [401][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:08:02]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.950 Prec@5 99.860 Error@1 5.050

==>>[2018-05-02 18:08:10] [Epoch=402/540] [Need: 01:11:03] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [402][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:08:11]
  Epoch: [402][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:08:22]
  Epoch: [402][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0041 (0.0058)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:08:33]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.940 Prec@5 99.850 Error@1 5.060

==>>[2018-05-02 18:08:41] [Epoch=403/540] [Need: 01:10:32] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [403][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:08:42]
  Epoch: [403][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0048 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:08:53]
  Epoch: [403][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0081 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:09:04]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.990 Prec@5 99.840 Error@1 5.010

==>>[2018-05-02 18:09:12] [Epoch=404/540] [Need: 01:10:01] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [404][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:09:12]
  Epoch: [404][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:09:23]
  Epoch: [404][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:09:34]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.010 Prec@5 99.840 Error@1 4.990

==>>[2018-05-02 18:09:42] [Epoch=405/540] [Need: 01:09:30] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [405][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:09:42]
  Epoch: [405][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0050)   Prec@1 100.000 (99.975)   Prec@5 100.000 (100.000)   [2018-05-02 18:09:53]
  Epoch: [405][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0050)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-05-02 18:10:04]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 94.930 Prec@5 99.850 Error@1 5.070

==>>[2018-05-02 18:10:12] [Epoch=406/540] [Need: 01:08:59] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [406][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:10:12]
  Epoch: [406][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0051)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:10:23]
  Epoch: [406][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0053)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:10:34]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.830 Prec@5 99.820 Error@1 5.170

==>>[2018-05-02 18:10:42] [Epoch=407/540] [Need: 01:08:27] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [407][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:10:42]
  Epoch: [407][200/500]   Time 0.053 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0058)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:10:53]
  Epoch: [407][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:11:04]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.940 Prec@5 99.840 Error@1 5.060

==>>[2018-05-02 18:11:12] [Epoch=408/540] [Need: 01:07:56] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [408][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:11:12]
  Epoch: [408][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:11:23]
  Epoch: [408][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:11:34]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.970 Prec@5 99.890 Error@1 5.030

==>>[2018-05-02 18:11:42] [Epoch=409/540] [Need: 01:07:25] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [409][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:11:42]
  Epoch: [409][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0057)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 18:11:53]
  Epoch: [409][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0056)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 18:12:04]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.010 Prec@5 99.860 Error@1 4.990

==>>[2018-05-02 18:12:12] [Epoch=410/540] [Need: 01:06:54] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [410][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:12:12]
  Epoch: [410][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0052 (0.0063)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:12:23]
  Epoch: [410][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0061)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:12:34]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.990 Prec@5 99.830 Error@1 5.010

==>>[2018-05-02 18:12:42] [Epoch=411/540] [Need: 01:06:23] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [411][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:12:42]
  Epoch: [411][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0082 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:12:53]
  Epoch: [411][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0058)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 18:13:04]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.980 Prec@5 99.880 Error@1 5.020

==>>[2018-05-02 18:13:12] [Epoch=412/540] [Need: 01:05:52] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [412][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:13:12]
  Epoch: [412][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0057 (0.0062)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 18:13:23]
  Epoch: [412][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:13:34]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.910 Prec@5 99.860 Error@1 5.090

==>>[2018-05-02 18:13:42] [Epoch=413/540] [Need: 01:05:21] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [413][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:13:42]
  Epoch: [413][200/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:13:53]
  Epoch: [413][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0027 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:14:05]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.900 Prec@5 99.850 Error@1 5.100

==>>[2018-05-02 18:14:13] [Epoch=414/540] [Need: 01:04:50] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [414][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0039 (0.0039)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:14:13]
  Epoch: [414][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:14:24]
  Epoch: [414][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:14:35]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.000 Prec@5 99.790 Error@1 5.000

==>>[2018-05-02 18:14:43] [Epoch=415/540] [Need: 01:04:18] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [415][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:14:43]
  Epoch: [415][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:14:54]
  Epoch: [415][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0055)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:15:05]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.010 Prec@5 99.860 Error@1 4.990

==>>[2018-05-02 18:15:13] [Epoch=416/540] [Need: 01:03:47] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [416][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:15:13]
  Epoch: [416][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0053)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:15:24]
  Epoch: [416][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0114 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:15:35]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.030 Prec@5 99.860 Error@1 4.970

==>>[2018-05-02 18:15:43] [Epoch=417/540] [Need: 01:03:16] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [417][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:15:43]
  Epoch: [417][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:15:54]
  Epoch: [417][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:16:05]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.940 Prec@5 99.810 Error@1 5.060

==>>[2018-05-02 18:16:13] [Epoch=418/540] [Need: 01:02:45] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [418][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:16:13]
  Epoch: [418][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0032 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:16:24]
  Epoch: [418][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:16:35]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.970 Prec@5 99.890 Error@1 5.030

==>>[2018-05-02 18:16:43] [Epoch=419/540] [Need: 01:02:14] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [419][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0101 (0.0101)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:16:43]
  Epoch: [419][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0059)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 18:16:54]
  Epoch: [419][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0057)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 18:17:05]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.870 Prec@5 99.880 Error@1 5.130

==>>[2018-05-02 18:17:13] [Epoch=420/540] [Need: 01:01:43] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [420][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:17:13]
  Epoch: [420][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:17:24]
  Epoch: [420][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0051 (0.0055)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:17:35]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.980 Prec@5 99.850 Error@1 5.020

==>>[2018-05-02 18:17:43] [Epoch=421/540] [Need: 01:01:12] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [421][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:17:43]
  Epoch: [421][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0067 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:17:54]
  Epoch: [421][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0058 (0.0054)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 18:18:05]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.010 Prec@5 99.850 Error@1 4.990

==>>[2018-05-02 18:18:13] [Epoch=422/540] [Need: 01:00:41] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [422][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:18:13]
  Epoch: [422][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0373 (0.0054)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:18:24]
  Epoch: [422][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0054)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:18:35]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.920 Prec@5 99.840 Error@1 5.080

==>>[2018-05-02 18:18:43] [Epoch=423/540] [Need: 01:00:10] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [423][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:18:43]
  Epoch: [423][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0056 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:18:54]
  Epoch: [423][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0133 (0.0057)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:19:05]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.940 Prec@5 99.850 Error@1 5.060

==>>[2018-05-02 18:19:13] [Epoch=424/540] [Need: 00:59:39] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [424][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0047 (0.0047)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:19:13]
  Epoch: [424][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:19:24]
  Epoch: [424][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0060)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 18:19:35]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.000 Prec@5 99.830 Error@1 5.000

==>>[2018-05-02 18:19:44] [Epoch=425/540] [Need: 00:59:08] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [425][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0027 (0.0027)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:19:44]
  Epoch: [425][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0073 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:19:55]
  Epoch: [425][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0034 (0.0054)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 18:20:06]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.980 Prec@5 99.850 Error@1 5.020

==>>[2018-05-02 18:20:14] [Epoch=426/540] [Need: 00:58:36] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [426][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0050 (0.0050)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:20:14]
  Epoch: [426][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:20:25]
  Epoch: [426][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0049 (0.0056)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 18:20:36]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 95.020 Prec@5 99.880 Error@1 4.980

==>>[2018-05-02 18:20:44] [Epoch=427/540] [Need: 00:58:05] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [427][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:20:44]
  Epoch: [427][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0437 (0.0058)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:20:55]
  Epoch: [427][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0060)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:21:06]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.070 Prec@5 99.900 Error@1 4.930

==>>[2018-05-02 18:21:14] [Epoch=428/540] [Need: 00:57:34] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [428][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:21:14]
  Epoch: [428][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0097 (0.0055)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:21:25]
  Epoch: [428][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:21:36]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.960 Prec@5 99.810 Error@1 5.040

==>>[2018-05-02 18:21:44] [Epoch=429/540] [Need: 00:57:03] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [429][000/500]   Time 0.077 (0.077)   Data 0.052 (0.052)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:21:44]
  Epoch: [429][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0054 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:21:55]
  Epoch: [429][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:22:06]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.970 Prec@5 99.900 Error@1 5.030

==>>[2018-05-02 18:22:14] [Epoch=430/540] [Need: 00:56:32] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [430][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:22:14]
  Epoch: [430][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:22:25]
  Epoch: [430][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0109 (0.0056)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:22:36]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.980 Prec@5 99.840 Error@1 5.020

==>>[2018-05-02 18:22:44] [Epoch=431/540] [Need: 00:56:01] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [431][000/500]   Time 0.079 (0.079)   Data 0.052 (0.052)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:22:44]
  Epoch: [431][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0099 (0.0053)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 18:22:55]
  Epoch: [431][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0054)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:23:06]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.980 Prec@5 99.840 Error@1 5.020

==>>[2018-05-02 18:23:14] [Epoch=432/540] [Need: 00:55:30] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [432][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:23:14]
  Epoch: [432][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0237 (0.0062)   Prec@1 99.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:23:25]
  Epoch: [432][400/500]   Time 0.056 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0060)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 18:23:36]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.980 Prec@5 99.860 Error@1 5.020

==>>[2018-05-02 18:23:44] [Epoch=433/540] [Need: 00:54:59] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [433][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0084 (0.0084)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:23:44]
  Epoch: [433][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0045 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:23:55]
  Epoch: [433][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0050 (0.0052)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 18:24:06]
  **Train** Prec@1 99.954 Prec@5 99.998 Error@1 0.046
  **Test** Prec@1 94.970 Prec@5 99.870 Error@1 5.030

==>>[2018-05-02 18:24:14] [Epoch=434/540] [Need: 00:54:28] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [434][000/500]   Time 0.088 (0.088)   Data 0.062 (0.062)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:24:14]
  Epoch: [434][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0051)   Prec@1 100.000 (99.985)   Prec@5 100.000 (100.000)   [2018-05-02 18:24:25]
  Epoch: [434][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0051)   Prec@1 100.000 (99.978)   Prec@5 100.000 (100.000)   [2018-05-02 18:24:36]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 94.990 Prec@5 99.860 Error@1 5.010

==>>[2018-05-02 18:24:44] [Epoch=435/540] [Need: 00:53:57] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [435][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:24:44]
  Epoch: [435][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:24:55]
  Epoch: [435][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0105 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:25:06]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.860 Prec@5 99.800 Error@1 5.140

==>>[2018-05-02 18:25:14] [Epoch=436/540] [Need: 00:53:26] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [436][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:25:14]
  Epoch: [436][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0160 (0.0052)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:25:25]
  Epoch: [436][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0041 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:25:36]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.010 Prec@5 99.860 Error@1 4.990

==>>[2018-05-02 18:25:45] [Epoch=437/540] [Need: 00:52:55] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [437][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:25:45]
  Epoch: [437][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:25:56]
  Epoch: [437][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0042 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:26:07]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.940 Prec@5 99.870 Error@1 5.060

==>>[2018-05-02 18:26:15] [Epoch=438/540] [Need: 00:52:24] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [438][000/500]   Time 0.078 (0.078)   Data 0.052 (0.052)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:26:15]
  Epoch: [438][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0033 (0.0060)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:26:26]
  Epoch: [438][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0067 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:26:37]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.940 Prec@5 99.880 Error@1 5.060

==>>[2018-05-02 18:26:45] [Epoch=439/540] [Need: 00:51:53] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [439][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0208 (0.0208)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:26:45]
  Epoch: [439][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0046 (0.0061)   Prec@1 100.000 (99.910)   Prec@5 100.000 (100.000)   [2018-05-02 18:26:56]
  Epoch: [439][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0176 (0.0056)   Prec@1 99.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:27:07]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.910 Prec@5 99.840 Error@1 5.090

==>>[2018-05-02 18:27:15] [Epoch=440/540] [Need: 00:51:22] [learning_rate=0.000010] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [440][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:27:15]
  Epoch: [440][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0086 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:27:26]
  Epoch: [440][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0060 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:27:37]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.970 Prec@5 99.880 Error@1 5.030

==>>[2018-05-02 18:27:45] [Epoch=441/540] [Need: 00:50:51] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [441][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:27:45]
  Epoch: [441][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0028 (0.0064)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 18:27:56]
  Epoch: [441][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0105 (0.0058)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 18:28:07]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.980 Prec@5 99.880 Error@1 5.020

==>>[2018-05-02 18:28:15] [Epoch=442/540] [Need: 00:50:20] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [442][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:28:15]
  Epoch: [442][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0048 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:28:26]
  Epoch: [442][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0055)   Prec@1 100.000 (99.960)   Prec@5 100.000 (99.998)   [2018-05-02 18:28:37]
  **Train** Prec@1 99.960 Prec@5 99.998 Error@1 0.040
  **Test** Prec@1 94.980 Prec@5 99.800 Error@1 5.020

==>>[2018-05-02 18:28:45] [Epoch=443/540] [Need: 00:49:49] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [443][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0158 (0.0158)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:28:45]
  Epoch: [443][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0038 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:28:56]
  Epoch: [443][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0048 (0.0052)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 18:29:07]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.000 Prec@5 99.840 Error@1 5.000

==>>[2018-05-02 18:29:16] [Epoch=444/540] [Need: 00:49:18] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [444][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0040 (0.0040)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:29:16]
  Epoch: [444][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0062 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:29:27]
  Epoch: [444][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0039 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:29:38]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.950 Prec@5 99.840 Error@1 5.050

==>>[2018-05-02 18:29:46] [Epoch=445/540] [Need: 00:48:47] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [445][000/500]   Time 0.078 (0.078)   Data 0.051 (0.051)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:29:46]
  Epoch: [445][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0046)   Prec@1 100.000 (99.980)   Prec@5 100.000 (100.000)   [2018-05-02 18:29:57]
  Epoch: [445][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0050)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-02 18:30:08]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 94.970 Prec@5 99.850 Error@1 5.030

==>>[2018-05-02 18:30:16] [Epoch=446/540] [Need: 00:48:16] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [446][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0190 (0.0190)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:30:16]
  Epoch: [446][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0036 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:30:27]
  Epoch: [446][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0059)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:30:38]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.930 Prec@5 99.870 Error@1 5.070

==>>[2018-05-02 18:30:46] [Epoch=447/540] [Need: 00:47:45] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [447][000/500]   Time 0.079 (0.079)   Data 0.054 (0.054)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:30:46]
  Epoch: [447][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0044 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:30:57]
  Epoch: [447][400/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0035 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:31:08]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.980 Prec@5 99.800 Error@1 5.020

==>>[2018-05-02 18:31:16] [Epoch=448/540] [Need: 00:47:14] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [448][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:31:16]
  Epoch: [448][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0037 (0.0054)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:31:27]
  Epoch: [448][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0043 (0.0057)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 18:31:38]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 95.000 Prec@5 99.840 Error@1 5.000

==>>[2018-05-02 18:31:46] [Epoch=449/540] [Need: 00:46:43] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [449][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:31:46]
  Epoch: [449][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0070 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:31:57]
  Epoch: [449][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0074 (0.0060)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 18:32:08]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.990 Prec@5 99.820 Error@1 5.010

==>>[2018-05-02 18:32:16] [Epoch=450/540] [Need: 00:46:12] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [450][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0056 (0.0056)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:32:16]
  Epoch: [450][200/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:32:27]
  Epoch: [450][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0068 (0.0058)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:32:39]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.950 Prec@5 99.840 Error@1 5.050

==>>[2018-05-02 18:32:47] [Epoch=451/540] [Need: 00:45:42] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [451][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:32:47]
  Epoch: [451][200/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0030 (0.0059)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:32:58]
  Epoch: [451][400/500]   Time 0.055 (0.055)   Data 0.000 (0.000)   Loss 0.0027 (0.0056)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:33:09]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 95.000 Prec@5 99.870 Error@1 5.000

==>>[2018-05-02 18:33:17] [Epoch=452/540] [Need: 00:45:11] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [452][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:33:17]
  Epoch: [452][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0037 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:33:28]
  Epoch: [452][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0037 (0.0053)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:33:40]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.930 Prec@5 99.870 Error@1 5.070

==>>[2018-05-02 18:33:48] [Epoch=453/540] [Need: 00:44:40] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [453][000/500]   Time 0.082 (0.082)   Data 0.053 (0.053)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:33:48]
  Epoch: [453][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0033 (0.0058)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:34:00]
  Epoch: [453][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0033 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:34:11]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.020 Prec@5 99.830 Error@1 4.980

==>>[2018-05-02 18:34:20] [Epoch=454/540] [Need: 00:44:09] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [454][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:34:20]
  Epoch: [454][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0036 (0.0053)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-02 18:34:31]
  Epoch: [454][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0033 (0.0054)   Prec@1 100.000 (99.968)   Prec@5 100.000 (100.000)   [2018-05-02 18:34:43]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 94.950 Prec@5 99.840 Error@1 5.050

==>>[2018-05-02 18:34:51] [Epoch=455/540] [Need: 00:43:39] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [455][000/500]   Time 0.085 (0.085)   Data 0.056 (0.056)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:34:51]
  Epoch: [455][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0040 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:35:03]
  Epoch: [455][400/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:35:14]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.920 Prec@5 99.840 Error@1 5.080

==>>[2018-05-02 18:35:23] [Epoch=456/540] [Need: 00:43:08] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [456][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:35:23]
  Epoch: [456][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0050 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:35:34]
  Epoch: [456][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0087 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:35:46]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.870 Prec@5 99.820 Error@1 5.130

==>>[2018-05-02 18:35:54] [Epoch=457/540] [Need: 00:42:37] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [457][000/500]   Time 0.084 (0.084)   Data 0.054 (0.054)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:35:55]
  Epoch: [457][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0065 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:36:06]
  Epoch: [457][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0127 (0.0062)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:36:18]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 94.960 Prec@5 99.860 Error@1 5.040

==>>[2018-05-02 18:36:26] [Epoch=458/540] [Need: 00:42:07] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [458][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0106 (0.0106)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:36:26]
  Epoch: [458][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0147 (0.0057)   Prec@1 99.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:36:38]
  Epoch: [458][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 18:36:49]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.960 Prec@5 99.870 Error@1 5.040

==>>[2018-05-02 18:36:57] [Epoch=459/540] [Need: 00:41:36] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [459][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:36:57]
  Epoch: [459][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0060)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 18:37:09]
  Epoch: [459][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0044 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:37:20]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.930 Prec@5 99.880 Error@1 5.070

==>>[2018-05-02 18:37:29] [Epoch=460/540] [Need: 00:41:05] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [460][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:37:29]
  Epoch: [460][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0033 (0.0058)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:37:40]
  Epoch: [460][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0058)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:37:52]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.980 Prec@5 99.810 Error@1 5.020

==>>[2018-05-02 18:38:00] [Epoch=461/540] [Need: 00:40:34] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [461][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:38:01]
  Epoch: [461][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0073 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:38:12]
  Epoch: [461][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0037 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:38:24]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.950 Prec@5 99.850 Error@1 5.050

==>>[2018-05-02 18:38:32] [Epoch=462/540] [Need: 00:40:04] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [462][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:38:32]
  Epoch: [462][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0062 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:38:44]
  Epoch: [462][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:38:55]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.920 Prec@5 99.860 Error@1 5.080

==>>[2018-05-02 18:39:03] [Epoch=463/540] [Need: 00:39:33] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [463][000/500]   Time 0.082 (0.082)   Data 0.054 (0.054)   Loss 0.0034 (0.0034)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:39:04]
  Epoch: [463][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0042 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:39:15]
  Epoch: [463][400/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0056)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:39:27]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.960 Prec@5 99.830 Error@1 5.040

==>>[2018-05-02 18:39:35] [Epoch=464/540] [Need: 00:39:02] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [464][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:39:35]
  Epoch: [464][200/500]   Time 0.055 (0.059)   Data 0.000 (0.000)   Loss 0.0307 (0.0053)   Prec@1 99.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-02 18:39:47]
  Epoch: [464][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0103 (0.0053)   Prec@1 99.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-02 18:39:58]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 95.040 Prec@5 99.820 Error@1 4.960

==>>[2018-05-02 18:40:06] [Epoch=465/540] [Need: 00:38:32] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [465][000/500]   Time 0.081 (0.081)   Data 0.053 (0.053)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:40:06]
  Epoch: [465][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:40:17]
  Epoch: [465][400/500]   Time 0.059 (0.055)   Data 0.000 (0.000)   Loss 0.0050 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:40:28]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.990 Prec@5 99.890 Error@1 5.010

==>>[2018-05-02 18:40:37] [Epoch=466/540] [Need: 00:38:01] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [466][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:40:37]
  Epoch: [466][200/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0052)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:40:48]
  Epoch: [466][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0072 (0.0056)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 18:41:00]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.900 Prec@5 99.830 Error@1 5.100

==>>[2018-05-02 18:41:09] [Epoch=467/540] [Need: 00:37:30] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [467][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:41:09]
  Epoch: [467][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0029 (0.0050)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:41:20]
  Epoch: [467][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0031 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:41:32]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.990 Prec@5 99.860 Error@1 5.010

==>>[2018-05-02 18:41:40] [Epoch=468/540] [Need: 00:36:59] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [468][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:41:40]
  Epoch: [468][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0061 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:41:51]
  Epoch: [468][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:42:03]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.920 Prec@5 99.840 Error@1 5.080

==>>[2018-05-02 18:42:11] [Epoch=469/540] [Need: 00:36:29] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [469][000/500]   Time 0.091 (0.091)   Data 0.062 (0.062)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:42:11]
  Epoch: [469][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:42:23]
  Epoch: [469][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0056)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:42:34]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.860 Prec@5 99.850 Error@1 5.140

==>>[2018-05-02 18:42:42] [Epoch=470/540] [Need: 00:35:58] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [470][000/500]   Time 0.087 (0.087)   Data 0.060 (0.060)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:42:43]
  Epoch: [470][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0051)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 18:42:54]
  Epoch: [470][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:43:05]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.960 Prec@5 99.890 Error@1 5.040

==>>[2018-05-02 18:43:13] [Epoch=471/540] [Need: 00:35:27] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [471][000/500]   Time 0.080 (0.080)   Data 0.055 (0.055)   Loss 0.0072 (0.0072)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:43:14]
  Epoch: [471][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0030 (0.0053)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 18:43:25]
  Epoch: [471][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0055)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 18:43:36]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.940 Prec@5 99.830 Error@1 5.060

==>>[2018-05-02 18:43:44] [Epoch=472/540] [Need: 00:34:56] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [472][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:43:44]
  Epoch: [472][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:43:56]
  Epoch: [472][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0052)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 18:44:07]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 94.990 Prec@5 99.860 Error@1 5.010

==>>[2018-05-02 18:44:16] [Epoch=473/540] [Need: 00:34:25] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [473][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0123 (0.0123)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:44:16]
  Epoch: [473][200/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0044 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:44:27]
  Epoch: [473][400/500]   Time 0.059 (0.056)   Data 0.000 (0.000)   Loss 0.0054 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:44:38]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 95.000 Prec@5 99.880 Error@1 5.000

==>>[2018-05-02 18:44:47] [Epoch=474/540] [Need: 00:33:55] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [474][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:44:47]
  Epoch: [474][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0045 (0.0052)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:44:58]
  Epoch: [474][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:45:09]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.960 Prec@5 99.880 Error@1 5.040

==>>[2018-05-02 18:45:17] [Epoch=475/540] [Need: 00:33:24] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [475][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0053 (0.0053)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:45:18]
  Epoch: [475][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:45:29]
  Epoch: [475][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0029 (0.0056)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 18:45:40]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.980 Prec@5 99.840 Error@1 5.020

==>>[2018-05-02 18:45:48] [Epoch=476/540] [Need: 00:32:53] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [476][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0282 (0.0282)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:45:48]
  Epoch: [476][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0057)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:46:00]
  Epoch: [476][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0032 (0.0056)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:46:11]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.960 Prec@5 99.840 Error@1 5.040

==>>[2018-05-02 18:46:19] [Epoch=477/540] [Need: 00:32:22] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [477][000/500]   Time 0.080 (0.080)   Data 0.053 (0.053)   Loss 0.0054 (0.0054)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:46:19]
  Epoch: [477][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:46:31]
  Epoch: [477][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0035 (0.0059)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-02 18:46:42]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 95.050 Prec@5 99.860 Error@1 4.950

==>>[2018-05-02 18:46:50] [Epoch=478/540] [Need: 00:31:51] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [478][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:46:50]
  Epoch: [478][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0051)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:47:01]
  Epoch: [478][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 18:47:13]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.980 Prec@5 99.890 Error@1 5.020

==>>[2018-05-02 18:47:21] [Epoch=479/540] [Need: 00:31:20] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [479][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:47:21]
  Epoch: [479][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0047 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:47:32]
  Epoch: [479][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0143 (0.0056)   Prec@1 99.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:47:44]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.950 Prec@5 99.840 Error@1 5.050

==>>[2018-05-02 18:47:52] [Epoch=480/540] [Need: 00:30:50] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [480][000/500]   Time 0.087 (0.087)   Data 0.058 (0.058)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:47:52]
  Epoch: [480][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0079 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:48:03]
  Epoch: [480][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0059 (0.0055)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:48:14]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 95.030 Prec@5 99.860 Error@1 4.970

==>>[2018-05-02 18:48:23] [Epoch=481/540] [Need: 00:30:19] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [481][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:48:23]
  Epoch: [481][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0120 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:48:34]
  Epoch: [481][400/500]   Time 0.058 (0.056)   Data 0.000 (0.000)   Loss 0.0049 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:48:45]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.950 Prec@5 99.850 Error@1 5.050

==>>[2018-05-02 18:48:54] [Epoch=482/540] [Need: 00:29:48] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [482][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:48:54]
  Epoch: [482][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0072 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:49:05]
  Epoch: [482][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:49:17]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.940 Prec@5 99.840 Error@1 5.060

==>>[2018-05-02 18:49:25] [Epoch=483/540] [Need: 00:29:17] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [483][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0178 (0.0178)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:49:25]
  Epoch: [483][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0052 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:49:36]
  Epoch: [483][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:49:47]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.910 Prec@5 99.840 Error@1 5.090

==>>[2018-05-02 18:49:56] [Epoch=484/540] [Need: 00:28:46] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [484][000/500]   Time 0.084 (0.084)   Data 0.057 (0.057)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:49:56]
  Epoch: [484][200/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0037 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:50:07]
  Epoch: [484][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:50:18]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.990 Prec@5 99.860 Error@1 5.010

==>>[2018-05-02 18:50:27] [Epoch=485/540] [Need: 00:28:16] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [485][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:50:27]
  Epoch: [485][200/500]   Time 0.060 (0.056)   Data 0.000 (0.000)   Loss 0.0063 (0.0050)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 18:50:38]
  Epoch: [485][400/500]   Time 0.056 (0.056)   Data 0.000 (0.000)   Loss 0.0038 (0.0052)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-02 18:50:49]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.940 Prec@5 99.850 Error@1 5.060

==>>[2018-05-02 18:50:58] [Epoch=486/540] [Need: 00:27:45] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [486][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:50:58]
  Epoch: [486][200/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0038 (0.0058)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:51:09]
  Epoch: [486][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0063 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:51:20]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.960 Prec@5 99.820 Error@1 5.040

==>>[2018-05-02 18:51:29] [Epoch=487/540] [Need: 00:27:14] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [487][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:51:29]
  Epoch: [487][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:51:41]
  Epoch: [487][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0043 (0.0055)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:51:52]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.970 Prec@5 99.890 Error@1 5.030

==>>[2018-05-02 18:52:01] [Epoch=488/540] [Need: 00:26:43] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [488][000/500]   Time 0.082 (0.082)   Data 0.057 (0.057)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:52:01]
  Epoch: [488][200/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0040 (0.0057)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 18:52:12]
  Epoch: [488][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0029 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:52:24]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.960 Prec@5 99.830 Error@1 5.040

==>>[2018-05-02 18:52:33] [Epoch=489/540] [Need: 00:26:12] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [489][000/500]   Time 0.091 (0.091)   Data 0.060 (0.060)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:52:33]
  Epoch: [489][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0239 (0.0054)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:52:45]
  Epoch: [489][400/500]   Time 0.055 (0.058)   Data 0.000 (0.000)   Loss 0.0328 (0.0054)   Prec@1 99.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 18:52:56]
  **Train** Prec@1 99.932 Prec@5 100.000 Error@1 0.068
  **Test** Prec@1 94.990 Prec@5 99.880 Error@1 5.010

==>>[2018-05-02 18:53:04] [Epoch=490/540] [Need: 00:25:42] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [490][000/500]   Time 0.079 (0.079)   Data 0.053 (0.053)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:53:04]
  Epoch: [490][200/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0039 (0.0059)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:53:16]
  Epoch: [490][400/500]   Time 0.054 (0.056)   Data 0.000 (0.000)   Loss 0.0027 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:53:27]
  **Train** Prec@1 99.944 Prec@5 100.000 Error@1 0.056
  **Test** Prec@1 94.910 Prec@5 99.860 Error@1 5.090

==>>[2018-05-02 18:53:35] [Epoch=491/540] [Need: 00:25:11] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [491][000/500]   Time 0.080 (0.080)   Data 0.054 (0.054)   Loss 0.0104 (0.0104)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:53:35]
  Epoch: [491][200/500]   Time 0.054 (0.055)   Data 0.000 (0.000)   Loss 0.0061 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:53:46]
  Epoch: [491][400/500]   Time 0.057 (0.056)   Data 0.000 (0.000)   Loss 0.0027 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:53:57]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 94.880 Prec@5 99.860 Error@1 5.120

==>>[2018-05-02 18:54:06] [Epoch=492/540] [Need: 00:24:40] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [492][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:54:06]
  Epoch: [492][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0036 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:54:17]
  Epoch: [492][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0076 (0.0060)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 18:54:29]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.950 Prec@5 99.880 Error@1 5.050

==>>[2018-05-02 18:54:37] [Epoch=493/540] [Need: 00:24:09] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [493][000/500]   Time 0.077 (0.077)   Data 0.051 (0.051)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:54:37]
  Epoch: [493][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:54:49]
  Epoch: [493][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0046 (0.0058)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 18:55:00]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.900 Prec@5 99.840 Error@1 5.100

==>>[2018-05-02 18:55:08] [Epoch=494/540] [Need: 00:23:38] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [494][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:55:08]
  Epoch: [494][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0053 (0.0052)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:55:20]
  Epoch: [494][400/500]   Time 0.061 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0054)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:55:31]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.970 Prec@5 99.860 Error@1 5.030

==>>[2018-05-02 18:55:40] [Epoch=495/540] [Need: 00:23:08] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [495][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:55:40]
  Epoch: [495][200/500]   Time 0.061 (0.058)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 18:55:51]
  Epoch: [495][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0057 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:56:03]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.980 Prec@5 99.870 Error@1 5.020

==>>[2018-05-02 18:56:12] [Epoch=496/540] [Need: 00:22:37] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [496][000/500]   Time 0.088 (0.088)   Data 0.060 (0.060)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:56:12]
  Epoch: [496][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0072 (0.0052)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 18:56:24]
  Epoch: [496][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0050 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 18:56:36]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.960 Prec@5 99.810 Error@1 5.040

==>>[2018-05-02 18:56:44] [Epoch=497/540] [Need: 00:22:06] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [497][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:56:44]
  Epoch: [497][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 18:56:56]
  Epoch: [497][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0062 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:57:08]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.920 Prec@5 99.840 Error@1 5.080

==>>[2018-05-02 18:57:17] [Epoch=498/540] [Need: 00:21:35] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [498][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:57:17]
  Epoch: [498][200/500]   Time 0.058 (0.060)   Data 0.000 (0.000)   Loss 0.0033 (0.0051)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 18:57:29]
  Epoch: [498][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0038 (0.0053)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 18:57:41]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.950 Prec@5 99.860 Error@1 5.050

==>>[2018-05-02 18:57:49] [Epoch=499/540] [Need: 00:21:05] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [499][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:57:50]
  Epoch: [499][200/500]   Time 0.061 (0.059)   Data 0.000 (0.000)   Loss 0.0032 (0.0060)   Prec@1 100.000 (99.905)   Prec@5 100.000 (100.000)   [2018-05-02 18:58:01]
  Epoch: [499][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0048 (0.0060)   Prec@1 100.000 (99.908)   Prec@5 100.000 (100.000)   [2018-05-02 18:58:13]
  **Train** Prec@1 99.908 Prec@5 100.000 Error@1 0.092
  **Test** Prec@1 94.940 Prec@5 99.880 Error@1 5.060

==>>[2018-05-02 18:58:22] [Epoch=500/540] [Need: 00:20:34] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [500][000/500]   Time 0.083 (0.083)   Data 0.057 (0.057)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:58:22]
  Epoch: [500][200/500]   Time 0.060 (0.058)   Data 0.000 (0.000)   Loss 0.0144 (0.0051)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:58:34]
  Epoch: [500][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0126 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:58:45]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.920 Prec@5 99.880 Error@1 5.080

==>>[2018-05-02 18:58:54] [Epoch=501/540] [Need: 00:20:03] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [501][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:58:54]
  Epoch: [501][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0048 (0.0051)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:59:06]
  Epoch: [501][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0034 (0.0055)   Prec@1 100.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 18:59:18]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.050 Prec@5 99.880 Error@1 4.950

==>>[2018-05-02 18:59:27] [Epoch=502/540] [Need: 00:19:32] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [502][000/500]   Time 0.083 (0.083)   Data 0.054 (0.054)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:59:27]
  Epoch: [502][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.0055 (0.0055)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 18:59:39]
  Epoch: [502][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0034 (0.0056)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 18:59:50]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.990 Prec@5 99.820 Error@1 5.010

==>>[2018-05-02 18:59:59] [Epoch=503/540] [Need: 00:19:02] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [503][000/500]   Time 0.091 (0.091)   Data 0.060 (0.060)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 18:59:59]
  Epoch: [503][200/500]   Time 0.060 (0.060)   Data 0.000 (0.001)   Loss 0.0030 (0.0057)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:00:11]
  Epoch: [503][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.0070 (0.0056)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 19:00:23]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.960 Prec@5 99.840 Error@1 5.040

==>>[2018-05-02 19:00:32] [Epoch=504/540] [Need: 00:18:31] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [504][000/500]   Time 0.091 (0.091)   Data 0.063 (0.063)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:00:32]
  Epoch: [504][200/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0031 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 19:00:44]
  Epoch: [504][400/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0039 (0.0057)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-02 19:00:55]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 95.020 Prec@5 99.860 Error@1 4.980

==>>[2018-05-02 19:01:04] [Epoch=505/540] [Need: 00:18:00] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [505][000/500]   Time 0.081 (0.081)   Data 0.054 (0.054)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:01:04]
  Epoch: [505][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0343 (0.0055)   Prec@1 99.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 19:01:15]
  Epoch: [505][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0035 (0.0057)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:01:27]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.900 Prec@5 99.860 Error@1 5.100

==>>[2018-05-02 19:01:35] [Epoch=506/540] [Need: 00:17:29] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [506][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0044 (0.0044)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:01:35]
  Epoch: [506][200/500]   Time 0.056 (0.058)   Data 0.000 (0.000)   Loss 0.0027 (0.0064)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 19:01:47]
  Epoch: [506][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0041 (0.0059)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2018-05-02 19:01:58]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 94.910 Prec@5 99.860 Error@1 5.090

==>>[2018-05-02 19:02:06] [Epoch=507/540] [Need: 00:16:58] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [507][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0057 (0.0057)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:02:06]
  Epoch: [507][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0030 (0.0052)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:02:18]
  Epoch: [507][400/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0028 (0.0052)   Prec@1 100.000 (99.963)   Prec@5 100.000 (100.000)   [2018-05-02 19:02:29]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 95.000 Prec@5 99.840 Error@1 5.000

==>>[2018-05-02 19:02:38] [Epoch=508/540] [Need: 00:16:28] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [508][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:02:38]
  Epoch: [508][200/500]   Time 0.058 (0.058)   Data 0.000 (0.000)   Loss 0.0031 (0.0054)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 19:02:49]
  Epoch: [508][400/500]   Time 0.063 (0.058)   Data 0.000 (0.000)   Loss 0.0054 (0.0060)   Prec@1 100.000 (99.923)   Prec@5 100.000 (100.000)   [2018-05-02 19:03:01]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.920 Prec@5 99.820 Error@1 5.080

==>>[2018-05-02 19:03:09] [Epoch=509/540] [Need: 00:15:57] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [509][000/500]   Time 0.083 (0.083)   Data 0.055 (0.055)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:03:10]
  Epoch: [509][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0033 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 19:03:21]
  Epoch: [509][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0032 (0.0059)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 19:03:32]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.940 Prec@5 99.840 Error@1 5.060

==>>[2018-05-02 19:03:41] [Epoch=510/540] [Need: 00:15:26] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [510][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:03:41]
  Epoch: [510][200/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0038 (0.0060)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 19:03:52]
  Epoch: [510][400/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0044 (0.0059)   Prec@1 100.000 (99.928)   Prec@5 100.000 (100.000)   [2018-05-02 19:04:04]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.940 Prec@5 99.840 Error@1 5.060

==>>[2018-05-02 19:04:13] [Epoch=511/540] [Need: 00:14:55] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [511][000/500]   Time 0.084 (0.084)   Data 0.058 (0.058)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:04:13]
  Epoch: [511][200/500]   Time 0.059 (0.060)   Data 0.000 (0.001)   Loss 0.0046 (0.0056)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 19:04:25]
  Epoch: [511][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.0099 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:04:37]
  **Train** Prec@1 99.934 Prec@5 100.000 Error@1 0.066
  **Test** Prec@1 94.990 Prec@5 99.860 Error@1 5.010

==>>[2018-05-02 19:04:46] [Epoch=512/540] [Need: 00:14:24] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [512][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:04:46]
  Epoch: [512][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0036 (0.0054)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:04:58]
  Epoch: [512][400/500]   Time 0.054 (0.059)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 19:05:09]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 95.070 Prec@5 99.880 Error@1 4.930

==>>[2018-05-02 19:05:18] [Epoch=513/540] [Need: 00:13:54] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [513][000/500]   Time 0.091 (0.091)   Data 0.061 (0.061)   Loss 0.0032 (0.0032)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:05:18]
  Epoch: [513][200/500]   Time 0.060 (0.059)   Data 0.000 (0.001)   Loss 0.0049 (0.0052)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 19:05:30]
  Epoch: [513][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0035 (0.0054)   Prec@1 100.000 (99.943)   Prec@5 100.000 (100.000)   [2018-05-02 19:05:42]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.970 Prec@5 99.880 Error@1 5.030

==>>[2018-05-02 19:05:51] [Epoch=514/540] [Need: 00:13:23] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [514][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.0046 (0.0046)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:05:51]
  Epoch: [514][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0149 (0.0051)   Prec@1 99.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 19:06:03]
  Epoch: [514][400/500]   Time 0.062 (0.060)   Data 0.000 (0.000)   Loss 0.0047 (0.0054)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 19:06:15]
  **Train** Prec@1 99.950 Prec@5 100.000 Error@1 0.050
  **Test** Prec@1 94.900 Prec@5 99.840 Error@1 5.100

==>>[2018-05-02 19:06:24] [Epoch=515/540] [Need: 00:12:52] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [515][000/500]   Time 0.086 (0.086)   Data 0.058 (0.058)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:06:24]
  Epoch: [515][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.0034 (0.0050)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 19:06:36]
  Epoch: [515][400/500]   Time 0.057 (0.059)   Data 0.000 (0.000)   Loss 0.0058 (0.0052)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 19:06:47]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 94.900 Prec@5 99.840 Error@1 5.100

==>>[2018-05-02 19:06:56] [Epoch=516/540] [Need: 00:12:21] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [516][000/500]   Time 0.084 (0.084)   Data 0.056 (0.056)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:06:56]
  Epoch: [516][200/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0036 (0.0056)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 19:07:07]
  Epoch: [516][400/500]   Time 0.055 (0.056)   Data 0.000 (0.000)   Loss 0.0042 (0.0059)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 19:07:18]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 95.040 Prec@5 99.880 Error@1 4.960

==>>[2018-05-02 19:07:27] [Epoch=517/540] [Need: 00:11:50] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [517][000/500]   Time 0.083 (0.083)   Data 0.054 (0.054)   Loss 0.0139 (0.0139)   Prec@1 99.000 (99.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:07:27]
  Epoch: [517][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0041 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 19:07:39]
  Epoch: [517][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0029 (0.0053)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 19:07:51]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 95.010 Prec@5 99.880 Error@1 4.990

==>>[2018-05-02 19:07:59] [Epoch=518/540] [Need: 00:11:19] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [518][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0109 (0.0109)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:07:59]
  Epoch: [518][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0037 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:08:11]
  Epoch: [518][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0030 (0.0055)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 19:08:23]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.940 Prec@5 99.820 Error@1 5.060

==>>[2018-05-02 19:08:32] [Epoch=519/540] [Need: 00:10:49] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [519][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:08:32]
  Epoch: [519][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0025 (0.0061)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 19:08:44]
  Epoch: [519][400/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0046 (0.0059)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 19:08:55]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 94.970 Prec@5 99.830 Error@1 5.030

==>>[2018-05-02 19:09:04] [Epoch=520/540] [Need: 00:10:18] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [520][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:09:04]
  Epoch: [520][200/500]   Time 0.059 (0.058)   Data 0.000 (0.000)   Loss 0.0033 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:09:15]
  Epoch: [520][400/500]   Time 0.062 (0.059)   Data 0.000 (0.000)   Loss 0.0036 (0.0055)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 19:09:27]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 94.930 Prec@5 99.830 Error@1 5.070

==>>[2018-05-02 19:09:36] [Epoch=521/540] [Need: 00:09:47] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [521][000/500]   Time 0.085 (0.085)   Data 0.057 (0.057)   Loss 0.0042 (0.0042)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:09:36]
  Epoch: [521][200/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0027 (0.0051)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:09:48]
  Epoch: [521][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0048 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:10:00]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.940 Prec@5 99.900 Error@1 5.060

==>>[2018-05-02 19:10:08] [Epoch=522/540] [Need: 00:09:16] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [522][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:10:08]
  Epoch: [522][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0034 (0.0057)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 19:10:19]
  Epoch: [522][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 19:10:31]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 94.930 Prec@5 99.800 Error@1 5.070

==>>[2018-05-02 19:10:39] [Epoch=523/540] [Need: 00:08:45] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [523][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:10:39]
  Epoch: [523][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2018-05-02 19:10:51]
  Epoch: [523][400/500]   Time 0.054 (0.057)   Data 0.000 (0.000)   Loss 0.0029 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:11:02]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.010 Prec@5 99.830 Error@1 4.990

==>>[2018-05-02 19:11:11] [Epoch=524/540] [Need: 00:08:14] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [524][000/500]   Time 0.085 (0.085)   Data 0.059 (0.059)   Loss 0.0041 (0.0041)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:11:11]
  Epoch: [524][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0042 (0.0054)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:11:23]
  Epoch: [524][400/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.0030 (0.0053)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 19:11:35]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 95.010 Prec@5 99.860 Error@1 4.990

==>>[2018-05-02 19:11:44] [Epoch=525/540] [Need: 00:07:43] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [525][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:11:44]
  Epoch: [525][200/500]   Time 0.067 (0.060)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.955)   Prec@5 100.000 (100.000)   [2018-05-02 19:11:56]
  Epoch: [525][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0033 (0.0054)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 19:12:08]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.940 Prec@5 99.840 Error@1 5.060

==>>[2018-05-02 19:12:17] [Epoch=526/540] [Need: 00:07:12] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [526][000/500]   Time 0.085 (0.085)   Data 0.058 (0.058)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:12:17]
  Epoch: [526][200/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0060 (0.0050)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 19:12:29]
  Epoch: [526][400/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.0055 (0.0052)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2018-05-02 19:12:41]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 94.970 Prec@5 99.870 Error@1 5.030

==>>[2018-05-02 19:12:49] [Epoch=527/540] [Need: 00:06:42] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [527][000/500]   Time 0.082 (0.082)   Data 0.056 (0.056)   Loss 0.0029 (0.0029)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:12:49]
  Epoch: [527][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.970)   Prec@5 100.000 (100.000)   [2018-05-02 19:13:01]
  Epoch: [527][400/500]   Time 0.057 (0.058)   Data 0.000 (0.000)   Loss 0.0050 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:13:12]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.970 Prec@5 99.870 Error@1 5.030

==>>[2018-05-02 19:13:21] [Epoch=528/540] [Need: 00:06:11] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [528][000/500]   Time 0.086 (0.086)   Data 0.059 (0.059)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:13:21]
  Epoch: [528][200/500]   Time 0.060 (0.060)   Data 0.000 (0.001)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 19:13:33]
  Epoch: [528][400/500]   Time 0.055 (0.060)   Data 0.000 (0.000)   Loss 0.0044 (0.0051)   Prec@1 100.000 (99.960)   Prec@5 100.000 (100.000)   [2018-05-02 19:13:45]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 95.040 Prec@5 99.840 Error@1 4.960

==>>[2018-05-02 19:13:54] [Epoch=529/540] [Need: 00:05:40] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [529][000/500]   Time 0.083 (0.083)   Data 0.056 (0.056)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:13:54]
  Epoch: [529][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0081 (0.0056)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 19:14:06]
  Epoch: [529][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0133 (0.0055)   Prec@1 99.000 (99.933)   Prec@5 100.000 (100.000)   [2018-05-02 19:14:17]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 94.950 Prec@5 99.840 Error@1 5.050

==>>[2018-05-02 19:14:26] [Epoch=530/540] [Need: 00:05:09] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [530][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0031 (0.0031)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:14:26]
  Epoch: [530][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0031 (0.0062)   Prec@1 100.000 (99.900)   Prec@5 100.000 (100.000)   [2018-05-02 19:14:37]
  Epoch: [530][400/500]   Time 0.058 (0.057)   Data 0.000 (0.000)   Loss 0.0051 (0.0058)   Prec@1 100.000 (99.920)   Prec@5 100.000 (100.000)   [2018-05-02 19:14:49]
  **Train** Prec@1 99.926 Prec@5 100.000 Error@1 0.074
  **Test** Prec@1 94.960 Prec@5 99.830 Error@1 5.040

==>>[2018-05-02 19:14:57] [Epoch=531/540] [Need: 00:04:38] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [531][000/500]   Time 0.092 (0.092)   Data 0.066 (0.066)   Loss 0.0037 (0.0037)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:14:57]
  Epoch: [531][200/500]   Time 0.056 (0.057)   Data 0.000 (0.001)   Loss 0.0059 (0.0055)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:15:09]
  Epoch: [531][400/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0043 (0.0054)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 19:15:20]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.990 Prec@5 99.870 Error@1 5.010

==>>[2018-05-02 19:15:29] [Epoch=532/540] [Need: 00:04:07] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [532][000/500]   Time 0.081 (0.081)   Data 0.055 (0.055)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:15:29]
  Epoch: [532][200/500]   Time 0.059 (0.057)   Data 0.000 (0.000)   Loss 0.0044 (0.0065)   Prec@1 100.000 (99.915)   Prec@5 100.000 (100.000)   [2018-05-02 19:15:40]
  Epoch: [532][400/500]   Time 0.055 (0.057)   Data 0.000 (0.000)   Loss 0.0062 (0.0064)   Prec@1 100.000 (99.918)   Prec@5 100.000 (100.000)   [2018-05-02 19:15:51]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 95.010 Prec@5 99.860 Error@1 4.990

==>>[2018-05-02 19:16:00] [Epoch=533/540] [Need: 00:03:36] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [533][000/500]   Time 0.082 (0.082)   Data 0.055 (0.055)   Loss 0.0036 (0.0036)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:16:00]
  Epoch: [533][200/500]   Time 0.056 (0.057)   Data 0.000 (0.000)   Loss 0.0039 (0.0054)   Prec@1 100.000 (99.945)   Prec@5 100.000 (100.000)   [2018-05-02 19:16:11]
  Epoch: [533][400/500]   Time 0.057 (0.057)   Data 0.000 (0.000)   Loss 0.0052 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:16:23]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.990 Prec@5 99.860 Error@1 5.010

==>>[2018-05-02 19:16:31] [Epoch=534/540] [Need: 00:03:05] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [534][000/500]   Time 0.080 (0.080)   Data 0.052 (0.052)   Loss 0.0049 (0.0049)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:16:31]
  Epoch: [534][200/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0033 (0.0053)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 19:16:43]
  Epoch: [534][400/500]   Time 0.059 (0.059)   Data 0.000 (0.000)   Loss 0.0045 (0.0056)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:16:55]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 94.990 Prec@5 99.870 Error@1 5.010

==>>[2018-05-02 19:17:04] [Epoch=535/540] [Need: 00:02:34] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [535][000/500]   Time 0.086 (0.086)   Data 0.056 (0.056)   Loss 0.0048 (0.0048)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:17:04]
  Epoch: [535][200/500]   Time 0.059 (0.060)   Data 0.000 (0.000)   Loss 0.0040 (0.0059)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2018-05-02 19:17:16]
  Epoch: [535][400/500]   Time 0.058 (0.059)   Data 0.000 (0.000)   Loss 0.0031 (0.0055)   Prec@1 100.000 (99.940)   Prec@5 100.000 (100.000)   [2018-05-02 19:17:27]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 94.990 Prec@5 99.830 Error@1 5.010

==>>[2018-05-02 19:17:36] [Epoch=536/540] [Need: 00:02:03] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [536][000/500]   Time 0.095 (0.095)   Data 0.067 (0.067)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:17:36]
  Epoch: [536][200/500]   Time 0.059 (0.060)   Data 0.000 (0.001)   Loss 0.0032 (0.0053)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:17:48]
  Epoch: [536][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0031 (0.0052)   Prec@1 100.000 (99.958)   Prec@5 100.000 (100.000)   [2018-05-02 19:18:00]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 95.030 Prec@5 99.880 Error@1 4.970

==>>[2018-05-02 19:18:09] [Epoch=537/540] [Need: 00:01:32] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [537][000/500]   Time 0.084 (0.084)   Data 0.055 (0.055)   Loss 0.0033 (0.0033)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:18:09]
  Epoch: [537][200/500]   Time 0.060 (0.059)   Data 0.000 (0.000)   Loss 0.0041 (0.0060)   Prec@1 100.000 (99.925)   Prec@5 100.000 (100.000)   [2018-05-02 19:18:21]
  Epoch: [537][400/500]   Time 0.060 (0.060)   Data 0.000 (0.000)   Loss 0.0032 (0.0059)   Prec@1 100.000 (99.935)   Prec@5 100.000 (100.000)   [2018-05-02 19:18:33]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 95.010 Prec@5 99.870 Error@1 4.990

==>>[2018-05-02 19:18:42] [Epoch=538/540] [Need: 00:01:01] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [538][000/500]   Time 0.086 (0.086)   Data 0.057 (0.057)   Loss 0.0043 (0.0043)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:18:42]
  Epoch: [538][200/500]   Time 0.061 (0.060)   Data 0.000 (0.000)   Loss 0.0028 (0.0057)   Prec@1 100.000 (99.945)   Prec@5 100.000 (99.995)   [2018-05-02 19:18:54]
  Epoch: [538][400/500]   Time 0.062 (0.060)   Data 0.000 (0.000)   Loss 0.0033 (0.0056)   Prec@1 100.000 (99.943)   Prec@5 100.000 (99.998)   [2018-05-02 19:19:06]
  **Train** Prec@1 99.946 Prec@5 99.998 Error@1 0.054
  **Test** Prec@1 94.920 Prec@5 99.870 Error@1 5.080

==>>[2018-05-02 19:19:15] [Epoch=539/540] [Need: 00:00:30] [learning_rate=0.000001] [Best : Accuracy=95.13, Error=4.87]
  Epoch: [539][000/500]   Time 0.090 (0.090)   Data 0.061 (0.061)   Loss 0.0110 (0.0110)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2018-05-02 19:19:15]
  Epoch: [539][200/500]   Time 0.059 (0.060)   Data 0.000 (0.001)   Loss 0.0034 (0.0056)   Prec@1 100.000 (99.950)   Prec@5 100.000 (100.000)   [2018-05-02 19:19:27]
  Epoch: [539][400/500]   Time 0.055 (0.060)   Data 0.000 (0.000)   Loss 0.0043 (0.0055)   Prec@1 100.000 (99.948)   Prec@5 100.000 (100.000)   [2018-05-02 19:19:39]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 94.910 Prec@5 99.880 Error@1 5.090
